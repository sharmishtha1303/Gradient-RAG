Dive into Deep Learning ASTONZHANG, ZACHARYC.
LIPTON, MULI, ANDALEXANDERJ.
SMOLA Contents Preface pagexxv Installation xxxiv Notation xxxvii 1 Introduction 1 2 Preliminaries 30 iii 3 Linear Neural Networksfor Regression 82 iv 4 Linear Neural Networksfor Classification 125 v 4.7.5 Fairness, Accountability, and Transparency in Machine Learning 164 vi 5 Multilayer Perceptrons 167 5.7.6 ğ¾-Fold Cross-Validation 204 vii 6 Buildersâ€™Guide 207 7 Convolutional Neural Networks 233 viii 7.4.3 1 1Convolutional Layer 255 8 Modern Convolutional Neural Networks 268 ix x 9 Recurrent Neural Networks 325 xi 10Modern Recurrent Neural Networks 369 xii 11Attention Mechanismsand Transformers 409 xiii 12Optimization Algorithms 468 xiv 12.10Adam 532 xv 12.11Learning Rate Scheduling 536 13Computational Performance 547 xvi 14Computer Vision 592 xvii 14.10Transposed Convolution 654 14.11Fully Convolutional Networks 659 14.12Neural Style Transfer 666 xviii 14.13Image Classification(CIFAR-10)on Kaggle 674 14.14Dog Breed Identification(Image Net Dogs)on Kaggle 682 15Natural Language Processing: Pretraining 690 xix 15.5.3 Interpreting Glo Ve from the Ratio of Co-occurrence Probabilities 713 15.10Pretraining BERT 739 16Natural Language Processing: Applications 744 xx 17Reinforcement Learning 781 xxi 18Gaussian Processes 797 18.3.2 Equations for Making Predictions and Learning Kernel Hyperparametersin GPRegression 817 xxii 19Hyperparameter Optimization 828 19.2.5 Example: Optimizingthe Hyperparametersofa Convolu- tional Neural Network 839 20Generative Adversarial Networks 880 xxiii xxiv Contents 21Recommender Systems 893 Appendix A Mathematicsfor Deep Learning 897 Appendix B Toolsfor Deep Learning 1035 References 1089 Preface Justafewyearsago, therewerenolegionsofdeeplearningscientistsdevelopingintelli- gent products and services at major companies and startups.
When we entered the field, machinelearningdidnotcommandheadlinesindailynewspapers.
Ourparentshadnoidea whatmachinelearningwas, letalonewhywemightpreferittoacareerinmedicineorlaw.
Machinelearningwasablueskiesacademicdisciplinewhoseindustrialsignificancewas limitedtoanarrowsetofreal-worldapplications, includingspeechrecognitionandcom- putervision.
Moreover, manyoftheseapplicationsrequiredsomuchdomainknowledge that they were often regarded as entirely separate areas for which machine learning was onesmallcomponent.
Atthattime, neuralnetworksâ€”thepredecessorsofthedeeplearn- ingmethodsthatwefocusoninthisbookâ€”weregenerallyregardedasoutmoded.
Yetinjustfewyears, deeplearninghastakentheworldbysurprise, drivingrapidprogress in such diverse fields as computer vision, natural language processing, automatic speech recognition, reinforcement learning, and biomedical informatics.
Moreover, the success ofdeeplearninginsomanytasksofpracticalinteresthasevencatalyzeddevelopmentsin theoreticalmachinelearningandstatistics.
Withtheseadvancesinhand, wecannowbuild cars that drive themselves with more autonomy than ever before (though less autonomy thansomecompaniesmighthaveyoubelieve), dialoguesystemsthatdebugcodebyasking clarifying questions, and software agents beating the best human players in the world at boardgamessuchas Go, afeatoncethoughttobedecadesaway.
Already, thesetoolsexert ever-widerinfluenceonindustryandsociety, changingthewaymoviesaremade, diseases arediagnosed, andplayingagrowingroleinbasicsciencesâ€”fromastrophysics, toclimate modeling, toweatherprediction, tobiomedicine.
About This Book This book represents our attempt to make deep learning approachable, teaching you the concepts, thecontext, andthecode.
One Medium Combining Code, Math, and HTML For any computing technology to reach its full impact, it must be well understood, well documented, and supported by mature, well-maintained tools.
The key ideas should be clearlydistilled, minimizingtheonboardingtimeneededtobringnewpractitionersupto xxv xxvi Preface date.
Mature libraries should automate common tasks, and exemplar code should make it easy for practitioners to modify, apply, and extend common applications to suit their needs.
As an example, take dynamic web applications.
Despite a large number of companies, suchas Amazon, developingsuccessfuldatabase-drivenwebapplicationsinthe1990s, the potentialofthistechnologytoaidcreativeentrepreneurswasrealizedtoafargreaterdegree onlyinthepasttenyears, owinginparttothedevelopmentofpowerful, well-documented frameworks.
Testingthepotentialofdeeplearningpresentsuniquechallengesbecauseanysingleappli- cationbringstogethervariousdisciplines.
Applyingdeeplearningrequiressimultaneously understanding(i)themotivationsforcastingaprobleminaparticularway;(ii)themath- ematicalformofagivenmodel;(iii)theoptimizationalgorithmsforfittingthemodelsto data;(iv)thestatisticalprinciplesthattelluswhenweshouldexpectourmodelstogeneral- izetounseendataandpracticalmethodsforcertifyingthattheyhave, infact, generalized; and(v)theengineeringtechniquesrequiredtotrainmodelsefficiently, navigatingthepit- fallsofnumericalcomputingandgettingthemostoutofavailablehardware.
Teachingthe criticalthinkingskillsrequiredtoformulateproblems, themathematicstosolvethem, and thesoftwaretoolstoimplementthosesolutionsallinoneplacepresentsformidablechal- lenges.
Ourgoalinthisbookistopresentaunifiedresourcetobringwould-bepractitioners uptospeed.
Whenwestartedthisbookproject, therewerenoresourcesthatsimultaneously(i)remained up to date; (ii) covered the breadth of modern machine learning practices with sufficient technical depth; and (iii) interleaved exposition of the quality one expects of a textbook withthecleanrunnablecodethatoneexpectsofahands-ontutorial.
Wefoundplentyof code examples illustrating how to use a given deep learning framework (e.
g., how to do basic numerical computing with matrices in Tensor Flow) or for implementing particular techniques(e.
g., codesnippetsfor Le Net, Alex Net, Res Net, etc.) scatteredacrossvarious blogpostsand Git Hubrepositories.
However, theseexamplestypicallyfocusedonhowto implement a given approach, but left out the discussion of why certain algorithmic deci- sionsaremade.
Whilesomeinteractiveresourceshavepoppedupsporadicallytoaddressa particulartopic, e.
g., theengagingblogpostspublishedonthewebsite Distill1, orpersonal 1 blogs, theyonlycoveredselectedtopicsindeeplearning, andoftenlackedassociatedcode.
Ontheotherhand, whileseveraldeeplearningtextbookshaveemergedâ€”e.
g., Goodfellow etal.
(2016), whichoffersacomprehensivesurveyonthebasicsofdeeplearningâ€”these resourcesdonotmarrythedescriptionstorealizationsoftheconceptsincode, sometimes leavingreaderscluelessastohowtoimplementthem.
Moreover, toomanyresourcesare hiddenbehindthepaywallsofcommercialcourseproviders.
Wesetouttocreatearesourcethatcould(i)befreelyavailableforeveryone;(ii)offersuffi- cienttechnicaldepthtoprovideastartingpointonthepathtoactuallybecominganapplied machinelearningscientist;(iii)includerunnablecode, showingreadershowtosolveprob- lemsinpractice;(iv)allowforrapidupdates, bothbyusandalsobythecommunityatlarge; 2 and(v)becomplementedbyaforum2 forinteractivediscussionoftechnicaldetailsandto answerquestions.
xxvii Preface Thesegoalswereofteninconflict.
Equations, theorems, andcitationsarebestmanagedand laidoutin La Te X.
Codeisbestdescribedin Python.
Andwebpagesarenativein HTML and Java Script.
Furthermore, wewantthecontenttobeaccessiblebothasexecutablecode, asaphysicalbook, asadownloadable PDF, andonthe Internetasawebsite.
Noworkflows seemed suited to these demands, so we decided to assemble our own (Section B.6).
We settled on Git Hub to share the source and to facilitate community contributions; Jupyter notebooksformixingcode, equationsandtext; Sphinxasarenderingengine; and Discourse asadiscussionplatform.
Whileoursystemisnotperfect, thesechoicesstrikeacompromise amongthecompetingconcerns.
Webelievethat Diveinto Deep Learningmightbethefirst bookpublishedusingsuchanintegratedworkflow.
Learningby Doing Many textbooks present concepts in succession, covering each in exhaustive detail.
For example, the excellent textbook of Bishop (2006), teaches each topic so thoroughly that getting to the chapter on linear regression requires a nontrivial amount of work.
While expertslovethisbookpreciselyforitsthoroughness, fortruebeginners, thispropertylimits itsusefulnessasanintroductorytext.
Inthisbook, weteachmostconceptsjustintime.
Inotherwords, youwilllearnconcepts at the very moment that they are needed to accomplish some practical end.
While we take some time at the outset to teach fundamental preliminaries, like linear algebra and probability, wewantyoutotastethesatisfactionoftrainingyourfirstmodelbeforeworrying aboutmoreesotericconcepts.
Aside from a few preliminary notebooks that provide a crash course in the basic mathe- maticalbackground, eachsubsequentchapterbothintroducesareasonablenumberofnew conceptsandprovidesseveralself-containedworkingexamples, usingrealdatasets.
This presentedanorganizationalchallenge.
Somemodelsmightlogicallybegroupedtogether in a single notebook.
And some ideas might be best taught by executing several models insuccession.
Bycontrast, thereisabigadvantagetoadheringtoapolicyofoneworking example, onenotebook: Thismakesitaseasyaspossibleforyoutostartyourownresearch projectsbyleveragingourcode.
Justcopyanotebookandstartmodifyingit.
Throughout, weinterleavetherunnablecodewithbackgroundmaterialasneeded.
Ingen- eral, weerronthesideofmakingtoolsavailablebeforeexplainingthemfully(oftenfilling in the background later).
For instance, we might use stochastic gradient descent before explainingwhyitisusefulorofferingsomeintuitionforwhyitworks.
Thishelpstogive practitionersthenecessaryammunitiontosolveproblemsquickly, attheexpenseofrequir- ingthereadertotrustuswithsomecuratorialdecisions.
This book teaches deep learning concepts from scratch.
Sometimes, we delve into fine detailsaboutmodelsthatwouldtypicallybehiddenfromusersbymoderndeeplearning frameworks.
This comes up especially in the basic tutorials, where we want you to un- derstand everything that happens in a given layer or optimizer.
In these cases, we often present two versions of the example: one where we implement everything from scratch, relyingonlyon Num Py-likefunctionalityandautomaticdifferentiation, andamoreprac- xxviii Preface tical example, where we write succinct code using the high-level APIs of deep learning frameworks.
Afterexplaininghowsomecomponentworks, werelyonthehigh-level API insubsequenttutorials.
Contentand Structure Thebookcanbedividedintoroughlythreeparts, dealingwithpreliminaries, deeplearning techniques, andadvancedtopicsfocusedonrealsystemsandapplications().
t Bookstructure.
Part1: Basicsand Preliminaries.
Chapter1isanintroductiontodeeplearning.
Then, in Chapter2, wequicklybringyouuptospeedontheprerequisitesrequiredforhands- on deep learning, such as how to store and manipulate data, and how to apply vari- ousnumericaloperationsbasedonelementaryconceptsfromlinearalgebra, calculus, and probability.
Chapter 3 and Chapter 5 cover the most fundamental concepts and techniques in deep learning, including regression and classification; linear models; multilayerperceptrons; andoverfittingandregularization.
Part 2: Modern Deep Learning Techniques.
Chapter 6 describes the key computa- tional components of deep learning systems and lays the groundwork for our sub- sequent implementations of more complex models.
Next, Chapter 7 and Chapter 8 present convolutional neural networks (CNNs), powerful tools that form the back- boneofmostmoderncomputervisionsystems.
Similarly, Chapter9and Chapter10 introducerecurrentneuralnetworks(RNNs), modelsthatexploitsequential(e.
g., tem- poral)structureindataandarecommonlyusedfornaturallanguageprocessingand timeseriesprediction.
In Chapter11, wedescribearelativelynewclassofmodels, based on so-called attention mechanisms, that has displaced RNNs as the dominant architecture for most natural language processing tasks.
These sections will bring youuptospeedonthemostpowerfulandgeneraltoolsthatarewidelyusedbydeep learningpractitioners.
xxix Preface Part3: Scalability, Eï¬€iciency, and Applications(availableonline3).
In Chapter12, we 3 discussseveralcommonoptimizationalgorithmsusedtotraindeeplearningmodels.
Next, in Chapter13, weexamineseveralkeyfactorsthatinfluencethecomputational performanceofdeeplearningcode.
Then, in Chapter14, weillustratemajorapplica- tionsofdeeplearningincomputervision.
Finally, in Chapter15and Chapter16, we demonstratehowtopretrainlanguagerepresentationmodelsandapplythemtonatural languageprocessingtasks.
Code Mostsectionsofthisbookfeatureexecutablecode.
Webelievethatsomeintuitionsarebest developedviatrialanderror, tweakingthecodeinsmallwaysandobservingtheresults.
Ideally, an elegant mathematical theory might tell us precisely how to tweak our code to achieveadesiredresult.
However, deeplearningpractitionerstodaymustoftentreadwhere nosolidtheoryprovidesguidance.
Despiteourbestattempts, formalexplanationsforthe efficacyofvarioustechniquesarestilllacking, foravarietyofreasons: themathematicsto characterizethesemodelscanbesodifficult; theexplanationlikelydependsonproperties of the data that currently lack clear definitions; and serious inquiry on these topics has only recently kicked into high gear.
We are hopeful that as the theory of deep learning progresses, eachfutureeditionofthisbookwillprovideinsightsthateclipsethosepresently available.
Toavoidunnecessaryrepetition, wecapturesomeofourmostfrequentlyimportedandused functions and classes in the d2l package.
Throughout, we mark blocks of code (such as functions, classes, orcollectionofimportstatements)with#@savetoindicatethattheywill beaccessedlaterviathe d2l package.
Weoffer adetailedoverviewoftheseclassesand functionsin Section B.8.
Thed2lpackageislightweightandonlyrequiresthefollowing dependencies: #@save import collections import hashlib import inspect import math import os import random import re import shutil import sys import tarfile import time import zipfile from collections import defaultdict import pandas as pd import requests from IPython import display from matplotlib import pyplot as plt from matplotlib_inline import backend_inline d2l = sys.
modules[__name__] xxx Preface Mostofthecodeinthisbookisbasedon Py Torch, apopularopen-sourceframeworkthat has been enthusiastically embraced by the deep learning research community.
All of the codeinthisbookhaspassedtestsunderthelateststableversionof Py Torch.
However, due to the rapid development of deep learning, some code in the print edition may not work properly in future versions of Py Torch.
We plan to keep the online version up to date.
In case you encounter any problems, please consult Installation (page xxxiv) to update yourcodeandruntimeenvironment.
Belowlistsdependenciesinour Py Torchimplemen- tation.
#@save import numpy as np import torch import torchvision from PIL import Image from scipy.
spatial import distance_matrix from torch import nn from torch.
nn import functional as F from torchvision import transforms Target Audience Thisbookisforstudents(undergraduateorgraduate), engineers, andresearchers, whoseek asolidgraspofthepracticaltechniquesofdeeplearning.
Becauseweexplaineverycon- 4 ceptfromscratch, nopreviousbackgroundindeeplearningormachinelearningisrequired.
Fully explaining the methods of deep learning requires some mathematics and program- ming, butwewillonlyassumethatyouenterwithsomebasics, includingmodestamounts 5 of linear algebra, calculus, probability, and Python programming.
Just in case you have forgottenanything, theonline Appendix4 providesarefresheronmostofthemathematics youwillfindinthisbook.
Usually, wewillprioritizeintuitionandideasovermathematical 6 rigor.
Ifyouwouldliketoextendthesefoundationsbeyondtheprerequisitestounderstand ourbook, wehappilyrecommend some other terrific resources: Linear Analysis by Bol- lobÃ¡s(1999)coverslinearalgebraandfunctionalanalysisingreatdepth.
Allof Statistics (Wasserman,2013)providesamarvelousintroductiontostatistics.
Joe Blitzsteinâ€™sbooks5 7 andcourses6 onprobabilityandinferencearepedagogicalgems.
Andifyouhavenotused Pythonbefore, youmaywanttoperusethis Pythontutorial7.
8 Notebooks, Website, Git Hub, and Forum 9 Allofournotebooksareavailablefordownloadonthe D2L.
aiwebsite8 andon Git Hub9.
Associatedwiththisbook, wehavelaunchedadiscussionforum, locatedatdiscuss.
d2l.
ai 10 10.
Whenever you have questions on any section of the book, you can find a link to the associateddiscussionpageattheendofeachnotebook.
xxxi Preface Acknowledgments Weareindebtedtothehundredsofcontributorsforboththe Englishandthe Chinesedrafts.
Theyhelpedimprovethecontentandofferedvaluablefeedback.
Thisbookwasoriginally implementedwith MXNetastheprimaryframework.
Wethank Anirudh Dagarand Yuan Tangforadaptingamajoritypartofearlier MXNetcodeinto Py Torchand Tensor Flowim- plementations, respectively.
Since July2021, wehaveredesignedandreimplementedthis bookin Py Torch, MXNet, and Tensor Flow, choosing Py Torchastheprimaryframework.
We thank Anirudh Dagar for adapting a majority part of more recent Py Torch code into JAX implementations.
We thank Gaosheng Wu, Liujun Hu, Ge Zhang, and Jiehang Xie from Baidu for adapting a majority part of more recent Py Torch code into Paddle Paddle implementations in the Chinese draft.
We thank Shuai Zhang for integrating the La Te X stylefromthepressintothe PDFbuilding.
On Git Hub, we thank every contributor of this English draft for making it better for ev- eryone.
Their Git Hub IDsornamesare(innoparticularorder): alxnorden, avinashingit, bowen0701, brettkoonce, Chaitanya Prakash Bapat, cryptonaut, Davide Fiocco, edgarro- man, gkutiel, John Mitro, Liang Pu, Rahul Agarwal, Mohamed Ali Jamaoui, Michael(Stu) Stewart, Mike MÃ¼ller, NRauschmayr, Prakhar Srivastav, sad-, sfermigier, Sheng Zha, sun- deepteki, topecongiro, tpdi, vermicelli, Vishaal Kapoor, Vishwesh Ravi Shrimali, Ya Ya B, Yuhong Chen, Evgeniy Smirnov, lgov, Simon Corston-Oliver, Igor Dzreyev, Ha Nguyen, pmuens, Andrei Lukovenko, senorcinco, vfdev-5, dsweet, Mohammad Mahdi Rahimi, Ab- hishek Gupta, uwsd, Dom KM, Lisa Oakley, Bowen Li, Aarush Ahuja, Prasanth Bud- dareddygari, brianhendee, mani2106, mtn, lkevinzc, caojilin, Lakshya, Fiete LÃ¼er, Surbhi Vijayvargeeya, Muhyun Kim, dennismalmgren, adursun, Anirudh Dagar, liqingnz, Pe- dro Larroy, lgov, ati-ozgur, Jun Wu, Matthias Blume, Lin Yuan, geogunow, Josh Gard- ner, Maximilian BÃ¶ther, Rakib Islam, Leonard Lausen, Abhinav Upadhyay, rongruosong, Steve Sedlmeyer, Ruslan Baratov, Rafael Schlatter, liusy182, Giannis Pappas, ati-ozgur, qbaza, dchoi77, Adam Gerson, Phuc Le, Mark Atwood, christabella, vn09, Haibin Lin, jjangga0214, Richy Chen, noelo, hansent, Giel Dops, dvincent1337, White D3vil, Peter Kulits, codypenta, joseppinilla, ahmaurya, karolszk, heytitle, Peter Goetz, rigtorp, Tiep Vu, sfilip, mlxd, Kale-ab Tessera, Sanjar Adilov, Matteo Ferrara, hsneto, Katarzyna Biesial- ska, Gregory Bruss, Duyâ€“Thanh Doan, paulaurel, graytowne, Duc Pham, sl7423, Jaedong Hwang, Yida Wang, cys4, clhm, Jean Kaddour, austinmw, trebeljahr, tbaums, Cuong V.
Nguyen, pavelkomarov, vzlamal, Not Another System, J-Arun-Mani, jancio, eldarkurtic, the-great-shazbot, doctorcolossus, gducharme, cclauss, Daniel-Mietchen, hoonose, bia- giom, abhinavsp0730, jonathanhrandall, ysraell, Nodar Okroshiashvili, Ugur Kap, Jiyang Kang, Steven Jokes, Tomer Kaftan, liweiwp, netyster, ypandya, Nishant Tharani, heiligerl, Sports THU, Hoa Nguyen, manuel-arno-korfmann-webentwicklung, aterzis-personal, nxby, Xiaoting He, Josiah Yoder, mathresearch, mzz2017, jroberayalas, iluu, ghejc, BSharmi, vkramdev, simonwardjones, Laksh KD, Tal Neoran, djliden, Nikhil95, Oren Barkan, guoweis, haozhu233, pratikhack, Yue Ying, tayfununal, steinsag, charleybeller, Andrew Lumsdaine, Jiekui Zhang, Deepak Pathak, Florian Donhauser, Tim Gates, Adriaan Tijsseling, Ron xxxii Preface Medina, Gaurav Saha, Murat Semerci, Lei Mao, Levi Mc Clenny, Joshua Broyde, jake221, jonbally, zyhazwraith, Brian Pulfer, Nick Tomasino, Lefan Zhang, Hongshen Yang, Vin- ney Cavallo, yuntai, Yuanxiang Zhu, amarazov, pasricha, Ben Greenawald, Shivam Upad- hyay, Quanshangze Du, Biswajit Sahoo, Parthe Pandit, Ishan Kumar, Homunculus K, Lane Schwartz, varadgunjal, Jason Wiener, Armin Gholampoor, Shreshtha13, eigen-arnav, Hyeong- gyu Kim, Emily Ong, BÃ¡lint MucsÃ¡nyi, Chase Du Bois, Juntian Tao, Wenxiang Xu, Lifu Huang, filevich, quake2005, nils-werner, Yiming Li, Marsel Khisamutdinov, Francesco â€œFumaâ€Fumagalli, Peilin Sun, Vincent Gurgul, qingfengtommy, Janmey Shukla, Mo Shan, Kaan Sancak, regob, Alex Sauer, Gopalakrishna Ramachandra, Tobias Uelwer, Chao Wang, Tian Cao, Nicolas Corthorn, akash5474, kxxt, zxydi1992, Jacob Britton, Shuangchi He, zh- mou, krahets, Jie-Han Chen, Atishay Garg, Marcel Flygare, adtygan, Nik Vaessen, bolded, Louis Schlessinger, Balaji Varatharajan, atgctg, Kaixin Li, Victor Barbaros, Riccardo Musto, Elizabeth Ho, azimjonn, Guilherme Miotto, Alessandro Finamore, Joji Joseph, Anthony Biel, Zeming Zhao, shjustinbaek, gab-chen, nantekoto, Yutaro Nishiyama, Oren Amsalem, Tian-Mao Mao, Amin Allahyar, Gijs van Tulder, Mikhail Berkov, iamorphen, Matthew Caseres, Andrew Walsh, pgg PL, Rohan Karthikeyan, Ryan Choi, and Likun Lei.
Wethank Amazon Web Services, especially Wen-Ming Ye, George Karypis, Swami Siva- subramanian, Peter De Santis, Adam Selipsky, and Andrew Jassyfortheirgeneroussupport in writing this book.
Without the available time, resources, discussions with colleagues, andcontinuousencouragement, thisbookwouldnothavehappened.
Duringtheprepara- tionofthebookforpublication, Cambridge University Presshasofferedexcellentsupport.
Wethankourcommissioningeditor David Tranahforhishelpandprofessionalism.
Summary Deep learning has revolutionized pattern recognition, introducing technology that now powers a wide range of technologies, in such diverse fields as computer vision, natural languageprocessing, andautomaticspeechrecognition.
Tosuccessfullyapplydeeplearn- ing, youmustunderstandhowtocastaproblem, thebasicmathematicsofmodeling, the algorithmsforfittingyourmodelstodata, andtheengineeringtechniquestoimplementit all.
Thisbookpresentsacomprehensiveresource, includingprose, figures, mathematics, andcode, allinoneplace.
Exercises 11 1.
Registeranaccountonthediscussionforumofthisbookdiscuss.
d2l.
ai11.
2.
Install Pythononyourcomputer.
xxxiii Preface 3.
Follow the links at the bottom of the section to the forum, where you will be able to seekouthelpanddiscussthebookandfindanswerstoyourquestionsbyengagingthe authorsandbroadercommunity.
Discussions12.
12 Installation Inordertogetupandrunning, wewillneedanenvironmentforrunning Python, the Jupyter Notebook, therelevantlibraries, andthecodeneededtorunthebookitself.
Installing Miniconda Yoursimplestoptionistoinstall Miniconda13.
Notethatthe Python3.
xversionisrequired.
13 Youcanskipthefollowingstepsifyourmachinealreadyhascondainstalled.
Visitthe Minicondawebsiteanddeterminetheappropriateversionforyoursystembased onyour Python3.
xversionandmachinearchitecture.
Supposethatyour Pythonversionis 3.9(ourtestedversion).
Ifyouareusingmac OS, youwoulddownloadthebashscriptwhose namecontainsthestringsâ€œMac OSXâ€, navigatetothedownloadlocation, andexecutethe installationasfollows(taking Intel Macsasanexample): # The file name is subject to changes sh Miniconda3-py39_4.12.0-Mac OSX-x86_64.
sh -b ALinuxuserwoulddownloadthefilewhosenamecontainsthestringsâ€œLinuxâ€andexecute thefollowingatthedownloadlocation: # The file name is subject to changes sh Miniconda3-py39_4.12.0-Linux-x86_64.
sh -b AWindowsuserwoulddownloadandinstall Minicondabyfollowingitsonlineinstructions 14 14.
On Windows, youmaysearchforcmdtoopenthe Command Prompt(command-line interpreter)forrunningcommands.
Next, initializetheshellsowecanruncondadirectly.
~/miniconda3/bin/conda init Thencloseandreopenyourcurrentshell.
Youshouldbeabletocreateanewenvironment asfollows: xxxiv xxxv Installation conda create --name d2l python=3.9 -y Nowwecanactivatethed2lenvironment: conda activate d2l Installing the Deep Learning Framework and the d2l Package Beforeinstallinganydeeplearningframework, pleasefirstcheckwhetherornotyouhave proper GPUsonyourmachine(the GPUsthatpowerthedisplayonastandardlaptopare notrelevantforourpurposes).
Forexample, ifyourcomputerhas NVIDIAGPUsandhas installed CUDA15, then youare all set.
If yourmachinedoes not house any GPU, there 15 isnoneedtoworryjustyet.
Your CPUprovidesmorethanenoughhorsepowertogetyou through the first few chapters.
Just remember that you will want to access GPUs before runninglargermodels.
Youcaninstall Py Torch(thespecifiedversionsaretestedatthetimeofwriting)witheither CPUor GPUsupportasfollows: pip install torch==2.0.0 torchvision==0.15.1 Ournextstepistoinstallthed2lpackagethatwedevelopedinordertoencapsulatefre- quentlyusedfunctionsandclassesfoundthroughoutthisbook: pip install d2l==1.0.3 Downloading and Running the Code Next, you will want to download the notebooks so that you can run each of the bookâ€™s code blocks.
Simply click on the â€œNotebooksâ€ tab at the top of any HTML page on the D2L.
aiwebsite16 todownloadthecodeandthenunzipit.
Alternatively, youcanfetchthe notebooksfromthecommandlineasfollows: 16 mkdir d2l-en && cd d2l-en unzip d2l-en.
zip && rm d2l-en.
zip cd pytorch xxxvi Installation Ifyoudonotalreadyhaveunzipinstalled, firstrunsudo apt-get install unzip.
Now wecanstartthe Jupyter Notebookserverbyrunning: jupyter notebook Atthispoint, youcanopenhttp://localhost:8888(itmayhavealreadyopenedautomatically) inyourwebbrowser.
Thenwecanrunthecodeforeachsectionofthebook.
Whenever you open a new command line window, you will need to execute conda activate d2l toactivatetheruntimeenvironmentbeforerunningthe D2Lnotebooks, orupdatingyour packages(eitherthedeeplearningframeworkorthed2lpackage).
Toexittheenvironment, runconda deactivate.
Discussions17.
17 Notation Throughoutthisbook, weadheretothefollowingnotationalconventions.
Notethatsome ofthesesymbolsareplaceholders, whileothersrefertospecificobjects.
Asageneralrule ofthumb, theindefinitearticleâ€œaâ€oftenindicatesthatthesymbolisaplaceholderandthat similarlyformattedsymbolscandenoteotherobjectsofthesametype.
Forexample,â€œğ‘¥: a scalarâ€meansthatlowercasedlettersgenerallyrepresentscalarvalues, butâ€œZ: thesetof integersâ€refersspecificallytothesymbol Z.
Numerical Objects ğ‘¥: ascalar x: avector X: amatrix X: ageneraltensor I: the identity matrix (of some given dimension), i.
e., a square matrix with 1 on all diagonalentriesand0onalloff-diagonals ğ‘¥ ğ‘–, Â»xâ€¦ ğ‘–: theğ‘–thelementofvectorx ğ‘¥ ğ‘–ğ‘—,ğ‘¥ ğ‘–,ğ‘—,Â»Xâ€¦ ğ‘–ğ‘—, Â»Xâ€¦ ğ‘–,ğ‘—: theelementofmatrix Xatrowğ‘–andcolumn ğ‘—.
Set Theory X: aset Z: thesetofintegers Zâ€š : thesetofpositiveintegers R: thesetofrealnumbers Rğ‘› : thesetofğ‘›-dimensionalvectorsofrealnumbers xxxvii xxxviii Notation Rğ‘ ğ‘ : Thesetofmatricesofrealnumberswithğ‘rowsandğ‘columns j Xj: cardinality(numberofelements)ofset X A[B: unionofsets A and B A\B: intersectionofsets A and B A n B: set subtraction of B from A (contains only those elements of A that do not belongto B) Functions and Operators ğ‘“â€ â€: afunction logâ€ â€: thenaturallogarithm(baseğ‘’) log â€ â€: logarithmtobase2 2 expâ€ â€: theexponentialfunction 1â€ â€: theindicatorfunction; evaluatesto1ifthebooleanargumentistrue, and0other- wise 1X â€ğ‘§â€: theset-membershipindicatorfunction; evaluatesto1iftheelementğ‘§belongsto theset Xand0otherwise â€ â€> : transposeofavectororamatrix X 1: inverseofmatrix X : Hadamard(elementwise)product Â» , â€¦: concatenation k k ğ‘: â„“ ğ‘ norm k k: â„“ norm 2 hx, yi: inner(dot)productofvectorsxandy Ë : summationoveracollectionofelements Ë› : productoveracollectionofelements d = ef : anequalityassertedasadefinitionofthesymbolontheleft-handside xxxix Notation Calculus ğ‘‘ğ‘¦ : derivativeofğ‘¦withrespecttoğ‘¥ ğ‘‘ğ‘¥ ğœ•ğ‘¦ : partialderivativeofğ‘¦withrespecttoğ‘¥ ğœ•ğ‘¥ r ğ‘¦: gradientofğ‘¦withrespecttox x fl ğ‘ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥: definiteintegralof ğ‘“ fromğ‘toğ‘withrespecttoğ‘¥ ğ‘ fl ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥: indefiniteintegralof ğ‘“ withrespecttoğ‘¥ Probability and Information Theory ğ‘‹: arandomvariable ğ‘ƒ: aprobabilitydistribution ğ‘‹ ğ‘ƒ: therandomvariable ğ‘‹ followsdistributionğ‘ƒ ğ‘ƒâ€ğ‘‹ =ğ‘¥â€: theprobabilityassignedtotheeventwhererandomvariable ğ‘‹ takesvalueğ‘¥ ğ‘ƒâ€ğ‘‹ jğ‘Œâ€: theconditionalprobabilitydistributionof ğ‘‹ givenğ‘Œ ğ‘â€ â€: aprobabilitydensityfunction(PDF)associatedwithdistributionğ‘ƒ ğ¸Â»ğ‘‹â€¦: expectationofarandomvariable ğ‘‹ ğ‘‹ ?ğ‘Œ: randomvariables ğ‘‹ andğ‘Œ areindependent ğ‘‹ ?ğ‘Œ j ğ‘: randomvariables ğ‘‹ andğ‘Œ areconditionallyindependentgivenğ‘ ğœ ğ‘‹: standarddeviationofrandomvariable ğ‘‹ Varâ€ğ‘‹â€: varianceofrandomvariable ğ‘‹, equaltoğœ2 ğ‘‹ Covâ€ğ‘‹,ğ‘Œâ€: covarianceofrandomvariables ğ‘‹ andğ‘Œ ğœŒâ€ğ‘‹,ğ‘Œâ€: the Pearsoncorrelationcoefficientbetween ğ‘‹ andğ‘Œ, equals Covâ€ğ‘‹,ğ‘Œâ€ ğœğ‘‹ğœğ‘Œ ğ»â€ğ‘‹â€: entropyofrandomvariable ğ‘‹ ğ· â€ğ‘ƒkğ‘„â€: the KL-divergence(orrelativeentropy)fromdistributionğ‘„ todistribution KL ğ‘ƒ Discussions18.
18 1 Introduction Untilrecently, nearlyeverycomputerprogramthatyoumighthaveinteractedwithduringan ordinarydaywascodedupasarigidsetofrulesspecifyingpreciselyhowitshouldbehave.
Say that we wanted to write an application to manage an e-commerce platform.
After huddlingaroundawhiteboardforafewhourstopondertheproblem, wemightsettleon thebroadstrokesofaworkingsolution, forexample: (i)usersinteractwiththeapplication throughaninterfacerunninginawebbrowserormobileapplication; (ii)ourapplication interacts with a commercial-grade database engine to keep track of each userâ€™s state and maintain records of historical transactions; and (iii) at the heart of our application, the businesslogic(youmightsay, thebrains)ofourapplicationspellsoutasetofrulesthat mapeveryconceivablecircumstancetothecorrespondingactionthatourprogramshould take.
Tobuildthebrainsofourapplication, wemightenumerateallthecommoneventsthatour programshouldhandle.
Forexample, wheneveracustomerclickstoaddanitemtotheir shoppingcart, ourprogramshouldaddanentrytotheshoppingcartdatabasetable, associ- atingthatuserâ€™s IDwiththerequestedproductâ€™s ID.
Wemightthenattempttostepthrough everypossiblecornercase, testingtheappropriatenessofourrulesandmakinganyneces- sarymodifications.
Whathappensifauserinitiatesapurchasewithanemptycart? While few developers ever get it completely right the first time (it might take some test runs to workoutthekinks), forthemostpartwecanwritesuchprogramsandconfidentlylaunch them before ever seeing a real customer.
Our ability to manually design automated sys- temsthatdrivefunctioningproductsandsystems, ofteninnovelsituations, isaremarkable cognitivefeat.
Andwhenyouareabletodevisesolutionsthatwork100%ofthetime, you typicallyshouldnotbeworryingaboutmachinelearning.
Fortunatelyforthegrowingcommunityofmachinelearningscientists, manytasksthatwe wouldliketoautomatedonotbendsoeasilytohumaningenuity.
Imaginehuddlingaround thewhiteboardwiththesmartestmindsyouknow, butthistimeyouaretacklingoneofthe followingproblems: Writeaprogramthatpredictstomorrowâ€™sweathergivengeographicinformation, satellite images, andatrailingwindowofpastweather.
Writeaprogramthattakesinafactoidquestion, expressedinfree-formtext, andanswers itcorrectly.
Writeaprogram that, givenan image, identifiesevery persondepictedin itanddraws outlinesaroundeach.
1 2 Introduction Write a program that presents users with products that theyare likelyto enjoy but un- likely, inthenaturalcourseofbrowsing, toencounter.
For these problems, even elite programmers would struggle to code up solutions from scratch.
The reasons can vary.
Sometimes the program that we are looking for follows a pattern that changes over time, so there is no fixed right answer! In such cases, any successful solution must adapt gracefully to a changing world.
At other times, the rela- tionship (say between pixels, and abstract categories) may be too complicated, requiring thousandsormillionsofcomputationsand followingunknownprinciples.
Inthecaseof imagerecognition, theprecisestepsrequiredtoperformthetaskliebeyondourconscious understanding, eventhoughoursubconsciouscognitiveprocessesexecutethetaskeffort- lessly.
Machinelearningisthestudyofalgorithmsthatcanlearnfromexperience.
Asamachine learning algorithm accumulates more experience, typically in the form of observational data or interactions with an environment, its performance improves.
Contrast this with ourdeterministice-commerceplatform, whichfollowsthesamebusinesslogic, nomatter howmuchexperienceaccrues, untilthedevelopersthemselveslearnanddecidethatitis timetoupdatethesoftware.
Inthisbook, wewillteachyouthefundamentalsofmachine learning, focusinginparticularondeeplearning, apowerfulsetoftechniquesdrivingin- novationsinareasasdiverseascomputervision, naturallanguageprocessing, healthcare, andgenomics.
1.1 A Motivating Example Before beginning writing, the authors of this book, like much of the work force, had to becomecaffeinated.
Wehoppedinthecarandstarteddriving.
Usingani Phone, Alexcalled out â€œHey Siriâ€, awakening the phoneâ€™s voice recognition system.
Then Mu commanded â€œdirectionsto Blue Bottlecoffeeshopâ€.
Thephonequicklydisplayedthetranscriptionof hiscommand.
Italsorecognizedthatwewereaskingfordirectionsandlaunchedthe Maps application(app)tofulfillourrequest.
Oncelaunched, the Mapsappidentifiedanumber ofroutes.
Nexttoeachroute, thephonedisplayedapredictedtransittime.
Whilethisstory wasfabricatedforpedagogicalconvenience, itdemonstratesthatinthespanofjustafew seconds, oureverydayinteractionswithasmartphonecanengageseveralmachinelearning models.
Imaginejustwritingaprogramtorespondtoawakewordsuchasâ€œAlexaâ€,â€œOKGoogleâ€, andâ€œHey Siriâ€.
Trycodingitupinaroombyyourselfwithnothingbutacomputerand acodeeditor, asillustratedin.1.1.
Howwouldyouwritesuchaprogramfromfirst principles? Thinkaboutitâ€¦theproblemishard.
Everysecond, themicrophonewillcol- lectroughly44,000samples.
Eachsampleisameasurementoftheamplitudeofthesound wave.
Whatrulecouldmapreliablyfromasnippetofrawaudiotoconfidentpredictions fyes, nogaboutwhetherthesnippetcontainsthewakeword? Ifyouarestuck, donotworry.
3 AMotivating Example Wedonotknowhowtowritesuchaprogramfromscratcheither.
Thatiswhyweusema- chinelearning.
t .1.1 Identifyawakeword.
Hereisthetrick.
Often, evenwhenwedonotknowhowtotellacomputerexplicitlyhow tomapfrominputstooutputs, wearenonethelesscapableofperformingthecognitivefeat ourselves.
In other words, even if you do not know how to program a computer to rec- ognize the word â€œAlexaâ€, you yourself are able to recognize it.
Armed with this ability, wecancollectahugedatasetcontainingexamplesofaudiosnippetsandassociatedlabels, indicating which snippets contain the wakeword.
In the currently dominant approach to machinelearning, wedonotattempttodesignasystemexplicitlytorecognizewakewords.
Instead, we define a flexible program whose behavior is determined by a number of pa- rameters.
Then we use the dataset to determine the best possible parameter values, i.
e., thosethatimprovetheperformanceofourprogramwithrespecttoachosenperformance measure.
Youcanthinkoftheparametersasknobsthatwecanturn, manipulatingthebehaviorof theprogram.
Oncetheparametersarefixed, wecalltheprogramamodel.
Thesetofall distinct programs (inputâ€“output mappings) that we can produce just by manipulating the parametersiscalledafamilyofmodels.
Andtheâ€œmeta-programâ€thatusesourdatasetto choosetheparametersiscalledalearningalgorithm.
Beforewecangoaheadandengagethelearningalgorithm, wehavetodefinetheproblem precisely, pinning down the exact nature of the inputs and outputs, and choosing an ap- propriate model family.
In this case, our model receivesa snippet of audioas input, and the model generates a selection among fyes, nog as output.
If all goes according to plan themodelâ€™sguesseswilltypicallybecorrectastowhetherthesnippetcontainsthewake word.
Ifwechoosetherightfamilyofmodels, thereshouldexistonesettingoftheknobssuch thatthemodelfiresâ€œyesâ€everytimeithearsthewordâ€œAlexaâ€.
Becausetheexactchoiceof thewakewordisarbitrary, wewillprobablyneedamodelfamilysufficientlyrichthat, via anothersettingoftheknobs, itcouldfireâ€œyesâ€onlyuponhearingthewordâ€œApricotâ€.
We expectthatthesamemodelfamilyshouldbesuitableforâ€œAlexaâ€recognitionandâ€œApricotâ€ recognitionbecausetheyseem, intuitively, tobesimilartasks.
However, wemightneeda differentfamilyofmodelsentirelyifwewanttodealwithfundamentallydifferentinputs oroutputs, sayifwewantedtomapfromimagestocaptions, orfrom Englishsentencesto Chinesesentences.
Asyoumightguess, ifwejustsetalloftheknobsrandomly, itisunlikelythatourmodel will recognize â€œAlexaâ€, â€œApricotâ€, or any other English word.
In machine learning, the learningistheprocessbywhichwediscovertherightsettingoftheknobsforcoercingthe 4 Introduction desiredbehaviorfromourmodel.
Inotherwords, wetrainourmodelwithdata.
Asshown in.1.2, thetrainingprocessusuallylookslikethefollowing: 1.
Startoffwitharandomlyinitializedmodelthatcannotdoanythinguseful.
2.
Grabsomeofyourdata(e.
g., audiosnippetsandcorrespondingfyes, noglabels).
3.
Tweaktheknobstomakethemodelperformbetterasassessedonthoseexamples.
4.
Repeat Steps2and3untilthemodelisawesome.
t .1.2 Atypicaltrainingprocess.
Tosummarize, ratherthancodeupawakewordrecognizer, wecodeupaprogramthatcan learntorecognizewakewords, ifpresentedwithalargelabeleddataset.
Youcanthinkof thisactofdeterminingaprogramâ€™sbehaviorbypresentingitwithadatasetasprogramming withdata.
Thatistosay, wecanâ€œprogramâ€acatdetectorbyprovidingourmachinelearning systemwithmanyexamplesofcatsanddogs.
Thiswaythedetectorwilleventuallylearn to emit a very large positive number if it is a cat, a very large negative number if it is a dog, andsomethingclosertozeroifitisnotsure.
Thisbarelyscratchesthesurfaceofwhat machine learning can do.
Deep learning, which we will explain in greater detail later, is justoneamongmanypopularmethodsforsolvingmachinelearningproblems.
1.2 Key Components Inourwakewordexample, wedescribedadatasetconsistingofaudiosnippetsandbinary labels, and we gave a hand-wavy sense of how we might train a model to approximate a mappingfromsnippetstoclassifications.
Thissortofproblem, wherewetrytopredicta designatedunknownlabelbasedonknowninputsgivenadatasetconsistingofexamples forwhichthelabelsareknown, iscalledsupervisedlearning.
Thisisjustoneamongmany kindsofmachinelearningproblems.
Beforeweexploreothervarieties, wewouldliketo shedmorelightonsomecorecomponentsthatwillfollowusaround, nomatterwhatkind ofmachinelearningproblemwetackle: 1.
Thedatathatwecanlearnfrom.
2.
Amodelofhowtotransformthedata.
3.
Anobjectivefunctionthatquantifieshowwell(orbadly)themodelisdoing.
4.
Analgorithmtoadjustthemodelâ€™sparameterstooptimizetheobjectivefunction.
5 Key Components 1.2.1 Data It might go without saying that you cannot do data science without data.
We could lose hundredsofpagesponderingwhatpreciselydatais, butfornow, wewillfocusonthekey propertiesofthedatasetsthatwewillbeconcernedwith.
Generally, weareconcernedwith acollectionofexamples.
Inordertoworkwithdatausefully, wetypicallyneedtocome upwithasuitablenumericalrepresentation.
Eachexample(ordatapoint, datainstance, sample)typicallyconsistsofasetofattributescalledfeatures(sometimescalledcovariates or inputs), based on which the model must make its predictions.
In supervised learning problems, ourgoalistopredictthevalueofaspecialattribute, calledthelabel(ortarget), thatisnotpartofthemodelâ€™sinput.
Ifwewereworkingwithimagedata, eachexamplemightconsistofanindividualphoto- graph(thefeatures)andanumberindicatingthecategorytowhichthephotographbelongs (thelabel).
Thephotographwouldberepresentednumericallyasthreegridsofnumerical valuesrepresentingthebrightnessofred, green, andbluelightateachpixellocation.
For example, a 200 200 pixel color photograph would consist of 200 200 3 = 120000 numericalvalues.
Alternatively, wemightworkwithelectronichealthrecorddataandtacklethetaskofpre- dictingthelikelihoodthatagivenpatientwillsurvivethenext30days.
Here, ourfeatures might consist of a collection of readily available attributes and frequently recorded mea- surements, includingage, vitalsigns, comorbidities, currentmedications, andrecentpro- cedures.
Thelabelavailablefortrainingwouldbeabinaryvalueindicatingwhethereach patientinthehistoricaldatasurvivedwithinthe30-daywindow.
Insuchcases, wheneveryexampleischaracterizedbythesamenumberofnumericalfea- tures, we say that the inputs are fixed-length vectors and we call the (constant) length of thevectorsthedimensionalityofthedata.
Asyoumightimagine, fixed-lengthinputscan beconvenient, givingusonelesscomplicationtoworryabout.
However, notalldatacan easilyberepresentedasfixed-lengthvectors.
Whilewemightexpectmicroscopeimagesto comefromstandardequipment, wecannotexpectimagesminedfromthe Internetalltohave thesameresolutionorshape.
Forimages, wemightconsidercroppingthemtoastandard size, but that strategy only gets us so far.
We risk losing information in the cropped-out portions.
Moreover, text data resists fixed-length representations even more stubbornly.
Considerthecustomerreviewsleftone-commercesitessuchas Amazon, IMDb, and Tri- p Advisor.
Someareshort: â€œitstinks!â€.
Othersrambleforpages.
Onemajoradvantageof deeplearningovertraditionalmethodsisthecomparativegracewithwhichmodernmodels canhandlevarying-lengthdata.
Generally, themoredatawehave, theeasierourjobbecomes.
Whenwehavemoredata, we cantrainmorepowerfulmodelsandrelylessheavilyonpreconceivedassumptions.
The regimechangefrom(comparatively)smalltobigdataisamajorcontributortothesuccess of modern deep learning.
To drive the point home, many of the most exciting models in deep learning do not work without large datasets.
Some others might work in the small dataregime, butarenobetterthantraditionalapproaches.
Finally, itisnotenoughtohavelotsofdataandtoprocessitcleverly.
Weneedtheright 6 Introduction data.
Ifthedataisfullofmistakes, orifthechosenfeaturesarenotpredictiveofthetarget quantityofinterest, learningisgoingtofail.
ThesituationiscapturedwellbytheclichÃ©: garbage in, garbage out.
Moreover, poor predictive performance is not the only poten- tial consequence.
In sensitive applications of machine learning, like predictive policing, resumescreening, andriskmodelsusedforlending, wemustbeespeciallyalerttothecon- sequencesofgarbagedata.
Onecommonlyoccurringfailuremodeconcernsdatasetswhere somegroupsofpeopleareunrepresentedinthetrainingdata.
Imagineapplyingaskincan- cerrecognitionsystemthathadneverseenblackskinbefore.
Failurecanalsooccurwhen thedatadoesnotonlyunder-representsomegroupsbutreflectssocietalprejudices.
Forex- ample, ifpasthiringdecisionsareusedtotrainapredictivemodelthatwillbeusedtoscreen resumesthenmachinelearningmodelscouldinadvertentlycaptureandautomatehistorical injustices.
Notethatthiscanallhappenwithoutthedatascientistactivelyconspiring, or evenbeingaware.
1.2.2 Models Most machine learning involves transforming the data in some sense.
We might want to buildasystemthatingestsphotosandpredictssmiley-ness.
Alternatively, wemightwantto ingestasetofsensorreadingsandpredicthownormalvs.
anomalousthereadingsare.
By model, wedenotethecomputationalmachineryforingestingdataofonetype, andspitting out predictions of a possibly different type.
In particular, we are interested in statistical modelsthatcanbeestimatedfromdata.
Whilesimplemodelsareperfectlycapableofad- dressingappropriatelysimpleproblems, theproblemsthatwefocusoninthisbookstretch thelimitsofclassicalmethods.
Deeplearningisdifferentiatedfromclassicalapproaches principallybythesetofpowerfulmodelsthatitfocuseson.
Thesemodelsconsistofmany successive transformations of the data that are chained together top to bottom, thus the name deep learning.
On our way to discussing deep models, we will also discuss some moretraditionalmethods.
1.2.3 Objective Functions Earlier, weintroducedmachinelearningaslearningfromexperience.
Bylearninghere, we meanimprovingatsometaskovertime.
Butwhoistosaywhatconstitutesanimprovement? You might imagine that we could propose updating our model, and some people might disagreeonwhetherourproposalconstitutedanimprovementornot.
Inordertodevelopaformalmathematicalsystemoflearningmachines, weneedtohave formalmeasuresofhowgood(orbad)ourmodelsare.
Inmachinelearning, andoptimiza- tion more generally, we call these objective functions.
By convention, we usually define objectivefunctionssothatlowerisbetter.
Thisismerelyaconvention.
Youcantakeany functionforwhichhigherisbetter, andturnitintoanewfunctionthatisqualitativelyiden- tical but for which lower is better by flipping the sign.
Because we choose lower to be better, thesefunctionsaresometimescalledlossfunctions.
Whentryingtopredictnumericalvalues, themostcommonlossfunctionissquarederror, i.
e., the square of the difference between the prediction and the ground truth target.
For classification, the most common objective is to minimize error rate, i.
e., the fraction of 7 Kindsof Machine Learning Problems examplesonwhichourpredictionsdisagreewiththegroundtruth.
Someobjectives(e.
g., squarederror)areeasytooptimize, whileothers(e.
g., errorrate)aredifficulttooptimize directly, owingtonon-differentiabilityorothercomplications.
Inthesecases, itiscommon insteadtooptimizeasurrogateobjective.
Duringoptimization, wethinkofthelossasafunctionofthemodelâ€™sparameters, andtreat thetrainingdatasetasaconstant.
Welearnthebestvaluesofourmodelâ€™sparametersby minimizingthelossincurredonasetconsistingofsomenumberofexamplescollectedfor training.
However, doingwellonthetrainingdatadoesnotguaranteethatwewilldowell on unseen data.
So we will typically want to split the available data into two partitions: the training dataset (or training set), for learning model parameters; and the test dataset (or test set), which is held out for evaluation.
At the end of the day, we typically report how our models perform on both partitions.
You could think of training performance as analogousto the scores that a studentachieveson the practice examsused to prepare for somerealfinalexam.
Eveniftheresultsareencouraging, thatdoesnotguaranteesuccess onthefinalexam.
Overthecourseofstudying, thestudentmightbegintomemorizethe practicequestions, appearingtomasterthetopicbutfalteringwhenfacedwithpreviously unseenquestionsontheactualfinalexam.
Whenamodelperformswellonthetrainingset butfailstogeneralizetounseendata, wesaythatitisoverfittingtothetrainingdata.
1.2.4 Optimization Algorithms Oncewehavegotsomedatasourceandrepresentation, amodel, andawell-definedobjec- tivefunction, weneedanalgorithmcapableofsearchingforthebestpossibleparameters for minimizing the loss function.
Popular optimization algorithms for deep learning are based on an approach called gradient descent.
In brief, at each step, this method checks to see, for each parameter, how that training set loss would change if you perturbed that parameterbyjustasmallamount.
Itwouldthenupdatetheparameterinthedirectionthat lowerstheloss.
1.3 Kinds of Machine Learning Problems Thewakewordprobleminourmotivatingexampleisjustoneamongmanythatmachine learning can tackle.
To motivate the reader further and provide us with some common languagethatwillfollowusthroughoutthebook, wenowprovideabroadoverviewofthe landscapeofmachinelearningproblems.
1.3.1 Supervised Learning Supervisedlearningdescribestaskswherewearegivenadatasetcontainingbothfeatures andlabelsandaskedtoproduceamodelthatpredictsthelabelswhengiveninputfeatures.
Each featureâ€“label pair is called an example.
Sometimes, when the context is clear, we mayusethetermexamplestorefertoacollectionofinputs, evenwhenthecorresponding 8 Introduction labelsareunknown.
Thesupervisioncomesintoplaybecause, forchoosingtheparame- ters, we(thesupervisors)providethemodelwithadatasetconsistingoflabeledexamples.
Inprobabilisticterms, wetypicallyareinterestedinestimatingtheconditionalprobability ofalabelgiveninputfeatures.
Whileitisjustoneamongseveralparadigms, supervised learningaccountsforthemajorityofsuccessfulapplicationsofmachinelearninginindus- try.
Partlythatisbecausemanyimportanttaskscanbedescribedcrisplyasestimatingthe probabilityofsomethingunknowngivenaparticularsetofavailabledata: Predictcancervs.
notcancer, givenacomputertomographyimage.
Predictthecorrecttranslationin French, givenasentencein English.
Predictthepriceofastocknextmonthbasedonthismonthâ€™sfinancialreportingdata.
Whileallsupervisedlearningproblemsarecapturedbythesimpledescriptionâ€œpredicting thelabelsgiveninputfeaturesâ€, supervisedlearningitselfcantakediverseformsandrequire tonsofmodelingdecisions, dependingon(amongotherconsiderations)thetype, size, and quantity of the inputs and outputs.
For example, we use different models for processing sequencesofarbitrarylengthsandfixed-lengthvectorrepresentations.
Wewillvisitmany oftheseproblemsindepththroughoutthisbook.
Informally, thelearningprocesslookssomethinglikethefollowing.
First, grababigcol- lectionofexamplesforwhichthefeaturesareknownandselectfromthemarandomsubset, acquiringthegroundtruthlabelsforeach.
Sometimestheselabelsmightbeavailabledata that have already been collected (e.
g., did a patient die within the following year?) and othertimeswemightneedtoemployhumanannotatorstolabelthedata,(e.
g., assigning imagestocategories).
Together, theseinputsandcorrespondinglabelscomprisethetrain- ingset.
Wefeedthetrainingdatasetintoasupervisedlearningalgorithm, afunctionthat takesasinputadatasetandoutputsanotherfunction: thelearnedmodel.
Finally, wecan feedpreviouslyunseeninputstothelearnedmodel, usingitsoutputsaspredictionsofthe t .3.1 Supervisedlearning.
Regression Perhapsthesimplestsupervisedlearningtasktowrapyourheadaroundisregression.
Con- sider, forexample, asetofdataharvestedfromadatabaseofhomesales.
Wemightcon- struct a table, in which each row corresponds to a different house, and each column cor- respondstosomerelevantattribute, suchasthesquarefootageofahouse, thenumberof bedrooms, the number of bathrooms, and the number of minutes (walking) to the center of town.
In this dataset, each example would be a specific house, and the corresponding 9 Kindsof Machine Learning Problems featurevectorwouldbeonerowinthetable.
Ifyoulivein New Yorkor San Francisco, and youarenotthe CEOof Amazon, Google, Microsoft, or Facebook, the(sq.
footage, no.
of bedrooms, no.
of bathrooms, walking distance) feature vector for your home might look somethinglike: Â»600,1,1,60â€¦.
However, ifyoulivein Pittsburgh, itmightlookmorelike Â»3000,4,3,10â€¦.
Fixed-lengthfeaturevectorslikethisareessentialformostclassicmachine learningalgorithms.
Whatmakesaproblemaregressionisactuallytheformofthetarget.
Saythatyouareinthe marketforanewhome.
Youmightwanttoestimatethefairmarketvalueofahouse, given somefeaturessuchasabove.
Thedataheremightconsistofhistoricalhomelistingsandthe labelsmightbetheobservedsalesprices.
Whenlabelstakeonarbitrarynumericalvalues (even within some interval), we call this a regression problem.
The goal is to produce a modelwhosepredictionscloselyapproximatetheactuallabelvalues.
Lotsofpracticalproblemsareeasilydescribedasregressionproblems.
Predictingtherating that a user will assign to a movie can be thought of as a regression problem and if you designed a great algorithm to accomplish this feat in 2009, you might have won the 1- million-dollar Netflixprize19.
Predictingthelengthofstayforpatientsinthehospitalis 19 also a regression problem.
A good rule of thumb is that any how much? or how many? problemislikelytoberegression.
Forexample: Howmanyhourswillthissurgerytake? Howmuchrainfallwillthistownhaveinthenextsixhours? Evenifyouhaveneverworkedwithmachinelearningbefore, youhaveprobablyworked througharegressionprobleminformally.
Imagine, forexample, thatyouhadyourdrainsre- pairedandthatyourcontractorspent3hoursremovinggunkfromyoursewagepipes.
Then theysentyouabillof350dollars.
Nowimaginethatyourfriendhiredthesamecontractor for 2 hours and received a bill of 250 dollars.
If someone then asked you how much to expectontheirupcominggunk-removalinvoiceyoumightmakesomereasonableassump- tions, suchasmorehoursworkedcostsmoredollars.
Youmightalsoassumethatthereis somebasechargeandthatthecontractorthenchargesperhour.
Iftheseassumptionsheld true, thengiventhesetwodataexamples, youcouldalreadyidentifythecontractorâ€™spricing structure: 100dollarsperhourplus50dollarstoshowupatyourhouse.
Ifyoufollowed thatmuch, thenyoualreadyunderstandthehigh-levelideabehindlinearregression.
Inthiscase, wecouldproducetheparametersthatexactlymatchedthecontractorâ€™sprices.
Sometimes this is not possible, e.
g., if some of the variation arises from factors beyond your two features.
In these cases, we will try to learn models that minimize the distance betweenourpredictionsandtheobservedvalues.
Inmostofourchapters, wewillfocuson minimizingthesquarederrorlossfunction.
Aswewillseelater, thislosscorrespondsto theassumptionthatourdatawerecorruptedby Gaussiannoise.
Classification Whileregressionmodelsaregreatforaddressinghowmany? questions, lotsofproblemsdo notfitcomfortablyinthistemplate.
Consider, forexample, abankthatwantstodevelopa 10 Introduction checkscanningfeatureforitsmobileapp.
Ideally, thecustomerwouldsimplysnapaphoto ofacheckandtheappwouldautomaticallyrecognizethetextfromtheimage.
Assuming thatwehadsomeabilitytosegmentoutimagepatchescorrespondingtoeachhandwritten character, thentheprimaryremainingtaskwouldbetodeterminewhichcharacteramong some known set is depicted in each image patch.
These kinds of which one? problems arecalledclassificationandrequireadifferentsetoftoolsfromthoseusedforregression, althoughmanytechniqueswillcarryover.
Inclassification, wewantourmodeltolookatfeatures, e.
g., thepixelvaluesinanimage, and then predict to which category (sometimes called a class) among some discrete set ofoptions, anexamplebelongs.
Forhandwrittendigits, wemighthavetenclasses, corre- sponding to the digits 0 through 9.
The simplest form of classification is when there are onlytwoclasses, aproblemwhichwecallbinaryclassification.
Forexample, ourdataset couldconsistofimagesofanimalsandourlabelsmightbetheclasses{cat, dog}.
Whereas inregressionwesoughtaregressortooutputanumericalvalue, inclassificationweseeka classifier, whoseoutputisthepredictedclassassignment.
Forreasonsthatwewillgetintoasthebookgetsmoretechnical, itcanbedifficulttoopti- mizeamodelthatcanonlyoutputafirmcategoricalassignment, e.
g., eitherâ€œcatâ€orâ€œdogâ€.
Inthesecases, itisusuallymucheasiertoexpressourmodelinthelanguageofprobabili- ties.
Givenfeaturesofanexample, ourmodelassignsaprobabilitytoeachpossibleclass.
Returningtoouranimalclassificationexamplewheretheclassesare{cat, dog}, aclassi- fiermightseeanimageandoutputtheprobabilitythattheimageisacatas0.9.
Wecan interpretthisnumberbysayingthattheclassifieris90%surethattheimagedepictsacat.
The magnitude of the probability for the predicted class conveys a notion of uncertainty.
It is not the only one available and we will discuss others in chapters dealing with more advancedtopics.
Whenwehavemorethantwopossibleclasses, wecalltheproblemmulticlassclassification.
weattackedregressionproblemsbytryingtominimizethesquarederrorlossfunction, the commonlossfunctionforclassificationproblemsiscalledcross-entropy, whosenamewill bedemystifiedwhenweintroduceinformationtheoryinlaterchapters.
Notethatthemostlikelyclassisnotnecessarilytheonethatyouaregoingtouseforyour decision.
Assumethatyoufindabeautifulmushroominyourbackyardasshownin.3.2.
Now, assumethatyoubuiltaclassifierandtrainedittopredictwhetheramushroomispoi- sonousbasedonaphotograph.
Sayourpoison-detectionclassifieroutputsthattheproba- ourmushroomisnotadeathcap.
Still, youwouldhavetobeafooltoeatit.
Thatisbecause thecertainbenefitofadeliciousdinnerisnotwortha20%riskofdyingfromit.
Inother words, theeffectoftheuncertainriskoutweighsthebenefitbyfar.
Thus, inordertomake adecisionaboutwhethertoeatthemushroom, weneedtocomputetheexpecteddetriment associatedwitheachactionwhichdependsbothonthelikelyoutcomesandthebenefitsor harmsassociatedwitheach.
Inthiscase, thedetrimentincurredbyeatingthemushroom 11 Kindsof Machine Learning Problems t .3.2 Deathcap-donoteat! Ourcautionwasjustified: asanymycologistwouldtellus, themushroomin.3.2is actuallyadeathcap.
Classificationcangetmuchmorecomplicatedthanjustbinaryormulticlassclassification.
Forinstance, therearesomevariantsofclassificationaddressinghierarchicallystructured classes.
Insuchcasesnotallerrorsareequalâ€”ifwemusterr, wemightprefertomisclassify to a related class rather than a distant class.
Usually, this is referred to as hierarchical classification.
Forinspiration, youmightthinkof Linnaeus20, whoorganizedfaunaina 20 hierarchy.
Inthecaseofanimalclassification, itmightnotbesobadtomistakeapoodleforaschnauzer, but our model would pay a huge penalty if it confused a poodle with a dinosaur.
Which hierarchy is relevant might depend on how you plan to use the model.
For example, rat- tlesnakesandgartersnakesmightbecloseonthephylogenetictree, butmistakingarattler foragartercouldhavefatalconsequences.
Tagging Someclassificationproblemsfitneatlyintothebinaryormulticlassclassificationsetups.
Forexample, wecouldtrainanormalbinaryclassifiertodistinguishcatsfromdogs.
Given thecurrentstateofcomputervision, wecandothiseasily, withoff-the-shelftools.
Nonethe- less, nomatterhowaccurateourmodelgets, wemightfindourselvesintroublewhenthe classifierencountersanimageofthe Town Musiciansof Bremen, apopular Germanfairy talefeaturingfouranimals(.3.3).
Asyoucansee, thephotofeaturesacat, arooster, adog, andadonkey, withsometreesin thebackground.
Ifweanticipateencounteringsuchimages, multiclassclassificationmight notbetherightproblemformulation.
Instead, wemightwanttogivethemodeltheoption ofsayingtheimagedepictsacat, adog, adonkey, andarooster.
12 Introduction t .3.3 Adonkey, adog, acat, andarooster.
Theproblemoflearningtopredictclassesthatarenotmutuallyexclusiveiscalledmulti- labelclassification.
Auto-taggingproblemsaretypicallybestdescribedintermsofmulti- labelclassification.
Thinkofthetagspeoplemightapplytopostsonatechnicalblog, e.
g., â€œmachinelearningâ€,â€œtechnologyâ€,â€œgadgetsâ€,â€œprogramminglanguagesâ€,â€œLinuxâ€,â€œcloud computingâ€, â€œAWSâ€.
Atypicalarticlemighthave5â€“10tagsapplied.
Typically, tagswill exhibit some correlation structure.
Posts about â€œcloud computingâ€ are likely to mention â€œAWSâ€andpostsaboutâ€œmachinelearningâ€arelikelytomentionâ€œGPUsâ€.
Sometimessuchtaggingproblemsdrawonenormouslabelsets.
The National Libraryof Medicineemploysmanyprofessionalannotatorswhoassociateeacharticletobeindexedin Pub Medwithasetoftagsdrawnfromthe Medical Subject Headings(Me SH)ontology, a collectionofroughly28,000tags.
Correctlytaggingarticlesisimportantbecauseitallows researcherstoconductexhaustivereviewsoftheliterature.
Thisisatime-consumingpro- cessandtypicallythereisaone-yearlagbetweenarchivingandtagging.
Machinelearning can provide provisional tags until each article has a proper manual review.
Indeed, for 21 severalyears, the Bio ASQorganizationhashostedcompetitions21 forthistask.
13 Kindsof Machine Learning Problems Search In the field of information retrieval, we often impose ranks on sets of items.
Take web searchforexample.
Thegoalislesstodeterminewhetheraparticularpageisrelevantfora query, butratherwhich, amongasetofrelevantresults, shouldbeshownmostprominently toaparticularuser.
Onewayofdoingthismightbetofirstassignascoretoeveryelement in the set and then to retrieve the top-rated elements.
Page Rank22, the original secret 22 sauce behind the Google search engine, was an early example of such a scoring system.
Weirdly, the scoring provided by Page Rank did not depend on the actual query.
Instead, they relied on a simple relevance filter to identify the set of relevantcandidates and then used Page Ranktoprioritizethemoreauthoritativepages.
Nowadays, searchenginesuse machinelearningandbehavioralmodelstoobtainquery-dependentrelevancescores.
There areentireacademicconferencesdevotedtothissubject.
Recommender Systems Recommender systems are another problem setting that is related to search and ranking.
Theproblemsaresimilarinsofarasthegoalistodisplayasetofitemsrelevanttotheuser.
Themaindifferenceistheemphasisonpersonalizationtospecificusersinthecontextof recommender systems.
For instance, for movie recommendations, the results page for a sciencefictionfanandtheresultspageforaconnoisseurof Peter Sellerscomediesmight differ significantly.
Similar problems pop up in other recommendation settings, e.
g., for retailproducts, music, andnewsrecommendation.
Insomecases, customersprovideexplicitfeedback, communicatinghowmuchtheylikeda particularproduct(e.
g., theproductratingsandreviewson Amazon, IMDb, or Goodreads).
Inothercases, theyprovideimplicitfeedback, e.
g., byskippingtitlesonaplaylist, which might indicate dissatisfaction or maybe just indicate that the song was inappropriate in context.
In the simplest formulations, these systems are trained to estimate some score, suchasanexpectedstarratingortheprobabilitythatagivenuserwillpurchaseaparticular item.
Givensuchamodel, foranygivenuser, wecouldretrievethesetofobjectswiththelargest scores, which could then be recommended to the user.
Production systems are consider- ably more advanced and take detailed user activity and item characteristics into account whencomputingsuchscores.
.3.4displaysthedeeplearningbooksrecommendedby Amazonbasedonpersonalizationalgorithmstunedtocapture Astonâ€™spreferences.
Despite their tremendous economic value, recommender systems naively built on top of predictivemodelssuffersomeseriousconceptualflaws.
Tostart, weonlyobservecensored feedback: users preferentially rate movies that they feel strongly about.
For example, on afive-pointscale, youmightnoticethatitemsreceivemanyone-andfive-starratingsbut thatthereareconspicuouslyfewthree-starratings.
Moreover, currentpurchasehabitsare oftenaresultoftherecommendationalgorithmcurrentlyinplace, butlearningalgorithms donotalwaystakethisdetailintoaccount.
Thusitispossibleforfeedbackloopstoform wherearecommendersystempreferentiallypushesanitemthatisthentakentobebetter (due to greater purchases) and in turn is recommended even more frequently.
Many of 14 Introduction t .3.4 Deeplearningbooksrecommendedby Amazon.
these problemsâ€”about how to deal with censoring, incentives, and feedback loopsâ€”are importantopenresearchquestions.
Sequence Learning Sofar, wehavelookedatproblemswherewehavesomefixednumberofinputsandproduce a fixed number of outputs.
For example, we considered predicting house prices given a fixedsetoffeatures: squarefootage, numberofbedrooms, numberofbathrooms, andthe transittimetodowntown.
Wealsodiscussedmappingfromanimage(offixeddimension) tothepredictedprobabilitiesthatitbelongstoeachamongafixednumberofclassesand predictingstarratingsassociatedwithpurchasesbasedontheuser IDandproduct IDalone.
Inthesecases, onceourmodelistrained, aftereachtestexampleisfedintoourmodel, it isimmediatelyforgotten.
Weassumedthatsuccessiveobservationswereindependentand thustherewasnoneedtoholdontothiscontext.
Buthowshouldwedealwithvideosnippets? Inthiscase, eachsnippetmightconsistof adifferentnumberofframes.
Andourguessofwhatisgoingonineachframemightbe muchstrongerifwetakeintoaccountthepreviousorsucceedingframes.
Thesamegoesfor language.
Forexample, onepopulardeeplearningproblemismachinetranslation: thetask ofingestingsentencesinsomesourcelanguageandpredictingtheirtranslationsinanother language.
Suchproblemsalsooccurinmedicine.
Wemightwantamodeltomonitorpatientsinthe intensivecareunitandtofireoffalertswhenevertheirriskofdyinginthenext24hours exceedssomethreshold.
Here, wewouldnotthrowawayeverythingthatweknowabout 15 Kindsof Machine Learning Problems thepatienthistoryeveryhour, becausewemightnotwanttomakepredictionsbasedonly onthemostrecentmeasurements.
Questions like these are among the most exciting applications of machine learning and theyareinstancesofsequencelearning.
Theyrequireamodeleithertoingestsequences of inputs or to emit sequences of outputs (or both).
Specifically, sequence-to-sequence learningconsidersproblemswherebothinputsandoutputsconsistofvariable-lengthse- quences.
Examplesincludemachinetranslationandspeech-to-texttranscription.
Whileit isimpossibletoconsideralltypesofsequencetransformations, thefollowingspecialcases areworthmentioning.
Tagging and Parsing.
This involves annotating a text sequence with attributes.
Here, theinputsandoutputsarealigned, i.
e., theyareofthesamenumberandoccurinacorre- spondingorder.
Forinstance, inpart-of-speech(Po S)tagging, weannotateeverywordin asentencewiththecorrespondingpartofspeech, i.
e.,â€œnounâ€orâ€œdirectobjectâ€.
Alterna- tively, wemightwanttoknowwhichgroupsofcontiguouswordsrefertonamedentities, likepeople, places, ororganizations.
Inthecartoonishlysimpleexamplebelow, wemight just want to indicate whether or not any word in the sentence is part of a named entity (taggedasâ€œEntâ€).
Tom has dinner in Washington with Sally Ent - - - Ent - Ent Automatic Speech Recognition.
Withspeechrecognition, theinputsequenceisanaudio recordingofaspeaker(.3.5), andtheoutputisatranscriptofwhatthespeakersaid.
The challenge is that there are many more audio frames (sound is typically sampled at 8k Hz or 16k Hz) than text, i.
e., there is no 1:1 correspondence between audio and text, sincethousandsofsamplesmaycorrespondtoasinglespokenword.
Thesearesequence- to-sequence learning problems, where the output is much shorter than the input.
While humansareremarkablygoodatrecognizingspeech, evenfromlow-qualityaudio, getting computerstoperformthesamefeatisaformidablechallenge.
t .3.5 -D-e-e-p- L-ea-r-ni-ng-inanaudiorecording.
Textto Speech.
Thisistheinverseofautomaticspeechrecognition.
Here, theinputistext andtheoutputisanaudiofile.
Inthiscase, theoutputismuchlongerthantheinput.
Machine Translation.
Unlikethecaseofspeechrecognition, wherecorrespondinginputs and outputs occur in the same order, in machine translation, unaligned data poses a new challenge.
Heretheinputandoutputsequencescanhavedifferentlengths, andthecorre- 16 Introduction spondingregionsoftherespectivesequencesmayappearinadifferentorder.
Considerthe followingillustrativeexampleofthepeculiartendencyof Germanstoplacetheverbsatthe endofsentences: German: Haben Sie sich schon dieses grossartige Lehrwerk angeschaut? English: Have you already looked at this excellent textbook? Wrong alignment: Have you yourself already this excellent textbook looked at? Manyrelatedproblemspopupinotherlearningtasks.
Forinstance, determiningtheorder inwhichauserreadsawebpageisatwo-dimensionallayoutanalysisproblem.
Dialogue problemsexhibitallkindsofadditionalcomplications, wheredeterminingwhattosaynext requirestakingintoaccountreal-worldknowledgeandthepriorstateoftheconversation acrosslongtemporaldistances.
Suchtopicsareactiveareasofresearch.
1.3.2 Unsupervisedand Self-Supervised Learning Thepreviousexamplesfocusedonsupervisedlearning, wherewefeedthemodelagiant dataset containing both the features and corresponding label values.
You could think of thesupervisedlearnerashavinganextremelyspecializedjobandanextremelydictatorial boss.
Thebossstandsoverthelearnerâ€™sshoulderandtellsthemexactlywhattodoinevery situationuntiltheylearntomapfromsituationstoactions.
Workingforsuchabosssounds prettylame.
Ontheotherhand, pleasingsuchabossisprettyeasy.
Youjustrecognizethe patternasquicklyaspossibleandimitatethebossâ€™sactions.
Considering the opposite situation, it could be frustrating to work for a boss who has no ideawhattheywantyoutodo.
However, ifyouplantobeadatascientist, youhadbetter getusedtoit.
Thebossmightjusthandyouagiantdumpofdataandtellyoutodosome datasciencewithit! Thissoundsvaguebecauseitisvague.
Wecallthisclassofproblems unsupervisedlearning, andthetypeandnumberofquestionswecanaskislimitedonlyby ourcreativity.
Wewilladdressunsupervisedlearningtechniquesinlaterchapters.
Towhet yourappetitefornow, wedescribeafewofthefollowingquestionsyoumightask.
Canwefindasmallnumberofprototypesthataccuratelysummarizethedata? Givena setofphotos, canwegroupthemintolandscapephotos, picturesofdogs, babies, cats, andmountainpeaks? Likewise, givenacollectionofusersâ€™browsingactivities, can wegroupthemintouserswithsimilarbehavior? Thisproblemistypicallyknownas clustering.
Canwefindasmallnumberofparametersthataccuratelycapturetherelevantproperties of the data? The trajectories of a ball are well described by velocity, diameter, and massoftheball.
Tailorshavedevelopedasmallnumberofparametersthatdescribe humanbodyshapefairlyaccuratelyforthepurposeoffittingclothes.
Theseproblems arereferredtoassubspaceestimation.
Ifthedependenceislinear, itiscalledprincipal componentanalysis.
Istherearepresentationof(arbitrarilystructured)objectsin Euclideanspacesuchthat symbolicpropertiescanbewellmatched? Thiscanbeusedtodescribeentitiesand theirrelations, suchasâ€œRomeâ€ â€œItalyâ€â€šâ€œFranceâ€=â€œParisâ€.
17 Kindsof Machine Learning Problems Isthereadescriptionoftherootcausesofmuchofthedatathatweobserve? Forinstance, ifwehavedemographicdataabouthouseprices, pollution, crime, location, education, and salaries, can we discover how they are related simply based on empirical data? The fields concerned with causality and probabilistic graphical models tackle such questions.
Anotherimportantandexcitingrecentdevelopmentinunsupervisedlearningisthead- ventofdeepgenerativemodels.
Thesemodelsestimatethedensityofthedata, either explicitlyor implicitly.
Oncetrained, wecanuse agenerativemodeleither toscore examplesaccordingtohowlikelytheyare, ortosamplesyntheticexamplesfromthe learneddistribution.
Earlydeeplearningbreakthroughsingenerativemodelingcame withtheinventionofvariationalautoencoders(Kingmaand Welling,2014, Rezende etal.,2014)andcontinuedwiththedevelopmentofgenerativeadversarialnetworks (Goodfellowetal.,2014).
Morerecentadvancesincludenormalizingflows(Dinhet al.,2014, Dinhetal.,2017)anddiffusionmodels(Hoetal.,2020, Sohl-Dicksteinet al.,2015, Songand Ermon,2019, Songetal.,2021).
Afurtherdevelopmentinunsupervisedlearninghasbeentheriseofself-supervisedlearn- ing, techniquesthatleveragesomeaspectoftheunlabeleddatatoprovidesupervision.
For text, wecantrainmodelstoâ€œfillintheblanksâ€bypredictingrandomlymaskedwordsus- ingtheirsurroundingwords(contexts)inbigcorporawithoutanylabelingeffort(Devlin et al., 2018)! For images, we may train models to tell the relative position between two croppedregionsofthesameimage(Doerschetal.,2015), topredictanoccludedpartofan imagebasedontheremainingportionsoftheimage, ortopredictwhethertwoexamples areperturbedversionsofthesameunderlyingimage.
Self-supervisedmodelsoftenlearn representationsthataresubsequentlyleveragedbyfine-tuningtheresultingmodelsonsome downstreamtaskofinterest.
1.3.3 Interactingwithan Environment So far, we have not discussed where data actually comes from, or what actually happens whenamachinelearningmodelgeneratesanoutput.
Thatisbecausesupervisedlearning andunsupervisedlearningdonotaddresstheseissuesinaverysophisticatedway.
Ineach case, wegrababigpileofdataupfront, thensetourpatternrecognitionmachinesinmotion withouteverinteractingwiththeenvironmentagain.
Becauseallthelearningtakesplace afterthealgorithmisdisconnectedfromtheenvironment, thisissometimescalledoffline learning.
Forexample, supervisedlearningassumesthesimpleinteractionpatterndepicted in.3.6.
Thissimplicityofofflinelearninghasitscharms.
Theupsideisthatwecanworryabout patternrecognitioninisolation, withnoconcernaboutcomplicationsarisingfrominterac- tionswithadynamicenvironment.
Butthisproblemformulationislimiting.
Ifyougrew upreading Asimovâ€™s Robotnovels, thenyouprobablypictureartificiallyintelligentagents capablenotonlyofmakingpredictions, butalsooftakingactionsintheworld.
Wewant to think about intelligent agents, not just predictive models.
This means that we need to thinkaboutchoosingactions, notjustmakingpredictions.
Incontrasttomerepredictions, actionsactuallyimpacttheenvironment.
Ifwewanttotrainanintelligentagent, wemust 18 Introduction t .3.6 Collectingdataforsupervisedlearningfromanenvironment.
account for the way its actions might impact the future observations of the agent, and so offlinelearningisinappropriate.
Consideringtheinteractionwithanenvironmentopensawholesetofnewmodelingques- tions.
Thefollowingarejustafewexamples.
Doestheenvironmentrememberwhatwedidpreviously? Doestheenvironmentwanttohelpus, e.
g., auserreadingtextintoaspeechrecognizer? Does the environment want to beat us, e.
g., spammers adapting their emails to evade spamfilters? Doestheenvironmenthaveshiftingdynamics? Forexample, wouldfuturedataalways resemble the past or would the patterns change over time, either naturally or in re- sponsetoourautomatedtools? These questions raise the problem of distribution shift, where training and test data are different.
Anexampleofthis, thatmanyofusmayhavemet, iswhentakingexamswritten by a lecturer, while the homework was composed by their teaching assistants.
Next, we brieflydescribereinforcementlearning, arichframeworkforposinglearningproblemsin whichanagentinteractswithanenvironment.
1.3.4 Reinforcement Learning Ifyouareinterestedinusingmachinelearningtodevelopanagentthatinteractswithan environment and takes actions, then you are probably going to wind up focusing on re- inforcement learning.
This might include applications to robotics, to dialogue systems, and even to developing artificial intelligence (AI) for video games.
Deep reinforcement learning, which applies deep learning to reinforcement learning problems, has surged in popularity.
Thebreakthroughdeep Q-network, thatbeathumansat Atarigamesusingonly thevisualinput(Mnihetal.,2015), andthe Alpha Goprogram, whichdethronedtheworld championattheboardgame Go(Silveretal.,2016), aretwoprominentexamples.
Reinforcementlearninggivesaverygeneralstatementofaprobleminwhichanagentinter- actswithanenvironmentoveraseriesoftimesteps.
Ateachtimestep, theagentreceives some observation from the environment and must choose an action that is subsequently transmittedbacktotheenvironmentviasomemechanism(sometimescalledanactuator), when, aftereachloop, theagentreceivesarewardfromtheenvironment.
Thisprocessis 19 Kindsof Machine Learning Problems illustratedin.3.7.
Theagentthenreceivesasubsequentobservation, andchoosesa subsequentaction, andsoon.
Thebehaviorofareinforcementlearningagentisgoverned byapolicy.
Inbrief, apolicyisjustafunctionthatmapsfromobservationsoftheenviron- menttoactions.
Thegoalofreinforcementlearningistoproducegoodpolicies.
t .3.7 Theinteractionbetweenreinforcementlearningandanenvironment.
Itishardtooverstatethegeneralityofthereinforcementlearningframework.
Forexample, supervised learning can be recast as reinforcement learning.
Say we had a classification problem.
We could create a reinforcement learning agent with one action corresponding toeachclass.
Wecouldthencreateanenvironmentwhichgavearewardthatwasexactly equaltothelossfunctionfromtheoriginalsupervisedlearningproblem.
Further, reinforcementlearningcanalsoaddressmanyproblemsthatsupervisedlearning cannot.
Forexample, insupervisedlearning, wealwaysexpectthatthetraininginputcomes associated with the correct label.
But in reinforcement learning, we do not assume that, for each observation the environment tells us the optimal action.
In general, we just get some reward.
Moreover, the environment may not even tell us which actions led to the reward.
Considerthegameofchess.
Theonlyrealrewardsignalcomesattheendofthegamewhen we either win, earning a reward of, say, 1, or when we lose, receiving a reward of, say, 1.
Soreinforcementlearnersmustdealwiththecreditassignmentproblem: determining whichactionstocreditorblameforanoutcome.
Thesamegoesforanemployeewhogets apromotionon October11.
Thatpromotionlikelyreflectsanumberofwell-chosenactions overthepreviousyear.
Gettingpromotedinthefuturerequiresfiguringoutwhichactions alongthewayledtotheearlierpromotions.
Reinforcement learners may also have to deal with the problem of partial observability.
Thatis, thecurrentobservationmightnottellyoueverythingaboutyourcurrentstate.
Say your cleaning robot found itself trapped in one of many identical closets in your house.
Rescuingtherobotinvolvesinferringitspreciselocationwhichmightrequireconsidering earlierobservationspriortoitenteringthecloset.
Finally, at any given point, reinforcement learners might know of one good policy, but theremightbemanyotherbetterpoliciesthattheagenthasnevertried.
Thereinforcement learnermustconstantlychoosewhethertoexploitthebest(currently)knownstrategyasa policy, ortoexplorethespaceofstrategies, potentiallygivingupsomeshort-termreward inexchangeforknowledge.
Thegeneralreinforcementlearningproblemhasaverygeneralsetting.
Actionsaffectsub- 20 Introduction sequentobservations.
Rewardsareonlyobservedwhentheycorrespondtothechosenac- tions.
Theenvironmentmaybeeitherfullyorpartiallyobserved.
Accountingforallthis complexity at once may be asking too much.
Moreover, not every practical problem ex- hibitsallthiscomplexity.
Asaresult, researchershavestudiedanumberofspecialcases ofreinforcementlearningproblems.
When the environment is fully observed, we call the reinforcement learning problem a Markovdecisionprocess.
Whenthestatedoesnotdependonthepreviousactions, wecall itacontextualbanditproblem.
Whenthereisnostate, justasetofavailableactionswith initiallyunknownrewards, wehavetheclassicmulti-armedbanditproblem.
1.4 Roots Wehavejustreviewedasmallsubsetofproblemsthatmachinelearningcanaddress.
For adiversesetofmachinelearningproblems, deeplearningprovidespowerfultoolsfortheir solution.
Althoughmanydeeplearningmethodsarerecentinventions, thecoreideasbe- hind learning from data have been studied for centuries.
In fact, humans have held the desiretoanalyzedataandtopredictfutureoutcomesforages, anditisthisdesirethatis attherootofmuchofnaturalscienceandmathematics.
Twoexamplesarethe Bernoulli distribution, named after Jacob Bernoulli (1655â€“1705)23, and the Gaussian distribution 23 discoveredby Carl Friedrich Gauss(1777â€“1855)24.
Gaussinvented, forinstance, theleast meansquaresalgorithm, whichisstillusedtodayforamultitudeofproblemsfrominsur- ancecalculationstomedicaldiagnostics.
Suchtoolsenhancedtheexperimentalapproach inthenaturalsciencesâ€”forinstance, Ohmâ€™slawrelatingcurrentandvoltageinaresistor 24 isperfectlydescribedbyalinearmodel.
Eveninthemiddleages, mathematicianshadakeenintuitionofestimates.
Forinstance, the geometry book of Jacob KÃ¶bel (1460â€“1533)25 illustrates averaging the length of 16 25 adultmenâ€™sfeettoestimatethetypicalfootlengthinthepopulation(.4.1).
As a group of individuals exited a church, 16 adult men were asked to line up in a row andhavetheirfeetmeasured.
Thesumofthesemeasurementswasthendividedby16to obtainanestimateforwhatnowiscalledonefoot.
Thisâ€œalgorithmâ€waslaterimprovedto dealwithmisshapenfeet; Thetwomenwiththeshortestandlongestfeetweresentaway, averagingonlyovertheremainder.
Thisisamongtheearliestexamplesofatrimmedmean estimate.
Statistics really took off with the availability and collection of data.
One of its pioneers, Ronald Fisher(1890â€“1962)26, contributedsignificantlytoitstheoryandalsoitsapplica- 26 tionsingenetics.
Manyofhisalgorithms(suchaslineardiscriminantanalysis)andcon- cepts (such as the Fisher information matrix) still hold a prominent place in the founda- tionsofmodernstatistics.
Evenhisdataresourceshadalastingimpact.
The Irisdataset that Fisherreleasedin1936isstillsometimesusedtodemonstratemachinelearningalgo- rithms.
Fisherwasalsoaproponentofeugenics, whichshouldremindusthatthemorally 21 Roots t .4.1 Estimatingthelengthofafoot.
dubious use of data science has as long and enduring a history as its productive use in industryandthenaturalsciences.
Otherinfluencesformachinelearningcamefromtheinformationtheoryof Claude Shan- non(1916â€“2001)27 andthetheoryofcomputationproposedby Alan Turing(1912â€“1954) 27 28.
Turingposedthequestionâ€œcanmachinesthink?â€ inhisfamouspaper Computing Ma- chineryand Intelligence(Turing,1950).
Describingwhatisnowknownasthe Turingtest, heproposedthatamachinecanbeconsideredintelligentifitisdifficultforahumanevalu- atortodistinguishbetweentherepliesfromamachineandthoseofahuman, basedpurely 28 ontextualinteractions.
Furtherinfluencescamefromneuroscienceandpsychology.
Afterall, humansclearlyex- hibitintelligentbehavior.
Manyscholarshaveaskedwhetheronecouldexplainandpos- siblyreverseengineerthiscapacity.
Oneofthefirstbiologicallyinspiredalgorithmswas formulatedby Donald Hebb(1904â€“1985)29.
Inhisgroundbreakingbook The Organiza- 29 tion of Behavior (Hebb, 1949), he posited that neurons learn by positive reinforcement.
This became known as the Hebbian learning rule.
These ideas inspired later work, such as Rosenblattâ€™sperceptronlearningalgorithm, andlaidthefoundationsofmanystochastic gradientdescentalgorithmsthatunderpindeeplearningtoday: reinforcedesirablebehav- ioranddiminishundesirablebehaviortoobtaingoodsettingsoftheparametersinaneural network.
22 Introduction Biologicalinspirationiswhatgaveneuralnetworkstheirname.
Foroveracentury(dating back to the models of Alexander Bain, 1873, and James Sherrington, 1890), researchers havetriedtoassemblecomputationalcircuitsthatresemblenetworksofinteractingneurons.
Overtime, theinterpretationofbiologyhasbecomelessliteral, butthenamestuck.
Atits heartlieafewkeyprinciplesthatcanbefoundinmostnetworkstoday: Thealternationoflinearandnonlinearprocessingunits, oftenreferredtoaslayers.
Theuseofthechainrule(alsoknownasbackpropagation)foradjustingparametersin theentirenetworkatonce.
Afterinitialrapidprogress, researchinneuralnetworkslanguishedfromaround1995until 2005.
This was mainly due to two reasons.
First, training a network is computationally veryexpensive.
Whilerandom-accessmemorywasplentifulattheendofthepastcentury, computationalpowerwasscarce.
Second, datasetswererelativelysmall.
Infact, Fisherâ€™s Iris dataset from 1936 wasstilla popular tool fortestingthe efficacy of algorithms.
The MNISTdatasetwithits60,000handwrittendigitswasconsideredhuge.
Giventhescarcityofdataandcomputation, strongstatisticaltoolssuchaskernelmethods, decision trees, and graphical models proved empirically superior in many applications.
Moreover, unlike neural networks, they did not require weeks to train and provided pre- dictableresultswithstrongtheoreticalguarantees.
1.5 The Road to Deep Learning Muchofthischangedwiththeavailabilityofmassiveamountsofdata, thankstothe World Wide Web, the advent of companies serving hundreds of millions of users online, a dis- seminationoflow-cost, high-qualitysensors, inexpensivedatastorage(Kryderâ€™slaw), and cheap computation (Mooreâ€™s law).
In particular, the landscape of computation in deep learningwasrevolutionizedbyadvancesin GPUsthatwereoriginallyengineeredforcom- puter gaming.
Suddenly algorithms and models that seemed computationally infeasible werewithinreach.
Thisisbestillustratedintab_intro_decade.
: Datasetvs.
computermemoryandcomputationalpower Table 1.5.1: label: tab_intro_decade 23 The Roadto Deep Learning Decade Dataset Mem- Floating point calculations per ory second 1970 100(Iris) 1KB 100KF(Intel8080) 1980 1K(housepricesin Boston) 100 1MF(Intel80186) KB 1990 10K(opticalcharacterrecog- 10MB 10MF(Intel80486) nition) 2000 10M(webpages) 100 1GF(Intel Core) MB 2010 10G(advertising) 1GB 1TF(NVIDIAC2050) 2020 1T(socialnetwork) 100 1PF(NVIDIADGX-2) GB Notethatrandom-accessmemoryhasnotkeptpacewiththegrowthindata.
Atthesame time, increasesincomputationalpowerhaveoutpacedthegrowthindatasets.
Thismeans thatstatisticalmodelsneedtobecomemorememoryefficient, andsotheyarefreetospend more computer cycles optimizing parameters, thanks to the increased compute budget.
Consequently, thesweetspotinmachinelearningandstatisticsmovedfrom(generalized) linear models and kernel methods to deep neural networks.
This is also one of the rea- sonswhymanyofthemainstaysofdeeplearning, suchasmultilayerperceptrons(Mc Cul- lochand Pitts,1943), convolutionalneuralnetworks(Le Cunetal.,1998), longshort-term memory(Hochreiterand Schmidhuber,1997), and Q-Learning(Watkinsand Dayan,1992), wereessentiallyâ€œrediscoveredâ€inthepastdecade, afterlyingcomparativelydormantfor considerabletime.
Therecentprogressinstatisticalmodels, applications, andalgorithmshassometimesbeen likenedtothe Cambrianexplosion: amomentofrapidprogressintheevolutionofspecies.
Indeed, the state of the art is not just a mere consequence of available resources applied todecades-oldalgorithms.
Notethatthelistofideasbelowbarelyscratchesthesurfaceof whathashelpedresearchersachievetremendousprogressoverthepastdecade.
Novelmethodsforcapacitycontrol, suchasdropout(Srivastavaetal.,2014), havehelped tomitigateoverfitting.
Here, noiseisinjected(Bishop, 1995)throughouttheneural networkduringtraining.
Attention mechanisms solved a second problem that had plagued statistics for over a century: howtoincreasethememoryandcomplexityofasystemwithoutincreasing thenumberoflearnableparameters.
Researchersfoundanelegantsolutionbyusing what can only be viewed as a learnable pointer structure (Bahdanau et al., 2014).
Ratherthanhavingtorememberanentiretextsequence, e.
g., formachinetranslation inafixed-dimensionalrepresentation, allthatneededtobestoredwasapointertothe intermediatestateofthetranslationprocess.
Thisallowedforsignificantlyincreased accuracyforlongsequences, sincethemodelnolongerneededtoremembertheentire sequencebeforecommencingthegenerationofanewone.
Builtsolelyonattentionmechanisms, the Transformerarchitecture(Vaswanietal.,2017) 24 Introduction has demonstrated superior scaling behavior: it performs better with an increase in datasetsize, modelsize, andamountoftrainingcompute(Kaplanetal.,2020).
This architecture has demonstrated compelling success in a wide range of areas, such as naturallanguageprocessing(Brownetal.,2020, Devlinetal.,2018), computervision (Dosovitskiyetal., 2021, Liuetal., 2021), speechrecognition(Gulatietal., 2020), reinforcementlearning(Chenetal.,2021), andgraphneuralnetworks(Dwivediand Bresson,2020).
Forexample, asingle Transformerpretrainedonmodalitiesasdiverse astext, images, jointtorques, andbuttonpressescanplay Atari, captionimages, chat, andcontrolarobot(Reedetal.,2022).
Modelingprobabilitiesoftextsequences, languagemodelscanpredicttextgivenother text.
Scaling up the data, model, and compute has unlocked a growing number of capabilitiesoflanguagemodelstoperformdesiredtasksviahuman-liketextgenera- tionbasedoninputtext(Aniletal.,2023, Brownetal.,2020, Chowdheryetal.,2022, Hoffmannetal.,2022, Open AI,2023, Raeetal.,2021, Touvronetal.,2023a, Touvron etal.,2023b).
Forinstance, aligninglanguagemodelswithhumanintent(Ouyanget al., 2022), Open AIâ€™s Chat GPT30 allowsuserstointeractwithitinaconversational 30 waytosolveproblems, suchascodedebuggingandcreativewriting.
Multi-stagedesigns, e.
g., viathememorynetworks(Sukhbaataretal.,2015)andtheneu- ralprogrammer-interpreter(Reedand De Freitas,2015)permittedstatisticalmodelers todescribeiterativeapproachestoreasoning.
Thesetoolsallowforaninternalstateof thedeepneuralnetworktobemodifiedrepeatedly, thuscarryingoutsubsequentsteps inachainofreasoning, justasaprocessorcanmodifymemoryforacomputation.
Akeydevelopmentindeepgenerativemodelingwastheinventionofgenerativeadver- sarialnetworks(Goodfellowetal.,2014).
Traditionally, statisticalmethodsfordensity estimationandgenerativemodelsfocusedonfindingproperprobabilitydistributions and(oftenapproximate)algorithmsforsamplingfromthem.
Asaresult, thesealgo- rithmswerelargelylimitedbythelackofflexibilityinherentinthestatisticalmodels.
Thecrucialinnovationingenerativeadversarialnetworkswastoreplacethesampler byanarbitraryalgorithmwithdifferentiableparameters.
Thesearethenadjustedin such a way that the discriminator (effectively a two-sample test) cannot distinguish fakefromrealdata.
Throughtheabilitytousearbitraryalgorithmstogeneratedata, densityestimationwasopeneduptoawidevarietyoftechniques.
Examplesofgal- lopingzebras(Zhuetal., 2017)andoffakecelebrityfaces(Karrasetal., 2017)are each testimony to this progress.
Even amateur doodlers can produce photorealistic imagesjustbasedonsketchesdescribingthelayoutofascene(Parketal.,2019).
Furthermore, whilethediffusionprocessgraduallyaddsrandomnoisetodatasamples, diffusionmodels(Hoetal.,2020, Sohl-Dicksteinetal.,2015)learnthedenoisingpro- cess to gradually construct data samples from random noise, reversing the diffusion process.
Theyhavestartedtoreplacegenerativeadversarialnetworksinmorerecent deepgenerativemodels, suchasin DALL-E2(Rameshetal.,2022)and Imagen(Sa- hariaetal.,2022)forcreativeartandimagegenerationbasedontextdescriptions.
In many cases, a single GPU is insufficient for processing the large amounts of data 25 Success Stories availablefortraining.
Overthepastdecadetheabilitytobuildparallelanddistributed trainingalgorithmshasimprovedsignificantly.
Oneofthekeychallengesindesigning scalable algorithms is that the workhorse of deep learning optimization, stochastic gradient descent, relies on relatively small minibatches of data to be processed.
At thesametime, smallbatcheslimittheefficiencyof GPUs.
Hence, trainingon1,024 GPUs with a minibatch size of, say, 32 images per batch amounts to an aggregate minibatchofabout32,000images.
Work, firstby Li(2017)andsubsequentlyby You 31 etal.
(2017)and Jiaetal.
(2018)pushedthesizeupto64,000observations, reducing trainingtimeforthe Res Net-50modelonthe Image Netdatasettolessthan7minutes.
Bycomparison, trainingtimeswereinitiallyoftheorderofdays.
32 Theabilitytoparallelizecomputationhasalsocontributedtoprogressinreinforcement learning.
This has led to significant progress in computers achieving superhuman performanceontaskslike Go, Atarigames, Starcraft, andinphysicssimulations(e.
g., 33 using Mu Jo Co) where environment simulators are available.
See, e.
g., Silver et al.
(2016)foradescriptionofsuchachievementsin Alpha Go.
Inanutshell, reinforcement learningworksbestifplentyof(state, action, reward)tuplesareavailable.
Simulation providessuchanavenue.
34 Deep learning frameworks have played a crucial role in disseminating ideas.
The first generationofopen-sourceframeworksforneuralnetworkmodelingconsistedof Caffe 35 31, Torch32, and Theano33.
Many seminal papers were written using these tools.
Thesehavenowbeensupersededby Tensor Flow34 (oftenusedviaitshigh-level API Keras35), CNTK36, Caffe 237, and Apache MXNet38.
The third generation of frameworksconsistsofso-calledimperativetoolsfordeeplearning, atrendthatwas 36 arguably ignited by Chainer39, which used a syntax similar to Python Num Py to describe models.
This idea was adopted by both Py Torch40, the Gluon API41 of MXNet, and JAX42.
37 Thedivisionoflaborbetweensystemresearchersbuildingbettertoolsandstatisticalmod- elersbuildingbetterneuralnetworkshasgreatlysimplifiedthings.
Forinstance, traininga linearlogisticregressionmodelusedtobeanontrivialhomeworkproblem, worthytogive 38 tonewmachinelearning Ph.
D.
studentsat Carnegie Mellon Universityin2014.
Bynow, thistaskcanbeaccomplishedwithunder10linesofcode, puttingitfirmlywithinthereach ofanyprogrammer.
39 1.6 Success Stories 40 41 Artificialintelligencehasalonghistoryofdeliveringresultsthatwouldbedifficulttoac- complishotherwise.
Forinstance, mailsortingsystemsusingopticalcharacterrecognition have been deployed since the 1990s.
This is, after all, the source of the famous MNIST 42 dataset of handwritten digits.
The same applies to reading checks for bank deposits and scoringcreditworthinessofapplicants.
Financialtransactionsarecheckedforfraudauto- 26 Introduction matically.
Thisformsthebackboneofmanye-commercepaymentsystems, suchas Pay Pal, Stripe, Ali Pay, We Chat, Apple, Visa, and Master Card.
Computerprogramsforchesshave beencompetitivefordecades.
Machinelearningfeedssearch, recommendation, personal- ization, andrankingonthe Internet.
Inotherwords, machinelearningispervasive, albeit oftenhiddenfromsight.
Itisonlyrecentlythat AIhasbeeninthelimelight, mostlyduetosolutionstoproblemsthat wereconsideredintractablepreviouslyandthataredirectlyrelatedtoconsumers.
Manyof suchadvancesareattributedtodeeplearning.
Intelligentassistants, suchas Appleâ€™s Siri, Amazonâ€™s Alexa, and Googleâ€™sassistant, are able to respond to spoken requests with a reasonable degree of accuracy.
This in- cludes menial jobs, like turning on light switches, and more complex tasks, such as arrangingbarberâ€™sappointmentsandofferingphonesupportdialog.
Thisislikelythe mostnoticeablesignthat AIisaffectingourlives.
Akeyingredientindigitalassistantsistheirabilitytorecognizespeechaccurately.
The accuracyofsuchsystemshasgraduallyincreasedtothepointofachievingparitywith humansforcertainapplications(Xiongetal.,2018).
Objectrecognitionhaslikewisecomealongway.
Identifyingtheobjectinapicturewas afairlychallengingtaskin2010.
Onthe Image Netbenchmarkresearchersfrom NEC Labs and University of Illinois at Urbana-Champaign achieved a top-five error rate of28%(Linetal.,2010).
By2017, thiserrorratewasreducedto2.25%(Huetal., 2018).
Similarly, stunningresultshavebeenachievedforidentifyingbirdsongandfor diagnosingskincancer.
Prowess in games used to provide a measuring stick for human ability.
Starting from TD-Gammon, a program for playing backgammon using temporal difference rein- forcementlearning, algorithmicandcomputationalprogresshasledtoalgorithmsfor awiderangeofapplications.
Comparedwithbackgammon, chesshasamuchmore complex state space and set of actions.
Deep Blue beat Garry Kasparov using mas- siveparallelism, special-purposehardwareandefficientsearchthroughthegametree (Campbelletal.,2002).
Goismoredifficultstill, duetoitshugestatespace.
Alpha Go reachedhumanparityin2015, usingdeeplearningcombinedwith Monte Carlotree sampling(Silveretal.,2016).
Thechallengein Pokerwasthatthestatespaceislarge andonlypartiallyobserved(wedonotknowtheopponentsâ€™cards).
Libratusexceeded humanperformancein Pokerusingefficientlystructuredstrategies(Brownand Sand- holm,2017).
Another indication of progress in AI is the advent of self-driving vehicles.
While full autonomyisnotyetwithinreach, excellentprogresshasbeenmadeinthisdirection, with companies such as Tesla, NVIDIA, and Waymo shipping products that enable partial autonomy.
What makes full autonomy so challenging is that proper driving requirestheabilitytoperceive, toreasonandtoincorporaterulesintoasystem.
At present, deeplearningisusedprimarilyinthevisualaspectoftheseproblems.
The restisheavilytunedbyengineers.
27 The Essenceof Deep Learning This barely scratches the surface of significant applications of machine learning.
For in- stance, robotics, logistics, computational biology, particle physics, and astronomy owe someoftheirmostimpressiverecentadvancesatleastinpartstomachinelearning, which isthusbecomingaubiquitoustoolforengineersandscientists.
Frequently, questions about a coming AI apocalypse and the plausibility of a singularity have been raised in non-technical articles.
The fear is that somehow machine learning systems will become sentient and make decisions, independently of their programmers, thatdirectlyimpactthelivesofhumans.
Tosomeextent, AIalreadyaffectsthelivelihood of humans in direct ways: creditworthiness is assessed automatically, autopilots mostly navigatevehicles, decisionsaboutwhethertograntbailusestatisticaldataasinput.
More frivolously, wecanask Alexatoswitchonthecoffeemachine.
Fortunately, we are far from a sentient AI system that could deliberately manipulate its humancreators.
First, AIsystemsareengineered, trained, anddeployedinaspecific, goal- orientedmanner.
Whiletheirbehaviormightgivetheillusionofgeneralintelligence, itisa combinationofrules, heuristicsandstatisticalmodelsthatunderliethedesign.
Second, at present, therearesimplynotoolsforartificialgeneralintelligencethatareabletoimprove themselves, reasonaboutthemselves, andthatareabletomodify, extend, andimprovetheir ownarchitecturewhiletryingtosolvegeneraltasks.
Amuchmorepressingconcernishow AIisbeingusedinourdailylives.
Itislikelythat manyroutinetasks, currentlyfulfilledbyhumans, canandwillbeautomated.
Farmrobots willlikelyreducethecostsfororganicfarmersbuttheywillalsoautomateharvestingop- erations.
Thisphaseoftheindustrialrevolutionmayhaveprofoundconsequencesforlarge swaths of society, since menial jobs provide much employment in many countries.
Fur- thermore, statisticalmodels, whenappliedwithoutcare, canleadtoracial, gender, orage biasandraisereasonableconcernsaboutproceduralfairnessifautomatedtodriveconse- quentialdecisions.
Itisimportanttoensurethatthesealgorithmsareusedwithcare.
With whatweknowtoday, thisstrikesusasamuchmorepressingconcernthanthepotentialof malevolentsuperintelligencefordestroyinghumanity.
1.7 The Essence of Deep Learning Thusfar, wehavetalkedinbroadtermsaboutmachinelearning.
Deeplearningisthesubset ofmachinelearningconcernedwithmodelsbasedonmany-layeredneuralnetworks.
Itis deepinpreciselythesensethatitsmodelslearnmanylayersoftransformations.
Whilethis mightsoundnarrow, deeplearninghasgivenrisetoadizzyingarrayofmodels, techniques, problemformulations, andapplications.
Manyintuitionshavebeendevelopedtoexplain thebenefitsofdepth.
Arguably, allmachinelearninghasmanylayersofcomputation, the first consisting of feature processing steps.
What differentiates deep learning is that the operations learned at each of the many layers of representations are learned jointly from data.
28 Introduction Theproblemsthatwehavediscussedsofar, suchaslearningfromtherawaudiosignal, the raw pixel values of images, or mapping between sentences of arbitrary lengths and their counterparts in foreign languages, are those where deep learning excels and traditional methodsfalter.
Itturnsoutthatthesemany-layeredmodelsarecapableofaddressinglow- levelperceptualdatainawaythatprevioustoolscouldnot.
Arguablythemostsignificant commonalityindeeplearningmethodsisend-to-endtraining.
Thatis, ratherthanassem- blingasystembasedoncomponentsthatareindividuallytuned, onebuildsthesystemand then tunes their performance jointly.
For instance, in computer vision scientists used to separate the process of feature engineering from the process of building machine learn- ing models.
The Canny edge detector (Canny, 1987) and Loweâ€™s SIFT feature extractor (Lowe, 2004) reigned supreme for over a decade as algorithms for mapping images into feature vectors.
In bygone days, the crucial part of applying machine learning to these problemsconsistedofcomingupwithmanually-engineeredwaysoftransformingthedata into some form amenable to shallow models.
Unfortunately, there is only so much that humanscanaccomplishbyingenuityincomparisonwithaconsistentevaluationovermil- lionsofchoicescarriedoutautomaticallybyanalgorithm.
Whendeeplearningtookover, thesefeatureextractorswerereplacedbyautomaticallytunedfiltersthatyieldedsuperior accuracy.
Thus, onekeyadvantageofdeeplearningisthatitreplacesnotonlytheshallowmodelsat theendoftraditionallearningpipelines, butalsothelabor-intensiveprocessoffeatureengi- neering.
Moreover, byreplacingmuchofthedomain-specificpreprocessing, deeplearning haseliminatedmanyoftheboundariesthatpreviouslyseparatedcomputervision, speech recognition, naturallanguageprocessing, medicalinformatics, andotherapplicationareas, therebyofferingaunifiedsetoftoolsfortacklingdiverseproblems.
Beyond end-to-end training, we are experiencing a transition from parametric statistical descriptionstofullynonparametricmodels.
Whendataisscarce, oneneedstorelyonsim- plifyingassumptionsaboutrealityinordertoobtainusefulmodels.
Whendataisabundant, thesecanbereplacedbynonparametricmodelsthatbetterfitthedata.
Tosomeextent, this mirrors the progress that physics experienced in the middle of the previous century with theavailabilityofcomputers.
Ratherthansolvingbyhandparametricapproximationsof howelectronsbehave, onecannowresorttonumericalsimulationsoftheassociatedpar- tialdifferentialequations.
Thishasledtomuchmoreaccuratemodels, albeitoftenatthe expenseofinterpretation.
Anotherdifferencefrompreviousworkistheacceptanceofsuboptimalsolutions, dealing withnonconvexnonlinearoptimizationproblems, andthewillingnesstotrythingsbefore provingthem.
Thisnew-foundempiricismindealingwithstatisticalproblems, combined witharapidinfluxoftalenthasledtorapidprogressinthedevelopmentofpracticalalgo- rithms, albeitinmanycasesattheexpenseofmodifyingandre-inventingtoolsthatexisted fordecades.
Intheend, thedeeplearningcommunitypridesitselfonsharingtoolsacrossacademicand corporate boundaries, releasing many excellent libraries, statistical models, and trained networksasopensource.
Itisinthisspiritthatthenotebooksformingthisbookarefreely availablefordistributionanduse.
Wehaveworkedhardtolowerthebarriersofaccessfor 29 Summary anyonewishingtolearnaboutdeeplearningandwehopethatourreaderswillbenefitfrom this.
1.8 Summary Machine learning studies how computer systems can leverage experience (often data) to improveperformanceatspecifictasks.
Itcombinesideasfromstatistics, datamining, and optimization.
Often, it is used as a means of implementing AI solutions.
As a class of machine learning, representational learning focuses on how to automatically find the ap- propriatewaytorepresentdata.
Consideredasmulti-levelrepresentationlearningthrough learningmanylayersoftransformations, deeplearningreplacesnotonlytheshallowmod- elsattheendoftraditionalmachinelearningpipelines, butalsothelabor-intensiveprocess of feature engineering.
Much of the recent progress in deep learning has been triggered by an abundance of data arising from cheap sensors and Internet-scale applications, and bysignificantprogressincomputation, mostlythrough GPUs.
Furthermore, theavailabil- ity of efficient deep learning frameworks has made design and implementation of whole system optimization significantly easier, and this is a key component in obtaining high performance.
1.9 Exercises 1.
Which parts of code that you are currently writing could be â€œlearnedâ€, i.
e., improved bylearningandautomaticallydeterminingdesignchoicesthataremadeinyourcode? Does your code include heuristic design choices? What data might you need to learn thedesiredbehavior? 2.
Whichproblemsthatyouencounterhavemanyexamplesfortheirsolution, yetnospe- cificwayforautomatingthem? Thesemaybeprimecandidatesforusingdeeplearning.
3.
Describe the relationships between algorithms, data, and computation.
How do char- acteristics of the data and the current available computational resources influence the appropriatenessofvariousalgorithms? 4.
Namesomesettingswhereend-to-endtrainingisnotcurrentlythedefaultapproachbut whereitmightbeuseful.
Discussions43.
43 2 Preliminaries Toprepareforyourdiveintodeeplearning, youwillneedafewsurvivalskills: (i)tech- niquesforstoringandmanipulatingdata;(ii)librariesforingestingandpreprocessingdata fromavarietyofsources; (iii)knowledgeofthebasiclinearalgebraicoperationsthatwe applytohigh-dimensionaldataelements;(iv)justenoughcalculustodeterminewhichdi- rection to adjust each parameter in order to decrease the loss function; (v) the ability to automatically compute derivatives so that you can forget much of the calculus you just learned;(vi)somebasicfluencyinprobability, ourprimarylanguageforreasoningunder uncertainty; and(vii)someaptitudeforfindinganswersintheofficialdocumentationwhen yougetstuck.
Inshort, thischapterprovidesarapidintroductiontothebasicsthatyouwillneedtofollow mostofthetechnicalcontentinthisbook.
2.1 Data Manipulation Inordertogetanythingdone, weneedsomewaytostoreandmanipulatedata.
Generally, therearetwoimportantthingsweneedtodowithdata: (i)acquirethem; and(ii)process themoncetheyareinsidethecomputer.
Thereisnopointinacquiringdatawithoutsome way to store it, so to start, letâ€™s get our hands dirty with ğ‘›-dimensional arrays, which we alsocalltensors.
Ifyoualreadyknowthe Num Pyscientificcomputingpackage, thiswillbe abreeze.
Forallmoderndeeplearningframeworks, thetensorclass(ndarrayin MXNet, Tensorin Py Torchand Tensor Flow)resembles Num Pyâ€™sndarray, withafewkillerfea- turesadded.
First, thetensorclasssupportsautomaticdifferentiation.
Second, itleverages GPUs to accelerate numerical computation, whereas Num Py only runs on CPUs.
These propertiesmakeneuralnetworksbotheasytocodeandfasttorun.
2.1.1 Getting Started Tostart, weimportthe Py Torchlibrary.
Notethatthepackagenameistorch.
import torch Atensorrepresentsa(possiblymultidimensional)arrayofnumericalvalues.
Intheone- dimensionalcase, i.
e., whenonlyoneaxisisneededforthedata, atensoriscalledavector.
30 31 Data Manipulation Withtwoaxes, atensoriscalledamatrix.
Withğ‘˜ >2axes, wedropthespecializednames andjustrefertotheobjectasağ‘˜th-ordertensor.
Py Torchprovidesavarietyoffunctionsforcreatingnewtensorsprepopulatedwithvalues.
Forexample, byinvokingarange(n), wecancreateavectorofevenlyspacedvalues, start- ingat0(included)andendingatn(notincluded).
Bydefault, theintervalsizeis1.
Unless otherwisespecified, newtensorsarestoredinmainmemoryanddesignatedfor CPU-based computation.
x = torch.
arange(12, dtype=torch.
float32) x Eachofthesevaluesiscalledanelementofthetensor.
Thetensorxcontains12elements.
Wecaninspectthetotalnumberofelementsinatensorviaitsnumelmethod.
x.
numel() 12 Wecanaccessatensorâ€™sshape(thelengthalongeachaxis)byinspectingitsshapeattribute.
Becausewearedealingwithavectorhere, theshapecontainsjustasingleelementandis identicaltothesize.
x.
shape torch.
Size([12]) Wecanchangetheshapeofatensorwithoutalteringitssizeorvalues, byinvokingreshape.
Forexample, wecantransformourvectorxwhoseshapeis(12,)toamatrix Xwithshape (3,4).
Thisnewtensorretainsallelementsbutreconfiguresthemintoamatrix.
Noticethat theelementsofourvectorarelaidoutonerowatatimeandthusx[3] == X[0, 3].
X = x.
reshape(3, 4) X tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]) Notethatspecifyingeveryshapecomponenttoreshapeisredundant.
Becausewealready knowourtensorâ€™ssize, wecanworkoutonecomponentoftheshapegiventherest.
For example, given a tensor of size ğ‘› and target shape (â„, ğ‘¤), we know that ğ‘¤ = ğ‘› â„.
To 32 Preliminaries automaticallyinferonecomponentoftheshape, wecanplacea-1fortheshapecomponent thatshouldbeinferredautomatically.
Inourcase, insteadofcallingx.
reshape(3, 4), we couldhaveequivalentlycalledx.
reshape(-1, 4)orx.
reshape(3, -1).
Practitioners often need to work with tensors initialized to contain all 0s or 1s.
We can construct a tensor with all elements set to 0 and a shape of (2, 3, 4) via the zeros func- tion.
torch.
zeros((2, 3, 4)) tensor([[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]]) Similarly, wecancreateatensorwithall1sbyinvokingones.
torch.
ones((2, 3, 4)) tensor([[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]]) Weoftenwishtosampleeachelementrandomly(andindependently)fromagivenprob- ability distribution.
For example, the parameters of neural networks are often initialized randomly.
The following snippet creates a tensor with elements drawn from a standard Gaussian(normal)distributionwithmean0andstandarddeviation1.
torch.
randn(3, 4) tensor([[ 0.1351, -0.9099, -0.2028, 2.1937], [-0.3200, -0.7545, 0.8086, -1.8730], [ 0.3929, 0.4931, 0.9114, -0.7072]]) Finally, we can construct tensors by supplying the exact values for each element by sup- plying(possiblynested)Pythonlist(s)containingnumericalliterals.
Here, weconstructa matrixwithalistoflists, wheretheoutermostlistcorrespondstoaxis0, andtheinnerlist correspondstoaxis1.
33 Data Manipulation torch.
tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) 2.1.2 Indexingand Slicing Aswith Pythonlists, wecanaccesstensorelementsbyindexing(startingwith0).
Toaccess anelementbasedonitspositionrelativetotheendofthelist, wecanusenegativeindexing.
Finally, we can access whole ranges of indices via slicing (e.
g., X[start: stop]), where the returned value includes the first index (start) but not the last (stop).
Finally, when onlyoneindex(orslice)isspecifiedforağ‘˜th-ordertensor, itisappliedalongaxis0.
Thus, in the following code, [-1] selects the last row and [1:3] selects the second and third rows.
X[-1], X[1:3] (tensor([ 8., 9., 10., 11.]), tensor([[ 4., 5., 6., 7.], [ 8., 9., 10., 11.]])) Beyondreadingthem, wecanalsowriteelementsofamatrixbyspecifyingindices.
X[1, 2] = 17 X tensor([[ 0., 1., 2., 3.], [ 4., 5., 17., 7.], [ 8., 9., 10., 11.]]) Ifwewanttoassignmultipleelementsthesamevalue, weapplytheindexingontheleft- handsideoftheassignmentoperation.
Forinstance,[:2, :] accessesthefirstandsecond rows, where: takesalltheelementsalongaxis1(column).
Whilewediscussedindexing formatrices, thisalsoworksforvectorsandfortensorsofmorethantwodimensions.
X[:2, :] = 12 X tensor([[12., 12., 12., 12.], [12., 12., 12., 12.], [ 8., 9., 10., 11.]]) 34 Preliminaries 2.1.3 Operations Nowthatweknowhowtoconstructtensorsandhowtoreadfromandwritetotheirele- ments, wecanbegintomanipulatethemwithvariousmathematicaloperations.
Amongthe mostusefulofthesearetheelementwiseoperations.
Theseapplyastandardscalaropera- tiontoeachelementofatensor.
Forfunctionsthattaketwotensorsasinputs, elementwise operations apply some standard binary operator on each pair of corresponding elements.
We can create an elementwise function from any function that maps from a scalar to a scalar.
Inmathematicalnotation, wedenotesuchunaryscalaroperators(takingoneinput)bythe signature ğ‘“ : R ! R.
Thisjustmeansthatthefunctionmapsfromanyrealnumberonto some other real number.
Most standard operators, including unary ones like ğ‘’ğ‘¥ , can be appliedelementwise.
torch.
exp(x) 22026.4648, 59874.1406]) Likewise, wedenotebinaryscalaroperators, whichmappairsofrealnumberstoa(single) real number via the signature ğ‘“ : R, R ! R.
Given any two vectors u and v of the same shape, and a binary operator ğ‘“, we can produce a vector c = ğ¹â€u, vâ€ by setting ğ‘ ğ‘– ğ‘“â€ğ‘¢ ğ‘– ,ğ‘£ ğ‘– â€ for all ğ‘–, where ğ‘ ğ‘– ,ğ‘¢ ğ‘–, and ğ‘£ ğ‘– are the ğ‘–th elements of vectors c, u, and v.
Here, weproducedthevector-valuedğ¹ : Rğ‘‘, Rğ‘‘ ! Rğ‘‘ byliftingthescalarfunctiontoan elementwisevectoroperation.
Thecommonstandardarithmeticoperatorsforaddition(+), subtraction(-), multiplication(*), division(/), andexponentiation(**)haveallbeenlifted toelementwiseoperationsforidentically-shapedtensorsofarbitraryshape.
x = torch.
tensor([1.0, 2, 4, 8]) y = torch.
tensor([2, 2, 2, 2]) x + y, x - y, x * y, x / y, x ** y (tensor([ 3., 4., 6., 10.]), tensor([-1., 0., 2., 6.]), tensor([ 2., 4., 8., 16.]), tensor([0.5000, 1.0000, 2.0000, 4.0000]), tensor([ 1., 4., 16., 64.])) Inadditiontoelementwisecomputations, wecanalsoperformlinearalgebraicoperations, such as dot products and matrix multiplications.
We will elaborate on these in Section 2.3.
Wecanalsoconcatenatemultipletensors, stackingthemend-to-endtoformalargerone.
Wejustneedtoprovidealistoftensorsandtellthesystemalongwhichaxistoconcatenate.
The example below shows what happens when we concatenate two matrices along rows 35 Data Manipulation (axis0)insteadofcolumns(axis1).
Wecanseethatthefirstoutputâ€™saxis-0length(6)is thesumofthetwoinputtensorsâ€™axis-0lengths(3â€š3); whilethesecondoutputâ€™saxis-1 length(8)isthesumofthetwoinputtensorsâ€™axis-1lengths(4â€š4).
X = torch.
arange(12, dtype=torch.
float32).
reshape((3,4)) Y = torch.
tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) torch.
cat((X, Y), dim=0), torch.
cat((X, Y), dim=1) (tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [ 2., 1., 4., 3.], [ 1., 2., 3., 4.], [ 4., 3., 2., 1.]]), Sometimes, wewanttoconstructabinarytensorvialogicalstatements.
Take X == Yasan example.
Foreachpositioni, j, if X[i, j]and Y[i, j]areequal, thenthecorresponding entryintheresulttakesvalue1, otherwiseittakesvalue0.
X == Y tensor([[False, True, False, True], [False, False, False, False], [False, False, False, False]]) Summingalltheelementsinthetensoryieldsatensorwithonlyoneelement.
X.
sum() tensor(66.) 2.1.4 Broadcasting By now, you know how to perform elementwise binary operations on two tensors of the sameshape.
Undercertainconditions, evenwhenshapesdiffer, wecanstillperformele- mentwisebinaryoperationsbyinvokingthebroadcastingmechanism.
Broadcastingworks accordingto thefollowingtwo-stepprocedure: (i)expandoneorbotharraysbycopying elementsalongaxeswithlength1sothatafterthistransformation, thetwotensorshavethe sameshape;(ii)performanelementwiseoperationontheresultingarrays.
a = torch.
arange(3).
reshape((3, 1)) b = torch.
arange(2).
reshape((1, 2)) a, b 36 Preliminaries (tensor([[0], [1], [2]]), tensor([[0, 1]])) Since a and b are 3 1 and 1 2 matrices, respectively, their shapes do not match up.
Broadcastingproducesalarger3 2matrixbyreplicatingmatrixaalongthecolumnsand matrixbalongtherowsbeforeaddingthemelementwise.
a + b tensor([[0, 1], [1, 2], [2, 3]]) 2.1.5 Saving Memory Runningoperationscancausenewmemorytobeallocatedtohostresults.
Forexample, if wewrite Y = X + Y, wedereferencethetensorthat Yusedtopointtoandinsteadpoint Yat thenewlyallocatedmemory.
Wecandemonstratethisissuewith Pythonâ€™sid()function, which gives us the exact address of the referenced object in memory.
Note that after we run Y = Y + X, id(Y)pointstoadifferentlocation.
Thatisbecause Pythonfirstevaluates Y + X, allocating new memory for the result and then points Y to this new location in memory.
before = id(Y) Y = Y + X id(Y) == before False This might be undesirable for two reasons.
First, we do not want to run around allocat- ing memory unnecessarily all the time.
In machine learning, we often have hundreds of megabytes of parameters and update all of them multiple times per second.
Whenever possible, wewanttoperformtheseupdatesinplace.
Second, wemightpointatthesame parameters from multiple variables.
If we do not update in place, we must be careful to updateallofthesereferences, lestwespringamemoryleakorinadvertentlyrefertostale parameters.
Fortunately, performing in-place operations is easy.
Wecan assign the result of an oper- ation to a previously allocated array Y by using slice notation: Y[:] = <expression>.
To illustrate this concept, we overwrite the values of tensor Z, after initializing it, using zeros_like, tohavethesameshapeas Y.
37 Data Manipulation Z = torch.
zeros_like(Y) print('id(Z):', id(Z)) Z[:] = X + Y print('id(Z):', id(Z)) id(Z): 140381179266448 id(Z): 140381179266448 Ifthevalueof Xisnotreusedinsubsequentcomputations, wecanalsouse X[:] = X + Y or X += Ytoreducethememoryoverheadoftheoperation.
before = id(X) X += Y id(X) == before True 2.1.6 Conversionto Other Python Objects Converting to a Num Py tensor (ndarray), or vice versa, is easy.
The torch tensor and Num Py array will share their underlying memory, and changing one through an in-place operationwillalsochangetheother.
A = X.
numpy() B = torch.
from_numpy(A) type(A), type(B) (numpy.
ndarray, torch.
Tensor) Toconvertasize-1tensortoa Pythonscalar, wecaninvoketheitemfunctionor Pythonâ€™s built-infunctions.
a = torch.
tensor([3.5]) a, a.
item(), float(a), int(a) (tensor([3.5000]), 3.5, 3.5, 3) 2.1.7 Summary Thetensorclassisthemaininterfaceforstoringandmanipulatingdataindeeplearningli- braries.
Tensorsprovideavarietyoffunctionalitiesincludingconstructionroutines; index- ingandslicing; basicmathematicsoperations; broadcasting; memory-efficientassignment; andconversiontoandfromother Pythonobjects.
38 Preliminaries 2.1.8 Exercises 1.
Runthecodeinthissection.
Changetheconditionalstatement X == Yto X < Yor X > Y, andthenseewhatkindoftensoryoucanget.
2.
Replace the two tensors that operate by element in the broadcasting mechanism with othershapes, e.
g.,3-dimensionaltensors.
Istheresultthesameasexpected? Discussions44.
44 2.2 Data Preprocessing Sofar, wehavebeenworkingwithsyntheticdatathatarrivedinready-madetensors.
How- ever, to apply deep learning in the wild we must extract messy data stored in arbitrary formats, andpreprocessittosuitourneeds.
Fortunately, thepandaslibrary45 candomuch 45 oftheheavylifting.
Thissection, whilenosubstituteforaproperpandastutorial46, will giveyouacrashcourseonsomeofthemostcommonroutines.
46 2.2.1 Readingthe Dataset Comma-separatedvalues(CSV)filesareubiquitousforthestoringoftabular(spreadsheet- like)data.
Inthem, eachlinecorrespondstoonerecordandconsistsofseveral(comma- separated)fields, e.
g.,â€œAlbert Einstein, March141879, Ulm, Federalpolytechnicschool, field ofgravitationalphysicsâ€.
Todemonstratehowtoload CSVfileswithpandas, wecreatea CSVfilebelow../data/house_tiny.
csv.
Thisfilerepresentsadatasetofhomes, where each row corresponds to a distinct home and the columns correspond to the number of rooms(Num Rooms), therooftype(Roof Type), andtheprice(Price).
import os with open(data_file, 'w') as f: f.
write('''Num Rooms, Roof Type, Price NA, NA,127500 2, NA,106000 4, Slate,178100 NA, NA,140000''') Nowletâ€™simportpandasandloadthedatasetwithread_csv.
import pandas as pd data = pd.
read_csv(data_file) print(data) 39 Data Preprocessing Num Rooms Roof Type Price 0 Na N Na N 127500 1 2.0 Na N 106000 2 4.0 Slate 178100 3 Na N Na N 140000 2.2.2 Data Preparation In supervised learning, we train models to predict a designated target value, given some setofinputvalues.
Ourfirststepinprocessingthedatasetistoseparateoutcolumnscor- responding to input versus target values.
We can select columns either by name or via integer-locationbasedindexing(iloc).
You might have noticed that pandas replaced all CSV entries with value NA with a spe- cial Na N (not a number) value.
This can also happen whenever an entry is empty, e.
g., â€œ3â€,270000â€.
Thesearecalledmissingvaluesandtheyaretheâ€œbedbugsâ€ofdatascience, a persistent menace that you will confront throughout your career.
Depending upon the context, missingvaluesmightbehandledeitherviaimputationordeletion.
Imputationre- placesmissingvalueswithestimatesoftheirvalueswhiledeletionsimplydiscardseither thoserowsorthosecolumnsthatcontainmissingvalues.
Herearesomecommonimputationheuristics.
Forcategoricalinputfields, wecantreat Na N asacategory.
Sincethe Roof Typecolumntakesvalues Slateand Na N, pandascanconvert thiscolumnintotwocolumns Roof Type_Slateand Roof Type_nan.
Arowwhoserooftype is Slatewillsetvaluesof Roof Type_Slateand Roof Type_nanto1and0, respectively.
Theconverseholdsforarowwithamissing Roof Typevalue.
inputs, targets = data.
iloc[:, 0:2], data.
iloc[:, 2] inputs = pd.
get_dummies(inputs, dummy_na=True) print(inputs) Num Rooms Roof Type_Slate Roof Type_nan 0 Na N False True 1 2.0 False True 2 4.0 True False 3 Na N False True Formissingnumericalvalues, onecommonheuristicistoreplacethe Na Nentrieswiththe meanvalueofthecorrespondingcolumn.
inputs = inputs.
fillna(inputs.
mean()) print(inputs) Num Rooms Roof Type_Slate Roof Type_nan 0 3.0 False True 1 2.0 False True (continuesonnextpage) 40 Preliminaries (continuedfrompreviouspage) 2 4.0 True False 3 3.0 False True 2.2.3 Conversiontothe Tensor Format Now that all the entries in inputs and targets are numerical, we can load them into a tensor(recall Section2.1).
import torch X = torch.
tensor(inputs.
to_numpy(dtype=float)) y = torch.
tensor(targets.
to_numpy(dtype=float)) X, y (tensor([[3., 0., 1.], [2., 0., 1.], [4., 1., 0.], [3., 0., 1.]], dtype=torch.
float64), 2.2.4 Discussion You now know how to partition data columns, impute missing variables, and load pan- dasdataintotensors.
In Section5.7, youwillpickupsomemoredataprocessingskills.
While this crash course kept things simple, data processing can get hairy.
For example, ratherthanarrivinginasingle CSVfile, ourdatasetmightbespreadacrossmultiplefiles extractedfromarelationaldatabase.
Forinstance, inane-commerceapplication, customer addressesmightliveinonetableandpurchasedatainanother.
Moreover, practitionersface myriaddatatypesbeyondcategoricalandnumeric, forexample, textstrings, images, audio data, and point clouds.
Oftentimes, advanced tools and efficient algorithms are required 47 inordertopreventdataprocessingfrombecomingthebiggestbottleneckinthemachine learningpipeline.
Theseproblemswillarisewhenwegettocomputervisionandnatural languageprocessing.
Finally, wemustpayattentiontodataquality.
Real-worlddatasetsare oftenplaguedbyoutliers, faultymeasurementsfromsensors, andrecordingerrors, which 48 mustbeaddressedbeforefeedingthedataintoanymodel.
Datavisualizationtoolssuchas seaborn47, Bokeh48, ormatplotlib49canhelpyoutomanuallyinspectthedataanddevelop intuitionsaboutthetypeofproblemsyoumayneedtoaddress.
49 2.2.5 Exercises 1.
Tryloadingdatasets, e.
g., Abalonefromthe UCIMachine Learning Repository50 and 50 inspect their properties.
What fraction of them has missing values? What fraction of thevariablesisnumerical, categorical, ortext? 51 2.
Tryindexingandselectingdatacolumnsbynameratherthanbycolumnnumber.
The pandasdocumentationonindexing51 hasfurtherdetailsonhowtodothis.
41 Linear Algebra 3.
Howlargeadatasetdoyouthinkyoucouldloadthisway? Whatmightbethelimita- tions? Hint: considerthetimetoreadthedata, representation, processing, andmemory footprint.
Trythisoutonyourlaptop.
Whathappensifyoutryitoutonaserver? 4.
Howwouldyoudealwithdatathathasaverylargenumberofcategories? Whatifthe categorylabelsareallunique? Shouldyouincludethelatter? 5.
Whatalternativestopandascanyouthinkof? Howaboutloading Num Pytensorsfrom afile52? Checkout Pillow53, the Python Imaging Library.
52 Discussions54.
53 2.3 Linear Algebra 54 Bynow, wecanloaddatasetsintotensorsandmanipulatethesetensorswithbasicmath- ematicaloperations.
Tostartbuildingsophisticatedmodels, wewillalsoneedafewtools fromlinearalgebra.
Thissectionoffersagentleintroductiontothemostessentialconcepts, startingfromscalararithmeticandrampinguptomatrixmultiplication.
import torch 2.3.1 Scalars Mosteverydaymathematicsconsistsofmanipulatingnumbersoneatatime.
Formally, we callthesevaluesscalars.
Forexample, thetemperaturein Palo Altoisabalmy72degrees Fahrenheit.
If you wanted to convert the temperature to Celsius you would evaluate the expression ğ‘ = 5â€ğ‘“ 32â€, setting ğ‘“ to 72.
In this equation, the values 5, 9, and 32 are 9 constantscalars.
Thevariablesğ‘and ğ‘“ ingeneralrepresentunknownscalars.
We denote scalars by ordinary lower-cased letters (e.
g., ğ‘¥, ğ‘¦, and ğ‘§) and the space of all (continuous)real-valued scalarsby R.
Forexpedience, wewillskippastrigorousdefini- tionsofspaces: justrememberthattheexpressionğ‘¥ 2 Risaformalwaytosaythatğ‘¥ is a real-valued scalar.
The symbol 2 (pronounced â€œinâ€) denotes membership in a set.
For example, ğ‘¥,ğ‘¦ 2 f0,1g indicates that ğ‘¥ and ğ‘¦ are variables that can only take values 0 or 1.
Scalarsareimplementedastensorsthatcontainonlyoneelement.
Below, weassigntwo scalarsandperformthefamiliaraddition, multiplication, division, andexponentiationop- erations.
x = torch.
tensor(3.0) y = torch.
tensor(2.0) x + y, x * y, x / y, x**y 42 Preliminaries (tensor(5.), tensor(6.), tensor(1.5000), tensor(9.)) 2.3.2 Vectors Forcurrentpurposes, youcanthinkofavectorasafixed-lengtharrayofscalars.
Aswith theircodecounterparts, wecallthesescalarstheelementsofthevector(synonymsinclude entriesandcomponents).
Whenvectorsrepresentexamplesfromreal-worlddatasets, their values hold some real-world significance.
For example, if we were training a model to predicttheriskofaloandefaulting, wemightassociateeachapplicantwithavectorwhose componentscorrespondtoquantitiesliketheirincome, lengthofemployment, ornumberof previousdefaults.
Ifwewerestudyingtheriskofheartattack, eachvectormightrepresent apatientanditscomponentsmightcorrespondtotheirmostrecentvitalsigns, cholesterol levels, minutesofexerciseperday, etc.
Wedenotevectorsbyboldlowercaseletters,(e.
g., x, y, andz).
Vectorsareimplementedas1st-ordertensors.
Ingeneral, suchtensorscanhavearbitrary lengths, subjecttomemorylimitations.
Caution: in Python, asinmostprogramminglan- guages, vector indices start at 0, also known as zero-based indexing, whereas in linear algebrasubscriptsbeginat1(one-basedindexing).
x = torch.
arange(3) x tensor([0, 1, 2]) Wecanrefertoanelementofavectorbyusingasubscript.
Forexample,ğ‘¥ denotesthe 2 secondelementofx.
Sinceğ‘¥ isascalar, wedonotboldit.
Bydefault, wevisualizevectors 2 bystackingtheirelementsvertically.
2ğ‘¥ 3 6 17 6 .
7 x= 6 .
.
7, (2.3.1) 6 7 6 7 4ğ‘¥ ğ‘›5 Here ğ‘¥ 1 ,...,ğ‘¥ ğ‘› are elements of the vector.
Later on, we will distinguish between such column vectors and row vectors whose elements are stacked horizontally.
Recall that we accessatensorâ€™selementsviaindexing.
x[2] tensor(2) To indicate that a vector contains ğ‘› elements, we write x 2 Rğ‘› .
Formally, we call ğ‘› the dimensionalityofthevector.
Incode, thiscorrespondstothetensorâ€™slength, accessiblevia Pythonâ€™sbuilt-inlenfunction.
43 Linear Algebra len(x) 3 Wecanalsoaccessthelengthviatheshapeattribute.
Theshapeisatuplethatindicates a tensorâ€™s length along each axis.
Tensors with just one axis have shapes with just one element.
x.
shape torch.
Size([3]) Oftentimes, thewordâ€œdimensionâ€getsoverloadedtomeanboththenumberofaxesandthe lengthalongaparticularaxis.
Toavoidthisconfusion, weuseordertorefertothenumber ofaxesanddimensionalityexclusivelytorefertothenumberofcomponents.
2.3.3 Matrices Justasscalarsare0th-ordertensorsandvectorsare1st-ordertensors, matricesare2nd-order tensors.
Wedenotematricesbyboldcapitalletters(e.
g., X, Y, and Z), andrepresentthem in code by tensors with two axes.
The expression A 2 Rğ‘š ğ‘› indicates that a matrix A containsğ‘š ğ‘›real-valuedscalars, arrangedasğ‘š rowsandğ‘›columns.
Whenğ‘š = ğ‘›, we saythatamatrixissquare.
Visually, wecanillustrateanymatrixasatable.
Torefertoan individualelement, wesubscriptboththerowandcolumnindices, e.
g.,ğ‘ ğ‘–ğ‘— isthevaluethat belongsto Aâ€™sğ‘–throwand ğ‘—thcolumn: 2ğ‘ ğ‘ ğ‘ 3 6 11 12 1ğ‘›7 6ğ‘ ğ‘ ğ‘ 7 6 21 22 2ğ‘›7 A= 6 6 6 .
.
.
.
.
.
.
7 7 7 .
(2.3.2) 6 7 4ğ‘ ğ‘š1 ğ‘ ğ‘š2 ğ‘ ğ‘šğ‘›5 Incode, werepresentamatrix A2Rğ‘š ğ‘› bya2nd-ordertensorwithshape(ğ‘š,ğ‘›).
Wecan convertanyappropriatelysizedğ‘š ğ‘›tensorintoanğ‘š ğ‘›matrixbypassingthedesired shapetoreshape: A = torch.
arange(6).
reshape(3, 2) A tensor([[0, 1], [2, 3], [4, 5]]) Sometimeswewanttofliptheaxes.
Whenweexchangeamatrixâ€™srowsandcolumns, the result is called its transpose.
Formally, we signify a matrix Aâ€™s transpose by A> and if 44 Preliminaries B=A> , thenğ‘ ğ‘–ğ‘— =ğ‘ ğ‘—ğ‘– forallğ‘–and ğ‘—.
Thus, thetransposeofanğ‘š ğ‘›matrixisanğ‘› ğ‘š matrix: 2ğ‘ ğ‘ ...
ğ‘ 3 6 11 21 ğ‘š17 6ğ‘ ğ‘ ...
ğ‘ 7 A > = 6 6 6 6 .
.
.
12 .
.
.
.
27 7 7 7 .
(2.3.3) 6 7 4ğ‘ 1ğ‘› ğ‘ 2ğ‘› ...
ğ‘ ğ‘šğ‘›5 Incode, wecanaccessanymatrixâ€™stransposeasfollows: A.
T tensor([[0, 2, 4], [1, 3, 5]]) Symmetricmatricesarethesubsetofsquarematricesthatareequaltotheirowntransposes: A=A> .
Thefollowingmatrixissymmetric: A = torch.
tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) A == A.
T tensor([[True, True, True], [True, True, True], [True, True, True]]) Matrices are useful for representing datasets.
Typically, rows correspond to individual recordsandcolumnscorrespondtodistinctattributes.
2.3.4 Tensors While you can go far in your machine learning journey with only scalars, vectors, and matrices, eventually you may need to work with higher-order tensors.
Tensors give us a generic way of describing extensions to ğ‘›th-order arrays.
We call software objects of thetensorclassâ€œtensorsâ€preciselybecausetheytoocanhavearbitrarynumbersofaxes.
Whileitmaybeconfusingtousethewordtensorforboththemathematicalobjectandits realizationincode, ourmeaningshouldusuallybeclearfromcontext.
Wedenotegeneral tensors by capital letters with a special font face (e.
g., X, Y, and Z) and their indexing mechanism(e.
g.,ğ‘¥ ğ‘–ğ‘—ğ‘˜ and Â»Xâ€¦ 1,2ğ‘– 1,3 )followsnaturallyfromthatofmatrices.
Tensors will become more important when we start working with images.
Each image arrivesasa3rd-ordertensorwithaxescorrespondingtotheheight, width, andchannel.
At eachspatiallocation, theintensitiesofeachcolor(red, green, andblue)arestackedalongthe channel.
Furthermore, acollectionofimagesisrepresentedincodebya4th-ordertensor, wheredistinctimagesareindexedalongthefirstaxis.
Higher-ordertensorsareconstructed, aswerevectorsandmatrices, bygrowingthenumberofshapecomponents.
45 Linear Algebra torch.
arange(24).
reshape(2, 3, 4) tensor([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) 2.3.5 Basic Propertiesof Tensor Arithmetic Scalars, vectors, matrices, andhigher-ordertensorsallhavesomehandyproperties.
Forex- ample, elementwiseoperationsproduceoutputsthathavethesameshapeastheiroperands.
A = torch.
arange(6, dtype=torch.
float32).
reshape(2, 3) B = A.
clone() # Assign a copy of A to B by allocating new memory A, A + B (tensor([[0., 1., 2.], [3., 4., 5.]]), tensor([[ 0., 2., 4.], [ 6., 8., 10.]])) Theelementwiseproductoftwomatricesiscalledtheir Hadamardproduct (denoted ).
Wecanspellouttheentriesofthe Hadamardproductoftwomatrices A, B2Rğ‘š ğ‘› : 2ğ‘ ğ‘ ğ‘ ğ‘ ...
ğ‘ ğ‘ 3 6 11 11 12 12 1ğ‘› 1ğ‘› 7 6ğ‘ ğ‘ ğ‘ ğ‘ ...
ğ‘ ğ‘ 7 6 21 21 22 22 2ğ‘› 2ğ‘› 7 A B= 6 6 6 .
.
.
.
.
.
.
7 7 7 .
(2.3.4) 6 7 4ğ‘ ğ‘š1 ğ‘ ğ‘š1 ğ‘ ğ‘š2 ğ‘ ğ‘š2 ...
ğ‘ ğ‘šğ‘› ğ‘ ğ‘šğ‘›5 A * B tensor([[ 0., 1., 4.], [ 9., 16., 25.]]) Adding or multiplying a scalar and a tensor produces a result with the same shape as the original tensor.
Here, each element of the tensor is added to (or multiplied by) the scalar.
a = 2 X = torch.
arange(24).
reshape(2, 3, 4) a + X, (a * X).
shape 46 Preliminaries (tensor([[[ 2, 3, 4, 5], [ 6, 7, 8, 9], [10, 11, 12, 13]], [[14, 15, 16, 17], [18, 19, 20, 21], [22, 23, 24, 25]]]), torch.
Size([2, 3, 4])) 2.3.6 Reduction Often, we wish to calculate the sum of a tensorâ€™s elements.
To express the sum of the Ë elementsinavectorxoflengthğ‘›, wewrite ğ‘– ğ‘› =1 ğ‘¥ ğ‘–.
Thereisasimplefunctionforit: x = torch.
arange(3, dtype=torch.
float32) x, x.
sum() (tensor([0., 1., 2.]), tensor(3.)) To express sums over the elements of tensors of arbitrary shape, we simply sum over all its axes.
For example, the sum of the elements of an ğ‘š ğ‘› matrix A could be written Ë Ë ğ‘– ğ‘š =1 ğ‘› ğ‘—=1 ğ‘ ğ‘–ğ‘—.
A.
shape, A.
sum() (torch.
Size([2, 3]), tensor(15.)) By default, invoking the sum function reduces a tensor along all of its axes, eventually producingascalar.
Ourlibrariesalsoallowustospecifytheaxesalongwhichthetensor shouldbereduced.
Tosumoverallelementsalongtherows(axis0), wespecifyaxis=0in sum.
Sincetheinputmatrixreducesalongaxis0togeneratetheoutputvector, thisaxisis missingfromtheshapeoftheoutput.
A.
shape, A.
sum(axis=0).
shape (torch.
Size([2, 3]), torch.
Size([3])) Specifyingaxis=1willreducethecolumndimension(axis1)bysummingupelementsof allthecolumns.
A.
shape, A.
sum(axis=1).
shape (torch.
Size([2, 3]), torch.
Size([2])) 47 Linear Algebra Reducingamatrixalongbothrowsandcolumnsviasummationisequivalenttosumming upalltheelementsofthematrix.
A.
sum(axis=[0, 1]) == A.
sum() # Same as A.
sum() tensor(True) Arelatedquantityisthemean, alsocalledtheaverage.
Wecalculatethemeanbydividing thesumbythetotalnumberofelements.
Becausecomputingthemeanissocommon, it getsadedicatedlibraryfunctionthatworksanalogouslytosum.
A.
mean(), A.
sum() / A.
numel() (tensor(2.5000), tensor(2.5000)) Likewise, the function for calculating the mean can also reduce a tensor along specific axes.
A.
mean(axis=0), A.
sum(axis=0) / A.
shape[0] 2.3.7 Non-Reduction Sum Sometimesitcanbeusefultokeepthenumberofaxesunchangedwheninvokingthefunc- tion for calculating the sum or mean.
This matters when we want to use the broadcast mechanism.
sum_A = A.
sum(axis=1, keepdims=True) sum_A, sum_A.
shape (tensor([[ 3.], [12.]]), torch.
Size([2, 1])) Forinstance, sincesum_Akeepsitstwoaxesaftersummingeachrow, wecandivide Aby sum_Awithbroadcastingtocreateamatrixwhereeachrowsumsupto1.
A / sum_A tensor([[0.0000, 0.3333, 0.6667], [0.2500, 0.3333, 0.4167]]) 48 Preliminaries Ifwewanttocalculatethecumulativesumofelementsof Aalongsomeaxis, sayaxis=0 (rowbyrow), wecancallthecumsumfunction.
Bydesign, thisfunctiondoesnotreduce theinputtensoralonganyaxis.
A.
cumsum(axis=0) tensor([[0., 1., 2.], [3., 5., 7.]]) 2.3.8 Dot Products Sofar, wehaveonlyperformedelementwiseoperations, sums, andaverages.
Andifthiswas allwecoulddo, linearalgebrawouldnotdeserveitsownsection.
Fortunately, thisiswhere things get more interesting.
One of the most fundamental operations is the dot product.
Giventwovectorsx, y 2Rğ‘‘ , theirdotproductx>y(alsoknownasinnerproduct, hx, yi) Ë isasumovertheproductsoftheelementsatthesameposition: x>y= ğ‘– ğ‘‘ =1 ğ‘¥ ğ‘– ğ‘¦ ğ‘–.
y = torch.
ones(3, dtype = torch.
float32) x, y, torch.
dot(x, y) Equivalently, wecancalculatethedotproductoftwovectorsbyperforminganelementwise multiplicationfollowedbyasum: torch.
sum(x * y) tensor(3.) Dotproductsareusefulinawiderangeofcontexts.
Forexample, givensomesetofval- ues, denotedbyavectorx 2 Rğ‘› , andasetofweights, denotedbyw 2 Rğ‘› , theweighted sumofthevaluesinxaccordingtotheweightsw couldbeexpressedasthedotproduct Ë x>w.
Whentheweightsarenonnegativeandsumto1, i.
e., ğ‘– ğ‘› =1 ğ‘¤ ğ‘– =1 , thedotprod- uctexpressesaweightedaverage.
Afternormalizingtwovectorstohaveunitlength, the dotproductsexpressthecosineoftheanglebetweenthem.
Laterinthissection, wewill formallyintroducethisnotionoflength.
2.3.9 Matrixâ€“Vector Products Nowthatweknowhowtocalculatedotproducts, wecanbegintounderstandtheproduct betweenanğ‘š ğ‘›matrix Aandanğ‘›-dimensionalvectorx.
Tostartoff, wevisualizeour 49 Linear Algebra matrixintermsofitsrowvectors 2 6a> 1 3 7 6 6a>7 7 A= 6 .
27, (2.3.5) 6 .
7 6 .
7 6 7 4a>5 ğ‘š whereeacha> 2Rğ‘› isarowvectorrepresentingtheğ‘–throwofthematrix A.
ğ‘– Thematrixâ€“vectorproduct Axissimplyacolumnvectoroflengthğ‘š, whoseğ‘–th element isthedotproducta>x: ğ‘– 2 6a> 1 3 7 2 6a> 1 x 3 7 6 6a>7 7 6 6a>x 7 7 6 .
7 6 .
7 6 .
7 6 .
7 6 7 6 7 4a>5 4a>x5 ğ‘š ğ‘š Wecanthinkofmultiplicationwithamatrix A 2 Rğ‘š ğ‘› asatransformationthatprojects vectorsfrom Rğ‘› to Rğ‘š .
Thesetransformationsareremarkablyuseful.
Forexample, wecan representrotationsasmultiplicationsbycertainsquarematrices.
Matrixâ€“vectorproducts alsodescribethekeycalculationinvolvedincomputingtheoutputsofeachlayerinaneural networkgiventheoutputsfromthepreviouslayer.
Toexpressamatrixâ€“vectorproductincode, weusethemvfunction.
Notethatthecolumn dimensionof A(itslengthalongaxis1)mustbethesameasthedimensionofx(itslength).
Pythonhasaconvenienceoperator@thatcanexecutebothmatrixâ€“vectorandmatrixâ€“matrix products(dependingonitsarguments).
Thuswecanwrite A@x.
A.
shape, x.
shape, torch.
mv(A, x), A@x 2.3.10 Matrixâ€“Matrix Multiplication Onceyouhavegottenthehangofdotproductsandmatrixâ€“vectorproducts, thenmatrixâ€“ matrixmultiplicationshouldbestraightforward.
Saythatwehavetwomatrices A2Rğ‘› ğ‘˜ and B2Rğ‘˜ ğ‘š : 2ğ‘ ğ‘ ğ‘ 3 2ğ‘ ğ‘ ğ‘ 3 6 11 12 1ğ‘˜7 6 11 12 1ğ‘š7 6ğ‘ ğ‘ ğ‘ 7 6ğ‘ ğ‘ ğ‘ 7 6 21 22 2ğ‘˜7 6 21 22 2ğ‘š7 A= 6 6 6 .
.
.
.
.
.
.
7 7 7 , B= 6 6 6 .
.
.
.
.
.
.
7 7 7 .
(2.3.7) 6 7 6 7 4ğ‘ ğ‘›1 ğ‘ ğ‘›2 ğ‘ ğ‘›ğ‘˜5 4ğ‘ ğ‘˜1 ğ‘ ğ‘˜2 ğ‘ ğ‘˜ğ‘š5 Leta> ğ‘– 2Rğ‘˜ denotetherowvectorrepresentingtheğ‘–throwofthematrix Aandletbğ‘— 2Rğ‘˜ 50 Preliminaries denotethecolumnvectorfromthe ğ‘—thcolumnofthematrix B: 2 6a> 1 3 7 6 6a>7 7 A= 6 6 .
.
27 7 , B= b 1 b 2 bğ‘š .
(2.3.8) 6 .
7 6 7 4a>5 ğ‘› To form the matrix product C 2 Rğ‘› ğ‘š , we simply compute each element ğ‘ ğ‘–ğ‘— as the dot productbetweentheğ‘–throwof Aandthe ğ‘—thcolumnof B, i.
e., a> ğ‘– bğ‘—: 2 6a> 1 3 7 2 6a> 1 b 1 a> 1 b 2 a> 1 bğ‘š 3 7 C=AB= 6 6 6 6 6 a .
.
.
> 2 7 7 7 7 7 b 1 b 2 bğ‘š = 6 6 6 6 6 a> 2 .
.
.
b 1 a> 2 .
.
.
.
bğ‘š 7 7 7 7 7 .
(2.3.9) 6 7 6 7 4a> ğ‘› 5 4a> ğ‘› b 1 a> ğ‘› b 2 a> ğ‘› bğ‘š5 Wecanthinkofthematrixâ€“matrixmultiplication ABasperformingğ‘šmatrixâ€“vectorprod- uctsorğ‘š ğ‘›dotproductsandstitchingtheresultstogethertoformanğ‘› ğ‘šmatrix.
Inthe followingsnippet, weperformmatrixmultiplicationon Aand B.
Here, Aisamatrixwith two rows and three columns, and B is a matrix with three rows and four columns.
After multiplication, weobtainamatrixwithtworowsandfourcolumns.
B = torch.
ones(3, 4) torch.
mm(A, B), A@B (tensor([[ 3., 3., 3., 3.], [12., 12., 12., 12.]]), tensor([[ 3., 3., 3., 3.], [12., 12., 12., 12.]])) The term matrixâ€“matrix multiplication is often simplified to matrix multiplication, and shouldnotbeconfusedwiththe Hadamardproduct.
2.3.11 Norms Someofthemostusefuloperatorsinlinearalgebraarenorms.
Informally, thenormofa vectortellsushowbigitis.
Forinstance, theâ„“ normmeasuresthe(Euclidean)lengthofa 2 vector.
Here, weareemployinganotionofsizethatconcernsthemagnitudeofavectorâ€™s components(notitsdimensionality).
Anormisafunction k k thatmapsavectortoascalarandsatisfiesthefollowingthree properties: 1.
Givenanyvectorx, ifwescale(allelementsof)thevectorbyascalarğ›¼ 2 R, itsnorm scalesaccordingly: kğ›¼xk = jğ›¼jkxk.
(2.3.10) 51 Linear Algebra 2.
Foranyvectorsxandy: normssatisfythetriangleinequality: kxâ€šyk kxkâ€škyk.
(2.3.11) 3.
Thenormofavectorisnonnegativeanditonlyvanishesifthevectoriszero: kxk >0forallxâ‰ 0.
(2.3.12) Manyfunctionsarevalidnormsanddifferentnormsencodedifferentnotionsofsize.
The Euclidean norm that we all learned in elementary school geometry when calculating the hypotenuseofarighttriangleisthesquarerootofthesumofsquaresofavectorâ€™selements.
Formally, thisiscalledtheâ„“ normandexpressedas 2 vt ğ‘› kxk = ğ‘¥2.
(2.3.13) 2 ğ‘– ğ‘–=1 Themethodnormcalculatestheâ„“ norm.
2 u = torch.
tensor([3.0, -4.0]) torch.
norm(u) tensor(5.) Theâ„“ normisalsocommonandtheassociatedmeasureiscalledthe Manhattandistance.
1 Bydefinition, theâ„“ normsumstheabsolutevaluesofavectorâ€™selements: 1 ğ‘› kxk 1 = jğ‘¥ ğ‘– j.
(2.3.14) ğ‘–=1 Compared to the â„“ norm, it is less sensitive to outliers.
To compute the â„“ norm, we 2 1 composetheabsolutevaluewiththesumoperation.
torch.
abs(u).
sum() tensor(7.) Boththeâ„“ 2 andâ„“ 1 normsarespecialcasesofthemoregeneralâ„“ ğ‘ norms: ! ğ‘› 1 ğ‘ kxk ğ‘ = jğ‘¥ ğ‘– jğ‘ .
(2.3.15) ğ‘–=1 Inthecaseofmatrices, mattersaremorecomplicated.
Afterall, matricescanbeviewed bothascollectionsofindividualentriesandasobjectsthatoperateonvectorsandtransform themintoothervectors.
Forinstance, wecanaskbyhowmuchlongerthematrixâ€“vector product Xvcouldberelativetov.
Thislineofthoughtleadstowhatiscalledthespectral 52 Preliminaries norm.
Fornow, weintroduce the Frobeniusnorm, whichis mucheasierto computeand definedasthesquarerootofthesumofthesquaresofamatrixâ€™selements: vut ğ‘š ğ‘› k Xk = ğ‘¥2 .
(2.3.16) F ğ‘–ğ‘— ğ‘–=1 ğ‘—=1 The Frobeniusnormbehavesasifitwereanâ„“ normofamatrix-shapedvector.
Invoking 2 thefollowingfunctionwillcalculatethe Frobeniusnormofamatrix.
torch.
norm(torch.
ones((4, 9))) tensor(6.) While we do not want to get too far ahead of ourselves, we already can plant some intu- ition about why these concepts are useful.
In deep learning, we are often trying to solve optimizationproblems: maximizetheprobabilityassignedtoobserveddata; maximizethe revenueassociatedwitharecommendermodel; minimizethedistancebetweenpredictions andthegroundtruthobservations; minimizethedistancebetweenrepresentationsofphotos ofthesamepersonwhilemaximizingthedistancebetweenrepresentationsofphotosofdif- ferentpeople.
Thesedistances, whichconstitutetheobjectivesofdeeplearningalgorithms, areoftenexpressedasnorms.
2.3.12 Discussion Inthissection, wehavereviewedallthelinearalgebrathatyouwillneedtounderstanda significantchunkofmoderndeeplearning.
Thereisalotmoretolinearalgebra, though, andmuchofitisusefulformachinelearning.
Forexample, matricescanbedecomposed intofactors, andthesedecompositionscanreveallow-dimensionalstructureinreal-world datasets.
Thereareentiresubfieldsofmachinelearningthatfocusonusingmatrixdecom- positions and their generalizations to high-order tensors to discover structure in datasets and solve prediction problems.
But this book focuses on deep learning.
And we believe youwillbemoreinclinedtolearnmoremathematicsonceyouhavegottenyourhandsdirty applyingmachinelearningtorealdatasets.
Sowhilewereservetherighttointroducemore mathematicslateron, wewrapupthissectionhere.
If you are eager to learn more linear algebra, there are many excellent books and online resources.
Foramoreadvancedcrashcourse, considercheckingout Strang(1993), Kolter (2008), and Petersenand Pedersen(2008).
Torecap: Scalars, vectors, matrices, andtensorsarethebasicmathematicalobjectsusedinlinear algebraandhavezero, one, two, andanarbitrarynumberofaxes, respectively.
Tensorscanbeslicedorreducedalongspecifiedaxesviaindexing, oroperationssuch assumandmean, respectively.
53 Linear Algebra Elementwiseproductsarecalled Hadamardproducts.
Bycontrast, dotproducts, matrixâ€“ vector products, and matrixâ€“matrix products are not elementwise operations and in generalreturnobjectshavingshapesthataredifferentfromthetheoperands.
Compared to Hadamard products, matrixâ€“matrix products take considerably longer to compute(cubicratherthanquadratictime).
Normscapture variousnotions ofthe magnitudeof a vector(or matrix), and arecom- monlyappliedtothedifferenceoftwovectorstomeasuretheirdistanceapart.
Commonvectornormsincludetheâ„“ andâ„“ norms, andcommonmatrixnormsinclude 1 2 thespectraland Frobeniusnorms.
2.3.13 Exercises 1.
Provethatthetransposeofthetransposeofamatrixisthematrixitself: â€A>â€> =A.
2.
Giventwomatrices Aand B, showthatsumandtranspositioncommute: A>â€šB> = â€Aâ€šBâ€> .
3.
Givenanysquarematrix A, is Aâ€šA> alwayssymmetric? Canyouprovetheresultby usingonlytheresultsoftheprevioustwoexercises? 4.
Wedefinedthetensor Xofshape(2,3,4)inthissection.
Whatistheoutputoflen(X)? Writeyouranswerwithoutimplementinganycode, thencheckyouranswerusingcode.
5.
For a tensor X of arbitrary shape, does len(X) always correspond to the length of a certainaxisof X? Whatisthataxis? 6.
Run A / A.
sum(axis=1)andseewhathappens.
Canyouanalyzetheresults? 7.
Whentravelingbetweentwopointsindowntown Manhattan, whatisthedistancethat youneedtocoverintermsofthecoordinates, i.
e., intermsofavenuesandstreets? Can youtraveldiagonally? 8.
Consider a tensor of shape (2, 3, 4).
What are the shapes of the summation outputs alongaxes0,1, and2? 9.
Feed a tensor with three or more axes to the linalg.
norm function and observe its output.
Whatdoesthisfunctioncomputefortensorsofarbitraryshape? 10.
Consider three large matrices, say A 2 R210 216, B 2 R216 25 and C 2 R25 214, ini- tializedwith Gaussianrandomvariables.
Youwanttocomputetheproduct ABC.
Is thereanydifferenceinmemoryfootprintandspeed, dependingonwhetheryoucompute â€ABâ€Cor Aâ€BCâ€.
Why? 11.
Considerthreelargematrices, say A2R210 216, B2R216 25 and C2R25 216.
Isthere anydifferenceinspeeddependingonwhetheryoucompute ABor AC> ? Why? What changesifyouinitialize C=B> withoutcloningmemory? Why? 12.
Considerthreematrices, say A, B, C2R100 200.
Constructatensorwiththreeaxesby 54 Preliminaries stackingÂ»A, B, Câ€¦.
Whatisthedimensionality? Sliceoutthesecondcoordinateofthe thirdaxistorecover B.
Checkthatyouransweriscorrect.
Discussions55.
55 2.4 Calculus Foralongtime, howtocalculatetheareaofacircleremainedamystery.
Then, in Ancient Greece, themathematician Archimedescameupwiththecleverideatoinscribeaseriesof polygonswithincreasingnumbersofverticesontheinsideofacircle(.4.1).
Fora polygonwithğ‘›vertices, weobtainğ‘›triangles.
Theheightofeachtriangleapproachesthe radiusğ‘Ÿaswepartitionthecirclemorefinely.
Atthesametime, itsbaseapproaches2ğœ‹ğ‘Ÿ ğ‘›, sincetheratiobetweenarcandsecantapproaches1foralargenumberofvertices.
Thus, theareaofthepolygonapproachesğ‘› ğ‘Ÿ 1â€2ğœ‹ğ‘Ÿ ğ‘›â€ =ğœ‹ğ‘Ÿ2.
2 t .4.1 Findingtheareaofacircleasalimitprocedure.
Thislimitingprocedureisattherootofbothdifferentialcalculusandintegralcalculus.
The formercantellushowtoincreaseordecreaseafunctionâ€™svaluebymanipulatingitsargu- ments.
Thiscomesinhandyfortheoptimizationproblemsthatwefaceindeeplearning, where we repeatedly update our parameters in order to decrease the loss function.
Opti- mizationaddresseshowtofitourmodelstotrainingdata, andcalculusisitskeyprerequisite.
However, donotforgetthatourultimategoalistoperformwellonpreviouslyunseendata.
Thatproblemiscalledgeneralizationandwillbeakeyfocusofotherchapters.
%matplotlib inline import numpy as np from matplotlib_inline import backend_inline from d2l import torch as d2l 2.4.1 Derivativesand Differentiation Put simply, a derivative is the rate of change in a function with respect to changes in its arguments.
Derivativescantellushowrapidlyalossfunctionwouldincreaseordecrease werewetoincreaseordecreaseeachparameterbyaninfinitesimallysmallamount.
For- mally, forfunctions ğ‘“ : R ! R, thatmapfromscalarstoscalars, thederivativeof ğ‘“ ata pointğ‘¥isdefinedas ğ‘“â€ğ‘¥â€šâ„â€ ğ‘“â€ğ‘¥â€ ğ‘“0â€ğ‘¥â€ = lim .
(2.4.1) â„!0 â„ 55 Calculus Thistermontherighthandsideiscalledalimitandittellsuswhathappenstothevalueof anexpressionasaspecifiedvariableapproachesaparticularvalue.
Thislimittellsuswhat the ratio between a perturbation â„ and the change in the function value ğ‘“â€ğ‘¥ â€š â„â€ ğ‘“â€ğ‘¥â€ convergestoasweshrinkitssizetozero.
When ğ‘“0â€ğ‘¥â€ exists, ğ‘“ issaidtobedifferentiableatğ‘¥; andwhen ğ‘“0â€ğ‘¥â€ existsforallğ‘¥ ona set, e.
g., theintervalÂ»ğ‘,ğ‘â€¦, wesaythat ğ‘“ isdifferentiableonthisset.
Notallfunctionsare differentiable, includingmanythatwewishtooptimize, suchasaccuracyandtheareaunder thereceivingoperatingcharacteristic(AUC).
However, becausecomputingthederivative ofthelossisacrucialstepinnearlyallalgorithmsfortrainingdeepneuralnetworks, we oftenoptimizeadifferentiablesurrogateinstead.
We can interpret the derivative ğ‘“0â€ğ‘¥â€ as the instantaneous rate of change of ğ‘“â€ğ‘¥â€ with respect to ğ‘¥.
Letâ€™s develop some intuition with an example.
Define ğ‘¢ = ğ‘“â€ğ‘¥â€ = 3ğ‘¥2 4ğ‘¥.
def f(x): return 3 * x ** 2 - 4 * x Setting ğ‘¥ = 1, we see that ğ‘“â€ğ‘¥â€šâ„â€ ğ‘“â€ğ‘¥â€ approaches 2 as â„ approaches 0.
While this ex- â„ perimentlackstherigorofamathematicalproof, wecanquicklyseethatindeed ğ‘“0â€1â€ = 2.
for h in 10.0**np.
arange(-1, -6, -1): print(f'h={h:.5f}, numerical limit={(f(1+h)-f(1))/h:.5f}') h=0.10000, numerical limit=2.30000 h=0.01000, numerical limit=2.03000 h=0.00100, numerical limit=2.00300 h=0.00010, numerical limit=2.00030 h=0.00001, numerical limit=2.00003 There are several equivalent notational conventions for derivatives.
Given ğ‘¦ = ğ‘“â€ğ‘¥â€, the followingexpressionsareequivalent: ğ‘‘ğ‘¦ ğ‘‘ğ‘“ ğ‘‘ ğ‘“0â€ğ‘¥â€ = ğ‘¦0 = ğ‘‘ğ‘¥ = ğ‘‘ğ‘¥ = ğ‘‘ğ‘¥ ğ‘“â€ğ‘¥â€ = ğ·ğ‘“â€ğ‘¥â€ = ğ· ğ‘¥ ğ‘“â€ğ‘¥â€, (2.4.2) wherethesymbols ğ‘‘ and ğ· aredifferentiationoperators.
Below, wepresentthederiva- ğ‘‘ğ‘¥ tivesofsomecommonfunctions: ğ‘‘ ğ¶ =0 foranyconstantğ¶ ğ‘‘ğ‘¥ ğ‘‘ ğ‘¥ğ‘› =ğ‘›ğ‘¥ğ‘› 1 forğ‘›â‰ 0 ğ‘‘ğ‘¥ (2.4.3) ğ‘‘ ğ‘’ğ‘¥ =ğ‘’ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ lnğ‘¥ =ğ‘¥ 1.
ğ‘‘ğ‘¥ 56 Preliminaries Functionscomposedfromdifferentiablefunctionsareoftenthemselvesdifferentiable.
The followingrulescomeinhandyforworkingwithcompositionsofanydifferentiablefunc- tions ğ‘“ andğ‘”, andconstantğ¶.
ğ‘‘ ğ‘‘ Â»ğ¶ğ‘“â€ğ‘¥â€â€¦ =ğ¶ ğ‘“â€ğ‘¥â€ Constantmultiplerule ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ ğ‘‘ ğ‘‘ Â»ğ‘“â€ğ‘¥â€â€šğ‘”â€ğ‘¥â€â€¦ = ğ‘“â€ğ‘¥â€â€š ğ‘”â€ğ‘¥â€ Sumrule ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ ğ‘‘ ğ‘‘ (2.4.4) Â»ğ‘“â€ğ‘¥â€ğ‘”â€ğ‘¥â€â€¦ = ğ‘“â€ğ‘¥â€ ğ‘”â€ğ‘¥â€â€šğ‘”â€ğ‘¥â€ ğ‘“â€ğ‘¥â€ Productrule ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ ğ‘“â€ğ‘¥â€ ğ‘”â€ğ‘¥â€ ğ‘‘ ğ‘“â€ğ‘¥â€ ğ‘“â€ğ‘¥â€ ğ‘‘ ğ‘”â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ = Quotientrule ğ‘‘ğ‘¥ ğ‘”â€ğ‘¥â€ ğ‘”2â€ğ‘¥â€ Usingthis, wecanapplytherulestofindthederivativeof3ğ‘¥2 4ğ‘¥via ğ‘‘ ğ‘‘ ğ‘‘ Â»3ğ‘¥2 4ğ‘¥â€¦ =3 ğ‘¥2 4 ğ‘¥ =6ğ‘¥ 4.
(2.4.5) ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Plugging in ğ‘¥ = 1 shows that, indeed, the derivative equals 2 at this location.
Note that derivativestellustheslopeofafunctionataparticularlocation.
2.4.2 Visualization Utilities We can visualize the slopes of functions using the matplotlib library.
We need to de- fineafewfunctions.
Asitsnameindicates, use_svg_displaytellsmatplotlibtooutput graphicsin SVGformatforcrisperimages.
Thecomment#@saveisaspecialmodifierthat allowsustosaveanyfunction, class, orothercodeblocktothed2lpackagesothatwecan invokeitlaterwithoutrepeatingthecode, e.
g., viad2l.
use_svg_display().
def use_svg_display(): #@save """Use the svg format to display a plot in Jupyter.""" backend_inline.
set_matplotlib_formats('svg') Conveniently, wecansetfiguresizeswithset_figsize.
Sincetheimportstatementfrom matplotlib import pyplot as pltwasmarkedvia#@saveinthed2lpackage, wecan calld2l.
plt.
def set_figsize(figsize=(3.5, 2.5)): #@save """Set the figure size for matplotlib.""" use_svg_display() d2l.
plt.
rc Params['figure.
figsize'] = figsize The set_axes function can associate axes with properties, including labels, ranges, and scales.
#@save def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend): """Set the axes for matplotlib.""" axes.
set_xlabel(xlabel), axes.
set_ylabel(ylabel) (continuesonnextpage) 57 Calculus (continuedfrompreviouspage) axes.
set_xscale(xscale), axes.
set_yscale(yscale) axes.
set_xlim(xlim), axes.
set_ylim(ylim) if legend: axes.
legend(legend) axes.
grid() Withthesethreefunctions, wecandefineaplotfunctiontooverlaymultiplecurves.
Much ofthecodehereisjustensuringthatthesizesandshapesofinputsmatch.
#@save def plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None, ylim=None, xscale='linear', yscale='linear', fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None): """Plot data points.""" def has_one_axis(X): # True if X (tensor or list) has 1 axis return (hasattr(X, "ndim") and X.
ndim == 1 or isinstance(X, list) and not hasattr(X[0], "__len__")) if has_one_axis(X): X = [X] if Y is None: X, Y = [[]] * len(X), X elif has_one_axis(Y): Y = [Y] if len(X) != len(Y): X = X * len(Y) set_figsize(figsize) if axes is None: axes = d2l.
plt.
gca() axes.
cla() for x, y, fmt in zip(X, Y, fmts): axes.
plot(x, y, fmt) if len(x) else axes.
plot(y, fmt) set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend) Nowwecanplotthefunctionğ‘¢ = ğ‘“â€ğ‘¥â€ anditstangentlineğ‘¦ =2ğ‘¥ 3atğ‘¥ =1, wherethe coefficient2istheslopeofthetangentline.
x = np.
arange(0, 3, 0.1) plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)']) 58 Preliminaries 2.4.3 Partial Derivativesand Gradients Thusfar, wehavebeendifferentiatingfunctionsofjustonevariable.
Indeeplearning, we also need to work with functions of many variables.
We briefly introduce notions of the derivativethatapplytosuchmultivariatefunctions.
Let ğ‘¦ = ğ‘“â€ğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘› â€ beafunctionwithğ‘›variables.
Thepartialderivativeof ğ‘¦ with respecttoitsğ‘–thparameterğ‘¥ ğ‘– is = lim 1 ğ‘– 1 ğ‘– ğ‘–â€š1 ğ‘› 1 ğ‘– ğ‘› .
(2.4.6) ğœ•ğ‘¥ ğ‘– â„!0 â„ tiveofğ‘¦withrespecttoğ‘¥ ğ‘–.
Thefollowingnotationalconventionsforpartialderivativesare allcommonandallmeanthesamething: ğœ•ğ‘¦ ğœ•ğ‘“ ğœ•ğ‘¥ = ğœ•ğ‘¥ =ğœ• ğ‘¥ğ‘– ğ‘“ =ğœ• ğ‘– ğ‘“ = ğ‘“ ğ‘¥ğ‘– = ğ‘“ ğ‘– = ğ· ğ‘– ğ‘“ = ğ· ğ‘¥ğ‘– ğ‘“.
(2.4.7) ğ‘– ğ‘– We can concatenate partial derivatives of a multivariate function with respect to all its variables to obtain a vector that is called the gradient of the function.
Suppose that the input of function ğ‘“ : Rğ‘› ! R is an ğ‘›-dimensional vector x = Â»ğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘› â€¦> and the outputisascalar.
Thegradientofthefunction ğ‘“ withrespecttoxisavectorofğ‘›partial derivatives: > Whenthereisnoambiguity, r ğ‘“â€xâ€ istypicallyreplacedbyrğ‘“â€xâ€.
Thefollowingrules x comeinhandyfordifferentiatingmultivariatefunctions: Forall A2Rğ‘š ğ‘› wehaver Ax=A> andr x>A=A.
x x Forsquarematrices A 2 Rğ‘› ğ‘› wehavethatr x>Ax = â€Aâ€šA>â€xandinparticular x r kxk2 =r x>x=2x.
x x Similarly, foranymatrix X, wehaver k Xk2 =2X.
X F 2.4.4 Chain Rule In deep learning, the gradients of concern are often difficult to calculate because we are workingwithdeeplynestedfunctions(offunctions(offunctionsâ€¦)).
Fortunately, thechain ruletakescareofthis.
Returningtofunctionsofasinglevariable, supposethatğ‘¦ = ğ‘“â€ğ‘”â€ğ‘¥â€â€ andthattheunderlyingfunctionsğ‘¦ = ğ‘“â€ğ‘¢â€andğ‘¢ =ğ‘”â€ğ‘¥â€arebothdifferentiable.
Thechain rulestatesthat ğ‘‘ğ‘¦ ğ‘‘ğ‘¦ ğ‘‘ğ‘¢ = .
(2.4.9) ğ‘‘ğ‘¥ ğ‘‘ğ‘¢ ğ‘‘ğ‘¥ Turningbacktomultivariatefunctions, supposethatğ‘¦ = ğ‘“â€uâ€hasvariablesğ‘¢ 1 ,ğ‘¢ 2 ,...,ğ‘¢ ğ‘š, statesthat ğœ•ğ‘¦ ğœ•ğ‘¦ ğœ•ğ‘¢ ğœ•ğ‘¦ ğœ•ğ‘¢ ğœ•ğ‘¦ ğœ•ğ‘¢ ğœ•ğ‘¥ ğœ•ğ‘¢ ğœ•ğ‘¥ ğœ•ğ‘¢ ğœ•ğ‘¥ ğœ•ğ‘¢ ğœ•ğ‘¥ x u ğ‘– 1 ğ‘– 2 ğ‘– ğ‘š ğ‘– 59 Calculus where A2Rğ‘› ğ‘š isamatrixthatcontainsthederivativeofvectoruwithrespecttovector x.
Thus, evaluatingthegradientrequirescomputingavectorâ€“matrixproduct.
Thisisone of the key reasons why linear algebra is such an integral building blockin building deep learningsystems.
2.4.5 Discussion Whilewehavejustscratchedthesurfaceofadeeptopic, anumberofconceptsalreadycome intofocus: first, thecompositionrulesfordifferentiationcanbeappliedroutinely, enabling us to compute gradients automatically.
This task requires no creativity and thus we can focusourcognitivepowerselsewhere.
Second, computingthederivativesofvector-valued functionsrequiresustomultiplymatricesaswetracethedependencygraphofvariables from output to input.
In particular, this graph is traversed in a forward direction when we evaluate a function and in a backwards direction when we compute gradients.
Later chapterswillformallyintroducebackpropagation, acomputationalprocedureforapplying thechainrule.
Fromtheviewpointofoptimization, gradientsallowustodeterminehowtomovethepa- rametersofamodelinordertolowertheloss, andeachstepoftheoptimizationalgorithms usedthroughoutthisbookwillrequirecalculatingthegradient.
2.4.6 Exercises 1.
Sofarwetooktherulesforderivativesforgranted.
Usingthedefinitionandlimitsprove thepropertiesfor(i) ğ‘“â€ğ‘¥â€ =ğ‘,(ii) ğ‘“â€ğ‘¥â€ =ğ‘¥ğ‘› ,(iii) ğ‘“â€ğ‘¥â€ =ğ‘’ğ‘¥ and(iv) ğ‘“â€ğ‘¥â€ =logğ‘¥.
2.
Inthesamevein, provetheproduct, sum, andquotientrulefromfirstprinciples.
3.
Provethattheconstantmultiplerulefollowsasaspecialcaseoftheproductrule.
4.
Calculatethederivativeof ğ‘“â€ğ‘¥â€ =ğ‘¥ğ‘¥ .
5.
Whatdoesitmeanthat ğ‘“0â€ğ‘¥â€ = 0forsomeğ‘¥? Giveanexampleofafunction ğ‘“ anda locationğ‘¥forwhichthismighthold.
6.
Plotthefunctionğ‘¦ = ğ‘“â€ğ‘¥â€ =ğ‘¥3 1 andplotitstangentlineatğ‘¥ =1.
ğ‘¥ 7.
Findthegradientofthefunction ğ‘“â€xâ€ =3ğ‘¥2â€š5ğ‘’ğ‘¥ 2.
1 8.
Whatisthegradientofthefunction ğ‘“â€xâ€ = kxk ? Whathappensforx=0? 2 9.
Can you write out the chain rule for the case where ğ‘¢ = ğ‘“â€ğ‘¥,ğ‘¦,ğ‘§â€ and ğ‘¥ = ğ‘¥â€ğ‘,ğ‘â€, ğ‘¦ = ğ‘¦â€ğ‘,ğ‘â€, andğ‘§ = ğ‘§â€ğ‘,ğ‘â€? 10.
Given a function ğ‘“â€ğ‘¥â€ that is invertible, compute the derivative of its inverse ğ‘“ 1â€ğ‘¥â€.
Here we have that ğ‘“ 1â€ğ‘“â€ğ‘¥â€â€ = ğ‘¥ and conversely ğ‘“â€ğ‘“ 1â€ğ‘¦â€â€ = ğ‘¦.
Hint: use these propertiesinyourderivation.
56 Discussions56.
60 Preliminaries 2.5 Automatic Differentiation Recallfrom Section2.4thatcalculatingderivativesisthecrucialstepinalltheoptimization algorithmsthatwewillusetotraindeepnetworks.
Whilethecalculationsarestraightfor- ward, workingthemoutbyhandcanbetediousanderror-prone, andtheseissuesonlygrow asourmodelsbecomemorecomplex.
Fortunatelyallmoderndeeplearningframeworkstakethisworkoffourplatesbyoffering automatic differentiation (often shortened to autograd).
As we pass data through each successivefunction, theframeworkbuildsacomputationalgraphthattrackshoweachvalue depends on others.
To calculate derivatives, automatic differentiation works backwards throughthisgraphapplyingthechainrule.
Thecomputationalalgorithmforapplyingthe chainruleinthisfashioniscalledbackpropagation.
While autograd libraries have become a hot concern over the past decade, they have a long history.
In fact the earliest references to autograd date back over half of a century (Wengert, 1964).
The core ideas behind modern backpropagation date to a Ph D thesis from1980(Speelpenning,1980)andwerefurtherdevelopedinthelate1980s(Griewank, 1989).
While backpropagation has become the default method for computing gradients, it is not the only option.
For instance, the Julia programming language employs forward propagation(Revelsetal.,2016).
Beforeexploringmethods, letâ€™sfirstmastertheautograd package.
import torch 2.5.1 ASimple Function Letâ€™sassumethatweareinterestedindifferentiatingthefunctionğ‘¦ =2x>xwithrespectto thecolumnvectorx.
Tostart, weassignxaninitialvalue.
x = torch.
arange(4.0) x tensor([0., 1., 2., 3.]) Before we calculate the gradient of ğ‘¦ with respect to x, we need a place to store it.
In general, we avoid allocating new memory every time we take a derivative because deep learningrequiressuccessivelycomputingderivativeswithrespecttothesameparameters agreatmanytimes, andwemightriskrunningoutofmemory.
Notethatthegradientof ascalar-valuedfunctionwithrespecttoavectorxisvector-valuedwiththesameshapeas x.
61 Automatic Differentiation # Can also create x = torch.
arange(4.0, requires_grad=True) x.
requires_grad_(True) x.
grad # The gradient is None by default Wenowcalculateourfunctionofxandassigntheresulttoy.
y = 2 * torch.
dot(x, x) y tensor(28., grad_fn=<Mul Backward0>) Wecannowtakethegradientofywithrespecttoxbycallingitsbackwardmethod.
Next, wecanaccessthegradientviaxâ€™sgradattribute.
y.
backward() x.
grad tensor([ 0., 4., 8., 12.]) Wealreadyknowthatthegradientofthefunction ğ‘¦ = 2x>xwithrespecttoxshouldbe 4x.
Wecannowverifythattheautomaticgradientcomputationandtheexpectedresultare identical.
x.
grad == 4 * x tensor([True, True, True, True]) Nowletâ€™scalculateanotherfunctionofxandtakeitsgradient.
Notethat Py Torchdoesnot automatically reset the gradient buffer when we record a new gradient.
Instead, the new gradientisaddedtothealready-storedgradient.
Thisbehaviorcomesinhandywhenwe wanttooptimizethesumofmultipleobjectivefunctions.
Toresetthegradientbuffer, we cancallx.
grad.
zero_()asfollows: x.
grad.
zero_() # Reset the gradient y = x.
sum() y.
backward() x.
grad tensor([1., 1., 1., 1.]) 2.5.2 Backwardfor Non-Scalar Variables When y is a vector, the most natural representation of the derivative of y with respect to a vector x is a matrix called the Jacobian that contains the partial derivatives of each 62 Preliminaries componentof ywithrespecttoeachcomponentof x.
Likewise, forhigher-orderyandx, theresultofdifferentiationcouldbeanevenhigher-ordertensor.
While Jacobiansdoshowupinsomeadvancedmachinelearningtechniques, morecom- monly we want to sum up the gradients of each component of y with respect to the full vector x, yielding a vector of the same shape as x.
For example, we often have a vector representingthevalueofourlossfunctioncalculatedseparatelyforeachexampleamonga batchoftrainingexamples.
Here, wejustwanttosumupthegradientscomputedindivid- uallyforeachexample.
Becausedeeplearningframeworksvaryinhowtheyinterpretgradientsofnon-scalarten- sors, Py Torch takes some steps to avoid confusion.
Invoking backward on a non-scalar elicitsanerrorunlesswetell Py Torchhowtoreducetheobjecttoascalar.
Moreformally, we need to provide some vector v such that backward will compute v>ğœ• y rather than x ğœ• y.
This next part may be confusing, but for reasons that will become clear later, this x argument(representingv)isnamedgradient.
Foramoredetaileddescription, see Yang Zhangâ€™s Mediumpost57.
57 x.
grad.
zero_() y = x * x y.
backward(gradient=torch.
ones(len(y))) # Faster: y.
sum().
backward() x.
grad tensor([0., 2., 4., 6.]) 2.5.3 Detaching Computation Sometimes, we wish to move some calculations outside of the recorded computational graph.
Forexample, saythatweusetheinputtocreatesomeauxiliaryintermediateterms for which we do not want to compute a gradient.
In this case, we need to detach the re- spectivecomputationalgraphfromthefinalresult.
Thefollowingtoyexamplemakesthis clearer: supposewehavez = x * yandy = x * xbutwewanttofocusonthedirect influenceof xonzratherthantheinfluenceconveyedviay.
Inthiscase, wecancreatea newvariableuthattakesthesamevalueasybutwhoseprovenance(howitwascreated) hasbeenwipedout.
Thusuhasnoancestorsinthegraphandgradientsdonotflowthrough utox.
Forexample, takingthegradientof z = x * uwillyieldtheresultu,(not3 * x * xasyoumighthaveexpectedsincez = x * x * x).
x.
grad.
zero_() y = x * x u = y.
detach() z = u * x z.
sum().
backward() x.
grad == u 63 Automatic Differentiation tensor([True, True, True, True]) Notethatwhilethisproceduredetachesyâ€™sancestorsfromthegraphleadingtoz, thecom- putational graph leading to y persists and thus we can calculate the gradient of y with respecttox.
x.
grad.
zero_() y.
sum().
backward() x.
grad == 2 * x tensor([True, True, True, True]) 2.5.4 Gradientsand Python Control Flow Sofarwereviewedcaseswherethepathfrominputtooutputwaswelldefinedviaafunc- tion such as z = x * x * x.
Programming offers us a lot more freedom in how we computeresults.
Forinstance, wecanmakethemdependonauxiliaryvariablesorcondi- tionchoicesonintermediateresults.
Onebenefitofusingautomaticdifferentiationisthat even if building the computational graph of a function required passing through a maze of Pythoncontrolflow(e.
g., conditionals, loops, andarbitraryfunctioncalls), wecanstill calculate the gradient of the resulting variable.
To illustrate this, consider the following codesnippetwherethenumberofiterationsofthewhileloopandtheevaluationoftheif statementbothdependonthevalueoftheinputa.
def f(a): b = a * 2 while b.
norm() < 1000: b = b * 2 if b.
sum() > 0: c = b else: c = 100 * b return c Below, we call this function, passing in a random value, as input.
Since the input is a randomvariable, wedonotknowwhatformthecomputationalgraphwilltake.
However, wheneverweexecutef(a)onaspecificinput, werealizeaspecificcomputationalgraph andcansubsequentlyrunbackward.
a = torch.
randn(size=(), requires_grad=True) d = f(a) d.
backward() Eventhoughourfunctionfis, fordemonstrationpurposes, abitcontrived, itsdependence ontheinputisquitesimple: itisalinear functionof awithpiecewisedefinedscale.
As 64 Preliminaries such, f(a) / aisavectorofconstantentriesand, moreover, f(a) / aneedstomatchthe gradientoff(a)withrespecttoa.
a.
grad == d / a tensor(True) Dynamic control flow is very common in deep learning.
For instance, when processing text, thecomputationalgraphdependsonthelengthoftheinput.
Inthesecases, automatic differentiationbecomesvitalforstatisticalmodelingsinceitisimpossibletocomputethe gradientapriori.
2.5.5 Discussion Youhavenowgottenatasteofthepowerofautomaticdifferentiation.
Thedevelopmentof librariesforcalculatingderivativesbothautomaticallyandefficientlyhasbeenamassive productivityboosterfordeeplearningpractitioners, liberatingthemsotheycanfocuson less menial.
Moreover, autograd lets us design massive models for which pen and paper gradientcomputationswouldbeprohibitivelytimeconsuming.
Interestingly, whileweuse autograd to optimize models (in a statistical sense) the optimization of autograd libraries themselves(inacomputationalsense)isarichsubjectofvitalinteresttoframeworkdesign- ers.
Here, toolsfromcompilersandgraphmanipulationareleveragedtocomputeresults inthemostexpedientandmemory-efficientmanner.
Fornow, trytorememberthesebasics: (i)attachgradientstothosevariableswithrespect towhichwedesirederivatives;(ii)recordthecomputationofthetargetvalue;(iii)execute thebackpropagationfunction; and(iv)accesstheresultinggradient.
2.5.6 Exercises 1.
Whyisthesecondderivativemuchmoreexpensivetocomputethanthefirstderivative? 2.
Afterrunningthefunctionforbackpropagation, immediatelyrunitagainandseewhat happens.
Investigate.
3.
In the control flow example where we calculate the derivative of d with respect to a, what would happen if we changed the variable a to a random vector or a matrix? At thispoint, theresultofthecalculationf(a)isnolongerascalar.
Whathappenstothe result? Howdoweanalyzethis? 4.
Let ğ‘“â€ğ‘¥â€ = sinâ€ğ‘¥â€.
Plotthegraphof ğ‘“ andofitsderivative ğ‘“0 .
Donotexploitthefact that ğ‘“0â€ğ‘¥â€ =cosâ€ğ‘¥â€butratheruseautomaticdifferentiationtogettheresult.
5.
Let ğ‘“â€ğ‘¥â€ = â€â€logğ‘¥2â€ sinğ‘¥â€â€šğ‘¥ 1.
Writeoutadependencygraphtracingresultsfrom ğ‘¥to ğ‘“â€ğ‘¥â€.
ğ‘‘ğ‘“ 6.
Usethechainruletocomputethederivative oftheaforementionedfunction, placing ğ‘‘ğ‘¥ eachtermonthedependencygraphthatyouconstructedpreviously.
65 Probabilityand Statistics 7.
Giventhegraphandtheintermediatederivativeresults, youhaveanumberofoptions when computing the gradient.
Evaluate the result once starting from ğ‘¥ to ğ‘“ and once from ğ‘“ tracingbacktoğ‘¥.
Thepathfromğ‘¥ to ğ‘“ iscommonlyknownasforwarddiffer- entiation, whereasthepathfrom ğ‘“ toğ‘¥isknownasbackwarddifferentiation.
8.
Whenmightyouwanttouseforward, andwhenbackward, differentiation? Hint: con- sider the amount of intermediate data needed, the ability to parallelize steps, and the sizeofmatricesandvectorsinvolved.
Discussions58.
58 2.6 Probability and Statistics Onewayoranother, machinelearningisallaboutuncertainty.
Insupervisedlearning, we wanttopredictsomethingunknown(thetarget)givensomethingknown(thefeatures).
De- pendingonourobjective, wemightattempttopredictthemostlikelyvalueofthetarget.
Or we might predict the value with the smallest expected distance from the target.
And sometimeswewishnotonlytopredictaspecificvaluebuttoquantifyouruncertainty.
For example, givensomefeaturesdescribingapatient, wemightwanttoknowhowlikelythey aretosufferaheartattackinthenextyear.
Inunsupervisedlearning, weoftencareabout uncertainty.
Todeterminewhetherasetofmeasurementsareanomalous, ithelpstoknow howlikelyoneistoobservevaluesinapopulationofinterest.
Furthermore, inreinforce- ment learning, we wish to develop agents that act intelligently in various environments.
Thisrequiresreasoningabouthowanenvironmentmightbeexpectedtochangeandwhat rewardsonemightexpecttoencounterinresponsetoeachoftheavailableactions.
Probabilityisthemathematicalfieldconcernedwithreasoningunderuncertainty.
Givena probabilisticmodelofsomeprocess, wecanreasonaboutthelikelihoodofvariousevents.
Theuseofprobabilitiestodescribethefrequenciesofrepeatableevents(likecointosses)is fairlyuncontroversial.
Infact, frequentistscholarsadheretoaninterpretationofprobability thatappliesonlytosuchrepeatableevents.
Bycontrast Bayesianscholarsusethelanguage ofprobabilitymorebroadlytoformalizereasoningunderuncertainty.
Bayesianprobability ischaracterizedbytwouniquefeatures: (i)assigningdegreesofbelieftonon-repeatable events, e.
g., whatistheprobabilitythatadamwillcollapse?; and(ii)subjectivity.
While Bayesianprobabilityprovidesunambiguousrulesforhowoneshouldupdatetheirbeliefsin lightofnewevidence, itallowsfordifferentindividualstostartoffwithdifferentpriorbe- liefs.
Statisticshelpsustoreasonbackwards, startingoffwithcollectionandorganization ofdataandbackingouttowhatinferenceswemightdrawabouttheprocessthatgenerated thedata.
Wheneverweanalyzeadataset, huntingforpatternsthatwehopemightcharac- terizeabroaderpopulation, weareemployingstatisticalthinking.
Manycourses, majors, theses, careers, departments, companies, andinstitutionshavebeendevotedtothestudyof probabilityandstatistics.
Whilethissectiononlyscratchesthesurface, wewillprovidethe foundationthatyouneedtobeginbuildingmodels.
66 Preliminaries %matplotlib inline import random import torch from torch.
distributions.
multinomial import Multinomial from d2l import torch as d2l 2.6.1 ASimple Example: Tossing Coins Imagine that we plan to toss a coin and want to quantify how likely we are to see heads (vs.
tails).
If the coin is fair, then both outcomes (heads and tails), are equally likely.
Moreover if weplan to toss the coin ğ‘› times then the fraction of heads that we expect to see should exactly match the expected fraction of tails.
One intuitive way to see this is bysymmetry: foreverypossibleoutcomewith ğ‘› headsand ğ‘› = â€ğ‘› ğ‘› â€ tails, thereis h t h anequallylikelyoutcomewithğ‘› headsandğ‘› tails.
Notethatthisisonlypossibleifon t h averageweexpecttosee1 2oftossescomeupheadsand1 2comeuptails.
Ofcourse, if youconductthisexperimentmanytimeswithğ‘› = 1000000tosseseach, youmightnever seeatrialwhereğ‘› =ğ‘› exactly.
h t Formally, the quantity 1 2 is called a probability and here it captures the certainty with whichanygiventosswillcomeupheads.
Probabilitiesassignscoresbetween0and1to outcomesofinterest, calledevents.
Heretheeventofinterestisheadsandwedenotethe correspondingprobabilityğ‘ƒâ€headsâ€.
Aprobabilityof1indicatesabsolutecertainty(imag- ineatrickcoinwherebothsideswereheads)andaprobabilityof0indicatesimpossibility (e.
g., ifbothsidesweretails).
Thefrequenciesğ‘› ğ‘›andğ‘› ğ‘›arenotprobabilitiesbutrather h t statistics.
Probabilitiesaretheoreticalquantitiesthatunderlythedatageneratingprocess.
Here, theprobability1 2isapropertyofthecoinitself.
Bycontrast, statisticsareempirical quantitiesthatarecomputedasfunctionsoftheobserveddata.
Ourinterestsinprobabilis- ticandstatisticalquantitiesareinextricablyintertwined.
Weoftendesignspecialstatistics calledestimatorsthat, givenadataset, produceestimatesofmodelparameterssuchasprob- abilities.
Moreover, whenthoseestimatorssatisfyanicepropertycalledconsistency, our estimateswillconvergetothecorrespondingprobability.
Inturn, theseinferredprobabili- tiestellaboutthelikelystatisticalpropertiesofdatafromthesamepopulationthatwemight encounterinthefuture.
Supposethatwestumbleduponarealcoinforwhichwedidnotknowthetrueğ‘ƒâ€headsâ€.
Toinvestigatethisquantitywithstatisticalmethods, weneedto(i)collectsomedata; and (ii) design an estimator.
Data acquisition here is easy; we can toss the coin many times andrecordalltheoutcomes.
Formally, drawingrealizationsfromsomeunderlyingrandom processiscalledsampling.
Asyoumighthaveguessed, onenaturalestimatoristheratio ofthenumberofobservedheadstothetotalnumberoftosses.
Now, supposethatthecoinwasinfactfair, i.
e., ğ‘ƒâ€headsâ€ = 0.5.
Tosimulatetossesofa faircoin, wecaninvokeanyrandomnumbergenerator.
Therearesomeeasywaystodraw samples of an event with probability 0.5.
For example Pythonâ€™s random.
random yields numbersintheinterval Â»0,1â€¦ wheretheprobabilityoflyinginanysub-interval Â»ğ‘,ğ‘â€¦ 67 Probabilityand Statistics Â»0,1â€¦ isequaltoğ‘ ğ‘.
Thuswecangetout0and1withprobability0.5eachbytesting whetherthereturnedfloatnumberisgreaterthan0.5: num_tosses = 100 heads = sum([random.
random() > 0.5 for _ in range(num_tosses)]) tails = num_tosses - heads print("heads, tails: ", [heads, tails]) heads, tails: [44, 56] More generally, we can simulate multiple draws from any variable with a finite number of possible outcomes (like the toss of a coin or roll of a die) by calling the multinomial function, settingthefirstargumenttothenumberofdrawsandthesecondasalistofprob- abilitiesassociatedwitheachofthepossibleoutcomes.
Tosimulatetentossesofafaircoin, weassignprobabilityvector[0.5, 0.5], interpretingindex0asheadsandindex1astails.
Thefunctionreturnsavectorwithlengthequaltothenumberofpossibleoutcomes(here, 2), wherethefirstcomponenttellsusthenumberofoccurrencesofheadsandthesecond componenttellsusthenumberofoccurrencesoftails.
fair_probs = torch.
tensor([0.5, 0.5]) Multinomial(100, fair_probs).
sample() tensor([50., 50.]) Each time you run this sampling process, you will receive a new random value that may differfromthepreviousoutcome.
Dividingbythenumberoftossesgivesusthefrequency ofeachoutcomeinourdata.
Notethatthesefrequencies, justliketheprobabilitiesthatthey areintendedtoestimate, sumto1.
Multinomial(100, fair_probs).
sample() / 100 tensor([0.4800, 0.5200]) Here, eventhoughoursimulatedcoinisfair(weourselvessettheprobabilities[0.5, 0.
5]), the counts of heads and tails may not be identical.
That is because we only drew a relativelysmallnumberofsamples.
Ifwedidnotimplementthesimulationourselves, and onlysawtheoutcome, howwouldweknowifthecoinwereslightlyunfairorifthepossible deviationfrom1 2wasjustanartifactofthesmallsamplesize? Letâ€™sseewhathappens whenwesimulate10,000tosses.
counts = Multinomial(10000, fair_probs).
sample() counts / 10000 68 Preliminaries tensor([0.4966, 0.5034]) Ingeneral, foraveragesofrepeatedevents(likecointosses), asthenumberofrepetitions grows, ourestimatesareguaranteedtoconvergetothetrueunderlyingprobabilities.
The mathematicalformulationofthisphenomenoniscalledthelawoflargenumbersandthe central limit theorem tells us that in many situations, as the sample size ğ‘› grows, these p errorsshouldgodownatarateof â€1 ğ‘›â€.
Letâ€™sgetsomemoreintuitionbystudyinghow ourestimateevolvesaswegrowthenumberoftossesfrom1to10,000.
counts = Multinomial(1, fair_probs).
sample((10000,)) cum_counts = counts.
cumsum(dim=0) estimates = cum_counts / cum_counts.
sum(dim=1, keepdims=True) estimates = estimates.
numpy() d2l.
set_figsize((4.5, 3.5)) d2l.
plt.
plot(estimates[:, 0], label=("P(coin=heads)")) d2l.
plt.
plot(estimates[:, 1], label=("P(coin=tails)")) d2l.
plt.
axhline(y=0.5, color='black', linestyle='dashed') d2l.
plt.
gca().
set_xlabel('Samples') d2l.
plt.
gca().
set_ylabel('Estimated probability') d2l.
plt.
legend(); Eachsolidcurvecorrespondstooneofthetwovaluesofthecoinandgivesourestimated probabilitythatthecointurnsupthatvalueaftereachgroupofexperiments.
Thedashed blacklinegivesthetrueunderlyingprobability.
Aswegetmoredatabyconductingmore experiments, thecurvesconvergetowardsthetrueprobability.
Youmightalreadybeginto see the shape of some of the more advanced questions that preoccupy statisticians: How quicklydoesthisconvergencehappen? Ifwehadalreadytestedmanycoinsmanufactured atthesameplant, howmightweincorporatethisinformation? 2.6.2 AMore Formal Treatment Wehavealreadygottenprettyfar: posingaprobabilisticmodel, generatingsyntheticdata, runningastatisticalestimator, empiricallyassessingconvergence, andreportingerrormet- 69 Probabilityand Statistics rics(checkingthedeviation).
However, togomuchfurther, wewillneedtobemorepre- cise.
Whendealingwithrandomness, wedenotethesetofpossibleoutcomes S andcallitthe sample space or outcome space.
Here, each element is a distinct possible outcome.
In thecaseofrollingasinglecoin, S = fheads, tailsg.
Forasingledie, S = f1,2,3,4,5,6g.
Whenflippingtwocoins, possibleoutcomesarefâ€heads, headsâ€,â€heads, tailsâ€,â€tails, headsâ€,â€tails, tailsâ€g.
Eventsaresubsetsofthesamplespace.
Forinstance, theeventâ€œthefirstcointosscomes up headsâ€ corresponds to the set fâ€heads, headsâ€,â€heads, tailsâ€g.
Whenever the outcome ğ‘§ of a random experiment satisfies ğ‘§ 2 A, then event A has occurred.
For a single roll ofadie, wecoulddefinetheeventsâ€œseeinga5â€(A = f5g)andâ€œseeinganoddnumberâ€ (B = f1,3,5g).
Inthiscase, ifthediecameup5, wewouldsaythatboth Aand Boccurred.
Ontheotherhand, ifğ‘§ =3, then A didnotoccurbut Bdid.
A probability function maps events onto real values ğ‘ƒ : A S ! Â»0,1â€¦.
The probabil- ity, denoted ğ‘ƒâ€Aâ€, ofanevent A inthegivensamplespace S, hasthefollowingproper- ties: Theprobabilityofanyevent A isanonnegativerealnumber, i.
e.,ğ‘ƒâ€Aâ€ 0; Theprobabilityoftheentiresamplespaceis1, i.
e.,ğ‘ƒâ€Sâ€ =1; Foranycountablesequenceofevents A 1 , A 2 ğ‘– \ A ğ‘— = ; forallğ‘– â‰  ğ‘—), theprobability â€” thatanyoft Ë hemhappensisequaltothesumof theirindividualprobabilities, i.
e.,ğ‘ƒâ€ 1 ğ‘–=1 A ğ‘– â€ = 1 ğ‘–=1 ğ‘ƒâ€A ğ‘– â€.
These axioms of probability theory, proposed by Kolmogorov (1933), can be applied to rapidlyderiveanumberofimportantconsequences.
Forinstance, itfollowsimmediately thattheprobabilityofanyevent Aoritscomplement A0 occurringis1(because A[A0 = S).
Wecanalsoprovethatğ‘ƒâ€;â€ =0because1= ğ‘ƒâ€S[S0â€ = ğ‘ƒâ€S[;â€ = ğ‘ƒâ€Sâ€â€šğ‘ƒâ€;â€ = 1â€šğ‘ƒâ€;â€.
Consequently, theprobabilityofanyevent A anditscomplement A0 occurring simultaneouslyisğ‘ƒâ€A\A0â€ =0.
Informally, thistellsusthatimpossibleeventshavezero probabilityofoccurring.
2.6.3 Random Variables When we spoke about events like the roll of a die coming up odds or the first coin toss coming up heads, we were invoking the idea of a random variable.
Formally, random variablesaremappingsfromanunderlyingsamplespacetoasetof(possiblymany)values.
Youmightwonderhowarandomvariableisdifferentfromthesamplespace, sincebothare collectionsofoutcomes.
Importantly, randomvariablescanbemuchcoarserthantheraw samplespace.
Wecandefineabinaryrandomvariablelikeâ€œgreaterthan0.5â€evenwhen theunderlyingsamplespaceisinfinite, e.
g., pointsonthelinesegmentbetween0and1.
Additionally, multiplerandomvariablescansharethesameunderlyingsamplespace.
For exampleâ€œwhethermyhomealarmgoesoffâ€andâ€œwhethermyhousewasburgledâ€areboth binaryrandomvariablesthatshareanunderlyingsamplespace.
Consequently, knowingthe valuetakenbyonerandomvariablecantellussomethingaboutthelikelyvalueofanother 70 Preliminaries randomvariable.
Knowingthatthealarmwentoff, wemightsuspectthatthehousewas likelyburgled.
Everyvaluetakenbyarandomvariablecorrespondstoasubsetoftheunderlyingsample space.
Thustheoccurrencewheretherandomvariableğ‘‹ takesvalueğ‘£, denotedbyğ‘‹ =ğ‘£, isaneventandğ‘ƒâ€ğ‘‹ = ğ‘£â€ denotesitsprobability.
Sometimesthisnotationcangetclunky, andwecanabusenotationwhenthecontextisclear.
Forexample, wemightuse ğ‘ƒâ€ğ‘‹â€ to referbroadlytothedistributionof ğ‘‹, i.
e., thefunctionthattellsustheprobabilitythat ğ‘‹ takesanygivenvalue.
Othertimeswewriteexpressionslike ğ‘ƒâ€ğ‘‹,ğ‘Œâ€ = ğ‘ƒâ€ğ‘‹â€ğ‘ƒâ€ğ‘Œâ€, asa shorthandtoexpressastatementthatistrueforallofthevaluesthattherandomvariables ğ‘‹ andğ‘Œ cantake, i.
e., forallğ‘–, ğ‘— itholdsthat ğ‘ƒâ€ğ‘‹ = ğ‘–andğ‘Œ = ğ‘—â€ = ğ‘ƒâ€ğ‘‹ = ğ‘–â€ğ‘ƒâ€ğ‘Œ = ğ‘—â€.
Othertimes, weabusenotationbywritingğ‘ƒâ€ğ‘£â€whentherandomvariableisclearfromthe context.
Sinceaneventinprobabilitytheoryisasetofoutcomesfromthesamplespace, wecanspecifyarangeofvaluesforarandomvariabletotake.
Forexample,ğ‘ƒâ€1 ğ‘‹ 3â€ denotestheprobabilityoftheeventf1 ğ‘‹ 3g.
Notethatthereisasubtledifferencebetweendiscreterandomvariables, likeflipsofacoin ortossesofadie, andcontinuousones, liketheweightandtheheightofapersonsampled atrandomfromthepopulation.
Inthiscaseweseldomreallycareaboutsomeoneâ€™sexact height.
Moreover, if we took precise enough measurements, we would find that no two peopleontheplanethavetheexactsameheight.
Infact, withfineenoughmeasurements, youwouldneverhavethesameheightwhenyouwakeupandwhenyougotosleep.
There islittlepointinaskingabouttheexactprobabilitythatsomeoneis1.801392782910287192 meters tall.
Instead, we typically care more about being able to say whether someoneâ€™s heightfallsintoagiveninterval, saybetween1.79and1.81meters.
Inthesecaseswework withprobabilitydensities.
Theheightofexactly1.80metershasnoprobability, butnonzero density.
Toworkouttheprobabilityassignedtoaninterval, wemusttakeanintegralofthe densityoverthatinterval.
2.6.4 Multiple Random Variables Youmighthavenoticedthatwecouldnotevenmakeitthroughtheprevioussectionwithout makingstatementsinvolvinginteractionsamongmultiplerandomvariables(recallğ‘ƒâ€ğ‘‹,ğ‘Œâ€ = ğ‘ƒâ€ğ‘‹â€ğ‘ƒâ€ğ‘Œâ€).
Mostofmachinelearningisconcernedwithsuchrelationships.
Here, thesam- plespacewouldbethepopulationofinterest, saycustomerswhotransactwithabusiness, photographsonthe Internet, orproteinsknowntobiologists.
Eachrandomvariablewould representthe(unknown)valueofadifferentattribute.
Wheneverwesampleanindividual from the population, we observe a realization of each of the random variables.
Because thevaluestakenbyrandomvariablescorrespondtosubsetsofthesamplespacethatcould beoverlapping, partiallyoverlapping, orentirelydisjoint, knowingthevaluetakenbyone randomvariablecancauseustoupdateourbeliefsaboutwhichvaluesofanotherrandom variablearelikely.
Ifapatientwalksintoahospitalandweobservethattheyarehaving trouble breathing and have lost their sense of smell, then we believe that they are more likely to have COVID-19 than we might if they had no trouble breathing and a perfectly ordinarysenseofsmell.
Whenworkingwithmultiplerandomvariables, wecanconstructeventscorrespondingto 71 Probabilityand Statistics every combination of values that the variables can jointly take.
The probability function thatassignsprobabilitiestoeachofthesecombinations(e.
g.ğ´=ğ‘andğµ= ğ‘)iscalledthe joint probability function and simply returns the probability assigned to the intersection of the corresponding subsets of the sample space.
The joint probability assigned to the eventwhererandomvariables ğ´andğµtakevaluesğ‘andğ‘, respectively, isdenotedğ‘ƒâ€ğ´= ğ‘,ğµ = ğ‘â€, wherethecommaindicatesâ€œandâ€.
Notethatforanyvaluesğ‘ andğ‘, itfollows that ğ‘ƒâ€ğ´=ğ‘,ğµ= ğ‘â€ ğ‘ƒâ€ğ´=ğ‘â€andğ‘ƒâ€ğ´=ğ‘,ğµ= ğ‘â€ ğ‘ƒâ€ğµ= ğ‘â€, (2.6.1) since for ğ´ = ğ‘ and ğµ = ğ‘ to happen, ğ´ = ğ‘ has to happen and ğµ = ğ‘ also has to happen.
Interestingly, thejointprobabilitytellsusallthatwecanknowabouttheserandom variablesinaprobabilisticsense, andcanbeusedtoderivemanyotherusefulquantities, including recovering the individual distributions ğ‘ƒâ€ğ´â€ and ğ‘ƒâ€ğµâ€.
To recover ğ‘ƒâ€ğ´ = ğ‘â€ wesimplysumupğ‘ƒâ€ğ´ = ğ‘,ğµ = ğ‘£â€ overallvaluesğ‘£ thattherandomvariable ğµcantake: Ë ğ‘ƒâ€ğ´=ğ‘â€ = ğ‘£ ğ‘ƒâ€ğ´=ğ‘,ğµ=ğ‘£â€.
Theratio ğ‘ƒâ€ğ´=ğ‘,ğµ=ğ‘â€ 1turnsouttobeextremelyimportant.
Itiscalledtheconditional ğ‘ƒâ€ğ´=ğ‘â€ probability, andisdenotedviatheâ€œjâ€symbol: ğ‘ƒâ€ğµ= ğ‘ j ğ´=ğ‘â€ = ğ‘ƒâ€ğ´=ğ‘,ğµ= ğ‘â€ ğ‘ƒâ€ğ´=ğ‘â€.
(2.6.2) Ittellsusthenewprobabilityassociatedwiththeevent ğµ = ğ‘, onceweconditiononthe fact ğ´ = ğ‘tookplace.
Wecanthinkofthisconditionalprobabilityasrestrictingattention onlytothesubsetofthesamplespaceassociatedwithğ´=ğ‘andthenrenormalizingsothat allprobabilitiessumto1.
Conditionalprobabilitiesareinfactjustordinaryprobabilities andthusrespectalloftheaxioms, aslongasweconditionalltermsonthesameeventand thusrestrictattentiontothesamesamplespace.
Forinstance, fordisjointevents Band B0 , wehavethatğ‘ƒâ€B[B0 j ğ´=ğ‘â€ = ğ‘ƒâ€B j ğ´=ğ‘â€â€šğ‘ƒâ€B0 j ğ´=ğ‘â€.
Using the definition of conditional probabilities, we can derive the famous result called Bayesâ€™theorem.
Byconstruction, wehavethat ğ‘ƒâ€ğ´,ğµâ€ = ğ‘ƒâ€ğµ j ğ´â€ğ‘ƒâ€ğ´â€ and ğ‘ƒâ€ğ´,ğµâ€ = ğ‘ƒâ€ğ´ j ğµâ€ğ‘ƒâ€ğµâ€.
Combining both equations yields ğ‘ƒâ€ğµ j ğ´â€ğ‘ƒâ€ğ´â€ = ğ‘ƒâ€ğ´ j ğµâ€ğ‘ƒâ€ğµâ€ and hence ğ‘ƒâ€ğµ j ğ´â€ğ‘ƒâ€ğ´â€ ğ‘ƒâ€ğ´ j ğµâ€ = .
(2.6.3) ğ‘ƒâ€ğµâ€ Thissimpleequationhasprofoundimplicationsbecauseitallowsustoreversetheorderof conditioning.
Ifweknowhowtoestimateğ‘ƒâ€ğµ j ğ´â€,ğ‘ƒâ€ğ´â€, andğ‘ƒâ€ğµâ€, thenwecanestimate ğ‘ƒâ€ğ´ j ğµâ€.
Weoftenfinditeasiertoestimateonetermdirectlybutnottheotherand Bayesâ€™ theoremcancometotherescuehere.
Forinstance, ifweknowtheprevalenceofsymptoms foragivendisease, andtheoverallprevalencesofthediseaseandsymptoms, respectively, wecandeterminehowlikelysomeoneistohavethediseasebasedontheirsymptoms.
In somecaseswemightnothavedirectaccesstoğ‘ƒâ€ğµâ€, suchastheprevalenceofsymptoms.
Inthiscaseasimplifiedversionof Bayesâ€™theoremcomesinhandy: ğ‘ƒâ€ğ´ j ğµâ€ / ğ‘ƒâ€ğµ j ğ´â€ğ‘ƒâ€ğ´â€.
(2.6.4) 72 Preliminaries Ë Sinceweknowthatğ‘ƒâ€ğ´ j ğµâ€ mustbenormalizedto1, i.
e., ğ‘ ğ‘ƒâ€ğ´ = ğ‘ j ğµâ€ =1, wecan useittocompute ğ‘ƒâ€ğµ j ğ´â€ğ‘ƒâ€ğ´â€ ğ‘ƒâ€ğ´ j ğµâ€ = Ë .
(2.6.5) ğ‘ ğ‘ƒâ€ğµ j ğ´=ğ‘â€ğ‘ƒâ€ğ´=ğ‘â€ In Bayesian statistics, we think of an observer as possessing some (subjective) prior be- liefs about the plausibility of the available hypotheses encoded in the prior ğ‘ƒâ€ğ»â€, and a likelihood function that says how likely one is to observe any value of the collected evi- denceforeachofthehypothesesintheclassğ‘ƒâ€ğ¸ j ğ»â€.
Bayesâ€™theoremistheninterpreted as telling us how to update the initial prior ğ‘ƒâ€ğ»â€ in light of the available evidence ğ¸ to produceposteriorbeliefsğ‘ƒâ€ğ» j ğ¸â€ = ğ‘ƒâ€ğ¸jğ»â€ğ‘ƒâ€ğ»â€ .
Informally, thiscanbestatedasâ€œpos- ğ‘ƒâ€ğ¸â€ teriorequalspriortimeslikelihood, dividedbytheevidenceâ€.
Now, becausetheevidence ğ‘ƒâ€ğ¸â€ is the same for all hypotheses, we can get away with simply normalizing over the hypotheses.
Ë Note that ğ‘ ğ‘ƒâ€ğ´ = ğ‘ j ğµâ€ = 1 also allows us to marginalize over random variables.
Thatis, wecandropvariablesfromajointdistributionsuchasğ‘ƒâ€ğ´,ğµâ€.
Afterall, wehave that ğ‘ƒâ€ğµ j ğ´=ğ‘â€ğ‘ƒâ€ğ´=ğ‘â€ = ğ‘ƒâ€ğµ,ğ´=ğ‘â€ = ğ‘ƒâ€ğµâ€.
(2.6.6) ğ‘ ğ‘ Independenceisanotherfundamentallyimportantconceptthatformsthebackboneofmany importantideasinstatistics.
Inshort, twovariablesareindependentifconditioningonthe valueof ğ´doesnotcauseanychangetotheprobabilitydistributionassociatedwithğµand viceversa.
Moreformally, independence, denoted ğ´ ? ğµ, requiresthatğ‘ƒâ€ğ´ j ğµâ€ = ğ‘ƒâ€ğ´â€ and, consequently, that ğ‘ƒâ€ğ´,ğµâ€ = ğ‘ƒâ€ğ´ j ğµâ€ğ‘ƒâ€ğµâ€ = ğ‘ƒâ€ğ´â€ğ‘ƒâ€ğµâ€.
Independence is often anappropriateassumption.
Forexample, iftherandomvariable ğ´representstheoutcome fromtossingonefaircoinandtherandomvariableğµrepresentstheoutcomefromtossing another, thenknowingwhether ğ´cameupheadsshouldnotinfluencetheprobabilityofğµ comingupheads.
Independence is especially useful when it holds among the successive draws of our data fromsomeunderlyingdistribution(allowingustomakestrongstatisticalconclusions)or whenitholdsamongvariousvariablesinourdata, allowingustoworkwithsimplermodels thatencodethisindependencestructure.
Ontheotherhand, estimatingthedependencies amongrandomvariablesisoftentheveryaimoflearning.
Wecaretoestimatetheprobabil- ityofdiseasegivensymptomsspecificallybecausewebelievethatdiseasesandsymptoms arenotindependent.
Notethatbecauseconditionalprobabilitiesareproperprobabilities, theconceptsofinde- pendenceanddependencealsoapplytothem.
Tworandomvariablesğ´andğµarecondition- allyindependentgivenathirdvariableğ¶ ifandonlyifğ‘ƒâ€ğ´,ğµ j ğ¶â€ = ğ‘ƒâ€ğ´ j ğ¶â€ğ‘ƒâ€ğµ j ğ¶â€.
Interestingly, two variables can be independent in general but become dependent when conditioning on a third.
This often occurs when the two random variables ğ´ and ğµ cor- respond to causes of some third variableğ¶.
For example, broken bones and lung cancer mightbeindependentinthegeneralpopulationbutifweconditiononbeinginthehospital thenwemightfindthatbrokenbonesarenegativelycorrelatedwithlungcancer.
Thatis 73 Probabilityand Statistics becausethebrokenboneexplainsawaywhysomepersonisinthehospitalandthuslowers theprobabilitythattheyarehospitalizedbecauseofhavinglungcancer.
Andconversely, twodependentrandomvariablescanbecomeindependentuponcondition- ingon athird.
This often happenswhen twootherwise unrelatedeventshaveacommon cause.
Shoesizeandreadinglevelarehighlycorrelatedamongelementaryschoolstudents, butthiscorrelationdisappearsifweconditiononage.
2.6.5 An Example Letâ€™sputourskillstothetest.
Assumethatadoctoradministersan HIVtesttoapatient.
This test is fairly accurate and fails only with 1% probability if the patient is healthy but reportedasdiseased, i.
e., healthypatientstestpositivein1%ofcases.
Moreover, itnever failstodetect HIVifthepatientactuallyhasit.
Weuseğ· 2 f0,1gtoindicatethediagnosis 1 (0ifnegativeand1ifpositive)andğ» 2 f0,1gtodenotethe HIVstatus.
Conditionalprobability ğ» =1 ğ» =0 ğ‘ƒâ€ğ· =1 j ğ»â€ 1 0.01 1 ğ‘ƒâ€ğ· =0 j ğ»â€ 0 0.99 1 Notethatthecolumnsumsareall1(buttherowsumsdonot), sincetheyareconditional probabilities.
Letâ€™s compute the probability of the patient having HIV if the test comes backpositive, i.
e.,ğ‘ƒâ€ğ» =1 j ğ· =1â€.
Intuitivelythisisgoingtodependonhowcommon 1 the disease is, since it affects the number of false alarms.
Assume that the population is fairlyfreeofthedisease, e.
g., ğ‘ƒâ€ğ» = 1â€ = 0.0015.
Toapply Bayesâ€™theorem, weneedto applymarginalizationtodetermine ğ‘ƒâ€ğ· =1â€ =ğ‘ƒâ€ğ· =1,ğ» =0â€â€šğ‘ƒâ€ğ· =1,ğ» =1â€ 1 1 1 =ğ‘ƒâ€ğ· =1 j ğ» =0â€ğ‘ƒâ€ğ» =0â€â€šğ‘ƒâ€ğ· =1 j ğ» =1â€ğ‘ƒâ€ğ» =1â€ (2.6.7) 1 1 =0.011485.
Thisleadsusto ğ‘ƒâ€ğ· =1 j ğ» =1â€ğ‘ƒâ€ğ» =1â€ ğ‘ƒâ€ğ» =1 j ğ· =1â€ = 1 =0.1306.
(2.6.8) 1 ğ‘ƒâ€ğ· =1â€ 1 Inotherwords, thereisonlya13.06%chancethatthepatientactuallyhas HIV, despitethe testbeingprettyaccurate.
Aswecansee, probabilitycanbecounterintuitive.
Whatshoulda patientdouponreceivingsuchterrifyingnews? Likely, thepatientwouldaskthephysician toadministeranothertesttogetclarity.
Thesecondtesthasdifferentcharacteristicsandit isnotasgoodasthefirstone.
Conditionalprobability ğ» =1 ğ» =0 ğ‘ƒâ€ğ· =1 j ğ»â€ 0.98 0.03 2 ğ‘ƒâ€ğ· =0 j ğ»â€ 0.02 0.97 2 74 Preliminaries Unfortunately, thesecondtestcomesbackpositive, too.
Letâ€™scalculatetherequisiteprob- abilitiestoinvoke Bayesâ€™theorembyassumingconditionalindependence: ğ‘ƒâ€ğ· =1,ğ· =1 j ğ» =0â€ = ğ‘ƒâ€ğ· =1 j ğ» =0â€ğ‘ƒâ€ğ· =1 j ğ» =0â€ = 0.0003, 1 2 1 2 ğ‘ƒâ€ğ· =1,ğ· =1 j ğ» =1â€ = ğ‘ƒâ€ğ· =1 j ğ» =1â€ğ‘ƒâ€ğ· =1 j ğ» =1â€ = 0.98.
1 2 1 2 (2.6.9) Nowwecanapplymarginalizationtoobtaintheprobabilitythatbothtestscomebackpos- itive: ğ‘ƒâ€ğ· =1,ğ· =1â€ 1 2 = ğ‘ƒâ€ğ· =1,ğ· =1,ğ» =0â€â€šğ‘ƒâ€ğ· =1,ğ· =1,ğ» =1â€ 1 2 1 2 = ğ‘ƒâ€ğ· =1,ğ· =1 j ğ» =0â€ğ‘ƒâ€ğ» =0â€â€šğ‘ƒâ€ğ· =1,ğ· =1 j ğ» =1â€ğ‘ƒâ€ğ» =1â€ 1 2 1 2 =0.00176955.
(2.6.10) Finally, theprobabilityofthepatienthaving HIVgiventhatbothtestsarepositiveis ğ‘ƒâ€ğ· =1,ğ· =1 j ğ» =1â€ğ‘ƒâ€ğ» =1â€ ğ‘ƒâ€ğ» =1 j ğ· =1,ğ· =1â€ = 1 2 =0.8307.
(2.6.11) 1 2 ğ‘ƒâ€ğ· =1,ğ· =1â€ 1 2 Thatis, thesecondtestallowedustogainmuchhigherconfidencethatnotalliswell.
De- spitethesecondtestbeingconsiderablylessaccuratethanthefirstone, itstillsignificantly improved our estimate.
The assumption of both tests being conditionally independent of each other was crucial for our ability to generate a more accurate estimate.
Take the ex- tremecasewherewerunthesametesttwice.
Inthissituationwewouldexpectthesame outcomebothtimes, hencenoadditionalinsightisgainedfromrunningthesametestagain.
Theastutereadermighthavenoticedthatthediagnosisbehavedlikeaclassifierhidingin plainsightwhereourabilitytodecidewhetherapatientishealthyincreasesasweobtain morefeatures(testoutcomes).
2.6.6 Expectations Often, makingdecisionsrequiresnotjustlookingattheprobabilitiesassignedtoindivid- ual events but composing them together into useful aggregates that can provide us with guidance.
For example, when random variables take continuous scalar values, we often careaboutknowingwhatvaluetoexpectonaverage.
Thisquantityisformallycalledan expectation.
Ifwearemakinginvestments, thefirstquantityofinterestmightbethereturn we can expect, averaging over all the possible outcomes (and weighting by the appropri- ate probabilities).
For instance, say that with 50% probability, an investment might fail altogether, with 40% probability it might provide a 2 return, and with 10% probability itmight providea 10 return10 .
Tocalculate theexpectedreturn, wesumoverallre- turns, multiplyingeachbytheprobabilitythattheywilloccur.
Thisyieldstheexpectation Ingeneral, theexpectation(oraverage)oftherandomvariable ğ‘‹ isdefinedas ğ¸Â»ğ‘‹â€¦ = ğ¸ ğ‘¥ ğ‘ƒ Â»ğ‘¥â€¦ = ğ‘¥ğ‘ƒâ€ğ‘‹ =ğ‘¥â€.
(2.6.12) ğ‘¥ 75 Probabilityand Statistics fl Likewise, fordensitiesweobtain ğ¸Â»ğ‘‹â€¦ = ğ‘¥ ğ‘‘ğ‘â€ğ‘¥â€.
Sometimesweareinterestedinthe expectedvalueofsomefunctionofğ‘¥.
Wecancalculatetheseexpectationsas â€ ğ¸ ğ‘¥ ğ‘ƒ Â»ğ‘“â€ğ‘¥â€â€¦ = ğ‘“â€ğ‘¥â€ğ‘ƒâ€ğ‘¥â€andğ¸ ğ‘¥ ğ‘ƒ Â»ğ‘“â€ğ‘¥â€â€¦ = ğ‘“â€ğ‘¥â€ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ (2.6.13) ğ‘¥ for discrete probabilities and densities, respectively.
Returning to the investment exam- ple from above, ğ‘“ might be the utility (happiness) associated with the return.
Behavior economistshavelongnotedthatpeopleassociategreaterdisutilitywithlosingmoneythan the utility gained from earning one dollar relative to their baseline.
Moreover, the value ofmoneytendstobesub-linear.
Possessing100kdollarsversuszerodollarscanmakethe differencebetweenpayingtherent, eatingwell, andenjoyingqualityhealthcareversussuf- feringthroughhomelessness.
Ontheotherhand, thegainsduetopossessing200kversus 100karelessdramatic.
ReasoninglikethismotivatestheclichÃ©thatâ€œtheutilityofmoney islogarithmicâ€.
Iftheutilityassociatedwithatotallosswere 1, andtheutilitiesassociatedwithreturnsof 1,2, and10were1,2and4, respectively, thentheexpectedhappinessofinvestingwould yourutilityfunction, youmightbebestoffkeepingthemoneyinthebank.
Forfinancialdecisions, wemightalsowanttomeasurehowriskyaninvestmentis.
Here, we carenotjustabouttheexpectedvaluebuthowmuchtheactualvaluestendtovaryrelative tothisvalue.
Notethatwecannotjusttaketheexpectationofthedifferencebetweenthe actualandexpectedvalues.
Thisisbecausetheexpectationofadifferenceisthedifference oftheexpectations, i.
e.,ğ¸Â»ğ‘‹ ğ¸Â»ğ‘‹â€¦â€¦ = ğ¸Â»ğ‘‹â€¦ ğ¸Â»ğ¸Â»ğ‘‹â€¦â€¦ =0.
However, wecanlookat theexpectationofanynon-negativefunctionofthisdifference.
Thevarianceofarandom variableiscalculatedbylookingattheexpectedvalueofthesquareddifferences: VarÂ»ğ‘‹â€¦ = ğ¸ â€ğ‘‹ ğ¸Â»ğ‘‹â€¦â€2 = ğ¸Â»ğ‘‹2â€¦ ğ¸Â»ğ‘‹â€¦2.
(2.6.14) Heretheequalityfollowsbyexpandingâ€ğ‘‹ ğ¸Â»ğ‘‹â€¦â€2 = ğ‘‹2 2ğ‘‹ğ¸Â»ğ‘‹â€¦â€šğ¸Â»ğ‘‹â€¦2andtaking expectationsforeachterm.
Thesquarerootofthevarianceisanotherusefulquantitycalled thestandarddeviation.
Whilethisandthevarianceconveythesameinformation(eithercan becalculatedfromtheother), thestandarddeviationhasthenicepropertythatitisexpressed inthesameunitsastheoriginalquantityrepresentedbytherandomvariable.
Lastly, thevarianceofafunctionofarandomvariableisdefinedanalogouslyas Varğ‘¥ ğ‘ƒ Â»ğ‘“â€ğ‘¥â€â€¦ = ğ¸ ğ‘¥ ğ‘ƒ Â»ğ‘“2â€ğ‘¥â€â€¦ ğ¸ ğ‘¥ ğ‘ƒ Â»ğ‘“â€ğ‘¥â€â€¦2.
(2.6.15) Returningtoourinvestmentexample, wecannowcomputethevarianceoftheinvestment.
isariskyinvestment.
Notethatbymathematicalconventionmeanandvarianceareoften referencedas ğœ‡ andğœ2.
Thisisparticularlythecasewheneverweuseittoparametrizea Gaussiandistribution.
Inthesamewayasweintroducedexpectationsandvarianceforscalarrandomvariables, wecandosoforvector-valuedones.
Expectationsareeasy, sincewecanapplythemel- ementwise.
For instance, ğ d = ef ğ¸ x ğ‘ƒ Â»xâ€¦ has coordinates ğœ‡ ğ‘– = ğ¸ x ğ‘ƒ Â»ğ‘¥ ğ‘– â€¦.
Covariances 76 Preliminaries aremorecomplicated.
Wedefinethembytakingexpectationsoftheouterproductofthe differencebetweenrandomvariablesandtheirmean: ğšº d = ef Cov x ğ‘ƒ Â»xâ€¦ = ğ¸ x ğ‘ƒ â€x ğâ€â€x ğâ€> .
(2.6.16) This matrix ğšº is referred to as the covariance matrix.
An easy way to see its effect is to considersomevectorvofthesamesizeasx.
Itfollowsthat v >ğšºv= ğ¸ x ğ‘ƒ v >â€x ğâ€â€x ğâ€> v =Varğ‘¥ ğ‘ƒ Â»v > xâ€¦.
(2.6.17) As such, ğšº allows us to compute the variance for any linear function of x by a simple matrix multiplication.
The off-diagonal elements tell us how correlated the coordinates are: avalueof0meansnocorrelation, wherealargerpositivevaluemeansthattheyare morestronglycorrelated.
2.6.7 Discussion In machine learning, there are many things to be uncertain about! We can be uncertain aboutthevalueofalabelgivenaninput.
Wecanbeuncertainabouttheestimatedvalueof aparameter.
Wecanevenbeuncertainaboutwhetherdataarrivingatdeploymentiseven fromthesamedistributionasthetrainingdata.
Byaleatoricuncertainty, wemeanuncertaintythatisintrinsictotheproblem, anddueto genuinerandomnessunaccountedforbytheobservedvariables.
Byepistemicuncertainty, wemeanuncertaintyoveramodelâ€™sparameters, thesortofuncertaintythatwecanhope to reduce by collecting more data.
We might have epistemic uncertainty concerning the probabilitythatacointurnsupheads, butevenonceweknowthisprobability, weareleft with aleatoric uncertainty about the outcome of any future toss.
No matter how long we watch someone tossing a fair coin, we will never be more or less than 50% certain that thenexttosswillcomeupheads.
Thesetermscomefrommechanicalmodeling,(seee.
g., Der Kiureghianand Ditlevsen(2009)forareviewonthisaspectofuncertaintyquantifica- tion59).
Itisworthnoting, however, thatthesetermsconstituteaslightabuseoflanguage.
59 Thetermepistemicreferstoanythingconcerningknowledgeandthus, inthephilosophical sense, alluncertaintyisepistemic.
Wesawthatsamplingdatafromsomeunknownprobabilitydistributioncanprovideuswith informationthatcanbeusedtoestimatetheparametersofthedatageneratingdistribution.
Thatsaid, therateatwhichthisispossiblecanbequiteslow.
Inourcointossingexample (andmanyothers)wecandonobetterthantodesignestimatorsthatconvergeatarateof p 1 ğ‘›, where ğ‘› isthe sample size (e.
g., the number oftosses).
This means that bygoing from10to1000observations(usuallyaveryachievabletask)weseeatenfoldreductionof uncertainty, whereasthenext1000observationshelpcomparativelylittle, offeringonlya 1.41timesreduction.
Thisisapersistentfeatureofmachinelearning: whilethereareoften easygains, ittakesaverylargeamountofdata, andoftenwithitanenormousamountof computation, to make further gains.
For an empirical review of this fact for large scale languagemodelssee Revelsetal.
(2016).
Wealsosharpenedourlanguageandtoolsforstatisticalmodeling.
Intheprocessofthat 77 Probabilityand Statistics welearnedaboutconditionalprobabilitiesandaboutoneofthemostimportantequations instatisticsâ€”Bayesâ€™theorem.
Itisaneffectivetoolfordecouplinginformationconveyed bydatathroughalikelihoodtermğ‘ƒâ€ğµ j ğ´â€ thataddresseshowwellobservationsğµmatch achoiceofparameters ğ´, andapriorprobabilityğ‘ƒâ€ğ´â€whichgovernshowplausibleapar- ticularchoiceof ğ´wasinthefirstplace.
Inparticular, wesawhowthisrulecanbeapplied toassignprobabilitiestodiagnoses, basedontheefficacyofthetestandtheprevalenceof thediseaseitself(i.
e., ourprior).
Lastly, weintroducedafirstsetofnontrivialquestionsabouttheeffectofaspecificproba- bilitydistribution, namelyexpectationsandvariances.
Whiletherearemanymorethanjust linearandquadraticexpectationsforaprobabilitydistribution, thesetwoalreadyprovide a good deal of knowledge about the possible behavior of the distribution.
For instance, Chebyshevâ€™s inequality60 statesthat ğ‘ƒâ€jğ‘‹ ğœ‡j ğ‘˜ğœâ€ 1 ğ‘˜2, where ğœ‡ is the expecta- 60 tion, ğœ2 is the variance of the distribution, and ğ‘˜ > 1 is a confidence parameter of our choopsing.
p Ittellsusthatdrawsfromadistributionliewithatleast50%probabilitywithin a Â» 2ğœ, 2ğœâ€¦ intervalcenteredontheexpectation.
2.6.8 Exercises 1.
Giveanexamplewhereobservingmoredatacanreducetheamountofuncertaintyabout theoutcometoanarbitrarilylowlevel.
2.
Giveanexamplewhereobservingmoredatawillonlyreducetheamountofuncertainty uptoapointandthennofurther.
Explainwhythisisthecaseandwhereyouexpectthis pointtooccur.
3.
Weempiricallydemonstratedconvergencetothemeanforthetossofacoin.
Calculate thevarianceoftheestimateoftheprobabilitythatweseeaheadafterdrawingğ‘›samples.
1.
Howdoesthevariancescalewiththenumberofobservations? 2.
Use Chebyshevâ€™sinequalitytoboundthedeviationfromtheexpectation.
3.
Howdoesitrelatetothecentrallimittheorem? 4.
Assumethatwedrawğ‘šsamplesğ‘¥ ğ‘– fromaprobabilitydistributionwithzeromeanand Ë unit variance.
Compute the averages ğ‘§ ğ‘š d = ef ğ‘š 1 ğ‘– ğ‘š =1 ğ‘¥ ğ‘–.
Can we apply Chebyshevâ€™s inequalityforeveryğ‘§ ğ‘šindependently? Whynot? 5.
Giventwoeventswithprobability ğ‘ƒâ€Aâ€ and ğ‘ƒâ€Bâ€, computeupperandlowerbounds onğ‘ƒâ€A[Bâ€andğ‘ƒâ€A\Bâ€.
Hint: graphthesituationusinga Venndiagram61.
61 6.
Assumethatwehaveasequenceofrandomvariables, sayğ´,ğµ, andğ¶, whereğµonlyde- pendsonğ´, andğ¶onlydependsonğµ, canyousimplifythejointprobabilityğ‘ƒâ€ğ´,ğµ,ğ¶â€? Hint: thisisa Markovchain62.
62 7.
In Section 2.6.5, assume that the outcomes of the two tests are not independent.
In particularassumethateithertestonitsownhasafalsepositiverateof10%andafalse negative rate of 1%.
That is, assume that ğ‘ƒâ€ğ· = 1 j ğ» = 0â€ = 0.1 and that ğ‘ƒâ€ğ· = 0 j ğ» = 1â€ = 0.01.
Moreover, assumethatfor ğ» = 1(infected)thetestoutcomesare 78 Preliminaries conditionallyindependent, i.
e., thatğ‘ƒâ€ğ· ,ğ· j ğ» = 1â€ = ğ‘ƒâ€ğ· j ğ» = 1â€ğ‘ƒâ€ğ· j ğ» = 1 2 1 2 1â€ but that for healthy patients the outcomes are coupled via ğ‘ƒâ€ğ· = ğ· = 1 j ğ» = 1 2 0â€ =0.02.
1.
Workoutthejointprobabilitytableforğ· andğ· , givenğ» =0basedontheinfor- 1 2 mationyouhavesofar.
2.
Derive the probability that the patient is diseased (ğ» = 1) after one test returns positive.
You can assume the same baseline probability ğ‘ƒâ€ğ» = 1â€ = 0.0015 as before.
3.
Derive the probability that the patient is diseased (ğ» = 1) after both tests return positive.
8.
Assumethatyouareanassetmanagerforaninvestmentbankandyouhaveachoiceof stocksğ‘  ğ‘–toinvestin.
Yourportfolioneedstoaddupto1withweightsğ›¼ ğ‘–foreachstock.
Thestockshaveanaveragereturn ğ = ğ¸ s ğ‘ƒ Â»sâ€¦ andcovarianceğšº =Cov s ğ‘ƒ Â»sâ€¦.
1.
Computetheexpectedreturnforagivenportfolioğœ¶.
2.
Ifyouwantedtomaximizethereturnoftheportfolio, howshouldyouchooseyour investment? 3.
Computethevarianceoftheportfolio.
4.
Formulateanoptimizationproblemofmaximizingthereturnwhilekeepingthevari- anceconstrainedtoanupperbound.
Thisisthe Nobel-Prizewinning Markovitzport- folio63 (Mangram,2013).
Tosolveityouwillneedaquadraticprogrammingsolver, 63 somethingwaybeyondthescopeofthisbook.
Discussions64.
64 2.7 Documentation Whilewecannotpossiblyintroduceeverysingle Py Torchfunctionandclass(andtheinfor- mationmightbecomeoutdatedquickly), the APIdocumentation65 andadditionaltutorials 65 66 and examples provide such documentation.
This section provides some guidance for howtoexplorethe Py Torch API.
66 import torch 2.7.1 Functionsand Classesina Module Toknowwhichfunctionsandclassescanbecalledinamodule, weinvokethedirfunc- tion.
Forinstance, wecanqueryallpropertiesinthemoduleforgeneratingrandomnum- bers: 79 Documentation print(dir(torch.
distributions)) ['Abs Transform', 'Affine Transform', 'Bernoulli', 'Beta', 'Binomial', â†©!'Cat Transform', 'Categorical', 'Cauchy', 'Chi2', 'Compose Transform', â†©!'Continuous Bernoulli', 'Corr Cholesky Transform', â†©!'Cumulative Distribution Transform', 'Dirichlet', 'Distribution', 'Exp Transform â†©!', 'Exponential', 'Exponential Family', 'Fisher Snedecor', 'Gamma', 'Geometric â†©!', 'Gumbel', 'Half Cauchy', 'Half Normal', 'Independent', 'Independent Transform â†©!', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'Log Normal', 'Logistic Normal', â†©!'Low Rank Multivariate Normal', 'Lower Cholesky Transform', 'Mixture Same Family', â†©!'Multinomial', 'Multivariate Normal', 'Negative Binomial', 'Normal', â†©!'One Hot Categorical', 'One Hot Categorical Straight Through', 'Pareto', 'Poisson', â†©! 'Positive Definite Transform', 'Power Transform', 'Relaxed Bernoulli', â†©!'Relaxed One Hot Categorical', 'Reshape Transform', 'Sigmoid Transform', â†©!'Softmax Transform', 'Softplus Transform', 'Stack Transform', â†©!'Stick Breaking Transform', 'Student T', 'Tanh Transform', 'Transform', â†©!'Transformed Distribution', 'Uniform', 'Von Mises', 'Weibull', 'Wishart', '__ â†©! all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '_ â†©!_name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', â†©!'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_ â†©! registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution â†©!', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', â†©!'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', â†©!'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal â†©!', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', â†©!'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_ â†©! hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', â†©!'relaxed_categorical', 'student T', 'transform_to', 'transformed_distribution â†©!', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart'] Generally, wecanignorefunctionsthatstartandendwith__(specialobjectsin Python)or functionsthatstartwithasingle_(usuallyinternalfunctions).
Basedontheremainingfunc- tionorattributenames, wemighthazardaguessthatthismoduleoffersvariousmethodsfor generatingrandomnumbers, includingsamplingfromtheuniformdistribution(uniform), normaldistribution(normal), andmultinomialdistribution(multinomial).
2.7.2 Specific Functionsand Classes Forspecificinstructionsonhowtouseagivenfunctionorclass, wecaninvokethehelp function.
Asanexample, letâ€™sexploretheusageinstructionsfortensorsâ€™onesfunction.
help(torch.
ones) Help on built-in function ones in module torch: ones(...) ones(*size, *, out=None, dtype=None, layout=torch.
strided, device=None, â†©! requires_grad=False) -> Tensor Returns a tensor filled with the scalar value 1, with the shape defined 80 Preliminaries by the variable argument size.
Args: size (int...): a sequence of integers defining the shape of theâ£ â†©! output tensor.
Can be a variable number of arguments or a collection like aâ£ â†©! list or tuple.
Keyword arguments: out (Tensor, optional): the output tensor.
dtype (torch.
dtype, optional): the desired data type of returnedâ£ â†©! tensor.
Default: if None, uses a global default (see torch.
set_default_ â†©! tensor_type()).
layout (torch.
layout, optional): the desired layout of returnedâ£ â†©! Tensor.
Default: torch.
strided.
device (torch.
device, optional): the desired device of returnedâ£ â†©! tensor.
Default: if None, uses the current device for the default tensorâ£ â†©! type (see torch.
set_default_tensor_type()).
device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensorâ£ â†©! types.
requires_grad (bool, optional): If autograd should record operationsâ£ â†©! on the returned tensor.
Default: False.
Example:: >>> torch.
ones(2, 3) tensor([[ 1., 1., 1.], [ 1., 1., 1.]]) >>> torch.
ones(5) Fromthedocumentation, wecanseethattheonesfunctioncreatesanewtensorwiththe specifiedshapeandsetsalltheelementstothevalueof1.
Wheneverpossible, youshould runaquicktesttoconfirmyourinterpretation: torch.
ones(4) tensor([1., 1., 1., 1.]) 81 Documentation In the Jupyter notebook, we can use ? to display the document in another window.
For example, list? will create content that is almost identical to help(list), displaying it inanewbrowserwindow.
Inaddition, ifweusetwoquestionmarks, suchaslist??, the Pythoncodeimplementingthefunctionwillalsobedisplayed.
Theofficialdocumentationprovidesplentyofdescriptionsandexamplesthatarebeyond thisbook.
Weemphasizeimportantusecasesthatwillgetyoustartedquicklywithprac- ticalproblems, ratherthancompletenessofcoverage.
Wealsoencourageyoutostudythe sourcecodeofthelibrariestoseeexamplesofhigh-qualityimplementationsofproduction code.
By doing this you will become a better engineer in addition to becoming a better scientist.
Discussions67.
67 3 Linear Neural Networks for Regression Beforeweworryaboutmakingourneuralnetworksdeep, itwillbehelpfultoimplement someshallowones, forwhichtheinputsconnectdirectlytotheoutputs.
Thiswillproveim- portantforafewreasons.
First, ratherthangettingdistractedbycomplicatedarchitectures, wecanfocusonthebasicsofneuralnetworktraining, includingparametrizingtheoutput layer, handlingdata, specifyingalossfunction, andtrainingthemodel.
Second, thisclass ofshallownetworkshappenstocomprisethesetoflinearmodels, whichsubsumesmany classical methods of statistical prediction, including linear and softmax regression.
Un- derstandingtheseclassicaltoolsispivotalbecausetheyarewidelyusedinmanycontexts andwewilloftenneedtousethemasbaselineswhenjustifyingtheuseoffancierarchi- tectures.
Thischapterwillfocusnarrowlyonlinearregressionandthenextonewillextend ourmodelingrepertoirebydevelopinglinearneuralnetworksforclassification.
3.1 Linear Regression Regressionproblemspopupwheneverwewanttopredictanumericalvalue.
Commonex- amplesincludepredictingprices(ofhomes, stocks, etc.), predictingthelengthofstay(for patientsinthehospital), forecastingdemand(forretailsales), amongnumerousothers.
Not everypredictionproblemisoneofclassicalregression.
Lateron, wewillintroduceclassifi- cationproblems, wherethegoalistopredictmembershipamongasetofcategories.
Asarunningexample, supposethatwewishtoestimatethepricesofhouses(indollars) basedontheirarea(insquarefeet)andage(inyears).
Todevelopamodelforpredicting houseprices, weneedtogetourhandsondata, includingthesalesprice, area, andagefor eachhome.
Intheterminologyofmachinelearning, thedatasetiscalledatrainingdataset ortrainingset, andeachrow(containingthedatacorrespondingtoonesale)iscalledan example (or data point, instance, sample).
The thing we are trying to predict (price) is called a label (or target).
The variables (age and area) upon which the predictions are basedarecalledfeatures(orcovariates).
%matplotlib inline import math import time import numpy as np (continuesonnextpage) 82 83 Linear Regression (continuedfrompreviouspage) import torch from d2l import torch as d2l 3.1.1 Basics Linearregressionisboththesimplestandmostpopularamongthestandardtoolsfortack- lingregressionproblems.
Datingbacktothedawnofthe19thcentury(Gauss,1809, Leg- endre,1805), linearregressionflowsfromafewsimpleassumptions.
First, weassumethat therelationshipbetweenfeaturesxandtarget ğ‘¦ isapproximatelylinear, i.
e., thatthecon- ditionalmean ğ¸Â»ğ‘Œ j ğ‘‹ = xâ€¦ canbeexpressedasaweightedsumofthefeaturesx.
This setup allows that the target value may still deviate from its expected value on account of observationnoise.
Next, wecanimposetheassumptionthatanysuchnoiseiswellbehaved, followinga Gaussiandistribution.
Typically, wewilluseğ‘›todenotethenumberofexam- plesinourdataset.
Weusesuperscriptstoenumeratesamplesandtargets, andsubscripts toindexcoordinates.
Moreconcretely, xâ€ğ‘–â€ denotestheğ‘–th sampleandğ‘¥â€ğ‘–â€ denotesits ğ‘—th ğ‘— coordinate.
Model At the heart of every solution is a model that describes how features can be transformed intoanestimateofthetarget.
Theassumptionoflinearitymeansthattheexpectedvalueof thetarget(price)canbeexpressedasaweightedsumofthefeatures(areaandage): price=ğ‘¤ areaâ€šğ‘¤ ageâ€šğ‘.
(3.1.1) area age Hereğ‘¤ andğ‘¤ arecalledweights, and ğ‘ iscalledabias(oroffsetorintercept).
The area age weightsdeterminetheinfluenceofeachfeatureonourprediction.
Thebiasdeterminesthe valueoftheestimatewhenallfeaturesarezero.
Eventhoughwewillneverseeanynewly- builthomeswithpreciselyzeroarea, westillneedthebiasbecauseitallowsustoexpress alllinearfunctionsofourfeatures(ratherthanrestrictingustolinesthatpassthroughthe origin).
Strictly speaking, (3.1.1) is an aï¬€ine transformation of input features, which is characterizedbyalineartransformationoffeaturesviaaweightedsum, combinedwitha translation via the added bias.
Given a dataset, our goal is to choose the weights w and thebiasğ‘that, onaverage, makeourmodelâ€™spredictionsfitthetruepricesobservedinthe dataascloselyaspossible.
Indisciplineswhereitiscommontofocusondatasetswithjustafewfeatures, explicitly expressingmodelslong-form, asin(3.1.1), iscommon.
Inmachinelearning, weusually workwithhigh-dimensionaldatasets, whereitismoreconvenienttoemploycompactlin- earalgebranotation.
Whenourinputsconsistof ğ‘‘ features, wecanassigneachanindex (between 1 and ğ‘‘) and express our prediction ğ‘¦Ë† (in general the â€œhatâ€ symbol denotes an estimate)as ğ‘¦Ë† =ğ‘¤ 1 ğ‘¥ 1 â€š â€šğ‘¤ ğ‘‘ ğ‘¥ ğ‘‘ â€šğ‘.
(3.1.2) 84 Linear Neural Networksfor Regression Collectingallfeaturesintoavectorx 2 Rğ‘‘ andallweightsintoavectorw 2 Rğ‘‘ , wecan expressourmodelcompactlyviathedotproductbetweenwandx: ğ‘¦Ë† =w > xâ€šğ‘.
(3.1.3) In (3.1.3), the vector x corresponds to the features of a single example.
We will often find it convenient to refer to features of our entire dataset of ğ‘› examples via the design matrix X 2 Rğ‘› ğ‘‘ .
Here, Xcontainsonerowforeveryexampleandonecolumnforevery feature.
For a collection of features X, the predictions yË† 2 Rğ‘› can be expressed via the matrixâ€“vectorproduct: yË† =Xwâ€šğ‘, (3.1.4) wherebroadcasting(Section2.1.4)isappliedduringthesummation.
Givenfeaturesofa trainingdataset Xandcorresponding(known)labelsy, thegoaloflinearregressionisto findtheweightvectorwandthebiastermğ‘suchthat, givenfeaturesofanewdataexample sampledfromthesamedistributionas X, thenewexampleâ€™slabelwill(inexpectation)be predictedwiththesmallesterror.
Even if we believe that the best model for predicting ğ‘¦ given x is linear, we would not expect to find a real-world dataset of ğ‘› examples where ğ‘¦â€ğ‘–â€ exactly equals w>xâ€ğ‘–â€ â€š ğ‘ for all 1 ğ‘– ğ‘›.
For example, whatever instruments we use to observe the features X andlabelsy, theremightbeasmallamountofmeasurementerror.
Thus, evenwhenwe areconfidentthattheunderlyingrelationshipislinear, wewillincorporateanoisetermto accountforsucherrors.
Beforewecangoaboutsearchingforthebestparameters(ormodelparameters)wandğ‘, wewillneedtwomorethings: (i)ameasureofthequalityofsomegivenmodel; and(ii)a procedureforupdatingthemodeltoimproveitsquality.
Loss Function Naturally, fittingourmodeltothedatarequiresthatweagreeonsomemeasureoffitness (or, equivalently, ofunfitness).
Lossfunctionsquantifythedistancebetweentherealand predictedvaluesofthetarget.
Thelosswillusuallybeanonnegativenumberwheresmaller valuesarebetterandperfectpredictionsincuralossof0.
Forregressionproblems, themost commonlossfunctionisthesquarederror.
Whenourpredictionforanexampleğ‘– is ğ‘¦Ë† â€ğ‘–â€ andthecorrespondingtruelabelisğ‘¦â€ğ‘–â€ , thesquarederrorisgivenby: 1 2 ğ‘™â€ğ‘–â€â€w,ğ‘â€ = ğ‘¦Ë† â€ğ‘–â€ ğ‘¦â€ğ‘–â€ .
(3.1.5) 2 Theconstant 1 makesnorealdifferencebutprovestobenotationallyconvenient, sinceit 2 cancelsoutwhenwetakethederivativeoftheloss.
Becausethetrainingdatasetisgiven to us, and thus is out of our control, the empirical error is only a function of the model parameters.
In .1.1, we visualize the fit of a linear regression model in a problem withone-dimensionalinputs.
Notethatlargedifferencesbetweenestimatesğ‘¦Ë† â€ğ‘–â€ andtargetsğ‘¦â€ğ‘–â€ leadtoevenlargercontri- butionstotheloss, duetoitsquadraticform(thisquadraticitycanbeadouble-edgesword; 85 Linear Regression t .1.1 Fittingalinearregressionmodeltoone-dimensionaldata.
whileitencouragesthemodeltoavoidlargeerrorsitcanalsoleadtoexcessivesensitivity toanomalousdata).
Tomeasurethequalityofamodelontheentiredatasetofğ‘›examples, wesimplyaverage(orequivalently, sum)thelossesonthetrainingset: ğ‘› ğ‘› 1 1 1 2 ğ¿â€w,ğ‘â€ = ğ‘™â€ğ‘–â€â€w,ğ‘â€ = w > x â€ğ‘–â€ â€šğ‘ ğ‘¦â€ğ‘–â€ .
(3.1.6) ğ‘› ğ‘› 2 ğ‘–=1 ğ‘–=1 Whentrainingthemodel, weseekparameters(w ,ğ‘ )thatminimizethetotallossacross alltrainingexamples: w ,ğ‘ =argmin ğ¿â€w,ğ‘â€.
(3.1.7) w,ğ‘ Analytic Solution Unlikemostofthemodelsthatwewillcover, linearregressionpresentsuswithasurpris- ingly easy optimization problem.
In particular, we can find the optimal parameters (as assessedonthetrainingdata)analyticallybyapplyingasimpleformulaasfollows.
First, wecansubsumethebiasğ‘intotheparameterwbyappendingacolumntothedesignma- trixconsistingofall1s.
Thenourpredictionproblemistominimizeky Xwk2.
Aslong asthedesignmatrix Xhasfullrank(nofeatureislinearlydependentontheothers), then therewillbejustonecriticalpointonthelosssurfaceanditcorrespondstotheminimum ofthelossovertheentiredomain.
Takingthederivativeofthelosswithrespecttowand settingitequaltozeroyields: ğœ• ky Xwk2 =2X >â€Xw yâ€ =0andhence X > y=X > Xw.
(3.1.8) w Solving for w provides us with the optimal solution for the optimization problem.
Note thatthissolution w = â€X > Xâ€ 1X > y (3.1.9) willonlybeuniquewhenthematrix X>Xisinvertible, i.
e., whenthecolumnsofthedesign matrixarelinearlyindependent(Goluband Van Loan,1996).
While simple problems like linear regression may admit analytic solutions, you should notgetusedtosuchgoodfortune.
Althoughanalyticsolutionsallowfornicemathematical analysis, therequirementofananalyticsolutionissorestrictivethatitwouldexcludealmost allexcitingaspectsofdeeplearning.
86 Linear Neural Networksfor Regression Minibatch Stochastic Gradient Descent Fortunately, evenincaseswherewecannotsolvethemodelsanalytically, wecanstillof- tentrainmodelseffectivelyinpractice.
Moreover, formanytasks, thosehard-to-optimize modelsturnouttobesomuchbetterthatfiguringouthowtotrainthemendsupbeingwell worththetrouble.
The key technique for optimizing nearly every deep learning model, and which we will call upon throughout this book, consists of iteratively reducing the error by updating the parametersinthedirectionthatincrementallylowersthelossfunction.
Thisalgorithmis calledgradientdescent.
Themostnaiveapplicationofgradientdescentconsistsoftakingthederivativeoftheloss function, whichisanaverageofthelossescomputedoneverysingleexampleinthedataset.
Inpractice, thiscanbeextremelyslow: wemustpassovertheentiredatasetbeforemaking asingleupdate, eveniftheupdatestepsmightbeverypowerful(Liuand Nocedal,1989).
Evenworse, ifthereisalotofredundancyinthetrainingdata, thebenefitofafullupdate islimited.
Theotherextremeistoconsideronlyasingleexampleatatimeandtotakeupdatesteps based on one observation at a time.
The resulting algorithm, stochastic gradientdescent (SGD)canbeaneffectivestrategy(Bottou,2010), evenforlargedatasets.
Unfortunately, SGDhasdrawbacks, bothcomputationalandstatistical.
Oneproblemarisesfromthefact thatprocessorsarealotfastermultiplyingandaddingnumbersthantheyareatmovingdata from main memory to processor cache.
It is up to an order of magnitude more efficient to perform a matrixâ€“vectormultiplication than a corresponding number of vectorâ€“vector operations.
Thismeansthatitcantakealotlongertoprocessonesampleatatimecompared toafullbatch.
Asecondproblemisthatsomeofthelayers, suchasbatchnormalization (to be described in Section 8.5), only work well when we have access to more than one observationatatime.
Thesolutiontobothproblemsistopickanintermediatestrategy: ratherthantakingafull batchoronlyasinglesampleatatime, wetakeaminibatchofobservations(Lietal.,2014).
Thespecificchoiceofthesizeofthesaidminibatchdependsonmanyfactors, suchasthe amountofmemory, thenumberofaccelerators, thechoiceoflayers, andthetotaldataset size.
Despiteallthat, anumberbetween32and256, preferablyamultipleofalargepower of2, isagoodstart.
Thisleadsustominibatchstochasticgradientdescent.
Initsmostbasicform, ineachiterationğ‘¡, wefirstrandomlysampleaminibatch B ğ‘¡ consist- ingofafixednumberj Bjoftrainingexamples.
Wethencomputethederivative(gradient) oftheaveragelossontheminibatchwithrespecttothemodelparameters.
Finally, wemul- tiplythegradientbyapredeterminedsmallpositivevalueğœ‚, calledthelearningrate, and subtracttheresultingtermfromthecurrentparametervalues.
Wecanexpresstheupdate asfollows: ğœ‚ â€w,ğ‘â€ â€w,ğ‘â€ j Bj ğœ• â€w,ğ‘â€ ğ‘™â€ğ‘–â€â€w,ğ‘â€.
(3.1.10) ğ‘–2Bğ‘¡ In summary, minibatch SGD proceeds as follows: (i) initialize the values of the model 87 Linear Regression parameters, typicallyatrandom;(ii)iterativelysamplerandomminibatchesfromthedata, updatingtheparametersinthedirectionofthenegativegradient.
Forquadraticlossesand affinetransformations, thishasaclosed-formexpansion: ğœ‚ ğœ‚ w w ğœ• ğ‘™â€ğ‘–â€â€w,ğ‘â€ =w x â€ğ‘–â€ w > x â€ğ‘–â€ â€šğ‘ ğ‘¦â€ğ‘–â€ j Bj w j Bj ğœ‚ ğ‘–2Bğ‘¡ ğœ‚ ğ‘–2Bğ‘¡ (3.1.11) ğ‘ ğ‘ j Bj ğœ• ğ‘ ğ‘™â€ğ‘–â€â€w,ğ‘â€ = ğ‘ j Bj w > x â€ğ‘–â€ â€šğ‘ ğ‘¦â€ğ‘–â€ .
ğ‘–2Bğ‘¡ ğ‘–2Bğ‘¡ Sincewepickaminibatch B weneedtonormalizebyitssize j Bj.
Frequentlyminibatch sizeandlearningrateareuser-defined.
Suchtunableparametersthatarenotupdatedinthe training loop are called hyperparameters.
They can be tuned automatically by a number oftechniques, suchas Bayesianoptimization(Frazier,2018).
Intheend, thequalityofthe solutionistypicallyassessedonaseparatevalidationdataset(orvalidationset).
Aftertrainingforsomepredeterminednumberofiterations(oruntilsomeotherstopping criterionismet), werecordtheestimatedmodelparameters, denotedwË†,ğ‘Ë†.
Notethatevenif ourfunctionistrulylinearandnoiseless, theseparameterswillnotbetheexactminimizers oftheloss, norevendeterministic.
Althoughthealgorithmconvergesslowlytowardsthe minimizers it typically will not find them exactly in a finite number of steps.
Moreover, the minibatches B used for updating the parameters are chosen at random.
This breaks determinism.
Linearregressionhappenstobealearningproblemwithaglobalminimum(whenever X isfullrank, orequivalently, whenever X>Xisinvertible).
However, thelosssurfacesfor deep networks contain many saddle points and minima.
Fortunately, wetypically do not careaboutfindinganexactsetofparametersbutmerelyanysetofparametersthatleads toaccuratepredictions(andthuslowloss).
Inpractice, deeplearningpractitionersseldom struggle to find parameters that minimize the loss on training sets (Frankle and Carbin, 2018, Izmailov et al., 2018).
The more formidable task is to find parameters that lead to accurate predictions on previously unseen data, a challenge called generalization.
We returntothesetopicsthroughoutthebook.
Predictions Given the model wË† >x â€š ğ‘Ë†, we can now make predictions for a new example, e.
g., pre- dicting the sales price of a previously unseen house given its area ğ‘¥ and age ğ‘¥ .
Deep 1 2 learningpractitionershavetakentocallingthepredictionphaseinferencebutthisisabitof amisnomerâ€”inferencerefersbroadlytoanyconclusionreachedonthebasisofevidence, includingboththevaluesoftheparametersandthelikelylabelforanunseeninstance.
If anything, inthestatisticsliteratureinferencemoreoftendenotesparameterinferenceand thisoverloadingofterminologycreatesunnecessaryconfusionwhendeeplearningprac- titionerstalktostatisticians.
Inthefollowingwewillsticktopredictionwheneverpossi- ble.
3.1.2 Vectorizationfor Speed 88 Linear Neural Networksfor Regression Whentrainingourmodels, wetypicallywanttoprocesswholeminibatchesofexamplessi- multaneously.
Doingthisefficientlyrequiresthatwevectorizethecalculationsandleverage fastlinearalgebralibrariesratherthanwritingcostlyfor-loopsin Python.
Toseewhythismatterssomuch, letâ€™sconsidertwomethodsforaddingvectors.
Tostart, we instantiatetwo10,000-dimensionalvectorscontainingall1s.
Inthefirstmethod, weloop overthevectorswitha Pythonfor-loop.
Inthesecond, werelyonasinglecallto+.
n = 10000 a = torch.
ones(n) b = torch.
ones(n) Nowwecanbenchmarktheworkloads.
First, weaddthem, onecoordinateatatime, using afor-loop.
c = torch.
zeros(n) t = time.
time() for i in range(n): c[i] = a[i] + b[i] f'{time.
time() - t:.5f} sec' '0.17802 sec' Alternatively, werelyonthereloaded+operatortocomputetheelementwisesum.
t = time.
time() d = a + b f'{time.
time() - t:.5f} sec' '0.00036 sec' Thesecondmethodisdramaticallyfasterthanthefirst.
Vectorizingcodeoftenyieldsorder- of-magnitudespeedups.
Moreover, wepushmoreofthemathematicstothelibrarysowe donothavetowriteasmanycalculationsourselves, reducingthepotentialforerrorsand increasingportabilityofthecode.
3.1.3 The Normal Distributionand Squared Loss Sofarwehavegivenafairlyfunctionalmotivationofthesquaredlossobjective: theoptimal parametersreturn the conditional expectation ğ¸Â»ğ‘Œ j ğ‘‹â€¦ wheneverthe underlyingpattern istrulylinear, andthelossassignslargepenaltiesforoutliers.
Wecanalsoprovideamore formalmotivationforthesquaredlossobjectivebymakingprobabilisticassumptionsabout thedistributionofnoise.
Linear regression was invented at the turn of the 19th century.
While it has long been debatedwhether Gaussor Legendrefirstthoughtuptheidea, itwas Gausswhoalsodis- covered the normal distribution (also called the Gaussian).
It turns out that the normal 89 Linear Regression distribution and linear regression with squaredloss share a deeper connection than com- monparentage.
Tobegin, recallthatanormaldistributionwithmeanğœ‡andvarianceğœ2(standarddeviation ğœ)isgivenas 1 1 ğ‘â€ğ‘¥â€ = p exp â€ğ‘¥ ğœ‡â€2 .
(3.1.12) 2ğœ‹ğœ2 2ğœ2 Belowwedefineafunctiontocomputethenormaldistribution.
def normal(x, mu, sigma): p = 1 / math.
sqrt(2 * math.
pi * sigma**2) return p * np.
exp(-0.5 * (x - mu)**2 / sigma**2) Wecannowvisualizethenormaldistributions.
# Use Num Py again for visualization x = np.
arange(-7, 7, 0.01) # Mean and standard deviation pairs params = [(0, 1), (0, 2), (3, 1)] d2l.
plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel='x', ylabel='p(x)', figsize=(4.5, 2.5), legend=[f'mean {mu}, std {sigma}' for mu, sigma in params]) Note that changing the mean corresponds to a shift along the ğ‘¥-axis, and increasing the variancespreadsthedistributionout, loweringitspeak.
Onewaytomotivatelinearregressionwithsquaredlossistoassumethatobservationsarise fromnoisymeasurements, wherethenoiseğœ–followsthenormaldistribution Nâ€0,ğœ2â€: ğ‘¦ =w > xâ€šğ‘â€šğœ– whereğœ– Nâ€0,ğœ2â€.
(3.1.13) Thus, wecannowwriteoutthelikelihoodofseeingaparticularğ‘¦foragivenxvia 1 1 ğ‘ƒâ€ğ‘¦ j xâ€ = p exp â€ğ‘¦ w > x ğ‘â€2 .
(3.1.14) 2ğœ‹ğœ2 2ğœ2 Assuch, thelikelihoodfactorizes.
Accordingtotheprincipleofmaximumlikelihood, the 90 Linear Neural Networksfor Regression best values of parameters w and ğ‘ are those that maximize the likelihood of the entire dataset: ğ‘› ğ‘ƒâ€y j Xâ€ = ğ‘â€ğ‘¦â€ğ‘–â€ j x â€ğ‘–â€â€.
(3.1.15) ğ‘–=1 Theequalityfollowssinceallpairsâ€xâ€ğ‘–â€,ğ‘¦â€ğ‘–â€â€weredrawnindependentlyofeachother.
Es- timatorschosenaccordingtotheprincipleofmaximumlikelihoodarecalledmaximumlike- lihood estimators.
While, maximizing the product of many exponential functions, might lookdifficult, wecansimplifythingssignificantly, withoutchangingtheobjective, bymax- imizing the logarithm of the likelihood instead.
For historical reasons, optimizations are moreoftenexpressedasminimizationratherthanmaximization.
So, withoutchangingany- thing, wecanminimizethenegativelog-likelihood, whichwecanexpressasfollows: ğ‘› 1 1 2 logğ‘ƒâ€y j Xâ€ = logâ€2ğœ‹ğœ2â€â€š ğ‘¦â€ğ‘–â€ w > x â€ğ‘–â€ ğ‘ .
(3.1.16) 2 2ğœ2 ğ‘–=1 Ifweassumethatğœisfixed, wecanignorethefirstterm, becauseitdoesnotdependonw or ğ‘.
Thesecondtermisidenticaltothesquarederrorlossintroducedearlier, exceptfor the multiplicative constant 1 .
Fortunately, the solution does not depend on ğœ either.
It ğœ2 followsthatminimizingthemeansquarederrorisequivalenttothemaximumlikelihood estimationofalinearmodelundertheassumptionofadditive Gaussiannoise.
3.1.4 Linear Regressionasa Neural Network While linear models are not sufficiently rich to express the many complicated networks thatwewillintroduceinthisbook,(artificial)neuralnetworksarerichenoughtosubsume linearmodelsasnetworksinwhicheveryfeatureisrepresentedbyaninputneuron, allof whichareconnecteddirectlytotheoutput.
.1.2depictslinearregressionasaneuralnetwork.
Thediagramhighlightsthecon- nectivity pattern, such as how each input is connected to the output, but not the specific valuestakenbytheweightsorbiases.
t .1.2 Linearregressionisasingle-layerneuralnetwork.
Theinputsareğ‘¥ 1 ,...,ğ‘¥ ğ‘‘.
Werefertoğ‘‘asthenumberofinputsorthefeaturedimensional- ityintheinputlayer.
Theoutputofthenetworkisğ‘œ .
Becausewearejusttryingtopredict 1 asinglenumericalvalue, wehaveonlyoneoutputneuron.
Notethattheinputvaluesareall given.
Thereisjustasinglecomputedneuron.
Insummary, wecanthinkoflinearregres- sionasasingle-layerfullyconnectedneuralnetwork.
Wewillencounternetworkswithfar morelayersinlaterchapters.
91 Linear Regression Biology Because linear regression predates computational neuroscience, it might seem anachro- nistictodescribelinearregressionintermsofneuralnetworks.
Nonetheless, theywerea natural place to start when the cyberneticists and neurophysiologists Warren Mc Culloch and Walter Pitts began to develop models of artificial neurons.
Consider the cartoonish picture of a biological neuron in .1.3, consisting of dendrites (input terminals), the nucleus(CPU), theaxon(outputwire), andtheaxonterminals(outputterminals), enabling connectionstootherneuronsviasynapses.
Dendrite Axon Terminal Node of Ranvier Cell body Axon Schwann cell t Myelin sheath Nucleus .1.3 Therealneuron(source: â€œAnatomyand Physiologyâ€bythe USNational Cancer Instituteâ€™s Surveillance, Epidemiologyand End Results(SEER)Program).
Information ğ‘¥ ğ‘– arriving from other neurons (or environmental sensors) is received in the dendrites.
Inparticular, thatinformationisweightedbysynapticweightsğ‘¤ ğ‘–, determining the effect of the inputs, e.
g., activation or inhibition via the product ğ‘¥ ğ‘– ğ‘¤ ğ‘–.
The weighted inputsarrivingfrommultiplesourcesareaggregatedinthenucleusasaweightedsumğ‘¦ = Ë ğ‘– ğ‘¥ ğ‘– ğ‘¤ ğ‘– â€šğ‘, possiblysubjecttosomenonlinearpostprocessingviaafunctionğœâ€ğ‘¦â€.
This informationisthensentviatheaxontotheaxonterminals, whereitreachesitsdestination (e.
g., anactuatorsuchasamuscle)oritisfedintoanotherneuronviaitsdendrites.
Certainly, thehigh-levelideathatmanysuchunitscouldbecombined, providedtheyhave thecorrectconnectivityandlearningalgorithm, toproducefarmoreinterestingandcom- plex behavior than any one neuron alone could express arises from our study of real bi- ological neural systems.
At the same time, most research in deep learning today draws inspirationfromamuchwidersource.
Weinvoke Russelland Norvig(2016)whopointed out that although airplanes might have been inspired by birds, ornithology has not been theprimarydriverofaeronauticsinnovationforsomecenturies.
Likewise, inspirationin deeplearningthesedayscomesinequalorgreatermeasurefrommathematics, linguistics, psychology, statistics, computerscience, andmanyotherfields.
3.1.5 Summary Inthissection, weintroducedtraditionallinearregression, wheretheparametersofalinear functionarechosentominimizesquaredlossonthetrainingset.
Wealsomotivatedthis choice of objective both via some practical considerations and through an interpretation oflinearregressionasmaximimumlikelihoodestimationunderanassumptionoflinearity and Gaussiannoise.
Afterdiscussingbothcomputationalconsiderationsandconnectionsto 92 Linear Neural Networksfor Regression statistics, weshowedhowsuchlinearmodelscouldbeexpressedassimpleneuralnetworks wheretheinputsaredirectlywiredtotheoutput(s).
Whilewewillsoonmovepastlinear modelsaltogether, theyaresufficienttointroducemostofthecomponentsthatallofour models require: parametric forms, differentiable objectives, optimization via minibatch stochasticgradientdescent, andultimately, evaluationonpreviouslyunseendata.
3.1.6 Exercises that ğ‘– â€ğ‘¥ ğ‘– ğ‘â€2isminimized.
1.
Findananalyticsolutionfortheoptimalvalueofğ‘.
2.
Howdoesthisproblemanditssolutionrelatetothenormaldistribution? Ë Ë 3.
Whatifwechangethelossfrom ğ‘– â€ğ‘¥ ğ‘– ğ‘â€2to ğ‘– jğ‘¥ ğ‘– ğ‘j? Canyoufindtheoptimal solutionforğ‘? 2.
Provethattheaffinefunctionsthatcanbeexpressedbyx>wâ€šğ‘areequivalenttolinear functionsonâ€x,1â€.
Ë 3.
A Ë ssume that you want to find quadratic functions of x, i.
e., ğ‘“â€xâ€ = ğ‘ â€š ğ‘– ğ‘¤ ğ‘– ğ‘¥ ğ‘– â€š ğ‘— ğ‘– ğ‘¤ ğ‘–ğ‘— ğ‘¥ ğ‘– ğ‘¥ ğ‘—.
Howwouldyouformulatethisinadeepnetwork? 4.
Recall that one of the conditions for the linear regression problem to be solvable was thatthedesignmatrix X>Xhasfullrank.
1.
Whathappensifthisisnotthecase? 2.
Howcouldyoufixit? Whathappensifyouaddasmallamountofcoordinate-wise independent Gaussiannoisetoallentriesof X? 3.
Whatistheexpectedvalueofthedesignmatrix X>Xinthiscase? 4.
Whathappenswithstochasticgradientdescentwhen X>Xdoesnothavefullrank? 5.
Assumethatthenoisemodelgoverningtheadditivenoiseğœ– istheexponentialdistribu- tion.
Thatis, ğ‘â€ğœ–â€ = 1expâ€ jğœ–jâ€.
2 1.
Writeoutthenegativelog-likelihoodofthedataunderthemodel logğ‘ƒâ€y j Xâ€.
2.
Canyoufindaclosedformsolution? 3.
Suggest a minibatch stochastic gradient descent algorithm to solve this problem.
Whatcouldpossiblygowrong(hint: whathappensnearthestationarypointaswe keeponupdatingtheparameters)? Canyoufixthis? 6.
Assume that we want to design a neural network with two layers by composing two linearlayers.
Thatis, theoutputofthefirstlayerbecomestheinputofthesecondlayer.
Whywouldsuchanaivecompositionnotwork? 7.
Whathappensifyouwanttouseregressionforrealisticpriceestimationofhousesor stockprices? 93 Object-Oriented Designfor Implementation 1.
Showthattheadditive Gaussiannoiseassumptionisnotappropriate.
Hint: canwe havenegativeprices? Whataboutfluctuations? 2.
Whywouldregressiontothelogarithmofthepricebemuchbetter, i.
e.,ğ‘¦ =logprice? 3.
Whatdoyouneedtoworryaboutwhendealingwithpennystock, i.
e., stockwithvery lowprices? Hint: canyoutradeatallpossibleprices? Whyisthisabiggerproblem forcheapstock? Formoreinformationreviewthecelebrated Blackâ€“Scholesmodel foroptionpricing(Blackand Scholes,1973).
8.
Supposewewanttouseregressiontoestimatethenumber ofapplessoldinagrocery store.
1.
Whataretheproblemswitha Gaussianadditivenoisemodel? Hint: youareselling apples, notoil.
2.
The Poissondistribution68 capturesdistributionsovercounts.
Itisgivenby ğ‘â€ğ‘˜ j 68 ğœ†â€ = ğœ†ğ‘˜ğ‘’ ğœ† ğ‘˜!.
Hereğœ† istheratefunctionand ğ‘˜ isthenumberofeventsyousee.
Provethatğœ†istheexpectedvalueofcountsğ‘˜.
3.
Designalossfunctionassociatedwiththe Poissondistribution.
4.
Designalossfunctionforestimatinglogğœ†instead.
69 Discussions69.
3.2 Object-Oriented Design for Implementation Inourintroductiontolinearregression, wewalkedthroughvariouscomponentsincluding the data, the model, the loss function, and the optimization algorithm.
Indeed, linear re- gressionisoneofthesimplestmachinelearningmodels.
Trainingit, however, usesmanyof thesamecomponentsthatothermodelsinthisbookrequire.
Therefore, beforedivinginto theimplementationdetailsitisworthdesigningsomeofthe APIsthatweusethroughout.
Treatingcomponentsindeeplearningasobjects, wecanstartbydefiningclassesforthese objectsandtheirinteractions.
Thisobject-orienteddesignforimplementationwillgreatly streamlinethepresentationandyoumightevenwanttouseitinyourprojects.
70 Inspired by open-source libraries such as Py Torch Lightning70, at a high level we wish tohavethree classes: (i) Module containsmodels, losses, and optimizationmethods; (ii) Data Module provides data loaders for training and validation; (iii) both classes are com- binedusingthe Trainerclass, whichallowsustotrainmodelsonavarietyofhardware platforms.
Most code in this book adapts Module and Data Module.
We will touch upon the Trainerclassonlywhenwediscuss GPUs, CPUs, paralleltraining, andoptimization algorithms.
94 Linear Neural Networksfor Regression import time import numpy as np import torch from torch import nn from d2l import torch as d2l 3.2.1 Utilities Weneedafewutilitiestosimplifyobject-orientedprogrammingin Jupyternotebooks.
One ofthechallengesisthatclassdefinitionstendtobefairlylongblocksofcode.
Notebook readability demands short code fragments, interspersed with explanations, a requirement incompatiblewiththestyleofprogrammingcommonfor Pythonlibraries.
Thefirstutility functionallowsustoregisterfunctionsasmethodsinaclassaftertheclasshasbeencreated.
Infact, wecandosoevenafterwehavecreatedinstancesoftheclass! Itallowsustosplit theimplementationofaclassintomultiplecodeblocks.
def add_to_class(Class): #@save """Register functions as methods in created class.""" def wrapper(obj): setattr(Class, obj.__name__, obj) return wrapper Letâ€™shaveaquicklookathowtouseit.
Weplantoimplementaclass Awithamethoddo.
Insteadofhavingcodeforboth Aanddointhesamecodeblock, wecanfirstdeclarethe class Aandcreateaninstancea.
class A: def __init__(self): self.
b = 1 a = A() Nextwedefinethemethoddoaswenormallywould, butnotinclass Aâ€™sscope.
Instead, wedecoratethismethodbyadd_to_classwithclass Aasitsargument.
Indoingso, the method is able to access the member variables of A just as we would expect had it been includedaspartof Aâ€™sdefinition.
Letâ€™sseewhathappenswhenweinvokeitfortheinstance a.
@add_to_class(A) def do(self): print('Class attribute "b" is', self.
b) a.
do() Class attribute "b" is 1 The second one is a utility class that saves all arguments in a classâ€™s __init__ method 95 Object-Oriented Designfor Implementation asclassattributes.
Thisallowsustoextendconstructorcallsignaturesimplicitlywithout additionalcode.
class Hyper Parameters: #@save """The base class of hyperparameters.""" def save_hyperparameters(self, ignore=[]): raise Not Implemented Wedeferitsimplementationinto Section B.7.
Touseit, wedefineourclassthatinherits from Hyper Parametersandcallssave_hyperparametersinthe__init__method.
# Call the fully implemented Hyper Parameters class saved in d2l class B(d2l.
Hyper Parameters): def __init__(self, a, b, c): self.
save_hyperparameters(ignore=['c']) print('self.
a =', self.
a, 'self.
b =', self.
b) print('There is no self.
c =', not hasattr(self, 'c')) b = B(a=1, b=2, c=3) self.
a = 1 self.
b = 2 There is no self.
c = True The final utility allows us to plot experiment progress interactively while it is going on.
Indeferencetothemuchmorepowerful(andcomplex)Tensor Board71 wenameit Pro- 71 gress Board.
Theimplementationisdeferredto Section B.7.
Fornow, letâ€™ssimplyseeit inaction.
Thedrawmethodplotsapoint(x, y)inthefigure, withlabelspecifiedinthelegend.
The optional every_n smooths the line by only showing 1 ğ‘› points in the figure.
Their valuesareaveragedfromtheğ‘›neighborpointsintheoriginalfigure.
class Progress Board(d2l.
Hyper Parameters): #@save """The board that plots data points in animation.""" def __init__(self, xlabel=None, ylabel=None, xlim=None, ylim=None, xscale='linear', yscale='linear', ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'], fig=None, axes=None, figsize=(3.5, 2.5), display=True): self.
save_hyperparameters() def draw(self, x, y, label, every_n=1): raise Not Implemented Inthefollowingexample, wedrawsinandcoswithadifferentsmoothness.
Ifyourunthis codeblock, youwillseethelinesgrowinanimation.
board = d2l.
Progress Board('x') for x in np.
arange(0, 10, 0.1): board.
draw(x, np.
sin(x), 'sin', every_n=2) board.
draw(x, np.
cos(x), 'cos', every_n=10) 96 Linear Neural Networksfor Regression 3.2.2 Models The Module class is the base class of all models we will implement.
At the very least weneedthreemethods.
Thefirst,__init__, storesthelearnableparameters, thetrain- ing_stepmethodacceptsadatabatchtoreturnthelossvalue, andfinally, configure_optimizers returnstheoptimizationmethod, oralistofthem, thatisusedtoupdatethelearnablepa- rameters.
Optionallywecandefinevalidation_steptoreporttheevaluationmeasures.
Sometimesweputthecodeforcomputingtheoutputintoaseparateforwardmethodto makeitmorereusable.
class Module(nn.
Module, d2l.
Hyper Parameters): #@save """The base class of models.""" def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1): super().__init__() self.
save_hyperparameters() self.
board = Progress Board() def loss(self, y_hat, y): raise Not Implemented Error def forward(self, X): assert hasattr(self, 'net'), 'Neural network is defined' return self.
net(X) def plot(self, key, value, train): """Plot a point in animation.""" assert hasattr(self, 'trainer'), 'Trainer is not inited' self.
board.
xlabel = 'epoch' if train: x = self.
trainer.
train_batch_idx / \ self.
trainer.
num_train_batches n = self.
trainer.
num_train_batches / \ self.
plot_train_per_epoch else: x = self.
trainer.
epoch + 1 n = self.
trainer.
num_val_batches / \ self.
plot_valid_per_epoch ('train_' if train else 'val_') + key, every_n=int(n)) (continuesonnextpage) 97 Object-Oriented Designfor Implementation (continuedfrompreviouspage) def training_step(self, batch): l = self.
loss(self(*batch[:-1]), batch[-1]) self.
plot('loss', l, train=True) return l def validation_step(self, batch): l = self.
loss(self(*batch[:-1]), batch[-1]) self.
plot('loss', l, train=False) def configure_optimizers(self): raise Not Implemented Error Youmaynoticethat Moduleisasubclassofnn.
Module, thebaseclassofneuralnetworks in Py Torch.
Itprovidesconvenientfeaturesforhandlingneuralnetworks.
Forexample, if wedefineaforwardmethod, suchasforward(self, X), thenforaninstanceawecan invokethismethodbya(X).
Thisworkssinceitcallstheforwardmethodinthebuilt-in __call__method.
Youcanfindmoredetailsandexamplesaboutnn.
Modulein Section 6.1.
3.2.3 Data The Data Moduleclassisthebaseclassfordata.
Quitefrequentlythe__init__methodis used to prepare the data.
This includes downloading and preprocessing if needed.
The train_dataloader returns the data loader for the training dataset.
A data loader is a (Python) generator that yields a data batch each time it is used.
This batch is then fed into the training_step method of Module to compute the loss.
There is an optional val_dataloader to return the validation dataset loader.
It behaves in the same manner, exceptthatityieldsdatabatchesforthevalidation_stepmethodin Module.
class Data Module(d2l.
Hyper Parameters): #@save """The base class of data.""" def __init__(self, root='../data', num_workers=4): self.
save_hyperparameters() def get_dataloader(self, train): raise Not Implemented Error def train_dataloader(self): return self.
get_dataloader(train=True) def val_dataloader(self): return self.
get_dataloader(train=False) 3.2.4 Training The Trainerclasstrainsthelearnableparametersinthe Moduleclasswithdataspecified in Data Module.
Thekeymethodisfit, whichacceptstwoarguments: model, aninstance of Module, and data, an instance of Data Module.
It then iterates over the entire dataset 98 Linear Neural Networksfor Regression max_epochstimestotrainthemodel.
Asbefore, wewilldefertheimplementationofthis methodtolaterchapters.
class Trainer(d2l.
Hyper Parameters): #@save """The base class for training models with data.""" def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0): self.
save_hyperparameters() assert num_gpus == 0, 'No GPU support yet' def prepare_data(self, data): self.
train_dataloader = data.
train_dataloader() self.
val_dataloader = data.
val_dataloader() self.
num_train_batches = len(self.
train_dataloader) self.
num_val_batches = (len(self.
val_dataloader) if self.
val_dataloader is not None else 0) def prepare_model(self, model): model.
trainer = self model.
board.
xlim = [0, self.
max_epochs] self.
model = model def fit(self, model, data): self.
prepare_data(data) self.
prepare_model(model) self.
optim = model.
configure_optimizers() self.
epoch = 0 self.
train_batch_idx = 0 self.
val_batch_idx = 0 for self.
epoch in range(self.
max_epochs): self.
fit_epoch() def fit_epoch(self): raise Not Implemented Error 3.2.5 Summary To highlight the object-oriented design for our future deep learning implementation, the above classes simply show how their objects store data and interact with each other.
We willkeepenrichingimplementationsoftheseclasses, suchasvia@add_to_class, inthe restofthebook.
Moreover, thesefullyimplementedclassesaresavedinthe D2Llibrary72 72 , alightweighttoolkitthatmakesstructuredmodelingfordeeplearningeasy.
Inparticular, itfacilitatesreusingmanycomponentsbetweenprojectswithoutchangingmuchatall.
For instance, wecanreplacejusttheoptimizer, justthemodel, justthedataset, etc.; thisdegree ofmodularitypaysdividendsthroughoutthebookintermsofconcisenessandsimplicity (thisiswhyweaddedit)anditcandothesameforyourownprojects.
3.2.6 Exercises 73 1.
Locate full implementations of the above classes that are saved in the D2L library73 .
Westronglyrecommendthatyoulookattheimplementationindetailonceyouhave gainedsomemorefamiliaritywithdeeplearningmodeling.
99 Synthetic Regression Data 2.
Removethesave_hyperparametersstatementinthe Bclass.
Canyoustillprintself.
a andself.
b? Optional: ifyouhavedivedintothefullimplementationofthe Hyper Pa- rametersclass, canyouexplainwhy? Discussions74.
74 3.3 Synthetic Regression Data Machine learning is all about extracting information from data.
So you might wonder, whatcouldwepossiblylearnfromsyntheticdata? Whilewemightnotcareintrinsically about the patterns that we ourselves baked into an artificial data generating model, such datasetsareneverthelessusefulfordidacticpurposes, helpingustoevaluatetheproperties ofourlearningalgorithmsandtoconfirmthatourimplementationsworkasexpected.
For example, if we create data for which the correct parameters are known a priori, then we cancheckthatourmodelcaninfactrecoverthem.
%matplotlib inline import random import torch from d2l import torch as d2l 3.3.1 Generatingthe Dataset For this example, we will work in low dimension for succinctness.
The following code snippetgenerates1000exampleswith2-dimensionalfeaturesdrawnfromastandardnor- maldistribution.
Theresultingdesignmatrix Xbelongsto R1000 2.
Wegenerateeachlabel byapplyingagroundtruthlinearfunction, corruptingthemviaadditivenoiseğ, drawnin- dependentlyandidenticallyforeachexample: y=Xwâ€šğ‘â€šğ.
(3.3.1) Forconvenienceweassumethatğ isdrawnfromanormaldistributionwithmean ğœ‡ = 0 andstandarddeviationğœ = 0.01.
Notethatforobject-orienteddesignweaddthecodeto the__init__methodofasubclassofd2l.
Data Module(introducedin Section3.2.3).
Itis goodpracticetoallowthesettingofanyadditionalhyperparameters.
Weaccomplishthis withsave_hyperparameters().
Thebatch_sizewillbedeterminedlater.
class Synthetic Regression Data(d2l.
Data Module): #@save """Synthetic data for linear regression.""" def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000, batch_size=32): super().__init__() self.
save_hyperparameters() n = num_train + num_val (continuesonnextpage) 100 Linear Neural Networksfor Regression (continuedfrompreviouspage) self.
X = torch.
randn(n, len(w)) noise = torch.
randn(n, 1) * noise self.
y = torch.
matmul(self.
X, w.
reshape((-1, 1))) + b + noise Below, wesetthetrueparameterstow= Â»2, 3.4â€¦> andğ‘ =4.2.
Later, wecancheckour estimatedparametersagainstthesegroundtruthvalues.
data = Synthetic Regression Data(w=torch.
tensor([2, -3.4]), b=4.2) Eachrowinfeaturesconsistsofavectorin R2 andeachrowinlabelsisascalar.
Letâ€™s havealookatthefirstentry.
print('features:', data.
X[0],'\nlabel:', data.
y[0]) features: tensor([0.9026, 1.0264]) label: tensor([2.5148]) 3.3.2 Readingthe Dataset Trainingmachinelearningmodelsoftenrequiresmultiplepassesoveradataset, grabbing one minibatch of examples at a time.
This data is then used to update the model.
To illustrate how this works, we implement the get_dataloader method, registering it in the Synthetic Regression Dataclassviaadd_to_class(introducedin Section3.2.1).
It takesabatchsize, amatrixoffeatures, andavectoroflabels, andgeneratesminibatchesof sizebatch_size.
Assuch, eachminibatchconsistsofatupleoffeaturesandlabels.
Note thatweneedtobemindfulofwhetherweâ€™reintrainingorvalidationmode: intheformer, wewillwanttoreadthedatainrandomorder, whereasforthelatter, beingabletoreaddata inapre-definedordermaybeimportantfordebuggingpurposes.
@d2l.
add_to_class(Synthetic Regression Data) def get_dataloader(self, train): if train: indices = list(range(0, self.
num_train)) # The examples are read in random order random.
shuffle(indices) else: indices = list(range(self.
num_train, self.
num_train+self.
num_val)) for i in range(0, len(indices), self.
batch_size): batch_indices = torch.
tensor(indices[i: i+self.
batch_size]) yield self.
X[batch_indices], self.
y[batch_indices] To build some intuition, letâ€™s inspect the first minibatch of data.
Each minibatch of fea- turesprovidesuswithbothitssizeandthedimensionalityofinputfeatures.
Likewise, our minibatchoflabelswillhaveamatchingshapegivenbybatch_size.
101 Synthetic Regression Data X, y = next(iter(data.
train_dataloader())) print('X shape:', X.
shape, '\ny shape:', y.
shape) X shape: torch.
Size([32, 2]) y shape: torch.
Size([32, 1]) While seemingly innocuous, the invocation of iter(data.
train_dataloader()) illus- trates the power of Pythonâ€™s object-oriented design.
Note that we added a method to the Synthetic Regression Dataclassaftercreatingthedataobject.
Nonetheless, theobject benefitsfromtheexpostfactoadditionoffunctionalitytotheclass.
Throughout the iteration we obtain distinct minibatches until the entire dataset has been exhausted(trythis).
Whiletheiterationimplementedaboveisgoodfordidacticpurposes, itisinefficientinwaysthatmightgetusintotroublewithrealproblems.
Forexample, it requiresthatweloadallthedatainmemoryandthatweperformlotsofrandommemory access.
Thebuilt-initeratorsimplementedinadeeplearningframeworkareconsiderably moreefficientandtheycandealwithsourcessuchasdatastoredinfiles, datareceivedvia astream, anddatageneratedorprocessedonthefly.
Nextletâ€™strytoimplementthesame methodusingbuilt-initerators.
3.3.3 Concise Implementationofthe Data Loader Ratherthanwritingourowniterator, wecancalltheexisting APIinaframeworktoload data.
As before, we need a dataset with features X and labels y.
Beyond that, we set batch_size in the built-in data loader and let it take care of shuffling examples effi- ciently.
@d2l.
add_to_class(d2l.
Data Module) #@save def get_tensorloader(self, tensors, train, indices=slice(0, None)): tensors = tuple(a[indices] for a in tensors) dataset = torch.
utils.
data.
Tensor Dataset(*tensors) return torch.
utils.
data.
Data Loader(dataset, self.
batch_size, shuffle=train) @d2l.
add_to_class(Synthetic Regression Data) #@save def get_dataloader(self, train): i = slice(0, self.
num_train) if train else slice(self.
num_train, None) return self.
get_tensorloader((self.
X, self.
y), train, i) Thenewdataloaderbehavesjustlikethepreviousone, exceptthatitismoreefficientand hassomeaddedfunctionality.
X, y = next(iter(data.
train_dataloader())) print('X shape:', X.
shape, '\ny shape:', y.
shape) 102 Linear Neural Networksfor Regression X shape: torch.
Size([32, 2]) y shape: torch.
Size([32, 1]) Forinstance, thedataloaderprovidedbytheframework APIsupportsthebuilt-in__len__ method, sowecanqueryitslength, i.
e., thenumberofbatches.
len(data.
train_dataloader()) 32 3.3.4 Summary Dataloadersareaconvenientwayofabstractingouttheprocessofloadingandmanipu- latingdata.
Thiswaythesamemachinelearningalgorithmiscapableofprocessingmany differenttypesandsourcesofdatawithouttheneedformodification.
Oneofthenicethings aboutdataloadersisthattheycanbecomposed.
Forinstance, wemightbeloadingimages andthenhaveapostprocessingfilterthatcropsthemormodifiestheminotherways.
As such, dataloaderscanbeusedtodescribeanentiredataprocessingpipeline.
Asforthemodelitself, thetwo-dimensionallinearmodelisaboutthesimplestwemight encounter.
It lets us test out the accuracy of regression models without worrying about havinginsufficientamountsofdataoranunderdeterminedsystemofequations.
Wewill putthistogooduseinthenextsection.
3.3.5 Exercises 1.
Whatwillhappenifthenumberofexamplescannotbedividedbythebatchsize.
How wouldyouchangethisbehaviorbyspecifyingadifferentargumentbyusingtheframe- workâ€™s API? 2.
Supposethatwewanttogenerateahugedataset, whereboththesizeoftheparameter vectorwandthenumberofexamplesnum_examplesarelarge.
1.
Whathappensifwecannotholdalldatainmemory? 2.
Howwouldyoushufflethedataifitisheldondisk? Yourtaskistodesignaneï¬€icient algorithmthatdoesnotrequiretoomanyrandomreadsorwrites.
Hint: pseudoran- dompermutationgenerators75 allowyoutodesignareshufflewithouttheneedto 75 storethepermutationtableexplicitly(Naorand Reingold,1999).
3.
Implementadatageneratorthatproducesnewdataonthefly, everytimetheiteratoris called.
4.
Howwouldyoudesignarandomdatageneratorthatgeneratesthesamedataeachtime itiscalled? 76 Discussions76.
103 Linear Regression Implementationfrom Scratch 3.4 Linear Regression Implementation from Scratch Wearenowreadytoworkthroughafullyfunctioningimplementationoflinearregression.
Inthissection, wewillimplementtheentiremethodfromscratch, including(i)themodel; (ii)thelossfunction; (iii)aminibatchstochasticgradientdescentoptimizer; and(iv)the trainingfunctionthatstitchesallofthesepiecestogether.
Finally, wewillrunoursynthetic datageneratorfrom Section3.3andapplyourmodelontheresultingdataset.
Whilemodern deeplearningframeworkscanautomatenearlyallofthiswork, implementingthingsfrom scratchistheonlywaytomakesurethatyoureallyknowwhatyouaredoing.
Moreover, whenitistimetocustomizemodels, definingourownlayersorlossfunctions, understand- ing how things work under the hood will prove handy.
In this section, we will rely only on tensors and automatic differentiation.
Later, we will introduce a more concise imple- mentation, takingadvantageofthebellsandwhistlesofdeeplearningframeworkswhile retainingthestructureofwhatfollowsbelow.
%matplotlib inline import torch from d2l import torch as d2l 3.4.1 Definingthe Model Before we can begin optimizing our modelâ€™s parameters by minibatch SGD, we need to havesomeparametersinthefirstplace.
Inthefollowingweinitializeweightsbydrawing randomnumbersfromanormaldistributionwithmean0andastandarddeviationof0.01.
Themagicnumber0.01oftenworkswellinpractice, butyoucanspecifyadifferentvalue throughtheargumentsigma.
Moreoverwesetthebiasto0.
Notethatforobject-oriented designweaddthecodetothe__init__methodofasubclassofd2l.
Module(introduced in Section3.2.2).
class Linear Regression Scratch(d2l.
Module): #@save """The linear regression model implemented from scratch.""" def __init__(self, num_inputs, lr, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
w = torch.
normal(0, sigma, (num_inputs, 1), requires_grad=True) self.
b = torch.
zeros(1, requires_grad=True) Nextwemustdefineourmodel, relatingitsinputandparameterstoitsoutput.
Usingthe samenotationas(3.1.4)forourlinearmodelwesimplytakethematrixâ€“vectorproductof theinputfeatures Xandthemodelweightsw, andaddtheoffsetğ‘ toeachexample.
The product Xw is a vector and ğ‘ is a scalar.
Because of the broadcasting mechanism (see Section2.1.4), whenweaddavectorandascalar, thescalarisaddedtoeachcomponentof thevector.
Theresultingforwardmethodisregisteredinthe Linear Regression Scratch classviaadd_to_class(introducedin Section3.2.1).
104 Linear Neural Networksfor Regression @d2l.
add_to_class(Linear Regression Scratch) #@save def forward(self, X): return torch.
matmul(X, self.
w) + self.
b 3.4.2 Definingthe Loss Function Since updating our model requires taking the gradient of our loss function, we ought to define the loss function first.
Here we use the squared loss function in (3.1.5).
In the implementation, we need to transform the true value y into the predicted valueâ€™s shape y_hat.
Theresultreturnedbythefollowingmethodwillalsohavethesameshapeasy_hat.
Wealsoreturntheaveragedlossvalueamongallexamplesintheminibatch.
@d2l.
add_to_class(Linear Regression Scratch) #@save def loss(self, y_hat, y): l = (y_hat - y) ** 2 / 2 return l.
mean() 3.4.3 Definingthe Optimization Algorithm As discussed in Section 3.1, linear regression has a closed-form solution.
However, our goalhereistoillustratehowtotrainmoregeneralneuralnetworks, andthatrequiresthat weteachyouhowtouseminibatch SGD.
Hencewewilltakethisopportunitytointroduce yourfirstworkingexampleof SGD.
Ateachstep, usingaminibatchrandomlydrawnfrom ourdataset, weestimatethegradientofthelosswithrespecttotheparameters.
Next, we updatetheparametersinthedirectionthatmayreducetheloss.
Thefollowingcodeappliestheupdate, givenasetofparameters, alearningratelr.
Since ourlossiscomputedasanaverageovertheminibatch, wedonotneedtoadjustthelearning rateagainstthebatchsize.
Inlaterchapterswewillinvestigatehowlearningratesshould beadjustedforverylargeminibatchesastheyariseindistributedlarge-scalelearning.
For now, wecanignorethisdependency.
Wedefineour SGDclass, asubclassofd2l.
Hyper Parameters(introducedin Section3.2.1), tohaveasimilar APIasthebuilt-in SGDoptimizer.
Weupdatetheparametersinthestep method.
Thezero_gradmethodsetsallgradientsto0, whichmustberunbeforeaback- propagationstep.
class SGD(d2l.
Hyper Parameters): #@save """Minibatch stochastic gradient descent.""" def __init__(self, params, lr): self.
save_hyperparameters() def step(self): for param in self.
params: param -= self.
lr * param.
grad def zero_grad(self): (continuesonnextpage) 105 Linear Regression Implementationfrom Scratch (continuedfrompreviouspage) for param in self.
params: if param.
grad is not None: param.
grad.
zero_() Wenextdefinetheconfigure_optimizersmethod, whichreturnsaninstanceofthe SGD class.
@d2l.
add_to_class(Linear Regression Scratch) #@save def configure_optimizers(self): return SGD([self.
w, self.
b], self.
lr) 3.4.4 Training Nowthatwehaveallofthepartsinplace(parameters, lossfunction, model, andoptimizer), we are ready to implement the main training loop.
It is crucial that you understand this codefullysinceyouwillemploysimilartrainingloopsforeveryotherdeeplearningmodel coveredinthisbook.
Ineachepoch, weiteratethroughtheentiretrainingdataset, passing once through every example (assuming that the number of examples is divisible by the batchsize).
Ineachiteration, wegrabaminibatchoftrainingexamples, andcomputeits loss through the modelâ€™s training_step method.
Then we compute the gradients with respect to each parameter.
Finally, we will call the optimization algorithm to update the modelparameters.
Insummary, wewillexecutethefollowingloop: Initializeparametersâ€w,ğ‘â€ Repeatuntildone Ë â€“ Computegradientg ğœ• â€w,ğ‘â€j B 1 j ğ‘–2B ğ‘™â€xâ€ğ‘–â€,ğ‘¦â€ğ‘–â€, w,ğ‘â€ â€“ Updateparametersâ€w,ğ‘â€ â€w,ğ‘â€ ğœ‚g Recallthatthesyntheticregressiondatasetthatwegeneratedin Section3.3doesnotprovide avalidationdataset.
Inmostcases, however, wewillwantavalidationdatasettomeasure our model quality.
Here we pass the validation dataloader once in each epoch to mea- sure the model performance.
Following our object-oriented design, the prepare_batch and fit_epoch methods are registered in the d2l.
Trainer class (introduced in Section 3.2.4).
@d2l.
add_to_class(d2l.
Trainer) #@save def prepare_batch(self, batch): return batch @d2l.
add_to_class(d2l.
Trainer) #@save def fit_epoch(self): self.
model.
train() for batch in self.
train_dataloader: loss = self.
model.
training_step(self.
prepare_batch(batch)) (continuesonnextpage) 106 Linear Neural Networksfor Regression (continuedfrompreviouspage) self.
optim.
zero_grad() with torch.
no_grad(): loss.
backward() if self.
gradient_clip_val > 0: # To be discussed later self.
clip_gradients(self.
gradient_clip_val, self.
model) self.
optim.
step() self.
train_batch_idx += 1 if self.
val_dataloader is None: return self.
model.
eval() for batch in self.
val_dataloader: with torch.
no_grad(): self.
model.
validation_step(self.
prepare_batch(batch)) self.
val_batch_idx += 1 Wearealmostreadytotrainthemodel, butfirstweneedsometrainingdata.
Hereweuse the Synthetic Regression Data class and pass in some ground truth parameters.
Then we train our model with the learning rate lr=0.03 and set max_epochs=3.
Note that in general, boththenumberofepochsandthelearningratearehyperparameters.
Ingeneral, setting hyperparameters is tricky and we will usually want to use a three-way split, one setfortraining, asecondforhyperparameterselection, andthethirdreservedforthefinal evaluation.
Weelidethesedetailsfornowbutwillrevisethemlater.
model = Linear Regression Scratch(2, lr=0.03) data = d2l.
Synthetic Regression Data(w=torch.
tensor([2, -3.4]), b=4.2) trainer = d2l.
Trainer(max_epochs=3) trainer.
fit(model, data) Becausewesynthesizedthedatasetourselves, weknowpreciselywhatthetrueparameters are.
Thus, wecanevaluateoursuccessintrainingbycomparingthetrueparameterswith thosethatwelearnedthroughourtrainingloop.
Indeedtheyturnouttobeverycloseto eachother.
with torch.
no_grad(): print(f'error in estimating b: {data.
b - model.
b}') 107 Linear Regression Implementationfrom Scratch error in estimating w: tensor([ 0.1408, -0.1493]) error in estimating b: tensor([0.2130]) Weshouldnottaketheabilitytoexactlyrecoverthegroundtruthparametersforgranted.
In general, for deep models unique solutions for the parameters do not exist, and even for linear models, exactly recovering the parameters is only possible when no feature is linearlydependentontheothers.
However, inmachinelearning, weareoftenlessconcerned withrecoveringtrueunderlyingparameters, butratherwithparametersthatleadtohighly accurateprediction(Vapnik,1992).
Fortunately, evenondifficultoptimizationproblems, stochasticgradientdescentcanoftenfindremarkablygoodsolutions, owingpartlytothe factthat, fordeepnetworks, thereexistmanyconfigurationsoftheparametersthatleadto highlyaccurateprediction.
3.4.5 Summary Inthissection, wetookasignificantsteptowardsdesigningdeeplearningsystemsbyim- plementingafullyfunctionalneuralnetworkmodelandtrainingloop.
Inthisprocess, we builtadataloader, amodel, alossfunction, anoptimizationprocedure, andavisualization andmonitoringtool.
Wedidthisbycomposinga Pythonobjectthatcontainsallrelevant componentsfortrainingamodel.
Whilethisisnotyetaprofessional-gradeimplementation itisperfectlyfunctionalandcodelikethiscouldalreadyhelpyoutosolvesmallproblems quickly.
Inthecomingsections, wewillseehowtodothisbothmoreconcisely(avoiding boilerplatecode)andmoreeï¬€iciently(usingour GPUstotheirfullpotential).
3.4.6 Exercises 1.
Whatwouldhappenifweweretoinitializetheweightstozero.
Wouldthealgorithm stillwork? Whatifweinitializedtheparameterswithvariance1000ratherthan0.01? 2.
Assume that you are Georg Simon Ohm77 trying to come up with a model for resis- 77 tancethatrelatesvoltageandcurrent.
Canyouuseautomaticdifferentiationtolearnthe parametersofyourmodel? 3.
Canyouuse Planckâ€™s Law78 todeterminethetemperatureofanobjectusingspectral 78 energy density? For reference, the spectral density ğµ of radiation emanating from a 1 black body is ğµâ€ğœ†,ğ‘‡â€ = 2â„ğ‘2 exp â„ğ‘ 1 .
Here ğœ† is the wavelength, ğ‘‡ is the ğœ†5 ğœ†ğ‘˜ğ‘‡ temperature, ğ‘ is the speed of light, â„ is Planckâ€™s constant, and ğ‘˜ is the Boltzmann constant.
Youmeasuretheenergyfordifferentwavelengthsğœ† andyounowneedtofit thespectraldensitycurveto Planckâ€™slaw.
4.
Whataretheproblemsyoumightencounterifyouwantedtocomputethesecondderiva- tivesoftheloss? Howwouldyoufixthem? 5.
Whyisthereshapemethodneededinthelossfunction? 6.
Experimentusingdifferentlearningratestofindouthowquicklythelossfunctionvalue drops.
Canyoureducetheerrorbyincreasingthenumberofepochsoftraining? 108 Linear Neural Networksfor Regression 7.
Ifthenumberofexamplescannotbedividedbythebatchsize, whathappenstodata_iter attheendofanepoch? 8.
Try implementing a different loss function, such as the absolute value loss (y_hat - 1.
Checkwhathappensforregulardata.
2.
Checkwhetherthereisadifferenceinbehaviorifyouactivelyperturbsomeentries, suchasğ‘¦ =10000, ofy.
5 3.
Canyouthinkofacheapsolutionforcombiningthebestaspectsofsquaredlossand absolutevalueloss? Hint: howcanyouavoidreallylargegradientvalues? 9.
Whydoweneedtoreshufflethedataset? Canyoudesignacasewhereamaliciously constructeddatasetwouldbreaktheoptimizationalgorithmotherwise? 79 Discussions79.
3.5 Concise Implementation of Linear Regression Deeplearninghaswitnessedasortof Cambrianexplosionoverthepastdecade.
Thesheer number of techniques, applications and algorithms by far surpasses the progress of pre- vious decades.
This is due to a fortuitous combination of multiple factors, one of which isthepowerfulfreetoolsofferedbyanumberofopen-sourcedeeplearningframeworks.
Theano(Bergstraetal.,2010), Dist Belief(Deanetal.,2012), and Caffe(Jiaetal.,2014) arguably represent the first generation of such models that found widespread adoption.
In contrast to earlier (seminal) works like SN2 (Simulateur Neuristique) (Bottou and Le Cun,1988), whichprovideda Lisp-likeprogrammingexperience, modernframeworksof- fer automatic differentiation and the convenience of Python.
These frameworks allow us toautomateandmodularizetherepetitiveworkofimplementinggradient-basedlearning algorithms.
In Section 3.4, we relied only on (i) tensors for data storage and linear algebra; and (ii) automaticdifferentiationforcalculatinggradients.
Inpractice, becausedataiterators, loss functions, optimizers, andneuralnetworklayersaresocommon, modernlibrariesimple- mentthesecomponentsforusaswell.
Inthissection, wewillshowyouhowtoimplement the linear regression model from Section 3.4 concisely by using high-level APIs of deep learningframeworks.
import numpy as np import torch from torch import nn from d2l import torch as d2l 109 Concise Implementationof Linear Regression 3.5.1 Definingthe Model Whenweimplementedlinearregressionfromscratchin Section3.4, wedefinedourmodel parameters explicitly and coded up the calculations to produce output using basic linear algebra operations.
You should know how to do this.
But once your models get more complex, andonceyouhavetodothisnearlyeveryday, youwillbegladoftheassistance.
Thesituationissimilartocodingupyourownblogfromscratch.
Doingitonceortwice isrewardingandinstructive, butyouwouldbealousywebdeveloperifyouspentamonth reinventingthewheel.
For standard operations, we can use a frameworkâ€™s predefined layers, which allow us to focusonthelayersusedtoconstructthemodelratherthanworryingabouttheirimplemen- layeriscalledfullyconnected, sinceeachofitsinputsisconnectedtoeachofitsoutputs bymeansofamatrixâ€“vectormultiplication.
In Py Torch, thefullyconnectedlayerisdefinedin Linearand Lazy Linearclasses(avail- ablesinceversion1.8.0).
Thelatterallowsuserstospecifymerelytheoutputdimension, whiletheformeradditionallyasksforhowmanyinputsgointothislayer.
Specifyinginput shapes is inconvenient and may require nontrivial calculations (such as in convolutional layers).
Thus, forsimplicity, wewillusesuchâ€œlazyâ€layerswheneverwecan.
class Linear Regression(d2l.
Module): #@save """The linear regression model implemented with high-level APIs.""" def __init__(self, lr): super().__init__() self.
save_hyperparameters() self.
net = nn.
Lazy Linear(1) self.
net.
bias.
data.
fill_(0) In the forward method we just invoke the built-in __call__ method of the predefined layerstocomputetheoutputs.
@d2l.
add_to_class(Linear Regression) #@save def forward(self, X): return self.
net(X) 3.5.2 Definingthe Loss Function The MSELoss class computes the mean squared error (without the 1 2 factor in (3.1.5)).
Bydefault, MSELossreturnstheaveragelossoverexamples.
Itisfaster(andeasiertouse) thanimplementingourown.
@d2l.
add_to_class(Linear Regression) #@save def loss(self, y_hat, y): fn = nn.
MSELoss() return fn(y_hat, y) 110 Linear Neural Networksfor Regression 3.5.3 Definingthe Optimization Algorithm Minibatch SGD is a standard tool for optimizing neural networks and thus Py Torch sup- portsitalongsideanumberofvariationsonthisalgorithmintheoptimmodule.
Whenwe instantiate an SGD instance, we specify the parameters to optimize over, obtainable from ourmodelviaself.
parameters(), andthelearningrate(self.
lr)requiredbyouropti- mizationalgorithm.
@d2l.
add_to_class(Linear Regression) #@save def configure_optimizers(self): return torch.
optim.
SGD(self.
parameters(), self.
lr) 3.5.4 Training Youmighthavenoticedthatexpressingourmodelthroughhigh-level APIsofadeeplearn- ingframeworkrequiresfewerlinesofcode.
Wedidnothavetoallocateparametersindi- vidually, define our loss function, or implement minibatch SGD.
Once we start working withmuchmorecomplexmodels, theadvantagesofthehigh-level APIwillgrowconsid- erably.
Now that we have all the basic pieces in place, the training loop itself is the same as the oneweimplementedfromscratch.
Sowejustcallthefitmethod(introducedin Section 3.2.4), whichreliesontheimplementationofthefit_epochmethodin Section3.4, totrain ourmodel.
model = Linear Regression(lr=0.03) data = d2l.
Synthetic Regression Data(w=torch.
tensor([2, -3.4]), b=4.2) trainer = d2l.
Trainer(max_epochs=3) trainer.
fit(model, data) Below, wecomparethemodelparameterslearnedbytrainingonfinitedataandtheactual parametersthatgeneratedourdataset.
Toaccessparameters, weaccesstheweightsandbias ofthelayerthatweneed.
Asinourimplementationfromscratch, notethatourestimated parametersareclosetotheirtruecounterparts.
@d2l.
add_to_class(Linear Regression) #@save (continuesonnextpage) 111 Concise Implementationof Linear Regression (continuedfrompreviouspage) def get_w_b(self): w, b = model.
get_w_b() print(f'error in estimating w: {data.
w - w.
reshape(data.
w.
shape)}') print(f'error in estimating b: {data.
b - b}') error in estimating w: tensor([ 0.0094, -0.0030]) error in estimating b: tensor([0.0137]) 3.5.5 Summary Thissectioncontainsthefirstimplementationofadeepnetwork(inthisbook)totapinto the conveniences afforded by modern deep learning frameworks, such as MXNet (Chen et al., 2015), JAX (Frostig et al., 2018), Py Torch (Paszke et al., 2019), and Tensorflow (Abadietal.,2016).
Weusedframeworkdefaultsforloadingdata, definingalayer, aloss function, anoptimizerandatrainingloop.
Whenevertheframeworkprovidesallnecessary features, itisgenerallyagoodideatousethem, sincethelibraryimplementationsofthese componentstendtobeheavilyoptimizedforperformanceandproperlytestedforreliability.
Atthesametime, trynottoforgetthatthesemodulescanbeimplementeddirectly.
Thisis especiallyimportantforaspiringresearcherswhowishtoliveontheleadingedgeofmodel development, where you will be inventing new components that cannot possibly exist in anycurrentlibrary.
In Py Torch, thedatamoduleprovidestoolsfordataprocessing, thennmoduledefinesa largenumberofneuralnetworklayersandcommonlossfunctions.
Wecaninitializethepa- rametersbyreplacingtheirvalueswithmethodsendingwith_.
Notethatweneedtospecify theinputdimensionsofthenetwork.
Whilethisistrivialfornow, itcanhavesignificant knock-on effects when we want to design complex networks with many layers.
Careful considerationsofhowtoparametrizethesenetworksisneededtoallowportability.
3.5.6 Exercises 1.
Howwouldyouneedtochangethelearningrateifyoureplacetheaggregatelossover theminibatchwithanaverageoverthelossontheminibatch? 2.
Reviewtheframeworkdocumentationtoseewhichlossfunctionsareprovided.
Inpar- ticular, replacethesquaredlosswith Huberâ€™srobustlossfunction.
Thatis, usetheloss function ( jğ‘¦ ğ‘¦0j ğœ ifjğ‘¦ ğ‘¦0j > ğœ ğ‘™â€ğ‘¦,ğ‘¦0â€ = 2 (3.5.1) 1 â€ğ‘¦ ğ‘¦0â€2 otherwise 2ğœ 3.
Howdoyouaccessthegradientoftheweightsofthemodel? 112 Linear Neural Networksfor Regression 4.
What is the effect on the solution if you change the learning rate and the number of epochs? Doesitkeeponimproving? 5.
Howdoesthesolutionchangeasyouvarytheamountofdatagenerated? 1.
PlottheestimationerrorforwË† w and ğ‘Ë† ğ‘ asafunctionoftheamountofdata.
Hint: increasetheamountofdatalogarithmicallyratherthanlinearly, i.
e.,5,10,20, 50,â€¦,10,000ratherthan1000,2000,â€¦,10,000.
2.
Whyisthesuggestioninthehintappropriate? Discussions80.
80 3.6 Generalization Consider two college students diligently preparing for their final exam.
Commonly, this preparationwill consistofpracticing and testingtheirabilities bytaking examsadminis- teredinpreviousyears.
Nonetheless, doingwellonpastexamsisnoguaranteethattheywill excelwhenitmatters.
Forinstance, imagineastudent, Extraordinary Ellie, whoseprepara- tionconsistedentirelyofmemorizingtheanswerstopreviousyearsâ€™examquestions.
Even if Elliewereendowedwithanextraordinarymemory, andthuscouldperfectlyrecallthean- swertoanypreviouslyseenquestion, shemightneverthelessfreezewhenfacedwithanew (previously unseen) question.
By comparison, imagine another student, Inductive Irene, withcomparablypoormemorizationskills, butaknackforpickinguppatterns.
Notethat iftheexamtrulyconsistedofrecycledquestionsfromapreviousyear, Elliewouldhandily outperform Irene.
Evenif Ireneâ€™sinferredpatternsyielded90%accuratepredictions, they couldnevercompetewith Ellieâ€™s100%recall.
However, eveniftheexamconsistedentirely offreshquestions, Irenemightmaintainher90%average.
Asmachinelearningscientists, ourgoalistodiscoverpatterns.
Buthowcanwebesurethat wehavetrulydiscoveredageneralpatternandnotsimplymemorizedourdata? Mostofthe time, ourpredictionsareonlyusefulifourmodeldiscoverssuchapattern.
Wedonotwant topredictyesterdayâ€™sstockprices, buttomorrowâ€™s.
Wedonotneedtorecognizealready diagnoseddiseasesforpreviouslyseenpatients, butratherpreviouslyundiagnosedailments inpreviouslyunseenpatients.
Thisproblemâ€”howtodiscoverpatternsthatgeneralizeâ€”is thefundamentalproblemofmachinelearning, andarguablyofallofstatistics.
Wemight cast this problem as just one slice of a far grander question that engulfs all of science: whenareweeverjustifiedinmakingtheleapfromparticularobservationstomoregeneral statements? In real life, we must fit our models using a finite collection of data.
The typical scales of that data vary wildly across domains.
For many important medical problems, we can onlyaccessafewthousanddatapoints.
Whenstudyingrarediseases, wemightbeluckyto accesshundreds.
Bycontrast, thelargestpublicdatasetsconsistingoflabeledphotographs, e.
g., Image Net(Dengetal.,2009), containmillionsofimages.
Andsomeunlabeledimage 113 Generalization collections such as the Flickr YFC100M dataset can be even larger, containing over 100 millionimages(Thomeeetal.,2016).
However, evenatthisextremescale, thenumberof available data points remains infinitesimally small compared to the space of all possible imagesatamegapixelresolution.
Wheneverweworkwithfinitesamples, wemustkeepin mindtheriskthatwemightfitourtrainingdata, onlytodiscoverthatwefailedtodiscover ageneralizablepattern.
Thephenomenonoffittingclosertoourtrainingdatathantotheunderlyingdistributionis calledoverfitting, andtechniquesforcombattingoverfittingareoftencalledregularization methods.
While it is no substitute for a proper introduction to statistical learning theory (see Boucheronetal.
(2005), Vapnik(1998)), wewillgiveyoujustenoughintuitiontoget going.
Wewillrevisitgeneralizationinmanychaptersthroughoutthebook, exploringboth whatisknownabouttheprinciplesunderlyinggeneralizationinvariousmodels, andalso heuristictechniquesthathavebeenfound(empirically)toyieldimprovedgeneralizationon tasksofpracticalinterest.
3.6.1 Training Errorand Generalization Error In the standard supervised learning setting, we assume that the training data and the test data are drawn independently from identical distributions.
This is commonly called the IIDassumption.
Whilethisassumptionisstrong, itisworthnotingthat, absentanysuch assumption, we would be dead in the water.
Why should we believe that training data sampled from distribution ğ‘ƒâ€ğ‘‹,ğ‘Œâ€ should tell us how to make predictions on test data generatedbyadifferentdistributionğ‘„â€ğ‘‹,ğ‘Œâ€? Makingsuchleapsturnsouttorequirestrong assumptionsabouthow ğ‘ƒ andğ‘„ arerelated.
Lateronwewilldiscusssomeassumptions that allow for shifts in distribution but first we need to understand the IID case, where ğ‘ƒâ€ â€ =ğ‘„â€ â€.
Tobeginwith, weneedtodifferentiatebetweenthetrainingerrorğ‘… , whichisastatistic emp calculatedonthetrainingdataset, andthegeneralizationerror ğ‘…, whichisanexpectation takenwithrespecttotheunderlyingdistribution.
Youcanthinkofthegeneralizationerror as what you would see if you applied your model to an infinite stream of additional data examplesdrawnfromthesameunderlyingdatadistribution.
Formallythetrainingerroris expressedasasum(withthesamenotationas Section3.1): ğ‘› 1 ğ‘… Â»X, y, ğ‘“â€¦ = ğ‘™â€x â€ğ‘–â€,ğ‘¦â€ğ‘–â€, ğ‘“â€x â€ğ‘–â€â€â€, (3.6.1) emp ğ‘› ğ‘–=1 whilethegeneralizationerrorisexpressedasanintegral: â€ â€ ğ‘…Â»ğ‘, ğ‘“â€¦ = ğ¸ â€x,ğ‘¦â€ ğ‘ƒ Â»ğ‘™â€x,ğ‘¦, ğ‘“â€xâ€â€â€¦ = ğ‘™â€x,ğ‘¦, ğ‘“â€xâ€â€ğ‘â€x,ğ‘¦â€ ğ‘‘xğ‘‘ğ‘¦.
(3.6.2) Problematically, we can never calculate the generalization error ğ‘… exactly.
Nobody ever tells us the precise form of the density function ğ‘â€x,ğ‘¦â€.
Moreover, we cannot sample an infinite stream of data points.
Thus, in practice, we must estimate the generalization error by applying our model to an independent test set constituted of a random selection of examples X0 and labels y0 that were withheld from our training set.
This consists of 114 Linear Neural Networksfor Regression applyingthesameformulathatwasusedforcalculatingtheempiricaltrainingerrorbutto atestset X0, y0 .
Crucially, whenweevaluateourclassifieronthetestset, weareworkingwithafixedclassi- fier(itdoesnotdependonthesampleofthetestset), andthusestimatingitserrorissimply theproblemofmeanestimation.
Howeverthesamecannotbesaidforthetrainingset.
Note thatthemodelwewindupwithdependsexplicitlyontheselectionofthetrainingsetand thusthetrainingerrorwillingeneralbeabiasedestimateofthetrueerrorontheunderly- ingpopulation.
Thecentralquestionofgeneralizationisthenwhenshouldweexpectour trainingerrortobeclosetothepopulationerror(andthusthegeneralizationerror).
Model Complexity Inclassicaltheory, whenwehavesimplemodelsandabundantdata, thetrainingandgen- eralization errors tend to be close.
However, when we work with more complex models and/orfewerexamples, weexpectthetrainingerrortogodownbutthegeneralizationgap togrow.
Thisshouldnotbesurprising.
Imagineamodelclasssoexpressivethatforany datasetofğ‘›examples, wecanfindasetofparametersthatcanperfectlyfitarbitrarylabels, evenifrandomlyassigned.
Inthiscase, evenifwefitourtrainingdataperfectly, howcan weconcludeanythingaboutthegeneralizationerror? Forallweknow, ourgeneralization errormightbenobetterthanrandomguessing.
Ingeneral, absentanyrestrictiononourmodelclass, wecannotconclude, basedonfitting thetrainingdataalone, thatourmodelhasdiscoveredanygeneralizablepattern(Vapniket al.,1994).
Ontheotherhand, ifourmodelclasswasnotcapableoffittingarbitrarylabels, thenitmusthavediscoveredapattern.
Learning-theoreticideasaboutmodelcomplexity derivedsomeinspirationfromtheideasof Karl Popper, aninfluentialphilosopherofsci- ence, whoformalizedthecriterionoffalsifiability.
Accordingto Popper, atheorythatcan explainanyandallobservationsisnotascientifictheoryatall! Afterall, whathasittoldus abouttheworldifithasnotruledoutanypossibility? Inshort, whatwewantisahypothesis thatcouldnot explainanyobservationswemightconceivablymakeandyetnevertheless happenstobecompatiblewiththoseobservationsthatweinfactmake.
Now what precisely constitutes an appropriate notion of model complexity is a complex matter.
Often, modelswithmoreparametersareabletofitagreaternumberofarbitrarily assignedlabels.
However, thisisnotnecessarilytrue.
Forinstance, kernelmethodsoperate inspaceswithinfinitenumbersofparameters, yettheircomplexityiscontrolledbyother means (SchÃ¶lkopf and Smola, 2002).
One notion of complexity that often proves useful is the range of values that the parameters can take.
Here, a model whose parameters are permittedtotakearbitraryvalueswouldbemorecomplex.
Wewillrevisitthisideainthe nextsection, whenweintroduceweightdecay, yourfirstpracticalregularizationtechnique.
Notably, itcanbedifficulttocomparecomplexityamongmembersofsubstantiallydifferent modelclasses(say, decisiontreesvs.
neuralnetworks).
Atthispoint, wemuststressanotherimportantpointthatwewillrevisitwhenintroducing deep neural networks.
When a model is capable of fitting arbitrary labels, low training errordoesnotnecessarilyimplylowgeneralizationerror.
However, itdoesnotnecessarily 115 Generalization implyhighgeneralizationerroreither! Allwecansaywithconfidenceisthatlowtraining error alone is not enough to certify low generalization error.
Deep neural networks turn out to be just such models: while they generalize well in practice, they are too powerful toallowustoconcludemuchonthebasisoftrainingerroralone.
Inthesecaseswemust relymoreheavilyonourholdoutdatatocertifygeneralizationafterthefact.
Erroronthe holdoutdata, i.
e., validationset, iscalledthevalidationerror.
3.6.2 Underfittingor Overfitting? Whenwecomparethetrainingandvalidationerrors, wewanttobemindfuloftwocom- monsituations.
First, wewanttowatchoutforcaseswhenourtrainingerrorandvalidation errorarebothsubstantialbutthereisalittlegapbetweenthem.
Ifthemodelisunableto reducethetrainingerror, thatcouldmeanthatourmodelistoosimple(i.
e., insufficiently expressive)tocapturethepatternthatwearetryingtomodel.
Moreover, sincethegener- alizationgap(ğ‘… ğ‘…)betweenourtrainingandgeneralizationerrorsissmall, wehave emp reasontobelievethatwecouldgetawaywithamorecomplexmodel.
Thisphenomenonis knownasunderfitting.
On the other hand, as we discussed above, we want to watch out for the cases when our trainingerrorissignificantlylowerthanourvalidationerror, indicatingsevereoverfitting.
Note that overfitting is not always a bad thing.
In deep learning especially, the best pre- dictivemodelsoftenperformfarbetterontrainingdatathanonholdoutdata.
Ultimately, weusuallycareaboutdrivingthegeneralizationerrorlower, andonlycareaboutthegap insofarasitbecomesanobstacletothatend.
Notethatifthetrainingerroriszero, thenthe generalizationgapispreciselyequaltothegeneralizationerrorandwecanmakeprogress onlybyreducingthegap.
Polynomial Curve Fitting Toillustratesomeclassicalintuitionaboutoverfittingandmodelcomplexity, considerthe following: given training data consisting of a single feature ğ‘¥ and a corresponding real- valuedlabelğ‘¦, wetrytofindthepolynomialofdegreeğ‘‘ ğ‘‘ ğ‘¦Ë† = ğ‘¥ğ‘–ğ‘¤ ğ‘– (3.6.3) ğ‘–=0 forestimatingthelabel ğ‘¦.
Thisisjustalinearregressionproblemwhereourfeaturesare givenbythepowersofğ‘¥, themodelâ€™sweightsaregivenbyğ‘¤ ğ‘–, andthebiasisgivenbyğ‘¤ 0 sinceğ‘¥0 =1forallğ‘¥.
Sincethisisjustalinearregressionproblem, wecanusethesquared errorasourlossfunction.
Ahigher-orderpolynomialfunctionismorecomplexthanalower-orderpolynomialfunc- tion, sincethehigher-orderpolynomialhasmoreparametersandthemodelfunctionâ€™sselec- tionrangeiswider.
Fixingthetrainingdataset, higher-orderpolynomialfunctionsshould alwaysachievelower(atworst, equal)trainingerrorrelativetolower-degreepolynomials.
Infact, whenevereachdataexamplehasadistinctvalueofğ‘¥, apolynomialfunctionwith degreeequaltothenumberofdataexamplescanfitthetrainingsetperfectly.
Wecompare 116 Linear Neural Networksfor Regression therelationshipbetweenpolynomialdegree(modelcomplexity)andbothunderfittingand overfittingin.6.1.
t .6.1 Influenceofmodelcomplexityonunderfittingandoverfitting.
Dataset Size Astheaboveboundalreadyindicates, anotherbigconsiderationtobearinmindisdataset size.
Fixingourmodel, thefewersampleswehaveinthetrainingdataset, themorelikely (andmoreseverely)wearetoencounteroverfitting.
Asweincreasetheamountoftraining data, the generalization error typically decreases.
Moreover, in general, more data never hurts.
Forafixedtaskanddatadistribution, modelcomplexityshouldnotincreasemore rapidlythantheamountofdata.
Givenmoredata, wemightattempttofitamorecomplex model.
Absent sufficient data, simpler models may be more difficult to beat.
For many tasks, deeplearningonlyoutperformslinearmodelswhenmanythousandsoftrainingex- amplesareavailable.
Inpart, thecurrentsuccessofdeeplearningowesconsiderablytothe abundanceofmassivedatasetsarisingfrom Internetcompanies, cheapstorage, connected devices, andthebroaddigitizationoftheeconomy.
3.6.3 Model Selection Typically, weselectourfinalmodelonlyafterevaluatingmultiplemodelsthatdifferinvari- ousways(differentarchitectures, trainingobjectives, selectedfeatures, datapreprocessing, learningrates, etc.).
Choosingamongmanymodelsisaptlycalledmodelselection.
In principle, we should not touch our test set until after we have chosen all our hyperpa- rameters.
Werewetousethetestdatainthemodelselectionprocess, thereisariskthatwe mightoverfitthetestdata.
Thenwewouldbeinserioustrouble.
Ifweoverfitourtraining data, thereisalwaystheevaluationontestdatatokeepushonest.
Butifweoverfitthetest data, howwouldweeverknow? See Ongetal.
(2005)foranexampleofhowthiscanlead toabsurdresultsevenformodelswherethecomplexitycanbetightlycontrolled.
Thus, we should never rely on the test data for model selection.
And yet we cannot rely solelyonthetrainingdataformodelselectioneitherbecausewecannotestimatethegen- eralizationerrorontheverydatathatweusetotrainthemodel.
Inpracticalapplications, thepicturegetsmuddier.
Whileideallywewouldonlytouchthe 117 Generalization testdataonce, toassesstheverybestmodelortocompareasmallnumberofmodelswith each other, real-world test data is seldom discarded after just one use.
We can seldom affordanewtestsetforeachroundofexperiments.
Infact, recyclingbenchmarkdatafor decades can have a significant impact on the development of algorithms, e.
g., for image classification81 andopticalcharacterrecognition82.
81 Thecommonpracticeforaddressingtheproblemoftrainingonthetestsetistosplitour datathreeways, incorporatingavalidationsetinadditiontothetrainingandtestdatasets.
Theresultisamurkybusinesswheretheboundariesbetweenvalidationandtestdataare 82 worryinglyambiguous.
Unlessexplicitlystatedotherwise, intheexperimentsinthisbook wearereallyworkingwithwhatshouldrightlybecalledtrainingdataandvalidationdata, withnotruetestsets.
Therefore, theaccuracyreportedineachexperimentofthebookis reallythevalidationaccuracyandnotatruetestsetaccuracy.
Cross-Validation Whentrainingdataisscarce, wemightnotevenbeabletoaffordtoholdoutenoughdatato constituteapropervalidationset.
Onepopularsolutiontothisproblemistoemployğ¾-fold cross-validation.
Here, theoriginal trainingdata issplit into ğ¾ non-overlappingsubsets.
Then model training and validation are executed ğ¾ times, each time training on ğ¾ 1 subsets and validating on a different subset (the one not used for training in that round).
Finally, thetrainingandvalidationerrorsareestimatedbyaveragingovertheresultsfrom theğ¾ experiments.
3.6.4 Summary This section explored some of the underpinnings of generalization in machine learning.
Someoftheseideasbecomecomplicatedandcounterintuitivewhenwegettodeepermod- els; here, modelsarecapableofoverfittingdatabadly, andtherelevantnotionsofcomplex- itycanbebothimplicitandcounterintuitive(e.
g., largerarchitectureswithmoreparameters generalizingbetter).
Weleaveyouwithafewrulesofthumb: 1.
Usevalidationsets(orğ¾-foldcross-validation)formodelselection; 2.
Morecomplexmodelsoftenrequiremoredata; 3.
Relevantnotionsofcomplexityincludeboththenumberofparametersandtherangeof valuesthattheyareallowedtotake; 4.
Keepingallelseequal, moredataalmostalwaysleadstobettergeneralization; 5.
This entire talk of generalization is all predicated on the IID assumption.
If we relax this assumption, allowing for distributions to shift between the train and testing peri- ods, thenwecannotsayanythingaboutgeneralizationabsentafurther(perhapsmilder) assumption.
3.6.5 Exercises 1.
Whencanyousolvetheproblemofpolynomialregressionexactly? 118 Linear Neural Networksfor Regression 2.
Giveatleastfiveexampleswheredependentrandomvariablesmaketreatingtheproblem as IIDdatainadvisable.
3.
Canyoueverexpecttoseezerotrainingerror? Underwhichcircumstanceswouldyou seezerogeneralizationerror? 4.
Whyisğ¾-foldcross-validationveryexpensivetocompute? 5.
Whyistheğ¾-foldcross-validationerrorestimatebiased? 6.
The VCdimensionisdefinedasthemaximumnumberofpointsthatcanbeclassified witharbitrarylabelsf 1gbyafunctionofaclassoffunctions.
Whymightthisnotbe a good idea for measuring how complex the class of functions is? Hint: consider the magnitudeofthefunctions.
7.
Your manager gives you a difficult dataset on which your current algorithm does not perform so well.
How would you justify to him that you need more data? Hint: you cannotincreasethedatabutyoucandecreaseit.
83 Discussions83.
3.7 Weight Decay Nowthatwehavecharacterizedtheproblemofoverfitting, wecanintroduceourfirstreg- ularization technique.
Recall that we can always mitigate overfitting by collecting more trainingdata.
However, thatcanbecostly, timeconsuming, orentirelyoutofourcontrol, making it impossible in the short run.
For now, we can assume that we already have as muchhigh-qualitydataasourresourcespermitandfocusthetoolsatourdisposalwhenthe datasetistakenasagiven.
Recallthatinourpolynomialregressionexample(Section3.6.2)wecouldlimitourmodelâ€™s capacitybytweakingthedegreeofthefittedpolynomial.
Indeed, limitingthenumberof features is a popular technique for mitigating overfitting.
However, simply tossing aside featurescanbetoobluntaninstrument.
Stickingwiththepolynomialregressionexample, considerwhatmighthappenwithhigh-dimensionalinput.
Thenaturalextensionsofpoly- nomials to multivariate data are called monomials, which are simply products of powers ofvariables.
Thedegreeofamonomialisthesumofthepowers.
Forexample,ğ‘¥2ğ‘¥ , and 1 2 ğ‘¥ ğ‘¥2arebothmonomialsofdegree3.
3 5 Notethatthenumberoftermswithdegreeğ‘‘ blowsuprapidlyasğ‘‘ growslarger.
Given ğ‘˜ variables, thenumberofmonomialsofdegreeğ‘‘is ğ‘˜ 1â€šğ‘‘ .
Evensmallchangesindegree, ğ‘˜ 1 sayfrom2to3, dramaticallyincreasethecomplexityofourmodel.
Thusweoftenneeda morefine-grainedtoolforadjustingfunctioncomplexity.
119 Weight Decay %matplotlib inline import torch from torch import nn from d2l import torch as d2l 3.7.1 Normsand Weight Decay Rather than directly manipulating the number of parameters, weight decay, operates by restrictingthevaluesthattheparameterscantake.
Morecommonlycalledâ„“ regularization 2 outsideofdeeplearningcircleswhenoptimizedbyminibatchstochasticgradientdescent, weightdecaymightbethemostwidelyusedtechniqueforregularizingparametricmachine learningmodels.
Thetechniqueismotivatedbythebasicintuitionthatamongallfunctions ğ‘“, thefunction ğ‘“ =0(assigningthevalue0toallinputs)isinsomesensethesimplest, and that we can measure the complexity of a function by the distance of its parameters from zero.
But how precisely should we measure the distance between a function and zero? There is no single right answer.
In fact, entire branches of mathematics, including parts of functional analysis and the theory of Banach spaces, are devoted to addressing such issues.
Onesimpleinterpretationmightbetomeasurethecomplexityofalinearfunction ğ‘“â€xâ€ = w>xbysomenormofitsweightvector, e.
g., kwk2.
Recallthatweintroducedtheâ„“ norm 2 andâ„“ 1 norm, whicharespecialcasesofthemoregeneralâ„“ ğ‘ norm, in Section2.3.11.
The most common method for ensuring a small weight vector is to add its norm as a penalty termtotheproblemofminimizingtheloss.
Thuswereplaceouroriginalobjective, min- imizingthepredictionlossonthetraininglabels, withnewobjective, minimizingthesum ofthepredictionlossandthepenaltyterm.
Now, ifourweightvectorgrowstoolarge, our learningalgorithmmightfocusonminimizingtheweightnormkwk2ratherthanminimiz- ingthetrainingerror.
Thatisexactlywhatwewant.
Toillustratethingsincode, werevive our previous example from Section 3.1 for linear regression.
There, our loss was given by ğ‘› 1 1 2 ğ¿â€w,ğ‘â€ = w > x â€ğ‘–â€ â€šğ‘ ğ‘¦â€ğ‘–â€ .
(3.7.1) ğ‘› 2 ğ‘–=1 Recall that xâ€ğ‘–â€ are the features, ğ‘¦â€ğ‘–â€ is the label for any data example ğ‘–, and â€w,ğ‘â€ are the weight and bias parameters, respectively.
To penalize the size of the weight vector, wemustsomehowadd kwk2 tothelossfunction, buthowshouldthemodeltradeoffthe standardlossforthisnewadditivepenalty? Inpractice, wecharacterizethistrade-offvia the regularization constant ğœ†, a nonnegative hyperparameter that we fit using validation data: ğœ† ğ¿â€w,ğ‘â€â€š kwk2.
(3.7.2) 2 Forğœ† = 0, werecoverouroriginallossfunction.
Forğœ† > 0, werestrictthesizeof kwk.
We divide by 2 by convention: when we take the derivative of a quadratic function, the 2 and 1 2 cancel out, ensuring that the expression for the update looks nice and simple.
Theastutereadermightwonderwhyweworkwiththesquarednormandnotthestandard 120 Linear Neural Networksfor Regression norm(i.
e., the Euclideandistance).
Wedothisforcomputationalconvenience.
Bysquaring theâ„“ norm, weremovethesquareroot, leavingthesumofsquaresofeachcomponentof 2 theweightvector.
Thismakesthederivativeofthepenaltyeasytocompute: thesumof derivativesequalsthederivativeofthesum.
Moreover, you might ask why we work with the â„“ norm in the first place and not, say, 2 theâ„“ norm.
Infact, otherchoicesarevalidandpopularthroughoutstatistics.
Whileâ„“ - 1 2 regularizedlinearmodelsconstitutetheclassicridgeregressionalgorithm,â„“ -regularized 1 linearregressionisasimilarlyfundamentalmethodinstatistics, popularlyknownaslasso regression.
Onereasontoworkwiththeâ„“ normisthatitplacesanoutsizepenaltyonlarge 2 componentsoftheweightvector.
Thisbiasesourlearningalgorithmtowardsmodelsthat distribute weight evenly across a larger number of features.
In practice, this might make themmorerobusttomeasurementerrorinasinglevariable.
Bycontrast,â„“ penaltieslead 1 tomodelsthatconcentrateweightsonasmallsetoffeaturesbyclearingtheotherweights tozero.
Thisgivesusaneffectivemethodforfeatureselection, whichmaybedesirablefor other reasons.
For example, if our model only relies on a few features, then we may not needtocollect, store, ortransmitdatafortheother(dropped)features.
Usingthesamenotationin(3.1.11), minibatchstochasticgradientdescentupdatesforâ„“ - 2 regularizedregressionasfollows: ğœ‚ w â€1 ğœ‚ğœ†â€w j Bj x â€ğ‘–â€ w > x â€ğ‘–â€ â€šğ‘ ğ‘¦â€ğ‘–â€ .
(3.7.3) ğ‘–2B Asbefore, weupdatew basedontheamountbywhichourestimatediffersfromtheob- servation.
However, wealsoshrinkthesizeofwtowardszero.
Thatiswhythemethodis sometimescalledâ€œweightdecayâ€: giventhepenaltytermalone, ouroptimizationalgorithm decays the weight at each step of training.
In contrast to feature selection, weight decay offers us a mechanism for continuously adjusting the complexity of a function.
Smaller valuesofğœ†correspondtolessconstrainedw, whereaslargervaluesofğœ†constrainwmore considerably.
Whetherweincludeacorrespondingbiaspenaltyğ‘2 canvaryacrossimple- mentations, andmayvaryacrosslayersofaneuralnetwork.
Often, wedonotregularize thebiasterm.
Besides, althoughâ„“ regularizationmaynotbeequivalenttoweightdecay 2 forotheroptimizationalgorithms, theideaofregularizationthroughshrinkingthesizeof weightsstillholdstrue.
3.7.2 High-Dimensional Linear Regression Wecanillustratethebenefitsofweightdecaythroughasimplesyntheticexample.
First, wegeneratesomedataasbefore: ğ‘‘ ğ‘–=1 Inthissyntheticdataset, ourlabelisgivenbyanunderlyinglinearfunctionofourinputs, corruptedby Gaussiannoisewithzeromeanandstandarddeviation0.01.
Forillustrative purposes, we can make the effects of overfitting pronounced, by increasing the dimen- 121 Weight Decay sionality of our problem to ğ‘‘ = 200 and working with a small training set with only 20 examples.
class Data(d2l.
Data Module): def __init__(self, num_train, num_val, num_inputs, batch_size): self.
save_hyperparameters() n = num_train + num_val self.
X = torch.
randn(n, num_inputs) noise = torch.
randn(n, 1) * 0.01 w, b = torch.
ones((num_inputs, 1)) * 0.01, 0.05 self.
y = torch.
matmul(self.
X, w) + b + noise def get_dataloader(self, train): i = slice(0, self.
num_train) if train else slice(self.
num_train, None) return self.
get_tensorloader([self.
X, self.
y], train, i) 3.7.3 Implementationfrom Scratch Now, letâ€™stryimplementingweightdecayfromscratch.
Sinceminibatchstochasticgradient descent is our optimizer, we just need to add the squared â„“ penalty to the original loss 2 function.
Definingâ„“ Norm Penalty 2 Perhaps the most convenient way of implementing this penalty is to square all terms in placeandsumthem.
def l2_penalty(w): return (w ** 2).
sum() / 2 Definingthe Model Inthefinalmodel, thelinearregressionandthesquaredlosshavenotchangedsince Section 3.4, sowewilljustdefineasubclassofd2l.
Linear Regression Scratch.
Theonlychange hereisthatourlossnowincludesthepenaltyterm.
class Weight Decay Scratch(d2l.
Linear Regression Scratch): def __init__(self, num_inputs, lambd, lr, sigma=0.01): super().__init__(num_inputs, lr, sigma) self.
save_hyperparameters() def loss(self, y_hat, y): return (super().
loss(y_hat, y) + self.
lambd * l2_penalty(self.
w)) Thefollowingcodefitsourmodelonthetrainingsetwith20examplesandevaluatesiton thevalidationsetwith100examples.
122 Linear Neural Networksfor Regression data = Data(num_train=20, num_val=100, num_inputs=200, batch_size=5) trainer = d2l.
Trainer(max_epochs=10) def train_scratch(lambd): model = Weight Decay Scratch(num_inputs=200, lambd=lambd, lr=0.01) model.
board.
yscale='log' trainer.
fit(model, data) print('L2 norm of w:', float(l2_penalty(model.
w))) Trainingwithout Regularization We now run this code with lambd = 0, disabling weight decay.
Note that we overfit badly, decreasingthetrainingerrorbutnotthevalidationerrorâ€”atextbookcaseofover- fitting.
train_scratch(0) L2 norm of w: 0.009948714636266232 Using Weight Decay Below, we run with substantial weight decay.
Note that the training error increases but the validation error decreases.
This is precisely the effect we expect from regulariza- tion.
train_scratch(3) L2 norm of w: 0.0017270983662456274 3.7.4 Concise Implementation Because weight decay is ubiquitous in neural network optimization, the deep learning frameworkmakesitespeciallyconvenient, integratingweightdecayintotheoptimization 123 Weight Decay algorithmitselfforeasyuseincombinationwithanylossfunction.
Moreover, thisintegra- tion serves a computational benefit, allowing implementation tricks to add weight decay tothealgorithm, withoutanyadditionalcomputationaloverhead.
Sincetheweightdecay portionoftheupdatedependsonlyonthecurrentvalueofeachparameter, theoptimizer musttoucheachparameteronceanyway.
Below, wespecifytheweightdecayhyperparameterdirectlythroughweight_decaywhen instantiatingouroptimizer.
Bydefault, Py Torchdecaysbothweightsandbiasessimulta- neously, but we can configure the optimizer to handle different parameters according to differentpolicies.
Here, weonlysetweight_decayfortheweights(thenet.
weightpa- rameters), hencethebias(thenet.
biasparameter)willnotdecay.
class Weight Decay(d2l.
Linear Regression): def __init__(self, wd, lr): super().__init__(lr) self.
save_hyperparameters() self.
wd = wd def configure_optimizers(self): return torch.
optim.
SGD([ {'params': self.
net.
weight, 'weight_decay': self.
wd}, {'params': self.
net.
bias}], lr=self.
lr) The plot looks similar to that when we implemented weight decay from scratch.
How- ever, this version runs faster and is easier to implement, benefits that will become more pronouncedasyouaddresslargerproblemsandthisworkbecomesmoreroutine.
model = Weight Decay(wd=3, lr=0.01) model.
board.
yscale='log' trainer.
fit(model, data) print('L2 norm of w:', float(l2_penalty(model.
get_w_b()[0]))) L2 norm of w: 0.013779522851109505 Sofar, wehavetouchedupononenotionofwhatconstitutesasimplelinearfunction.
How- 84 ever, evenforsimplenonlinearfunctions, thesituationcanbemuchmorecomplex.
Tosee this, theconceptofreproducingkernel Hilbertspace(RKHS)84 allowsonetoapplytools 124 Linear Neural Networksfor Regression introduced for linear functions in a nonlinear context.
Unfortunately, RKHS-based algo- rithms tend to scale poorly to large, high-dimensional data.
In this book we will often adopt the common heuristic whereby weight decay is applied to all layers of a deep net- work.
3.7.5 Summary Regularizationisacommonmethodfordealingwithoverfitting.
Classicalregularization techniquesaddapenaltytermtothelossfunction(whentraining)toreducethecomplexity of the learned model.
One particular choice for keeping the model simple is using an â„“ 2 penalty.
Thisleadstoweightdecayintheupdatestepsoftheminibatchstochasticgradient descent algorithm.
In practice, the weight decay functionality is provided in optimizers from deep learning frameworks.
Different sets of parameters can have different update behaviorswithinthesametrainingloop.
3.7.6 Exercises 1.
Experimentwiththevalueofğœ†intheestimationprobleminthissection.
Plottraining andvalidationaccuracyasafunctionofğœ†.
Whatdoyouobserve? 2.
Useavalidationsettofindtheoptimalvalueofğœ†.
Isitreallytheoptimalvalue? Does thismatter? Ë 3.
Whatwouldtheupdateequationslooklikeifinsteadof kwk2 weused ğ‘– jğ‘¤ ğ‘– j asour penaltyofchoice(â„“ regularization)? 1 4.
We know that kwk2 = w>w.
Can you find a similar equation for matrices (see the Frobeniusnormin Section2.3.11)? 5.
Reviewtherelationshipbetweentrainingerrorandgeneralizationerror.
Inadditionto weight decay, increased training, and the use of a model of suitable complexity, what otherwaysmighthelpusdealwithoverfitting? 6.
In Bayesianstatisticsweusetheproductofpriorandlikelihoodtoarriveataposterior viağ‘ƒâ€ğ‘¤ j ğ‘¥â€ / ğ‘ƒâ€ğ‘¥ j ğ‘¤â€ğ‘ƒâ€ğ‘¤â€.
Howcanyouidentifyğ‘ƒâ€ğ‘¤â€withregularization? Discussions85.
85 4 Linear Neural Networks for Classification Nowthatyouhaveworkedthroughallofthemechanicsyouarereadytoapplytheskills youhavelearnedtobroaderkindsoftasks.
Evenaswepivottowardsclassification, most oftheplumbingremainsthesame: loadingthedata, passingitthroughthemodel, generat- ingoutput, calculatingtheloss, takinggradientswithrespecttoweights, andupdatingthe model.
However, the precise form of the targets, the parametrization of the output layer, andthechoiceoflossfunctionwilladapttosuittheclassificationsetting.
4.1 Softmax Regression In Section 3.1, we introduced linear regression, working through implementations from scratch in Section 3.4 and again using high-level APIs of a deep learning framework in Section3.5todotheheavylifting.
Regressionisthehammerwereachforwhenwewanttoanswerhowmuch? orhowmany? questions.
Ifyouwanttopredictthenumberofdollars(price)atwhichahousewillbesold, orthenumberofwinsabaseballteammighthave, orthenumberofdaysthatapatientwill remainhospitalizedbeforebeingdischarged, thenyouareprobablylookingforaregression model.
However, even within regression models, there are important distinctions.
For instance, the price of a house will never be negative and changes might often be relative toitsbaselineprice.
Assuch, itmightbemoreeffectivetoregressonthelogarithmofthe price.
Likewise, thenumberofdaysapatientspendsinhospitalisadiscretenonnegative randomvariable.
Assuch, leastmeansquaresmightnotbeanidealapproacheither.
This sortoftime-to-eventmodelingcomeswithahostofothercomplicationsthataredealtwith inaspecializedsubfieldcalledsurvivalmodeling.
The point here is not to overwhelm you but just to let you know that there is a lot more to estimation than simply minimizing squared errors.
And more broadly, there is a lot more to supervised learning than regression.
In this section, we focus on classification problemswhereweputasidehowmuch? questionsandinsteadfocusonwhichcategory? questions.
Doesthisemailbelonginthespamfolderortheinbox? Isthiscustomermorelikelytosignupornottosignupforasubscriptionservice? 125 126 Linear Neural Networksfor Classification Doesthisimagedepictadonkey, adog, acat, orarooster? Whichmovieis Astonmostlikelytowatchnext? Whichsectionofthebookareyougoingtoreadnext? Colloquially, machine learning practitioners overload the word classification to describe twosubtlydifferentproblems: (i)thosewhereweareinterestedonlyinhardassignments ofexamplestocategories(classes); and(ii)thosewherewewishtomakesoftassignments, i.
e., toassesstheprobabilitythateachcategoryapplies.
Thedistinctiontendstogetblurred, inpart, becauseoften, evenwhenweonlycareabouthardassignments, westillusemodels thatmakesoftassignments.
Evenmore, therearecaseswheremorethanonelabelmightbetrue.
Forinstance, anews articlemightsimultaneouslycoverthetopicsofentertainment, business, andspaceflight, butnotthetopicsofmedicineorsports.
Thus, categorizingitintooneoftheabovecate- goriesontheirownwouldnotbeveryuseful.
Thisproblemiscommonlyknownasmulti- 86 labelclassification86.
See Tsoumakasand Katakis(2007)foranoverviewand Huanget al.
(2015)foraneffectivealgorithmwhentaggingimages.
4.1.1 Classification Togetourfeetwet, letâ€™sstartwithasimpleimageclassificationproblem.
Here, eachinput consistsofa2 2grayscaleimage.
Wecanrepresenteachpixelvaluewithasinglescalar, givingusfourfeaturesğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥ .
Further, letâ€™sassumethateachimagebelongstoone 1 2 3 4 amongthecategoriesâ€œcatâ€,â€œchickenâ€, andâ€œdogâ€.
Next, wehavetochoosehowtorepresentthelabels.
Wehavetwoobviouschoices.
Per- hapsthemostnaturalimpulsewouldbetochooseğ‘¦ 2 f1,2,3g, wheretheintegersrepresent fdog, cat, chickengrespectively.
Thisisagreatwayofstoringsuchinformationonacom- puter.
If the categories had some natural ordering among them, say if we were trying to 87 predict fbaby, toddler, adolescent, youngadult, adult, geriatricg, then it might even make sense to cast this as an ordinal regression87 problem and keep the labels in this format.
See Moon et al.
(2010) for an overview of different types of ranking loss functions and Beuteletal.
(2014)fora Bayesianapproachthataddressesresponseswithmorethanone mode.
Ingeneral, classificationproblemsdonotcomewithnaturalorderingsamongtheclasses.
Fortunately, statisticianslongagoinventedasimplewaytorepresentcategoricaldata: the one-hot encoding.
A one-hot encoding is a vector with as many components as we have categories.
Thecomponentcorrespondingtoaparticularinstanceâ€™scategoryissetto1and allothercomponentsaresetto0.
Inourcase, alabelğ‘¦wouldbeathree-dimensionalvector, withâ€1,0,0â€correspondingtoâ€œcatâ€,â€0,1,0â€toâ€œchickenâ€, andâ€0,0,1â€toâ€œdogâ€: ğ‘¦ 2 fâ€1,0,0â€,â€0,1,0â€,â€0,0,1â€g.
(4.1.1) 127 Softmax Regression Linear Model In order to estimate the conditional probabilities associated with all the possible classes, weneedamodelwithmultipleoutputs, oneperclass.
Toaddressclassificationwithlin- earmodels, wewillneedasmanyaffinefunctionsaswehaveoutputs.
Strictlyspeaking, we only need one fewer, since the final category has to be the difference between 1 and thesumoftheothercategories, butforreasonsofsymmetryweuseaslightlyredundant parametrization.
Each output corresponds to its own affine function.
In our case, since we have 4 features and 3 possible output categories, we need 12 scalars to represent the weights(ğ‘¤withsubscripts), and3scalarstorepresentthebiases(ğ‘withsubscripts).
This yields: ğ‘œ =ğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘ , 1 1 11 2 12 3 13 4 14 1 ğ‘œ =ğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘ , (4.1.2) 2 1 21 2 22 3 23 4 24 2 ğ‘œ =ğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘¥ ğ‘¤ â€šğ‘ .
3 1 31 2 32 3 33 4 34 3 Thecorrespondingneuralnetworkdiagramisshownin.1.1.
Justasinlinearregres- sion, weuseasingle-layerneuralnetwork.
Andsincethecalculationofeachoutput,ğ‘œ ,ğ‘œ , 1 2 andğ‘œ , dependsoneveryinput,ğ‘¥ ,ğ‘¥ ,ğ‘¥ , andğ‘¥ , theoutputlayercanalsobedescribedas 3 1 2 3 4 afullyconnectedlayer.
t .1.1 Softmaxregressionisasingle-layerneuralnetwork.
Foramoreconcisenotationweusevectorsandmatrices: o=Wxâ€šbismuchbettersuited formathematicsandcode.
Notethatwehavegatheredallofourweightsintoa3 4matrix andallbiasesb2R3inavector.
The Softmax Assuming a suitable loss function, we could try, directly, to minimize the difference be- tweenoandthelabelsy.
Whileitturnsoutthattreatingclassificationasavector-valued regressionproblemworkssurprisinglywell, itisnonethelessunsatisfactoryinthefollowing ways: Thereisnoguaranteethattheoutputsğ‘œ ğ‘– sumupto1inthewayweexpectprobabilities tobehave.
Thereisnoguaranteethattheoutputsğ‘œ ğ‘– areevennonnegative, eveniftheiroutputssum upto1, orthattheydonotexceed1.
Bothaspectsrendertheestimationproblemdifficulttosolveandthesolutionverybrittle tooutliers.
Forinstance, ifweassumethatthereisapositivelineardependencybetween thenumberofbedroomsandthelikelihoodthatsomeonewillbuyahouse, theprobability 128 Linear Neural Networksfor Classification might exceed 1 when it comes to buying a mansion! As such, we need a mechanism to â€œsquishâ€theoutputs.
Therearemanywayswemightaccomplishthisgoal.
Forinstance, wecouldassumethat theoutputsoarecorruptedversionsofy, wherethecorruptionoccursbymeansofadding noiseğ drawnfromanormaldistribution.
Inotherwords, y=oâ€šğ, whereğœ– ğ‘– Nâ€0,ğœ2â€.
Thisistheso-calledprobitmodel88, firstintroducedby Fechner(1860).
Whileappealing, 88 itdoesnotworkquiteaswellnorleadtoaparticularlyniceoptimizationproblem, when comparedtothesoftmax.
Anotherwaytoaccomplishthisgoal(andtoensurenonnegativity)istouseanexponential function ğ‘ƒâ€ğ‘¦ = ğ‘–â€ / expğ‘œ ğ‘–.
Thisdoesindeedsatisfytherequirementthattheconditional class probability increases with increasing ğ‘œ ğ‘–, it is monotonic, and all probabilities are nonnegative.
Wecanthentransformthesevaluessothattheyaddupto1bydividingeach bytheirsum.
Thisprocessiscallednormalization.
Puttingthesetwopiecestogethergives usthesoftmaxfunction: yË† =softmaxâ€oâ€ where ğ‘¦Ë†ğ‘– = Ë e ğ‘— x e p x â€ p ğ‘œ â€ ğ‘– ğ‘œ â€ ğ‘— â€ .
(4.1.3) NotethatthelargestcoordinateofocorrespondstothemostlikelyclassaccordingtoyË†.
Moreover, becausethesoftmaxoperationpreservestheorderingamongitsarguments, we donotneedtocomputethesoftmaxtodeterminewhichclasshasbeenassignedthehighest probability.
Thus, argmaxğ‘¦Ë†ğ‘— =argmaxğ‘œ ğ‘— .
(4.1.4) ğ‘— ğ‘— Theideaofasoftmaxdatesbackto Gibbs(1902), whoadaptedideasfromphysics.
Dating even further back, Boltzmann, the father of modern statistical physics, used this trick to modeladistributionoverenergystatesingasmolecules.
Inparticular, hediscoveredthat theprevalenceofastateofenergyinathermodynamicensemble, suchasthemoleculesina gas, isproportionaltoexpâ€ ğ¸ ğ‘˜ğ‘‡â€.
Here,ğ¸ istheenergyofastate,ğ‘‡ isthetemperature, and ğ‘˜ is the Boltzmann constant.
When statisticians talk about increasing or decreasing theâ€œtemperatureâ€ofastatisticalsystem, theyrefertochangingğ‘‡ inordertofavorlower or higher energy states.
Following Gibbsâ€™ idea, energy equates to error.
Energy-based models (Ranzato et al., 2007) use this point of view when describing problems in deep learning.
Vectorization Toimprovecomputationalefficiency, wevectorizecalculationsinminibatchesofdata.
As- sumethatwearegivenaminibatch X2Rğ‘› ğ‘‘ ofğ‘›exampleswithdimensionality(number ofinputs)ğ‘‘.
Moreover, assumethatwehaveğ‘ categoriesintheoutput.
Thentheweights satisfy W 2Rğ‘‘ ğ‘ andthebiassatisfiesb2R1 ğ‘ .
O=XWâ€šb, (4.1.5) YË† =softmaxâ€Oâ€.
129 Softmax Regression This accelerates the dominant operation into a matrixâ€“matrix product XW.
Moreover, sinceeachrowin Xrepresentsadataexample, thesoftmaxoperationitselfcanbecomputed rowwise: foreachrowof O, exponentiateallentriesandthennormalizethembythesum.
Note, though, thatcaremustbetakentoavoidexponentiatingandtakinglogarithmsoflarge numbers, sincethiscancausenumericaloverfloworunderflow.
Deeplearningframeworks takecareofthisautomatically.
4.1.2 Loss Function NowthatwehaveamappingfromfeaturesxtoprobabilitiesyË†, weneedawaytooptimize the accuracy of this mapping.
We will rely on maximum likelihood estimation, the very samemethodthatweencounteredwhenprovidingaprobabilisticjustificationforthemean squarederrorlossin Section3.1.3.
Log-Likelihood ThesoftmaxfunctiongivesusavectoryË†, whichwecaninterpretasthe(estimated)con- ditionalprobabilitiesofeachclass, givenanyinputx, suchas ğ‘¦Ë† =ğ‘ƒâ€ğ‘¦ = cat j xâ€.
Inthe 1 followingweassumethatforadatasetwithfeatures Xthelabels Yarerepresentedusing a one-hot encoding label vector.
We can compare the estimates with reality by checking howprobabletheactualclassesareaccordingtoourmodel, giventhefeatures: ğ‘› ğ‘ƒâ€Y j Xâ€ = ğ‘ƒâ€y â€ğ‘–â€ j x â€ğ‘–â€â€.
(4.1.6) ğ‘–=1 Weareallowedtousethefactorizationsinceweassumethateachlabelisdrawnindepen- dentlyfromitsrespectivedistributionğ‘ƒâ€y j xâ€ğ‘–â€â€.
Sincemaximizingtheproductofterms isawkward, wetakethenegativelogarithmtoobtaintheequivalentproblemofminimizing thenegativelog-likelihood: ğ‘› ğ‘› logğ‘ƒâ€Y j Xâ€ = logğ‘ƒâ€y â€ğ‘–â€ j x â€ğ‘–â€â€ = ğ‘™â€y â€ğ‘–â€, yË† â€ğ‘–â€â€, (4.1.7) ğ‘–=1 ğ‘–=1 where for any pair of label y and model prediction yË† over ğ‘ classes, the loss function ğ‘™ is ğ‘ ğ‘™â€y, yË†â€ = ğ‘¦ ğ‘—logğ‘¦Ë†ğ‘— .
(4.1.8) ğ‘—=1 Forreasonsexplainedlateron, thelossfunctionin(4.1.8)iscommonlycalledthecross- entropyloss.
Sinceyisaone-hotvectoroflengthğ‘, thesumoverallitscoordinates ğ‘— van- ishesforallbutoneterm.
Notethatthelossğ‘™â€y, yË†â€isboundedfrombelowby0wheneveryË† isaprobabilityvector: nosingleentryislargerthan1, hencetheirnegativelogarithmcan- notbelowerthan0;ğ‘™â€y, yË†â€ =0onlyifwepredicttheactuallabelwithcertainty.
Thiscan neverhappenforanyfinitesettingoftheweightsbecausetakingasoftmaxoutputtowards 1 requires taking the corresponding input ğ‘œ ğ‘– to infinity (or all other outputs ğ‘œ ğ‘— for ğ‘— â‰  ğ‘– tonegativeinfinity).
Evenifourmodelcouldassignanoutputprobabilityof0, anyerror madewhenassigningsuchhighconfidencewouldincurinfiniteloss( log0=1).
130 Linear Neural Networksfor Classification Softmaxand Cross-Entropy Loss Sincethesoftmaxfunctionandthecorrespondingcross-entropylossaresocommon, itis worthunderstandingabitbetterhowtheyarecomputed.
Plugging(4.1.3)intothedefini- tionofthelossin(4.1.8)andusingthedefinitionofthesoftmaxweobtain ğ‘ expâ€ğ‘œ ğ‘— â€ ğ‘™â€y, yË†â€ = ğ‘—=1 ğ‘¦ ğ‘—logË ğ‘ ğ‘˜=1 expâ€ğ‘œ ğ‘˜ â€ ğ‘ ğ‘ ğ‘ = ğ‘¦ ğ‘—log expâ€ğ‘œ ğ‘˜ â€ ğ‘¦ ğ‘— ğ‘œ ğ‘— (4.1.9) ğ‘—=1 ğ‘˜=1 ğ‘—=1 ğ‘ ğ‘ =log expâ€ğ‘œ ğ‘˜ â€ ğ‘¦ ğ‘— ğ‘œ ğ‘— .
ğ‘˜=1 ğ‘—=1 Tounderstandabitbetterwhatisgoingon, considerthederivativewithrespecttoanylogit ğ‘œ ğ‘—.
Weget expâ€ğ‘œ ğ‘— â€ ğœ• ğ‘œğ‘— ğ‘™â€y, yË†â€ = Ë ğ‘ ğ‘˜=1 expâ€ğ‘œ ğ‘˜ â€ ğ‘¦ ğ‘— =softmaxâ€oâ€ ğ‘— ğ‘¦ ğ‘— .
(4.1.10) In other words, the derivative is the difference between the probability assigned by our model, asexpressedbythesoftmaxoperation, andwhatactuallyhappened, asexpressed byelementsintheone-hotlabelvector.
Inthissense, itisverysimilartowhatwesawin regression, wherethegradientwasthedifferencebetweentheobservation ğ‘¦ andestimate ğ‘¦Ë†.
This is not a coincidence.
In any exponential family model, the gradients of the log- likelihoodaregivenbypreciselythisterm.
Thisfactmakescomputinggradientseasyin practice.
Nowconsiderthecasewhereweobservenotjustasingleoutcomebutanentiredistribution overoutcomes.
Wecanusethesamerepresentationasbeforeforthelabely.
Theonlydif- ferenceisthatratherthanavectorcontainingonlybinaryentries, sayâ€0,0,1â€, wenowhave agenericprobabilityvector, sayâ€0.1,0.2,0.7â€.
Themaththatweusedpreviouslytodefine thelossğ‘™ in(4.1.8)stillworkswell, justthattheinterpretationisslightlymoregeneral.
It istheexpectedvalueofthelossforadistributionoverlabels.
Thislossiscalledthecross- entropylossanditisoneofthemostcommonlyusedlossesforclassificationproblems.
We candemystifythenamebyintroducingjustthebasicsofinformationtheory.
Inanutshell, itmeasuresthenumberofbitsneededtoencodewhatwesee, y, relativetowhatwepredict thatshouldhappen, yË†.
Weprovideaverybasicexplanationinthefollowing.
Forfurther detailsoninformationtheorysee Coverand Thomas(1999)or Mac Kay(2003).
4.1.3 Information Theory Basics Manydeeplearningpapersuseintuitionandtermsfrominformationtheory.
Tomakesense of them, we need some common language.
This is a survival guide.
Information theory dealswiththeproblemofencoding, decoding, transmitting, andmanipulatinginformation (alsoknownasdata).
131 Softmax Regression Entropy Thecentralideaininformationtheoryistoquantifytheamountofinformationcontained indata.
Thisplacesalimitonourabilitytocompressdata.
Foradistributionğ‘ƒitsentropy, ğ»Â»ğ‘ƒâ€¦, isdefinedas: ğ»Â»ğ‘ƒâ€¦ = ğ‘ƒâ€ğ‘—â€logğ‘ƒâ€ğ‘—â€.
(4.1.11) ğ‘— Oneofthefundamentaltheoremsofinformationtheorystatesthatinordertoencodedata drawnrandomlyfromthedistributionğ‘ƒ, weneedatleastğ»Â»ğ‘ƒâ€¦ â€œnatsâ€toencodeit(Shan- non,1948).
Ifyouwonderwhataâ€œnatâ€is, itistheequivalentofbitbutwhenusingacode withbaseğ‘’ratherthanonewithbase2.
Thus, onenatis 1 1.44bit.
logâ€2â€ Surprisal Youmightbewonderingwhatcompressionhastodowithprediction.
Imaginethatwehave a stream of data that we want to compress.
If it is always easy for us to predict the next token, thenthisdataiseasytocompress.
Taketheextremeexamplewhereeverytokenin thestreamalwaystakesthesamevalue.
Thatisaveryboringdatastream! Andnotonly itisboring, butitisalsoeasytopredict.
Becausethetokensarealwaysthesame, wedo nothavetotransmitanyinformationtocommunicatethecontentsofthestream.
Easyto predict, easytocompress.
Howeverifwecannotperfectlypredicteveryevent, thenwemightsometimesbesurprised.
Oursurpriseisgreaterwhenaneventisassignedlowerprobability.
Claude Shannonsettled onlog 1 = logğ‘ƒâ€ğ‘—â€toquantifyoneâ€™ssurprisalatobservinganeventğ‘—havingassigned ğ‘ƒâ€ğ‘—â€ it a (subjective) probability ğ‘ƒâ€ğ‘—â€.
The entropy defined in (4.1.11) is then the expected surprisalwhenoneassignedthecorrectprobabilitiesthattrulymatchthedata-generating process.
Cross-Entropy Revisited Soifentropyisthelevelofsurpriseexperiencedbysomeonewhoknowsthetrueproba- bility, thenyoumightbewondering, whatiscross-entropy? Thecross-entropyfrom ğ‘ƒ to ğ‘„, denotedğ»â€ğ‘ƒ,ğ‘„â€, istheexpectedsurprisalofanobserverwithsubjectiveprobabilities ğ‘„uponseeingdatathatwasactuallygeneratedaccordingtoprobabilitiesğ‘ƒ.
Thisisgiven Ë by ğ»â€ğ‘ƒ,ğ‘„â€ d = ef ğ‘— ğ‘ƒâ€ğ‘—â€logğ‘„â€ğ‘—â€.
The lowest possible cross-entropy is achieved when ğ‘ƒ =ğ‘„.
Inthiscase, thecross-entropyfromğ‘ƒtoğ‘„isğ»â€ğ‘ƒ,ğ‘ƒâ€ = ğ»â€ğ‘ƒâ€.
Inshort, wecanthinkofthecross-entropyclassificationobjectiveintwoways: (i)asmax- imizingthelikelihoodoftheobserveddata; and(ii)asminimizingoursurprisal(andthus thenumberofbits)requiredtocommunicatethelabels.
4.1.4 Summaryand Discussion Inthissection, weencounteredthefirstnontriviallossfunction, allowingustooptimizeover discreteoutputspaces.
Keyinitsdesignwasthatwetookaprobabilisticapproach, treating 132 Linear Neural Networksfor Classification discretecategoriesasinstancesofdrawsfromaprobabilitydistribution.
Asasideeffect, weencounteredthesoftmax, aconvenientactivationfunctionthattransformsoutputsofan ordinaryneuralnetworklayerintovaliddiscreteprobabilitydistributions.
Wesawthatthe derivative of the cross-entropy loss when combined with softmax behaves very similarly to the derivative of squared error; namely by taking the difference between the expected behavioranditsprediction.
And, whilewewereonlyabletoscratchtheverysurfaceofit, weencounteredexcitingconnectionstostatisticalphysicsandinformationtheory.
Whilethisisenoughtogetyouonyourway, andhopefullyenoughtowhetyourappetite, we hardly dived deep here.
Among other things, we skipped over computational con- siderations.
Specifically, for any fully connected layer with ğ‘‘ inputs and ğ‘ outputs, the parametrizationandcomputationalcostis Oâ€ğ‘‘ğ‘â€, whichcanbeprohibitivelyhighinprac- tice.
Fortunately, thiscostoftransformingğ‘‘ inputsintoğ‘outputscanbereducedthrough approximation and compression.
For instance Deep Fried Convnets (Yang et al., 2015) uses a combination of permutations, Fourier transforms, and scaling to reduce the cost fromquadratictolog-linear.
Similartechniquesworkformoreadvancedstructuralmatrix approximations (Sindhwani et al., 2015).
Lastly, we can use quaternion-like decomposi- tions to reduce the cost to Oâ€ğ‘‘ğ‘â€, again if we are willing to trade off a small amount of ğ‘› accuracyforcomputationalandstoragecost(Zhangetal.,2021)basedonacompression factor ğ‘›.
This is an active area of research.
What makes it challenging is that we do not necessarily strive for the most compact representation or the smallest number of floating pointoperationsbutratherforthesolutionthatcanbeexecutedmostefficientlyonmodern GPUs.
4.1.5 Exercises 1.
Wecanexploretheconnectionbetweenexponentialfamiliesandsoftmaxinsomemore depth.
1.
Computethesecondderivativeofthecross-entropylossğ‘™â€y, yË†â€forsoftmax.
2.
Computethevarianceofthedistributiongivenbysoftmaxâ€oâ€andshowthatitmatches thesecondderivativecomputedabove.
2.
Assumethatwehavethreeclasseswhichoccurwithequalprobability, i.
e., theproba- bilityvectorisâ€1,1,1â€.
3 3 3 1.
Whatistheproblemifwetrytodesignabinarycodeforit? 2.
Canyoudesignabettercode? Hint: whathappensifwetrytoencodetwoindepen- dentobservations? Whatifweencodeğ‘›observationsjointly? 3.
When encoding signals transmitted over a physical wire, engineers do not always use 89 binarycodes.
Forinstance, PAM-389 usesthreesignallevelsf 1,0,1gasopposedto two levels f0,1g.
How many ternary units do you need to transmit an integer in the rangef0,...,7g? Whymightthisbeabetterideaintermsofelectronics? 90 4.
The Bradleyâ€“Terrymodel90 usesalogisticmodeltocapturepreferences.
Forauserto 133 Softmax Regression choosebetweenapplesandorangesoneassumesscoresğ‘œ andğ‘œ .
Ourrequire- apple orange mentsarethatlargerscoresshouldleadtoahigherlikelihoodinchoosingtheassociated itemandthattheitemwiththelargestscoreisthemostlikelyonetobechosen(Bradley and Terry,1952).
1.
Provethatsoftmaxsatisfiesthisrequirement.
2.
What happens if you want to allow for a default option of choosing neither apples nororanges? Hint: nowtheuserhasthreechoices.
5.
Softmaxgetsitsnamefromthefollowingmapping: Real Soft Maxâ€ğ‘,ğ‘â€ =logâ€expâ€ğ‘â€â€š expâ€ğ‘â€â€.
1.
Provethat Real Soft Maxâ€ğ‘,ğ‘â€ >maxâ€ğ‘,ğ‘â€.
2.
Howsmallcanyoumakethedifferencebetweenbothfunctions? Hint: withoutloss ofgeneralityyoucansetğ‘ =0andğ‘ ğ‘.
3.
Provethatthisholdsforğœ† 1Real Soft Maxâ€ğœ†ğ‘,ğœ†ğ‘â€, providedthatğœ† >0.
4.
Showthatforğœ† !1wehaveğœ† 1Real Soft Maxâ€ğœ†ğ‘,ğœ†ğ‘â€ ! maxâ€ğ‘,ğ‘â€.
5.
Constructananalogoussoftminfunction.
6.
Extendthistomorethantwonumbers.
Ë 6.
The function ğ‘”â€xâ€ d = ef log ğ‘–expğ‘¥ ğ‘– is sometimes also referred to as the log-partition 91 function91.
1.
Provethatthefunctionisconvex.
Hint: todoso, usethefactthatthefirstderivative amounts to the probabilities from the softmax function and show that the second derivativeisthevariance.
2.
Showthatğ‘”istranslationinvariant, i.
e.,ğ‘”â€xâ€šğ‘â€ =ğ‘”â€xâ€.
3.
Whathappensifsomeofthecoordinatesğ‘¥ ğ‘– areverylarge? Whathappensiftheyâ€™re allverysmall? 4.
Showthatifwechooseğ‘ =maxğ‘– ğ‘¥ ğ‘– weendupwithanumericallystableimplemen- tation.
7.
Assumethatwehavesomeprobabilitydistributionğ‘ƒ.
Supposewepickanotherdistri- butionğ‘„withğ‘„â€ğ‘–â€ / ğ‘ƒâ€ğ‘–â€ğ›¼ forğ›¼ >0.
1.
Whichchoiceofğ›¼ correspondstodoublingthetemperature? Whichchoicecorre- spondstohalvingit? 2.
Whathappensifweletthetemperatureapproach0? 92 3.
Whathappensifweletthetemperatureapproach1? Discussions92.
134 Linear Neural Networksfor Classification 4.2 The Image Classification Dataset One widely used dataset for image classification is the MNIST dataset93 (Le Cun et al., 93 1998)ofhandwrittendigits.
Atthetimeofitsreleaseinthe1990sitposedaformidable challenge to most machine learning algorithms, consisting of 60,000 images of 28 28 pixelsresolution(plusatestdatasetof10,000images).
Toputthingsintoperspective, back in1995, a Sun SPARCStation5withawhopping64MBof RAMandablistering5MFLOPs wasconsideredstateoftheartequipmentformachinelearningat AT&TBell Laboratories.
Achieving high accuracy on digit recognition was a key component in automating letter sortingforthe USPSinthe1990s.
Deepnetworkssuchas Le Net-5(Le Cunetal.,1995), support vector machines with invariances (SchÃ¶lkopf et al., 1996), and tangent distance classifiers(Simardetal.,1998)allcouldreacherrorratesbelow1%.
Foroveradecade, MNISTservedasthepointofreferenceforcomparingmachinelearn- ing algorithms.
While it had a good run as a benchmark dataset, even simple models by todayâ€™sstandardsachieveclassificationaccuracyover95%, makingitunsuitablefordistin- guishingbetweenstrongmodelsandweakerones.
Evenmore, thedatasetallowsforvery high levels of accuracy, not typically seen in many classification problems.
This skewed algorithmic development towards specific families of algorithms that can take advantage ofcleandatasets, suchasactivesetmethodsandboundary-seekingactivesetalgorithms.
Today, MNISTservesasmoreofasanitycheckthanasabenchmark.
Image Net(Denget al.,2009)posesamuchmorerelevantchallenge.
Unfortunately, Image Netistoolargefor many of the examples and illustrations in this book, as it would take too long to train to maketheexamplesinteractive.
Asasubstitutewewillfocusourdiscussioninthecoming sectionsonthequalitativelysimilar, butmuchsmaller Fashion-MNISTdataset(Xiaoetal., 2017)whichwasreleasedin2017.
Itcontainsimagesof10categoriesofclothingat28 28 pixelsresolution.
%matplotlib inline import time import torch import torchvision from torchvision import transforms from d2l import torch as d2l d2l.
use_svg_display() 4.2.1 Loadingthe Dataset Sincethe Fashion-MNISTdatasetissouseful, allmajorframeworksprovidepreprocessed versionsofit.
Wecandownloadandreaditintomemoryusingbuilt-inframeworkutili- ties.
135 The Image Classification Dataset class Fashion MNIST(d2l.
Data Module): #@save """The Fashion-MNIST dataset.""" def __init__(self, batch_size=64, resize=(28, 28)): super().__init__() self.
save_hyperparameters() trans = transforms.
Compose([transforms.
Resize(resize), transforms.
To Tensor()]) self.
train = torchvision.
datasets.
Fashion MNIST( root=self.
root, train=True, transform=trans, download=True) self.
val = torchvision.
datasets.
Fashion MNIST( root=self.
root, train=False, transform=trans, download=True) Fashion-MNISTconsistsofimagesfrom10categories, eachrepresentedby6000images inthetrainingdatasetandby1000inthetestdataset.
Atestdatasetisusedforevaluating modelperformance(itmustnotbeusedfortraining).
Consequentlythetrainingsetandthe testsetcontain60,000and10,000images, respectively.
data = Fashion MNIST(resize=(32, 32)) len(data.
train), len(data.
val) (60000, 10000) Theimagesaregrayscaleandupscaledto32 32pixelsinresolutionabove.
Thisissimilar totheoriginal MNISTdatasetwhichconsistedof(binary)blackandwhiteimages.
Note, though, thatmostmodernimagedatahasthreechannels(red, green, blue)andthathyper- spectralimagescanhaveinexcessof100channels(the Hy Mapsensorhas126channels).
By convention we store an image as a ğ‘ â„ ğ‘¤ tensor, where ğ‘ is the number of color channels,â„istheheightandğ‘¤isthewidth.
data.
train[0][0].
shape torch.
Size([1, 32, 32]) Thecategoriesof Fashion-MNISThavehuman-understandablenames.
Thefollowingcon- veniencemethodconvertsbetweennumericlabelsandtheirnames.
@d2l.
add_to_class(Fashion MNIST) #@save def text_labels(self, indices): """Return text labels.""" labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'] return [labels[int(i)] for i in indices] 4.2.2 Readinga Minibatch Tomakeourlifeeasierwhenreadingfromthetrainingandtestsets, weusethebuilt-indata iteratorratherthancreatingonefromscratch.
Recallthatateachiteration, adataiterator 136 Linear Neural Networksfor Classification readsaminibatchofdatawithsizebatch_size.
Wealsorandomlyshuffletheexamples forthetrainingdataiterator.
@d2l.
add_to_class(Fashion MNIST) #@save def get_dataloader(self, train): data = self.
train if train else self.
val return torch.
utils.
data.
Data Loader(data, self.
batch_size, shuffle=train, num_workers=self.
num_workers) Toseehowthisworks, letâ€™sloadaminibatchofimagesbyinvokingthetrain_dataloader method.
Itcontains64images.
X, y = next(iter(data.
train_dataloader())) print(X.
shape, X.
dtype, y.
shape, y.
dtype) torch.
Size([64, 1, 32, 32]) torch.
float32 torch.
Size([64]) torch.
int64 Letâ€™slookatthetimeittakestoreadtheimages.
Eventhoughitisabuilt-inloader, itisnot blazinglyfast.
Nonetheless, thisissufficientsinceprocessingimageswithadeepnetwork takes quite a bit longer.
Hence it is good enough that training a network will not be I/O constrained.
tic = time.
time() for X, y in data.
train_dataloader(): continue f'{time.
time() - tic:.2f} sec' '4.69 sec' 4.2.3 Visualization Wewilloftenbeusingthe Fashion-MNISTdataset.
Aconveniencefunctionshow_images can be used to visualize the images and the associated labels.
Skipping implementation details, we just show the interface below: we only need to know how to invoke d2l.
show_imagesratherthanhowitworksforsuchutilityfunctions.
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save """Plot a list of images.""" raise Not Implemented Error Letâ€™sputittogooduse.
Ingeneral, itisagoodideatovisualizeandinspectdatathatyouare trainingon.
Humansareverygoodatspottingodditiesandbecauseofthat, visualization servesasanadditionalsafeguardagainstmistakesanderrorsinthedesignofexperiments.
Herearetheimagesandtheircorrespondinglabels(intext)forthefirstfewexamplesinthe trainingdataset.
137 The Image Classification Dataset @d2l.
add_to_class(Fashion MNIST) #@save def visualize(self, batch, nrows=1, ncols=8, labels=[]): X, y = batch if not labels: labels = self.
text_labels(y) d2l.
show_images(X.
squeeze(1), nrows, ncols, titles=labels) batch = next(iter(data.
val_dataloader())) data.
visualize(batch) Wearenowreadytoworkwiththe Fashion-MNISTdatasetinthesectionsthatfollow.
4.2.4 Summary Wenowhaveaslightlymorerealisticdatasettouseforclassification.
Fashion-MNISTisan apparelclassificationdatasetconsistingofimagesrepresenting10categories.
Wewilluse thisdatasetinsubsequentsectionsandchapterstoevaluatevariousnetworkdesigns, from asimplelinearmodelto advancedresidualnetworks.
Aswecommonlydowithimages, wereadthemasatensorofshape(batchsize, numberofchannels, height, width).
Fornow, weonlyhaveonechannelastheimagesaregrayscale(thevisualizationaboveusesafalse colorpaletteforimprovedvisibility).
Lastly, dataiteratorsareakeycomponentforefficientperformance.
Forinstance, wemight use GPUs for efficient image decompression, video transcoding, or other preprocessing.
Wheneverpossible, youshouldrelyonwell-implementeddataiteratorsthatexploithigh- performancecomputingtoavoidslowingdownyourtrainingloop.
4.2.5 Exercises 1.
Doesreducingthebatch_size(forinstance, to1)affectthereadingperformance? 2.
The data iterator performance is important.
Do you think the current implementation isfastenough? Explorevariousoptionstoimproveit.
Useasystemprofilertofindout wherethebottlenecksare.
94 3.
Checkouttheframeworkâ€™sonline APIdocumentation.
Whichotherdatasetsareavail- able? Discussions94.
138 Linear Neural Networksfor Classification 4.3 The Base Classification Model Youmayhavenoticedthattheimplementationsfromscratchandtheconciseimplementa- tionusingframeworkfunctionalitywerequitesimilarinthecaseofregression.
Thesame istrueforclassification.
Sincemanymodelsinthisbookdealwithclassification, itisworth addingfunctionalitiestosupportthissettingspecifically.
Thissectionprovidesabaseclass forclassificationmodelstosimplifyfuturecode.
import torch from d2l import torch as d2l 4.3.1 The Classifier Class Wedefinethe Classifierclassbelow.
Inthevalidation_stepwereportboththeloss valueandtheclassificationaccuracyonavalidationbatch.
Wedrawanupdateforevery num_val_batches batches.
This has the benefit of generating the averaged loss and ac- curacyonthewholevalidationdata.
Theseaveragenumbersarenotexactlycorrectifthe finalbatchcontainsfewerexamples, butweignorethisminordifferencetokeepthecode simple.
class Classifier(d2l.
Module): #@save """The base class of classification models.""" def validation_step(self, batch): Y_hat = self(*batch[:-1]) self.
plot('loss', self.
loss(Y_hat, batch[-1]), train=False) self.
plot('acc', self.
accuracy(Y_hat, batch[-1]), train=False) Bydefaultweuseastochasticgradientdescentoptimizer, operatingonminibatches, just aswedidinthecontextoflinearregression.
@d2l.
add_to_class(d2l.
Module) #@save def configure_optimizers(self): return torch.
optim.
SGD(self.
parameters(), lr=self.
lr) 4.3.2 Accuracy Giventhepredictedprobabilitydistributiony_hat, wetypicallychoosetheclasswiththe highest predicted probability whenever we must output a hard prediction.
Indeed, many applicationsrequirethatwemakeachoice.
Forinstance, Gmailmustcategorizeanemail intoâ€œPrimaryâ€,â€œSocialâ€,â€œUpdatesâ€,â€œForumsâ€, orâ€œSpamâ€.
Itmightestimateprobabilities internally, butattheendofthedayithastochooseoneamongtheclasses.
Whenpredictionsareconsistentwiththelabelclassy, theyarecorrect.
Theclassification accuracy is the fraction of all predictions that are correct.
Although it can be difficult to optimizeaccuracydirectly(itisnotdifferentiable), itisoftentheperformancemeasurethat 139 The Base Classification Model wecareaboutthemost.
Itisoftentherelevantquantityinbenchmarks.
Assuch, wewill nearlyalwaysreportitwhentrainingclassifiers.
Accuracyiscomputedasfollows.
First, ify_hatisamatrix, weassumethattheseconddi- mensionstorespredictionscoresforeachclass.
Weuseargmaxtoobtainthepredictedclass bytheindexforthelargestentryineachrow.
Thenwecomparethepredictedclasswith thegroundtruthyelementwise.
Sincetheequalityoperator==issensitivetodatatypes, weconverty_hatâ€™sdatatypetomatchthatof y.
Theresultisatensorcontainingentries of0(false)and1(true).
Takingthesumyieldsthenumberofcorrectpredictions.
@d2l.
add_to_class(Classifier) #@save def accuracy(self, Y_hat, Y, averaged=True): """Compute the number of correct predictions.""" Y_hat = Y_hat.
reshape((-1, Y_hat.
shape[-1])) preds = Y_hat.
argmax(axis=1).
type(Y.
dtype) compare = (preds == Y.
reshape(-1)).
type(torch.
float32) return compare.
mean() if averaged else compare 4.3.3 Summary Classificationisasufficientlycommonproblemthatitwarrantsitsownconveniencefunc- tions.
Of central importance in classification is the accuracy of the classifier.
Note that whileweoftencareprimarilyaboutaccuracy, wetrainclassifierstooptimizeavarietyof other objectives for statistical and computational reasons.
However, regardless of which lossfunctionwasminimizedduringtraining, itisusefultohaveaconveniencemethodfor assessingtheaccuracyofourclassifierempirically.
4.3.4 Exercises 1.
Denoteby ğ¿ thevalidationloss, andlet ğ¿q beitsquickanddirtyestimatecomputed v v bythelossfunctionaveraginginthissection.
Lastly, denotebyğ‘™b thelossonthelast v minibatch.
Expressğ¿ intermsofğ¿q,ğ‘™b, andthesampleandminibatchsizes.
v v v 2.
Show that the quick and dirty estimate ğ¿q is unbiased.
That is, show that ğ¸Â»ğ¿ â€¦ = v v 95 ğ¸Â»ğ¿qâ€¦.
Whywouldyoustillwanttouseğ¿ instead? v v 3.
Given a multiclass classification loss, denoting by ğ‘™â€ğ‘¦,ğ‘¦0â€ the penalty of estimating ğ‘¦0 when we see ğ‘¦ and given a probabilty ğ‘â€ğ‘¦ j ğ‘¥â€, formulate the rule for an optimal selectionofğ‘¦0 .
Hint: expresstheexpectedloss, usingğ‘™ and ğ‘â€ğ‘¦ j ğ‘¥â€.
Discussions95.
140 Linear Neural Networksfor Classification 4.4 Softmax Regression Implementation from Scratch Becausesoftmaxregressionissofundamental, webelievethatyououghttoknowhowto implementityourself.
Here, welimitourselvestodefiningthesoftmax-specificaspectsof themodelandreusetheothercomponentsfromourlinearregressionsection, includingthe trainingloop.
import torch from d2l import torch as d2l 4.4.1 The Softmax Letâ€™sbeginwiththemostimportantpart: themappingfromscalarstoprobabilities.
Fora refresher, recalltheoperationofthesumoperatoralongspecificdimensionsinatensor, as (bydefault)oronlyoverelementsinthesameaxis.
Theaxisvariableletsuscomputerow andcolumnsums: X.
sum(0, keepdims=True), X.
sum(1, keepdims=True) (tensor([[5., 7., 9.]]), tensor([[ 6.], [15.]])) Computing the softmax requires three steps: (i) exponentiation of each term; (ii) a sum over each row to compute the normalization constant for each example; (iii) division of eachrowbyitsnormalizationconstant, ensuringthattheresultsumsto1: expâ€Xğ‘–ğ‘— â€ softmaxâ€Xâ€ ğ‘–ğ‘— = Ë ğ‘˜expâ€Xğ‘–ğ‘˜ â€ .
(4.4.1) The(logarithmofthe)denominatoriscalledthe(log)partitionfunction.
Itwasintroduced instatisticalphysics96 tosumoverallpossiblestatesinathermodynamicensemble.
The 96 implementationisstraightforward: def softmax(X): X_exp = torch.
exp(X) partition = X_exp.
sum(1, keepdims=True) return X_exp / partition # The broadcasting mechanism is applied here For any input X, we turn each element into a nonnegative number.
Each row sums up to 1, asisrequiredforaprobability.
Caution: thecodeaboveisnotrobustagainstverylarge orverysmallarguments.
Whileitissufficienttoillustratewhatishappening, youshould 141 Softmax Regression Implementationfrom Scratch not usethiscodeverbatimforanyseriouspurpose.
Deeplearningframeworkshavesuch protectionsbuiltinandwewillbeusingthebuilt-insoftmaxgoingforward.
X = torch.
rand((2, 5)) X_prob = softmax(X) X_prob, X_prob.
sum(1) tensor([1., 1.])) 4.4.2 The Model Wenowhaveeverythingthatweneedtoimplementthesoftmaxregressionmodel.
Asin ourlinearregressionexample, eachinstancewillberepresentedbyafixed-lengthvector.
Sincetherawdatahereconsistsof 28 28pixelimages, weflatteneachimage, treating them as vectors of length 784.
In later chapters, we will introduce convolutional neural networks, whichexploitthespatialstructureinamoresatisfyingway.
In softmax regression, the number of outputs from our network should be equal to the numberofclasses.
Sinceourdatasethas10classes, ournetworkhasanoutputdimension of10.
Consequently, ourweightsconstitutea784 10matrixplusa1 10rowvectorfor thebiases.
Aswithlinearregression, weinitializetheweights Wwith Gaussiannoise.
The biasesareinitializedaszeros.
class Softmax Regression Scratch(d2l.
Classifier): def __init__(self, num_inputs, num_outputs, lr, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
W = torch.
normal(0, sigma, size=(num_inputs, num_outputs), requires_grad=True) self.
b = torch.
zeros(num_outputs, requires_grad=True) def parameters(self): return [self.
W, self.
b] Thecodebelowdefineshowthenetworkmapseachinputtoanoutput.
Notethatweflatten each28 28pixelimageinthebatchintoavectorusingreshapebeforepassingthedata throughourmodel.
@d2l.
add_to_class(Softmax Regression Scratch) def forward(self, X): X = X.
reshape((-1, self.
W.
shape[0])) return softmax(torch.
matmul(X, self.
W) + self.
b) 4.4.3 The Cross-Entropy Loss Nextweneedtoimplementthecross-entropylossfunction(introducedin Section4.1.2).
Thismaybethemostcommonlossfunctioninallofdeeplearning.
Atthemoment, appli- 142 Linear Neural Networksfor Classification cationsof deeplearning easilycastas classification problemsfaroutnumber thosebetter treatedasregressionproblems.
Recallthatcross-entropytakesthenegativelog-likelihoodofthepredictedprobabilityas- signedtothetruelabel.
Forefficiencyweavoid Pythonfor-loopsanduseindexinginstead.
Inparticular, theone-hotencodinginyallowsustoselectthematchingtermsinyË†.
Toseethisinactionwecreatesampledatay_hatwith2examplesofpredictedprobabilities over3classesandtheircorrespondinglabelsy.
Thecorrectlabelsare0and2respectively (i.
e., thefirstandthirdclass).
Usingyastheindicesoftheprobabilitiesiny_hat, wecan pickouttermsefficiently.
y = torch.
tensor([0, 2]) y_hat[[0, 1], y] tensor([0.1000, 0.5000]) Nowwecanimplementthecross-entropylossfunctionbyaveragingoverthelogarithmsof theselectedprobabilities.
def cross_entropy(y_hat, y): return -torch.
log(y_hat[list(range(len(y_hat))), y]).
mean() cross_entropy(y_hat, y) tensor(1.4979) @d2l.
add_to_class(Softmax Regression Scratch) def loss(self, y_hat, y): return cross_entropy(y_hat, y) 4.4.4 Training Wereusethefitmethoddefinedin Section3.4totrainthemodelwith10epochs.
Notethat thenumberofepochs(max_epochs), theminibatchsize(batch_size), andlearningrate (lr) are adjustable hyperparameters.
That means that while these values are not learned duringourprimarytrainingloop, theystillinfluencetheperformanceofourmodel, both vis-Ã -vistrainingandgeneralizationperformance.
Inpracticeyouwillwanttochoosethese valuesbasedonthevalidationsplitofthedataandthen, ultimately, toevaluateyourfinal modelonthetestsplit.
Asdiscussedin Section3.6.3, wewillregardthetestdataof Fashion- MNISTasthevalidationset, thusreportingvalidationlossandvalidationaccuracyonthis split.
143 Softmax Regression Implementationfrom Scratch data = d2l.
Fashion MNIST(batch_size=256) model = Softmax Regression Scratch(num_inputs=784, num_outputs=10, lr=0.1) trainer = d2l.
Trainer(max_epochs=10) trainer.
fit(model, data) 4.4.5 Prediction Nowthattrainingiscomplete, ourmodelisreadytoclassifysomeimages.
X, y = next(iter(data.
val_dataloader())) preds = model(X).
argmax(axis=1) preds.
shape torch.
Size([256]) Wearemoreinterestedintheimageswelabelincorrectly.
Wevisualizethembycomparing theiractuallabels(firstlineoftextoutput)withthepredictionsfromthemodel(secondline oftextoutput).
wrong = preds.
type(y.
dtype) != y X, y, preds = X[wrong], y[wrong], preds[wrong] labels = [a+'\n'+b for a, b in zip( data.
text_labels(y), data.
text_labels(preds))] data.
visualize([X, y], labels=labels) 4.4.6 Summary Bynowwearestartingtogetsomeexperiencewithsolvinglinearregressionandclassifi- cationproblems.
Withit, wehavereachedwhatwouldarguablybethestateoftheartof 144 Linear Neural Networksfor Classification 1960â€“1970sofstatisticalmodeling.
Inthenextsection, wewillshowyouhowtoleverage deeplearningframeworkstoimplementthismodelmuchmoreefficiently.
4.4.7 Exercises 1.
Inthissection, wedirectlyimplementedthesoftmaxfunctionbasedonthemathematical definitionofthesoftmaxoperation.
Asdiscussedin Section4.1thiscancausenumerical instabilities.
1.
Testwhethersoftmaxstillworkscorrectlyifaninputhasavalueof100.
2.
Testwhethersoftmaxstillworkscorrectlyifthelargestofallinputsissmallerthan 100? 3.
Implementafixbylookingatthevaluerelativetothelargestentryintheargument.
2.
Implement a cross_entropy function that follows the definition of the cross-entropy Ë lossfunction ğ‘– ğ‘¦ ğ‘–logğ‘¦Ë†ğ‘–.
1.
Tryitoutinthecodeexampleofthissection.
2.
Whydoyouthinkitrunsmoreslowly? 3.
Shouldyouuseit? Whenwoulditmakesenseto? 4.
Whatdoyouneedtobecarefulof? Hint: considerthedomainofthelogarithm.
3.
Isitalwaysagoodideatoreturnthemostlikelylabel? Forexample, wouldyoudothis formedicaldiagnosis? Howwouldyoutrytoaddressthis? 4.
Assumethatwewanttousesoftmaxregressiontopredictthenextwordbasedonsome features.
Whataresomeproblemsthatmightarisefromalargevocabulary? 5.
Experimentwiththehyperparametersofthecodeinthissection.
Inparticular: 1.
Plothowthevalidationlosschangesasyouchangethelearningrate.
2.
Dothevalidationandtraininglosschangeasyouchangetheminibatchsize? How largeorsmalldoyouneedtogobeforeyouseeaneffect? 97 Discussions97.
4.5 Concise Implementation of Softmax Regression Justashigh-leveldeeplearningframeworksmadeiteasiertoimplementlinearregression (see Section3.5), theyaresimilarlyconvenienthere.
145 Concise Implementationof Softmax Regression import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 4.5.1 Definingthe Model Asin Section3.5, weconstructourfullyconnectedlayerusingthebuilt-inlayer.
Thebuilt- in__call__methodtheninvokesforwardwheneverweneedtoapplythenetworktosome input.
Weusea Flattenlayertoconvertthefourth-ordertensor Xtosecondorderbykeepingthe dimensionalityalongthefirstaxisunchanged.
class Softmax Regression(d2l.
Classifier): #@save """The softmax regression model.""" def __init__(self, num_outputs, lr): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential(nn.
Flatten(), nn.
Lazy Linear(num_outputs)) def forward(self, X): return self.
net(X) 4.5.2 Softmax Revisited In Section4.4wecalculatedourmodelâ€™soutputandappliedthecross-entropyloss.
While thisisperfectlyreasonablemathematically, itisriskycomputationally, becauseofnumer- icalunderflowandoverflowintheexponentiation.
Recallthatthesoftmaxfunctioncomputesprobabilitiesviağ‘¦Ë†ğ‘— = Ëe ğ‘˜ x e p x â€ p ğ‘œ â€ ğ‘— ğ‘œ â€ ğ‘˜â€ .
Ifsomeofthe ğ‘œ ğ‘˜ areverylarge, i.
e., verypositive, thenexpâ€ğ‘œ ğ‘˜ â€ mightbelargerthanthelargestnumber wecanhaveforcertaindatatypes.
Thisiscalledoverflow.
Likewise, ifeveryargumentis averylargenegativenumber, wewillgetunderflow.
Forinstance, singleprecisionfloating pointnumbersapproximatelycovertherangeof10 38to1038.
Assuch, ifthelargestterm in o lies outside the interval Â» 90,90â€¦, the result will not be stable.
A way round this problemistosubtractğ‘œÂ¯ d = ef maxğ‘˜ ğ‘œ ğ‘˜ fromallentries: expğ‘œ ğ‘— expâ€ğ‘œ ğ‘— ğ‘œÂ¯â€expğ‘œÂ¯ expâ€ğ‘œ ğ‘— ğ‘œÂ¯â€ ğ‘¦Ë†ğ‘— = Ë ğ‘˜expğ‘œ ğ‘˜ = Ë ğ‘˜expâ€ğ‘œ ğ‘˜ ğ‘œÂ¯â€expğ‘œÂ¯ = Ë ğ‘˜expâ€ğ‘œ ğ‘˜ ğ‘œÂ¯â€ .
(4.5.1) By construction we know that ğ‘œ ğ‘— ğ‘œÂ¯ 0 for all ğ‘—.
As such, for a ğ‘-class classification problem, the denominator is contained in the interval Â»1,ğ‘â€¦.
Moreover, the numerator never exceeds 1, thus preventing numerical overflow.
Numerical underflow only occurs whenexpâ€ğ‘œ ğ‘— ğ‘œÂ¯â€ numericallyevaluatesas0.
Nonetheless, afewstepsdowntheroadwe mightfindourselvesintroublewhenwewanttocomputelogğ‘¦Ë†ğ‘— aslog0.
Inparticular, in backpropagation, wemightfindourselvesfacedwithascreenfulofthedreaded Na N(Nota Number)results.
146 Linear Neural Networksfor Classification Fortunately, wearesavedbythefactthateventhoughwearecomputingexponentialfunc- tions, weultimatelyintendtotaketheirlog(whencalculatingthecross-entropyloss).
By combining softmax and cross-entropy, we can escape the numerical stability issues alto- gether.
Wehave: expâ€ğ‘œ ğ‘— ğ‘œÂ¯â€ logğ‘¦Ë†ğ‘— =logË ğ‘˜expâ€ğ‘œ ğ‘˜ ğ‘œÂ¯â€ =ğ‘œ ğ‘— ğ‘œÂ¯ log ğ‘˜ expâ€ğ‘œ ğ‘˜ ğ‘œÂ¯â€.
(4.5.2) Thisavoidsbothoverflowandunderflow.
Wewillwanttokeeptheconventionalsoftmax functionhandyincaseweeverwanttoevaluatetheoutputprobabilitiesbyourmodel.
But insteadofpassingsoftmaxprobabilitiesintoournewlossfunction, wejustpassthelogits andcomputethesoftmaxanditslogallatonceinsidethecross-entropylossfunction, which doessmartthingsliketheâ€œLog Sum Exptrickâ€98.
98 @d2l.
add_to_class(d2l.
Classifier) #@save def loss(self, Y_hat, Y, averaged=True): Y_hat = Y_hat.
reshape((-1, Y_hat.
shape[-1])) Y = Y.
reshape((-1,)) return F.
cross_entropy( Y_hat, Y, reduction='mean' if averaged else 'none') 4.5.3 Training Next we train our model.
We use Fashion-MNIST images, flattened to 784-dimensional featurevectors.
data = d2l.
Fashion MNIST(batch_size=256) model = Softmax Regression(num_outputs=10, lr=0.1) trainer = d2l.
Trainer(max_epochs=10) trainer.
fit(model, data) Asbefore, thisalgorithmconvergestoasolutionthatisreasonablyaccurate, albeitthistime withfewerlinesofcodethanbefore.
4.5.4 Summary High-level APIsareveryconvenientathidingfromtheiruserpotentiallydangerousaspects, such as numerical stability.
Moreover, they allow users to design models concisely with 147 Generalizationin Classification veryfewlinesofcode.
Thisisbothablessingandacurse.
Theobviousbenefitisthatit makesthingshighlyaccessible, eventoengineerswhonevertookasingleclassofstatistics intheirlife(infact, theyarepartofthetargetaudienceofthebook).
Buthidingthesharp edgesalsocomeswithaprice: adisincentivetoaddnewanddifferentcomponentsonyour own, sincethereislittlemusclememoryfordoingit.
Moreover, itmakesitmoredifficult tofix thingswhenevertheprotectivepaddingofaframeworkfailstocoverallthecorner casesentirely.
Again, thisisduetolackoffamiliarity.
As such, we strongly urge you to review both the bare bones and the elegant versions of manyoftheimplementationsthatfollow.
Whileweemphasizeeaseofunderstanding, the implementationsarenonethelessusuallyquiteperformant(convolutionsarethebigexcep- tionhere).
Itisourintentiontoallowyoutobuildonthesewhenyouinventsomethingnew thatnoframeworkcangiveyou.
4.5.5 Exercises 1.
Deep learning uses many different number formats, including FP64 double precision (usedextremelyrarely), FP32singleprecision, BFLOAT16(goodforcompressedrep- resentations), FP16 (very unstable), TF32 (a new format from NVIDIA), and INT8.
Compute the smallest and largest argument of the exponential function for which the resultdoesnotleadtonumericalunderfloworoverflow.
2.
INT8isaverylimitedformatconsistingofnonzeronumbersfrom1to255.
Howcould youextenditsdynamicrangewithoutusingmorebits? Dostandardmultiplicationand additionstillwork? 3.
Increasethenumberofepochsfortraining.
Whymightthevalidationaccuracydecrease afterawhile? Howcouldwefixthis? 4.
What happens as you increase the learning rate? Compare the loss curves for several learningrates.
Whichoneworksbetter? When? Discussions99.
99 4.6 Generalization in Classification So far, we have focused on how to tackle multiclass classification problems by training (linear) neural networks with multiple outputs and softmax functions.
Interpreting our modelâ€™s outputs as probabilistic predictions, we motivated and derived the cross-entropy lossfunction, whichcalculatesthenegativeloglikelihoodthatourmodel(forafixedset of parameters) assigns to the actual labels.
And finally, we put these tools into practice by fitting our model to the training set.
However, as always, our goal is to learn general patterns, as assessedempiricallyonpreviouslyunseendata(thetestset).
Highaccuracy onthetrainingsetmeansnothing.
Whenevereachofourinputsisunique(andindeedthis istrueformosthigh-dimensionaldatasets), wecanattainperfectaccuracyonthetraining 148 Linear Neural Networksfor Classification setbyjustmemorizingthedatasetonthefirsttrainingepoch, andsubsequentlylookingup thelabelwheneverweseeanewimage.
Andyet, memorizingtheexactlabelsassociated with the exact training examples does not tell us how to classify new examples.
Absent furtherguidance, wemighthavetofallbackonrandomguessingwheneverweencounter newexamples.
Anumberofburningquestionsdemandimmediateattention: 1.
How many test examples do we need to give a good estimate of the accuracy of our classifiersontheunderlyingpopulation? 2.
Whathappensifwekeepevaluatingmodelsonthesametestrepeatedly? 3.
Whyshouldweexpectthatfittingourlinearmodelstothetrainingsetshouldfareany betterthanournaivememorizationscheme? Whereas Section3.6introducedthebasicsofoverfittingandgeneralizationinthecontextof linearregression, thischapterwillgoalittledeeper, introducingsomeofthefoundational ideasofstatisticallearningtheory.
Itturnsoutthatweoftencanguaranteegeneralization apriori: formanymodels, andforanydesiredupperboundonthegeneralizationgap ğœ–, we can often determine some required number of samples ğ‘› such that if our training set containsatleastğ‘› samples, ourempiricalerrorwillliewithinğœ– ofthetrueerror, forany datageneratingdistribution.
Unfortunately, italsoturnsoutthatwhilethesesortsofguar- anteesprovideaprofoundsetofintellectualbuildingblocks, theyareoflimitedpractical utility to the deep learning practitioner.
In short, these guarantees suggest that ensuring generalization of deep neural networks a priori requires an absurd number of examples (perhapstrillionsormore), evenwhenwefindthat, onthetaskswecareabout, deepneural networkstypicallygeneralizeremarkablywellwithfarfewerexamples(thousands).
Thus deep learning practitioners often forgo a priori guarantees altogether, instead employing methods that have generalized well on similar problems in the past, and certifying gen- eralization post hoc through empirical evaluations.
When we get to Chapter 5, we will revisit generalization and provide a light introduction to the vast scientific literature that hassprunginattemptstoexplainwhydeepneuralnetworksgeneralizeinpractice.
4.6.1 The Test Set Sincewehavealreadybeguntorelyontestsetsasthegoldstandardmethodforassessing generalizationerror, letâ€™sgetstartedbydiscussingthepropertiesofsucherrorestimates.
Letâ€™sfocusonafixedclassifier ğ‘“, withoutworryingabouthowitwasobtained.
Moreover supposethatwepossessafreshdatasetofexamples D = â€xâ€ğ‘–â€,ğ‘¦â€ğ‘–â€â€ ğ‘– ğ‘› =1 thatwerenotused totraintheclassifier ğ‘“.
Theempiricalerrorofourclassifier ğ‘“ on Dissimplythefraction ofinstancesforwhichtheprediction ğ‘“â€xâ€ğ‘–â€â€disagreeswiththetruelabelğ‘¦â€ğ‘–â€ , andisgiven bythefollowingexpression: ğ‘› 1 ğœ– D â€ğ‘“â€ = ğ‘› 1â€ğ‘“â€x â€ğ‘–â€â€ â‰  ğ‘¦â€ğ‘–â€â€.
(4.6.1) ğ‘–=1 Bycontrast, thepopulationerroristheexpectedfractionofexamplesintheunderlyingpop- ulation(somedistribution ğ‘ƒâ€ğ‘‹,ğ‘Œâ€ characterizedbyprobabilitydensityfunction ğ‘â€x,ğ‘¦â€) 149 Generalizationin Classification forwhichourclassifierdisagreeswiththetruelabel: â€ â€ ğœ–â€ğ‘“â€ = ğ¸ â€x,ğ‘¦â€ ğ‘ƒ1â€ğ‘“â€xâ€ â‰  ğ‘¦â€ = 1â€ğ‘“â€xâ€ â‰  ğ‘¦â€ğ‘â€x,ğ‘¦â€ ğ‘‘xğ‘‘ğ‘¦.
(4.6.2) Whileğœ–â€ğ‘“â€ isthequantitythatweactuallycareabout, wecannotobserveitdirectly, just aswecannotdirectlyobservetheaverageheightinalargepopulationwithoutmeasuring every single person.
We can only estimate this quantity based on samples.
Because our testset D isstatisticallyrepresentativeoftheunderlyingpopulation, wecanviewğœ– D â€ğ‘“â€ asastatisticalestimatorofthepopulationerrorğœ–â€ğ‘“â€.
Moreover, becauseourquantityof interestğœ–â€ğ‘“â€isanexpectation(oftherandomvariable1â€ğ‘“â€ğ‘‹â€ â‰ ğ‘Œâ€)andthecorresponding estimatorğœ– D â€ğ‘“â€isthesampleaverage, estimatingthepopulationerrorissimplytheclassic problemofmeanestimation, whichyoumayrecallfrom Section2.6.
Animportantclassicalresultfromprobabilitytheorycalledthecentrallimittheoremguar- anteesthatwheneverwepossessğ‘›randomsamplesğ‘ 1 ,...,ğ‘ ğ‘› drawnfromanydistribution withmeanğœ‡andstandarddeviationğœ, then, asthenumberofsamplesğ‘›approachesinfin- ity, thesampleaverageğœ‡Ë†approximatelytendstowardsanormaldistributioncenteredatthe p truemeanandwithstandarddeviationğœ ğ‘›.
Already, thistellsussomethingimportant: asthenumberofexamp p lesgrowslarge, ourtesterrorğœ– D â€ğ‘“â€shouldapproachthetrueerror ğœ–â€ğ‘“â€ at a rate of Oâ€1 ğ‘›â€.
Thus, to estimate our test error twice as precisely, we must collectfourtimesaslargeatestset.
Toreduceourtesterrorbyafactorofonehundred, we p mustcollecttenthousandtimesaslargeatestset.
Ingeneral, sucharateof Oâ€1 ğ‘›â€ is oftenthebestwecanhopeforinstatistics.
Now that we know something about the asymptotic rate at which our test error ğœ– D â€ğ‘“â€ converges to the true error ğœ–â€ğ‘“â€, we can zoom in on some important details.
Recall that the random variable of interest 1â€ğ‘“â€ğ‘‹â€ â‰  ğ‘Œâ€ can only take values 0 and 1 and thus is a Bernoullirandomvariable, characterizedbyaparameterindicatingtheprobabilitythat ittakesvalue1.
Here, 1meansthatourclassifiermadeanerror, sotheparameterofour randomvariableisactuallythetrueerrorrateğœ–â€ğ‘“â€.
Thevarianceğœ2ofa Bernoullidepends onitsparameter(here, ğœ–â€ğ‘“â€)accordingtotheexpressionğœ–â€ğ‘“â€â€1 ğœ–â€ğ‘“â€â€.
Whileğœ–â€ğ‘“â€ is initiallyunknown, weknowthat it cannot be greater than 1.
A little investigationof this functionrevealsthatourvarianceishighestwhenthetrueerrorrateiscloseto0.5andcan befarlowerwhenitiscloseto0orcloseto1.
Thistellsusthattheasymptoticstandard deviationofourestimateğœ– p D â€ğ‘“â€ oftheerror ğœ–â€ğ‘“â€ (overthechoiceofthe ğ‘› testsamples) cannotbeanygreaterthan 0.25 ğ‘›.
If we ignore the fact that this rate characterizes behavior as the test set size approaches infinity rather than when we possess finite samples, this tells us that if we want our test error ğœ– D â€ğ‘“â€ to approximate the population error ğœ–â€ğ‘“â€ such that one standard deviation correspondstoanintervalof 0.01, thenweshouldcollectroughly2500samples.
Ifwe wanttofittwostandarddeviationsinthatrangeandthusbe95%confidentthatğœ– D â€ğ‘“â€ 2 ğœ–â€ğ‘“â€ 0.01, thenwewillneed10,000samples! Thisturnsouttobethesizeofthetestsetsformanypopularbenchmarksinmachinelearn- ing.
Youmightbesurprisedtofindoutthatthousandsofapplieddeeplearningpapersget publishedeveryyearmakingabigdealoutoferrorrateimprovementsof0.01orless.
Of 150 Linear Neural Networksfor Classification course, whentheerrorratesaremuchcloserto0, thenanimprovementof0.01canindeed beabigdeal.
Onepeskyfeatureofouranalysisthusfaristhatitreallyonlytellsusaboutasymptotics, i.
e., how the relationship between ğœ– D and ğœ– evolves as our sample size goes to infinity.
Fortunately, because our random variable is bounded, we can obtain valid finite sample boundsbyapplyinganinequalitydueto Hoeffding(1963): ğ‘ƒâ€ğœ– D â€ğ‘“â€ ğœ–â€ğ‘“â€ ğ‘¡â€ <exp 2ğ‘›ğ‘¡2 .
(4.6.3) Solvingforthesmallestdatasetsizethatwouldallowustoconcludewith95%confidence thatthedistanceğ‘¡betweenourestimateğœ– D â€ğ‘“â€andthetrueerrorrateğœ–â€ğ‘“â€doesnotexceed 0.01, youwillfindthatroughly15,000examplesarerequiredascomparedtothe10,000 examplessuggestedbytheasymptoticanalysisabove.
Ifyougodeeperintostatisticsyou will find that this trend holds generally.
Guarantees that hold even in finite samples are typically slightly more conservative.
Note that in the scheme of things, these numbers arenotsofarapart, reflectingthegeneralusefulnessofasymptoticanalysisforgivingus ballparkfigureseveniftheyarenotguaranteeswecantaketocourt.
4.6.2 Test Set Reuse In some sense, you are now set up to succeed at conducting empirical machine learning research.
Nearlyallpracticalmodelsaredevelopedandvalidatedbasedontestsetperfor- manceandyouarenowamasterofthetestset.
Foranyfixedclassifier ğ‘“, youknowhow toevaluateitstesterrorğœ– D â€ğ‘“â€, andknowpreciselywhatcan(andcannot)besaidaboutits populationerrorğœ–â€ğ‘“â€.
Soletâ€™ssaythatyoutakethisknowledgeandpreparetotrainyourfirstmodel ğ‘“ .
Knowing 1 justhowconfidentyouneedtobeintheperformanceofyourclassifierâ€™serrorrateyouapply ouranalysisabovetodetermineanappropriatenumberofexamplestosetasideforthetest set.
Moreover, letâ€™sassumethatyoutookthelessonsfrom Section3.6toheartandmade suretopreservethesanctityofthetestsetbyconductingallofyourpreliminaryanalysis, hyperparametertuning, andevenselectionamongmultiplecompetingmodelarchitectures onavalidationset.
Finallyyouevaluateyourmodel ğ‘“ onthetestsetandreportanunbiased 1 estimateofthepopulationerrorwithanassociatedconfidenceinterval.
So far everything seems to be going well.
However, that night you wake up at 3am with abrilliantideaforanewmodelingapproach.
Thenextday, youcodeupyournewmodel, tuneitshyperparametersonthevalidationsetandnotonlyareyougettingyournewmodel ğ‘“ to work but its error rate appears to be much lower than ğ‘“ â€™s.
However, the thrill of 2 1 discovery suddenly fades as you prepare for the final evaluation.
You do not have a test set! Eventhoughtheoriginaltestset Disstillsittingonyourserver, younowfacetwoformidable problems.
First, whenyoucollectedyourtestset, youdeterminedtherequiredlevelofpre- cision under the assumption that you were evaluating a single classifier ğ‘“.
However, if you get into the business of evaluating multiple classifiers ğ‘“ 1 ,..., ğ‘“ ğ‘˜ on the same test set, youmustconsidertheproblemoffalsediscovery.
Before, youmighthavebeen95%sure 151 Generalizationin Classification thatğœ– D â€ğ‘“â€ 2 ğœ–â€ğ‘“â€ 0.01forasingleclassifier ğ‘“ andthustheprobabilityofamisleading resultwasamere5%.
With ğ‘˜ classifiersinthemix, itcanbehardtoguaranteethatthere isnotevenoneamongthemwhosetestsetperformanceismisleading.
With20classifiers underconsideration, youmighthavenopoweratalltoruleoutthepossibilitythatatleast oneamongthemreceivedamisleadingscore.
Thisproblemrelatestomultiplehypothesis testing, whichdespiteavastliteratureinstatistics, remainsapersistentproblemplaguing scientificresearch.
Ifthatisnotenoughtoworryyou, thereisaspecialreasontodistrusttheresultsthatyou get on subsequent evaluations.
Recall that our analysis of test set performance rested on theassumptionthattheclassifierwaschosenabsentanycontactwiththetestsetandthus wecouldviewthetestsetasdrawnrandomlyfromtheunderlyingpopulation.
Here, not only are you testing multiple functions, the subsequent function ğ‘“ was chosen after you 2 observed the test set performance of ğ‘“ .
Once information from the test set has leaked 1 tothemodeler, itcanneverbeatruetestsetagaininthestrictestsense.
Thisproblemis calledadaptiveoverfittingandhasrecentlyemergedasatopicofintenseinteresttolearning theoristsandstatisticians(Dworketal.,2015).
Fortunately, whileitispossibletoleakall informationoutofaholdoutset, andthetheoreticalworstcasescenariosarebleak, these analysesmaybetooconservative.
Inpractice, takecaretocreaterealtestsets, toconsult themasinfrequentlyaspossible, toaccountformultiplehypothesistestingwhenreporting confidenceintervals, andtodialupyourvigilancemoreaggressivelywhenthestakesare highandyourdatasetsizeissmall.
Whenrunningaseriesofbenchmarkchallenges, itis oftengoodpracticetomaintainseveraltestsetssothataftereachround, theoldtestsetcan bedemotedtoavalidationset.
4.6.3 Statistical Learning Theory Putsimply, testsetsareallthatwereallyhave, andyetthisfactseemsstrangelyunsatisfy- ing.
First, weseldompossessatruetestsetâ€”unlesswearetheonescreatingthedataset, someone else has probably already evaluated their own classifier on our ostensible â€œtest setâ€.
And even when we have first dibs, we soon find ourselves frustrated, wishing we couldevaluateoursubsequentmodelingattemptswithoutthegnawingfeelingthatwecan- nottrustour numbers.
Moreover, evenatrue testset canonlytellus posthoc whethera classifierhasinfactgeneralizedtothepopulation, notwhetherwehaveanyreasontoexpect apriorithatitshouldgeneralize.
Withthesemisgivingsinmind, youmightnowbesufficientlyprimedtoseetheappealof statistical learning theory, the mathematical subfield of machine learning whose practi- tionersaimtoelucidatethefundamentalprinciplesthatexplainwhy/whenmodelstrained onempiricaldatacan/willgeneralizetounseendata.
Oneoftheprimaryaimsofstatistical learningresearchershasbeentoboundthegeneralizationgap, relatingthepropertiesofthe modelclasstothenumberofsamplesinthedataset.
Learning theorists aim to bound the difference between the empirical error ğœ– S â€ğ‘“ S â€ of a learned classifier ğ‘“ S, both trained and evaluated on the training set S, and the true error ğœ–â€ğ‘“ S â€ of that same classifier on the underlying population.
This might look similar to theevaluationproblemthatwejustaddressedbutthereisamajordifference.
Earlier, the 152 Linear Neural Networksfor Classification classifier ğ‘“ wasfixedandweonlyneededadatasetforevaluativepurposes.
Andindeed, anyfixedclassifierdoesgeneralize: itserrorona(previouslyunseen)datasetisanunbiased estimate of the population error.
But what can we say when a classifier is trained and evaluated on the same dataset? Can we ever be confident that the training error will be closetothetestingerror? Supposethatourlearnedclassifier ğ‘“ S mustbechosenfromsomepre-specifiedsetoffunc- tions F.
Recallfromourdiscussionoftestsetsthatwhileitiseasytoestimatetheerrorofa singleclassifier, thingsgethairywhenwebegintoconsidercollectionsofclassifiers.
Even iftheempiricalerrorofanyone(fixed)classifierwillbeclosetoitstrueerrorwithhigh probability, onceweconsideracollectionofclassifiers, weneedtoworryaboutthepossi- bilitythatjustoneofthemwillreceiveabadlyestimatederror.
Theworryisthatwemight pick such a classifier and thereby grossly underestimate the population error.
Moreover, evenforlinearmodels, becausetheirparametersarecontinuouslyvalued, wearetypically choosingfromaninfiniteclassoffunctions(j Fj =1).
One ambitious solution to the problem is to develop analytic tools for proving uniform convergence, i.
e., that with high probability, the empirical error rate for every classifier in the class ğ‘“ 2 F will simultaneously converge to its true error rate.
In other words, we seek a theoretical principle that would allow us to state that with probability at least 1 ğ›¿ (for some small ğ›¿) no classifierâ€™s error rate ğœ–â€ğ‘“â€ (among all classifiers in the class F) will be misestimated by more than some small amount ğ›¼.
Clearly, we cannot make suchstatementsforallmodelclasses F.
Recalltheclassofmemorizationmachinesthat alwaysachieveempiricalerror0butneveroutperformrandomguessingontheunderlying population.
In a sense the class of memorizers is too flexible.
Nosucha uniform convergenceresult couldpossiblyhold.
Ontheotherhand, afixedclassifierisuselessâ€”itgeneralizesperfectly, but fits neither the training data nor the test data.
The central question of learning has thushistoricallybeenframedasatrade-offbetweenmoreflexible(highervariance)model classesthatbetterfitthetrainingdatabutriskoverfitting, versusmorerigid(higherbias) model classes that generalize well but risk underfitting.
A central question in learning theoryhasbeentodeveloptheappropriatemathematicalanalysistoquantifywhereamodel sitsalongthisspectrum, andtoprovidetheassociatedguarantees.
In a series of seminal papers, Vapnik and Chervonenkis extended the theory on the con- vergence of relative frequencies to more general classes of functions (Vapnik and Cher- vonenkis, 1964, Vapnik and Chervonenkis, 1968, Vapnik and Chervonenkis, 1971, Vap- nikand Chervonenkis,1981, Vapnikand Chervonenkis,1991, Vapnikand Chervonenkis, 1974).
Oneofthekeycontributionsofthislineofworkisthe Vapnikâ€“Chervonenkis(VC) dimension, whichmeasures(onenotionof)thecomplexity(flexibility)ofamodelclass.
Moreover, oneoftheirkeyresultsboundsthedifferencebetweentheempiricalerrorand thepopulationerrorasafunctionofthe VCdimensionandthenumberofsamples: p ğ‘ƒ ğ‘…Â»ğ‘, ğ‘“â€¦ ğ‘… Â»X, Y, ğ‘“â€¦ < ğ›¼ 1 ğ›¿ for ğ›¼ ğ‘ â€VC logğ›¿â€ ğ‘›.
(4.6.4) emp Here ğ›¿ > 0 is the probability that the bound is violated, ğ›¼ is the upper bound on the generalizationgap, andğ‘›isthedatasetsize.
Lastly,ğ‘ > 0isaconstantthatdependsonly 153 Generalizationin Classification on the scale of the loss that can be incurred.
One use of the bound might be to plug in desiredvaluesofğ›¿ andğ›¼ todeterminehowmanysamplestocollect.
The VCdimension quantifiesthelargestnumberofdatapointsforwhichwecanassignanyarbitrary(binary) labeling and for each find some model ğ‘“ in the class that agrees with that labeling.
For example, linear models on ğ‘‘-dimensional inputs have VC dimension ğ‘‘ â€š1.
It is easy to seethatalinecanassignanypossiblelabelingtothreepointsintwodimensions, butnot tofour.
Unfortunately, thetheorytendstobeoverlypessimisticformorecomplexmodels andobtainingthisguaranteetypicallyrequiresfarmoreexamplesthanareactuallyneeded toachievethedesirederrorrate.
Notealsothatfixingthemodelclassandğ›¿, ourerrorrate p again decays with the usual Oâ€1 ğ‘›â€ rate.
It seems unlikely that we could do better in termsofğ‘›.
However, aswevarythemodelclass, VCdimensioncanpresentapessimistic pictureofthegeneralizationgap.
4.6.4 Summary Themoststraightforwardwaytoevaluateamodelistoconsultatestsetcomprisedofpre- viously unseen data.
Test set evaluations provide an unbiased estimate of the true error p and converge at the desired Oâ€1 ğ‘›â€ rate as the test set grows.
We can provide approx- imate confidence intervals based on exact asymptotic distributions or valid finite sample confidence intervals based on (more conservative) finite sample guarantees.
Indeed test setevaluationisthebedrockofmodernmachinelearningresearch.
However, testsetsare seldomtruetestsets(usedbymultipleresearchersagainandagain).
Oncethesametestset is used to evaluate multiple models, controlling for false discovery can be difficult.
This cancausehugeproblemsintheory.
Inpractice, thesignificanceoftheproblemdependson thesizeoftheholdoutsetsinquestionandwhethertheyaremerelybeingusedtochoose hyperparametersoriftheyareleakinginformationmoredirectly.
Nevertheless, itisgood practicetocuraterealtestsets(ormultiple)andtobeasconservativeaspossibleabouthow oftentheyareused.
Hopingtoprovideamoresatisfyingsolution, statisticallearningtheoristshavedeveloped methodsforguaranteeinguniformconvergenceoveramodelclass.
Ifindeedeverymodelâ€™s empirical error simultaneously converges to its true error, then we are free to choose the modelthatperformsbest, minimizingthetrainingerror, knowingthatittoowillperform similarlywellontheholdoutdata.
Crucially, anyoneofsuchresultsmustdependonsome propertyofthemodelclass.
Vladimir Vapnikand Alexey Chernovenkisintroducedthe VC dimension, presentinguniformconvergenceresultsthatholdforallmodelsina VCclass.
Thetrainingerrorsforallmodelsintheclassare(simultaneously)guaranteedtobeclose p totheirtrueerrors, andguaranteedtogrowevencloserat Oâ€1 ğ‘›â€ rates.
Followingthe revolutionarydiscoveryof VCdimension, numerousalternativecomplexitymeasureshave been proposed, each facilitating an analogous generalization guarantee.
See Boucheron et al.
(2005) for a detailed discussion of several advanced ways of measuring function complexity.
Unfortunately, whilethesecomplexitymeasureshavebecomebroadlyuseful tools in statistical theory, they turn out to be powerless (as straightforwardly applied) for explainingwhydeepneuralnetworksgeneralize.
Deepneuralnetworksoftenhavemillions ofparameters(ormore), andcaneasilyassignrandomlabelstolargecollectionsofpoints.
Nevertheless, theygeneralizewellonpracticalproblemsand, surprisingly, theyoftengen- 154 Linear Neural Networksfor Classification eralizebetter, whentheyarelargeranddeeper, despiteincurringhigher VCdimensions.
In thenextchapter, wewillrevisitgeneralizationinthecontextofdeeplearning.
4.6.5 Exercises 1.
If we wish to estimate the error of a fixed model ğ‘“ to within 0.0001 with probability greaterthan99.9%, howmanysamplesdoweneed? 2.
Supposethatsomebodyelsepossessesalabeledtestset Dandonlymakesavailablethe unlabeledinputs(features).
Nowsupposethatyoucanonlyaccessthetestsetlabelsby runningamodel ğ‘“ (withnorestrictionsplacedonthemodelclass)oneachoftheun- labeledinputsandreceivingthecorrespondingerrorğœ– D â€ğ‘“â€.
Howmanymodelswould you need to evaluate before you leak the entire test set and thus could appear to have error0, regardlessofyourtrueerror? 3.
Whatisthe VCdimensionoftheclassoffifth-orderpolynomials? 4.
Whatisthe VCdimensionofaxis-alignedrectanglesontwo-dimensionaldata? 100 Discussions100.
4.7 Environment and Distribution Shift Intheprevioussections, weworkedthroughanumberofhands-onapplicationsofmachine learning, fittingmodelstoavarietyofdatasets.
Andyet, weneverstoppedtocontemplate either where data came from in the first place or what we ultimately plan to do with the outputs from our models.
Too often, machine learning developers in possession of data rushtodevelopmodelswithoutpausingtoconsiderthesefundamentalissues.
Manyfailedmachinelearningdeploymentscanbetracedbacktothisfailure.
Sometimes modelsappeartoperformmarvelouslyasmeasuredbytestsetaccuracybutfailcatastroph- icallyindeploymentwhenthedistributionofdatasuddenlyshifts.
Moreinsidiously, some- timestheverydeploymentofamodelcanbethecatalystthatperturbsthedatadistribution.
Say, forexample, thatwetrainedamodeltopredictwhowillrepayratherthandefaultona loan, findingthatanapplicantâ€™schoiceoffootwearwasassociatedwiththeriskofdefault (Oxfordsindicaterepayment, sneakersindicatedefault).
Wemightbeinclinedthereafter tograntaloantoanyapplicantwearing Oxfordsandtodenyallapplicantswearingsneak- ers.
In this case, our ill-considered leap from pattern recognition to decision-making and our failure to critically consider the environment might have disastrous consequences.
For starters, assoonaswebeganmakingdecisionsbasedonfootwear, customerswouldcatch onandchangetheirbehavior.
Beforelong, allapplicantswouldbewearing Oxfords, with- outanycoincidentimprovementincredit-worthiness.
Takeaminutetodigestthisbecause 155 Environmentand Distribution Shift similarissuesaboundinmanyapplicationsofmachinelearning: byintroducingourmodel- baseddecisionstotheenvironment, wemightbreakthemodel.
Whilewecannotpossiblygivethesetopicsacompletetreatmentinonesection, weaimhere toexposesomecommonconcerns, andtostimulatethecriticalthinkingrequiredtodetect suchsituationsearly, mitigatedamage, andusemachinelearningresponsibly.
Someofthe solutionsaresimple(askfortheâ€œrightâ€data), somearetechnicallydifficult(implementa reinforcement learning system), and others require that we step outside the realm of sta- tisticalpredictionaltogetherandgrapplewithdifficultphilosophicalquestionsconcerning theethicalapplicationofalgorithms.
4.7.1 Typesof Distribution Shift Tobegin, westickwiththepassivepredictionsettingconsideringthevariouswaysthatdata distributionsmightshiftandwhatmightbedonetosalvagemodelperformance.
Inoneclas- sicsetup, weassumethatourtrainingdatawassampledfromsomedistribution ğ‘ ğ‘† â€x,ğ‘¦â€ butthatourtestdatawillconsistofunlabeledexamplesdrawnfromsomedifferentdistri- butionğ‘ ğ‘‡ â€x,ğ‘¦â€.
Already, wemustconfrontasoberingreality.
Absentanyassumptionson how ğ‘ ğ‘† and ğ‘ ğ‘‡ relatetoeachother, learningarobustclassifierisimpossible.
Considerabinaryclassificationproblem, wherewewishtodistinguishbetweendogsand cats.
Ifthedistributioncanshiftinarbitraryways, thenoursetuppermitsthepathological caseinwhichthedistributionoverinputsremainsconstant: ğ‘ ğ‘† â€xâ€ = ğ‘ ğ‘‡ â€xâ€, butthelabels areallflipped: ğ‘ ğ‘† â€ğ‘¦ j xâ€ =1 ğ‘ ğ‘‡ â€ğ‘¦ j xâ€.
Inotherwords, if Godcansuddenlydecidethat inthefutureallâ€œcatsâ€arenowdogsandwhatwepreviouslycalledâ€œdogsâ€arenowcatsâ€” withoutanychangeinthedistributionofinputs ğ‘â€xâ€, thenwecannotpossiblydistinguish thissettingfromoneinwhichthedistributiondidnotchangeatall.
Fortunately, undersomerestrictedassumptionsonthewaysourdatamightchangeinthefu- ture, principledalgorithmscandetectshiftandsometimesevenadaptonthefly, improving ontheaccuracyoftheoriginalclassifier.
Covariate Shift Among categories of distribution shift, covariate shift may be the most widely studied.
Here, weassumethatwhilethedistributionofinputsmaychangeovertime, thelabeling function, i.
e., theconditionaldistribution ğ‘ƒâ€ğ‘¦ j xâ€ doesnotchange.
Statisticianscallthis covariateshift becausetheproblemarisesduetoashiftinthedistributionofthecovari- ates(features).
Whilewecansometimesreasonaboutdistributionshiftwithoutinvoking causality, wenotethatcovariateshiftisthenaturalassumptiontoinvokeinsettingswhere webelievethatxcausesğ‘¦.
Considerthechallengeofdistinguishingcatsanddogs.
Ourtrainingdatamightconsistof imagesofthekindin.7.1.
Attesttimeweareaskedtoclassifytheimagesin.7.2.
Thetrainingsetconsistsofphotos, whilethetestsetcontainsonlycartoons.
Trainingona 156 Linear Neural Networksfor Classification t .7.1 Trainingdatafordistinguishingcatsanddogs(illustrations: Lafeez Hossain/500px/ Getty Images; ilkermetinkursova/i Stock/Getty Images Plus; Global P/i Stock/Getty Images Plus; Musthafa Aboobakuru/500px/Getty Images).
t .7.2 Testdatafordistinguishingcatsanddogs(illustrations: SIBAS_minich/i Stock/Getty Images Plus; Ghrzuzudu/i Stock/Getty Images Plus; id-work/Digital Vision Vectors/ Getty Images; Yime/i Stock/Getty Images Plus).
datasetwithsubstantiallydifferentcharacteristicsfromthetestsetcanspelltroubleabsent acoherentplanforhowtoadapttothenewdomain.
Label Shift Labelshiftdescribestheconverseproblem.
Here, weassumethatthelabelmarginalğ‘ƒâ€ğ‘¦â€ canchangebuttheclass-conditionaldistribution ğ‘ƒâ€x j ğ‘¦â€ remainsfixedacrossdomains.
Labelshiftisareasonableassumptiontomakewhenwebelievethat ğ‘¦ causesx.
Forex- ample, wemaywanttopredictdiagnosesgiventheirsymptoms(orothermanifestations), evenastherelativeprevalenceofdiagnosesarechangingovertime.
Labelshiftistheap- propriateassumptionherebecausediseasescausesymptoms.
Insomedegeneratecasesthe labelshiftandcovariateshiftassumptionscanholdsimultaneously.
Forexample, whenthe labelisdeterministic, thecovariateshiftassumptionwillbesatisfied, evenwhen ğ‘¦ causes x.
Interestingly, in these cases, it is often advantageous to work with methods that flow fromthelabelshiftassumption.
Thatisbecausethesemethodstendtoinvolvemanipulat- ing objects that look like labels (often low-dimensional), as opposed to objects that look likeinputs, whichtendtobehigh-dimensionalindeeplearning.
157 Environmentand Distribution Shift Concept Shift We may also encounter the related problem of concept shift, which arises when the very definitions of labels can change.
This sounds weirdâ€”a cat is a cat, no? However, other categoriesaresubjecttochangesinusageovertime.
Diagnosticcriteriaformentalillness, whatpassesforfashionable, andjobtitles, areallsubjecttoconsiderableamountsofcon- ceptshift.
Itturnsoutthatifwenavigatearoundthe United States, shiftingthesourceof ourdatabygeography, wewillfindconsiderableconceptshiftregardingthedistributionof namesforsoftdrinksasshownin.7.3.
t .7.3 Conceptshiftforsoftdrinknamesinthe United States(CC-BY: Alan Mc Conchie, Pop Vs Soda.
com).
Ifweweretobuildamachinetranslationsystem, thedistribution ğ‘ƒâ€ğ‘¦ j xâ€ mightbedif- ferentdependingonourlocation.
Thisproblemcanbetrickytospot.
Wemighthopeto exploitknowledgethatshiftonlytakesplacegraduallyeitherinatemporalorgeographic sense.
4.7.2 Examplesof Distribution Shift Before delving into formalism and algorithms, we can discuss some concrete situations wherecovariateorconceptshiftmightnotbeobvious.
Medical Diagnostics Imaginethatyouwanttodesignanalgorithmtodetectcancer.
Youcollectdatafromhealthy andsickpeopleandyoutrainyouralgorithm.
Itworksfine, givingyouhighaccuracyand you conclude that you are ready for a successful career in medical diagnostics.
Not so fast.
Thedistributionsthatgaverisetothetrainingdataandthoseyouwillencounterinthewild 158 Linear Neural Networksfor Classification mightdifferconsiderably.
Thishappenedtoanunfortunatestartupthatsomeofweauthors workedwithyearsago.
Theyweredevelopingabloodtestforadiseasethatpredominantly affectsoldermenandhopedtostudyitusingbloodsamplesthattheyhadcollectedfrom patients.
However, itisconsiderablymoredifficulttoobtainbloodsamplesfromhealthy men than from sick patients already in the system.
To compensate, the startup solicited blooddonationsfromstudentsonauniversitycampustoserveashealthycontrolsinde- velopingtheir test.
Then theyaskedwhether wecould help them to builda classifier for detectingthedisease.
Asweexplainedtothem, itwouldindeedbeeasytodistinguishbetweenthehealthyand sickcohortswithnear-perfectaccuracy.
However, thatisbecausethetestsubjectsdiffered inage, hormonelevels, physicalactivity, diet, alcoholconsumption, andmanymorefac- tors unrelated to the disease.
This was unlikely to be the case with real patients.
Due to theirsamplingprocedure, wecouldexpecttoencounterextremecovariateshift.
Moreover, thiscasewasunlikelytobecorrectableviaconventionalmethods.
Inshort, theywasteda significantsumofmoney.
Self-Driving Cars Sayacompanywantedtoleveragemachinelearningfordevelopingself-drivingcars.
One keycomponenthereisaroadsidedetector.
Sincerealannotateddataisexpensivetoget, they had the (smart and questionable) idea to use synthetic data from a game rendering engineasadditionaltrainingdata.
Thisworkedreallywellonâ€œtestdataâ€drawnfromthe renderingengine.
Alas, insidearealcaritwasadisaster.
Asitturnedout, theroadsidehad beenrenderedwithaverysimplistictexture.
Moreimportantly, alltheroadsidehadbeen renderedwiththesametextureandtheroadsidedetectorlearnedaboutthisâ€œfeatureâ€very quickly.
Asimilarthinghappenedtothe USArmywhentheyfirsttriedtodetecttanksintheforest.
Theytookaerialphotographsoftheforestwithouttanks, thendrovethetanksintotheforest andtookanothersetofpictures.
Theclassifierappearedtoworkperfectly.
Unfortunately, it hadmerelylearnedhowtodistinguishtreeswithshadowsfromtreeswithoutshadowsâ€”the firstsetofpictureswastakenintheearlymorning, thesecondsetatnoon.
Nonstationary Distributions A much more subtle situation arises when the distribution changes slowly (also known as nonstationary distribution) and the model is not updated adequately.
Below are some typicalcases.
Wetrainacomputationaladvertisingmodelandthenfailtoupdateitfrequently(e.
g., we forgettoincorporatethatanobscurenewdevicecalledani Padwasjustlaunched).
Webuildaspamfilter.
Itworkswellatdetectingallspamthatwehaveseensofar.
But thenthespammerswiseupandcraftnewmessagesthatlookunlikeanythingwehave seenbefore.
159 Environmentand Distribution Shift We build a product recommendation system.
It works throughout the winter but then continuestorecommend Santahatslongafter Christmas.
More Anecdotes Webuildafacedetector.
Itworkswellonallbenchmarks.
Unfortunatelyitfailsontest dataâ€”theoffendingexamplesareclose-upswherethefacefillstheentireimage(no suchdatawasinthetrainingset).
Webuildawebsearchengineforthe USmarketandwanttodeployitinthe UK.
Wetrainanimageclassifierbycompilingalargedatasetwhereeachamongalargeset of classes is equally represented in the dataset, say 1000 categories, represented by 1000 images each.
Then we deploy the system in the real world, where the actual labeldistributionofphotographsisdecidedlynon-uniform.
4.7.3 Correctionof Distribution Shift Aswehavediscussed, therearemanycaseswheretrainingandtestdistributions ğ‘ƒâ€x,ğ‘¦â€ are different.
In some cases, we get lucky and the models work despite covariate, label, or concept shift.
In other cases, we can do better by employing principled strategies to copewiththeshift.
Theremainderofthissectiongrowsconsiderablymoretechnical.
The impatientreadercouldcontinueontothenextsectionasthismaterialisnotprerequisiteto subsequentconcepts.
Empirical Riskand Risk Letâ€™sfirstreflectonwhatexactlyishappeningduringmodeltraining: weiterateoverfea- turesandassociatedlabelsoftrainingdatafâ€x 1 ,ğ‘¦ 1 â€,...,â€xğ‘› ,ğ‘¦ ğ‘› â€gandupdatetheparam- etersofamodel ğ‘“ aftereveryminibatch.
Forsimplicitywedonotconsiderregularization, sowelargelyminimizethelossonthetraining: ğ‘› 1 mini ğ‘“ mize ğ‘› ğ‘™â€ğ‘“â€xğ‘– â€,ğ‘¦ ğ‘– â€, (4.7.1) ğ‘–=1 whereğ‘™ isthelossfunctionmeasuringâ€œhowbadâ€theprediction ğ‘“â€xğ‘– â€isgiventheassoci- atedlabel ğ‘¦ ğ‘–.
Statisticianscallthetermin(4.7.1)empiricalrisk.
Theempiricalriskisan averagelossoverthetrainingdataforapproximatingtherisk, whichistheexpectationof thelossovertheentirepopulationofdatadrawnfromtheirtruedistributionğ‘â€x,ğ‘¦â€: â€ â€ ğ¸ ğ‘â€x,ğ‘¦â€ Â»ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€â€¦ = ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€ğ‘â€x,ğ‘¦â€ ğ‘‘xğ‘‘ğ‘¦.
(4.7.2) However, in practice we typically cannot obtain the entire population of data.
Thus, em- piricalriskminimization, whichisminimizingtheempiricalriskin(4.7.1), isapractical strategyformachinelearning, withthehopeofapproximatelyminimizingtherisk.
160 Linear Neural Networksfor Classification Covariate Shift Correction Assumethatwewanttoestimatesomedependencyğ‘ƒâ€ğ‘¦ j xâ€forwhichwehavelabeleddata â€xğ‘– ,ğ‘¦ ğ‘– â€.
Unfortunately, theobservationsxğ‘– aredrawnfromsomesourcedistributionğ‘â€xâ€ rather than the target distribution ğ‘â€xâ€.
Fortunately, the dependency assumption means that the conditional distribution does not change: ğ‘â€ğ‘¦ j xâ€ = ğ‘â€ğ‘¦ j xâ€.
If the source distributionğ‘â€xâ€isâ€œwrongâ€, wecancorrectforthatbyusingthefollowingsimpleidentity intherisk: â€ â€ â€ â€ ğ‘â€xâ€ ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€ğ‘â€ğ‘¦ j xâ€ğ‘â€xâ€ ğ‘‘xğ‘‘ğ‘¦ = ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€ğ‘â€ğ‘¦ j xâ€ğ‘â€xâ€ ğ‘‘xğ‘‘ğ‘¦.
ğ‘â€xâ€ (4.7.3) Inotherwords, weneedtoreweigheachdataexamplebytheratiooftheprobabilitythatit wouldhavebeendrawnfromthecorrectdistributiontothatfromthewrongone: ğ›½ ğ‘– d = ef ğ‘ ğ‘ â€ â€ x x ğ‘– ğ‘– â€ â€ .
(4.7.4) Plugging in the weight ğ›½ ğ‘– for each data example â€xğ‘– ,ğ‘¦ ğ‘– â€ we can train our model using weightedempiricalriskminimization: ğ‘› 1 mini ğ‘“ mize ğ‘› ğ›½ ğ‘– ğ‘™â€ğ‘“â€xğ‘– â€,ğ‘¦ ğ‘– â€.
(4.7.5) ğ‘–=1 Alas, wedonotknowthatratio, sobeforewecandoanythingusefulweneedtoestimate it.
Manymethodsareavailable, includingsomefancyoperator-theoreticapproachesthat attempttorecalibratetheexpectationoperatordirectlyusingaminimum-normoramaxi- mumentropyprinciple.
Notethatforanysuchapproach, weneedsamplesdrawnfromboth distributionsâ€”theâ€œtrueâ€ ğ‘, e.
g., byaccesstotestdata, andtheoneusedforgeneratingthe training set ğ‘ (the latter is trivially available).
Note however, that we only need features x ğ‘â€xâ€; wedonotneedtoaccesslabelsğ‘¦ ğ‘â€ğ‘¦â€.
In this case, there exists a very effective approach that will give almost as good results astheoriginal: namely, logisticregression, whichisaspecialcaseofsoftmaxregression (see Section4.1)forbinaryclassification.
Thisisallthatisneededtocomputeestimated probabilityratios.
Welearnaclassifiertodistinguishbetweendatadrawnfrom ğ‘â€xâ€ and datadrawnfromğ‘â€xâ€.
Ifitisimpossibletodistinguishbetweenthetwodistributionsthen itmeansthattheassociatedinstancesareequallylikelytocomefromeitheroneofthose twodistributions.
Ontheotherhand, anyinstancesthatcanbewelldiscriminatedshould besignificantlyoverweightedorunderweightedaccordingly.
Forsimplicityâ€™ssakeassumethatwehaveanequalnumberofinstancesfrombothdistribu- tions ğ‘â€xâ€andğ‘â€xâ€, respectively.
Nowdenotebyğ‘§labelsthatare1fordatadrawnfrom ğ‘ and 1fordatadrawnfromğ‘.
Thentheprobabilityinamixeddatasetisgivenby ğ‘â€xâ€ ğ‘ƒâ€ğ‘§ =1 j xâ€ ğ‘â€xâ€ ğ‘ƒâ€ğ‘§ =1 j xâ€ = andhence = .
(4.7.6) ğ‘â€xâ€â€šğ‘â€xâ€ ğ‘ƒâ€ğ‘§ = 1 j xâ€ ğ‘â€xâ€ Thus, ifweusealogisticregressionapproach, where ğ‘ƒâ€ğ‘§ = 1 j xâ€ = 1 (â„isa 1â€šexpâ€ â„â€xâ€â€ 161 Environmentand Distribution Shift parametrizedfunction), itfollowsthat ğ›½ ğ‘– = expâ€ 1 â„ â€ â€ x 1 ğ‘– â€ â€š â€ ex â€1 pâ€ â€š e â„ x â€ p x â€ ğ‘– â€â€ â„ â€ â€xğ‘– â€â€â€ =expâ€â„â€xğ‘– â€â€.
(4.7.7) As a result, we need to solve two problems: the first, to distinguish between data drawn frombothdistributions, andthenaweightedempiricalriskminimizationproblemin(4.7.5) whereweweightermsby ğ›½ ğ‘–.
Nowwearereadytodescribeacorrectionalgorithm.
Supposethatwehaveatrainingset assume that xğ‘– for all 1 ğ‘– ğ‘› are drawn from some source distribution and uğ‘– for all 1 ğ‘– ğ‘š are drawn from the target distribution.
Here is a prototypical algorithm for correctingcovariateshift: 1.
Createabinary-classificationtrainingset: fâ€x 1 , 1â€,...,â€xğ‘› , 1â€,â€u 1 ,1â€,...,â€uğ‘š ,1â€g.
2.
Trainabinaryclassifierusinglogisticregressiontogetthefunctionâ„.
3.
Weightrainingdatausing ğ›½ ğ‘– =expâ€â„â€xğ‘– â€â€ orbetter ğ›½ ğ‘– =minâ€expâ€â„â€xğ‘– â€â€,ğ‘â€ forsome constantğ‘.
Notethattheabovealgorithmreliesonacrucialassumption.
Forthisschemetowork, we needthateachdataexampleinthetarget(e.
g., testtime)distributionhadnonzeroproba- bilityofoccurringattrainingtime.
Ifwefindapointwhere ğ‘â€xâ€ > 0butğ‘â€xâ€ = 0, then thecorrespondingimportanceweightshouldbeinfinity.
Label Shift Correction Assume that we are dealing with a classification task with ğ‘˜ categories.
Using the same notationin Section4.7.3,ğ‘andğ‘arethesourcedistribution(e.
g., trainingtime)andtarget distribution(e.
g., testtime), respectively.
Assumethatthedistributionoflabelsshiftsover time: ğ‘â€ğ‘¦â€ â‰  ğ‘â€ğ‘¦â€, buttheclass-conditionaldistributionstaysthesame: ğ‘â€x j ğ‘¦â€ = ğ‘â€x j ğ‘¦â€.
If the source distribution ğ‘â€ğ‘¦â€ is â€œwrongâ€, we can correct for that according to the followingidentityintheriskasdefinedin(4.7.2): â€ â€ â€ â€ ğ‘â€ğ‘¦â€ ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€ğ‘â€x j ğ‘¦â€ğ‘â€ğ‘¦â€ ğ‘‘xğ‘‘ğ‘¦ = ğ‘™â€ğ‘“â€xâ€,ğ‘¦â€ğ‘â€x j ğ‘¦â€ğ‘â€ğ‘¦â€ ğ‘‘xğ‘‘ğ‘¦.
ğ‘â€ğ‘¦â€ (4.7.8) Here, ourimportanceweightswillcorrespondtothelabellikelihoodratios: ğ‘â€ğ‘¦ â€ ğ›½ ğ‘– d = ef ğ‘â€ğ‘¦ ğ‘– â€ .
(4.7.9) ğ‘– Onenicethingaboutlabelshiftisthatifwehaveareasonablygoodmodelonthesource distribution, thenwecangetconsistentestimatesoftheseweightswithouteverhavingto dealwiththeambientdimension.
Indeeplearning, theinputstendtobehigh-dimensional objectslikeimages, whilethelabelsareoftensimplerobjectslikecategories.
To estimate the target label distribution, we first take our reasonably good off-the-shelf 162 Linear Neural Networksfor Classification classifier(typicallytrainedonthetrainingdata)andcomputeitsâ€œconfusionâ€matrixusing thevalidationset(alsofromthetrainingdistribution).
Theconfusionmatrix, C, issimplya ğ‘˜ ğ‘˜matrix, whereeachcolumncorrespondstothelabelcategory(groundtruth)andeach rowcorrespondstoourmodelâ€™spredictedcategory.
Eachcellâ€™svalueğ‘ ğ‘–ğ‘— isthefractionof totalpredictionsonthevalidationsetwherethetruelabelwas ğ‘— andourmodelpredicted ğ‘–.
Now, wecannotcalculatetheconfusionmatrixonthetargetdatadirectlybecausewedo not get to see the labels for the examples that we see in the wild, unless we invest in a complex real-time annotation pipeline.
What we can do, however, is average all of our modelâ€™s predictions at test time together, yielding the mean model outputs ğœ‡â€yË†â€ 2 Rğ‘˜ , wheretheğ‘–thelementğœ‡â€ğ‘¦Ë†ğ‘– â€isthefractionofthetotalpredictionsonthetestsetwhereour modelpredictedğ‘–.
Itturnsoutthatundersomemildconditionsâ€”ifourclassifierwasreasonablyaccuratein thefirstplace, andifthetargetdatacontainsonlycategoriesthatwehaveseenbefore, and if the label shift assumption holds in the first place (the strongest assumption here)â€”we canestimatethetestsetlabeldistributionbysolvingasimplelinearsystem Cğ‘â€yâ€ = ğœ‡â€yË†â€, (4.7.10) Ë because as an estimate ğ‘˜ ğ‘—=1 ğ‘ ğ‘–ğ‘— ğ‘â€ğ‘¦ ğ‘— â€ = ğœ‡â€ğ‘¦Ë†ğ‘– â€ holds for all 1 ğ‘– ğ‘˜, where ğ‘â€ğ‘¦ ğ‘— â€ is the ğ‘—th element of the ğ‘˜-dimensional label distribution vector ğ‘â€yâ€.
If our classifier is sufficientlyaccuratetobeginwith, thentheconfusionmatrix Cwillbeinvertible, andwe getasolution ğ‘â€yâ€ =C 1ğœ‡â€yË†â€.
Because we observe the labels on the source data, it is easy to estimate the distribution ğ‘â€ğ‘¦â€.
Then, for any training example ğ‘– with label ğ‘¦ ğ‘–, we can take the ratio of our esti- mated ğ‘â€ğ‘¦ ğ‘– â€ ğ‘â€ğ‘¦ ğ‘– â€ to calculate the weight ğ›½ ğ‘–, and plug this into weighted empirical risk minimizationin(4.7.5).
Concept Shift Correction Conceptshiftismuchhardertofixinaprincipledmanner.
Forinstance, inasituationwhere suddenlytheproblemchangesfromdistinguishingcatsfromdogstooneofdistinguishing white from black animals, it will be unreasonable to assume that we can do much better than just collecting new labels and training from scratch.
Fortunately, in practice, such extremeshiftsarerare.
Instead, whatusuallyhappensisthatthetaskkeepsonchanging slowly.
Tomakethingsmoreconcrete, herearesomeexamples: Incomputationaladvertising, newproductsarelaunched, oldproductsbecomelesspop- ular.
Thismeansthatthedistributionoveradsandtheirpopularitychangesgradually andanyclick-throughratepredictorneedstochangegraduallywithit.
Traffic camera lenses degrade gradually due to environmental wear, affecting image qualityprogressively.
Newscontentchangesgradually(i.
e., mostofthenewsremainsunchangedbutnewsto- riesappear).
163 Environmentand Distribution Shift In suchcases, wecan use the same approachthat weused fortraining networksto make themadapttothechangeinthedata.
Inotherwords, weusetheexistingnetworkweights andsimplyperformafewupdatestepswiththenewdataratherthantrainingfromscratch.
4.7.4 ATaxonomyof Learning Problems Armedwithknowledgeabouthowtodealwithchangesindistributions, wecannowcon- sidersomeotheraspectsofmachinelearningproblemformulation.
Batch Learning Inbatchlearning, wehaveaccesstotrainingfeaturesandlabelsfâ€x 1 ,ğ‘¦ 1 â€,...,â€xğ‘› ,ğ‘¦ ğ‘› â€g, whichweusetotrainamodel ğ‘“â€xâ€.
Lateron, wedeploythismodeltoscorenewdataâ€x,ğ‘¦â€ drawnfromthesamedistribution.
Thisisthedefaultassumptionforanyoftheproblems thatwediscusshere.
Forinstance, wemighttrainacatdetectorbasedonlotsofpictures ofcatsanddogs.
Oncewehavetrainedit, weshipitaspartofasmartcatdoorcomputer visionsystemthatletsonlycatsin.
Thisistheninstalledinacustomerâ€™shomeandisnever updatedagain(barringextremecircumstances).
Online Learning Nowimaginethatthedataâ€xğ‘– ,ğ‘¦ ğ‘– â€arrivesonesampleatatime.
Morespecifically, assume that we first observe xğ‘–, then we need to come up with an estimate ğ‘“â€xğ‘– â€.
Only once we have done this do we observe ğ‘¦ ğ‘– and so receive a reward or incur a loss, given our decision.
Many real problems fall into this category.
For example, we need to predict tomorrowâ€™s stock price, which allows us to trade based on that estimate and at the end of the day we find out whether our estimate made us a profit.
In other words, in online learning, we have the following cycle where we are continuously improving our model givennewobservations: model ğ‘“ ğ‘¡ ! dataxğ‘¡ ! estimate ğ‘“ ğ‘¡ â€xğ‘¡ â€ ! (4.7.11) observationğ‘¦ ğ‘¡ ! lossğ‘™â€ğ‘¦ ğ‘¡ , ğ‘“ ğ‘¡ â€xğ‘¡ â€â€ ! model ğ‘“ ğ‘¡â€š1 Bandits Banditsareaspecialcaseoftheproblemabove.
Whileinmostlearningproblemswehave acontinuouslyparametrizedfunction ğ‘“ wherewewanttolearnitsparameters(e.
g., adeep network), inabanditproblemweonlyhaveafinitenumberofarmsthatwecanpull, i.
e., a finite number of actions that wecan take.
It is not very surprising that forthis simpler problem stronger theoretical guarantees in terms of optimality can be obtained.
We list itmainlysincethisproblemisoften(confusingly)treatedasifitwereadistinctlearning setting.
164 Linear Neural Networksfor Classification Control Inmanycasestheenvironmentrememberswhatwedid.
Notnecessarilyinanadversarial mannerbutitwilljustrememberandtheresponsewilldependonwhathappenedbefore.
For instance, a coffee boiler controller will observe different temperatures depending on whether it was heating the boiler previously.
PID (proportional-integral-derivative) con- troller algorithms are a popular choice there.
Likewise, a userâ€™s behavior on a news site willdependonwhatweshowedthempreviously(e.
g., theywillreadmostnewsonlyonce).
Manysuchalgorithms forma modelof theenvironmentinwhichtheyact soas tomake theirdecisionsappearlessrandom.
Recently, controltheory(e.
g., PIDvariants)hasalso beenusedtoautomaticallytunehyperparameterstoachievebetterdisentanglingandrecon- structionquality, andimprovethediversityofgeneratedtextandthereconstructionquality ofgeneratedimages(Shaoetal.,2020).
Reinforcement Learning In the more general case of an environment with memory, we may encounter situations where the environment is trying to cooperate with us (cooperative games, in particular for non-zero-sum games), or others where the environment will try to win.
Chess, Go, Backgammon, or Star Craftaresomeofthecasesinreinforcementlearning.
Likewise, we mightwanttobuildagoodcontrollerforautonomouscars.
Othercarsarelikelytorespond totheautonomouscarâ€™sdrivingstyleinnontrivialways, e.
g., tryingtoavoidit, tryingto causeanaccident, ortryingtocooperatewithit.
Consideringthe Environment Onekeydistinctionbetweenthedifferentsituationsaboveisthatastrategythatmighthave workedthroughoutinthecaseofastationaryenvironment, mightnotworkthroughoutin anenvironmentthatcanadapt.
Forinstance, anarbitrageopportunitydiscoveredbyatrader islikelytodisappearonceitisexploited.
Thespeedandmanneratwhichtheenvironment changesdeterminestoalargeextentthetypeofalgorithmsthatwecanbringtobear.
For instance, if we know that things may only change slowly, we can force any estimate to change only slowly, too.
If we know that the environment might change instantaneously, butonlyveryinfrequently, wecanmakeallowancesforthat.
Thesetypesofknowledgeare crucialfortheaspiringdatascientistindealingwithconceptshift, i.
e., whentheproblem thatisbeingsolvedcanchangeovertime.
4.7.5 Fairness, Accountability, and Transparencyin Machine Learning Finally, itisimportanttorememberthatwhenyoudeploymachinelearningsystemsyou arenotmerelyoptimizingapredictivemodelâ€”youaretypicallyprovidingatoolthatwill beusedto(partiallyorfully)automatedecisions.
Thesetechnicalsystemscanimpactthe livesofindividualswhoaresubjecttotheresultingdecisions.
Theleapfromconsidering predictionstomakingdecisionsraisesnotonlynewtechnicalquestions, butalsoaslewof 165 Environmentand Distribution Shift ethicalquestionsthatmustbecarefullyconsidered.
Ifwearedeployingamedicaldiagnos- ticsystem, weneedtoknowforwhichpopulationsitmayworkandforwhichitmaynot.
Overlookingforeseeableriskstothewelfareofasubpopulationcouldcauseustoadminis- terinferiorcare.
Moreover, oncewecontemplatedecision-makingsystems, wemuststep backandreconsiderhowweevaluateourtechnology.
Amongotherconsequencesofthis changeofscope, wewillfindthataccuracyisseldomtherightmeasure.
Forinstance, when translatingpredictionsintoactions, wewilloftenwanttotakeintoaccountthepotentialcost sensitivityoferringinvariousways.
Ifonewayofmisclassifyinganimagecouldbeper- ceivedasaracialsleightofhand, whilemisclassificationtoadifferentcategorywouldbe harmless, thenwemightwanttoadjustourthresholdsaccordingly, accountingforsocietal valuesindesigningthedecision-makingprotocol.
Wealsowanttobecarefulabouthow predictionsystemscanleadtofeedbackloops.
Forexample, considerpredictivepolicing systems, whichallocatepatrolofficerstoareaswithhighforecastedcrime.
Itiseasytosee howaworryingpatterncanemerge: 1.
Neighborhoodswithmorecrimegetmorepatrols.
2.
Consequently, morecrimesarediscoveredintheseneighborhoods, enteringthetraining dataavailableforfutureiterations.
3.
Exposedtomorepositives, themodelpredictsyetmorecrimeintheseneighborhoods.
4.
Inthenextiteration, theupdatedmodeltargetsthesameneighborhoodevenmoreheav- ilyleadingtoyetmorecrimesdiscovered, etc.
Often, thevariousmechanismsbywhichamodelâ€™spredictionsbecomecoupledtoitstrain- ing data are unaccounted for in the modeling process.
This can lead to what researchers call runaway feedback loops.
Additionally, we want to be careful about whether we are addressingtherightprobleminthefirstplace.
Predictivealgorithmsnowplayanoutsize roleinmediatingthedisseminationofinformation.
Shouldthenewsthatanindividualen- countersbedeterminedbythesetof Facebookpagestheyhave Liked? Thesearejustafew amongthemanypressingethicaldilemmasthatyoumightencounterinacareerinmachine learning.
4.7.6 Summary Inmanycasestrainingandtestsetsdonotcomefromthesamedistribution.
Thisiscalled distributionshift.
Theriskistheexpectationofthelossovertheentirepopulationofdata drawnfromtheirtruedistribution.
However, thisentirepopulationisusuallyunavailable.
Empiricalriskisanaveragelossoverthetrainingdatatoapproximatetherisk.
Inpractice, weperformempiricalriskminimization.
Under the corresponding assumptions, covariate and label shift can be detected and cor- rectedforattesttime.
Failuretoaccountforthisbiascanbecomeproblematicattesttime.
Insomecases, theenvironmentmayrememberautomatedactionsandrespondinsurprising ways.
We must account for this possibility when building models and continue to moni- torlivesystems, opentothepossibilitythatourmodelsandtheenvironmentwillbecome entangledinunanticipatedways.
166 Linear Neural Networksfor Classification 4.7.7 Exercises 1.
Whatcouldhappenwhenwechangethebehaviorofasearchengine? Whatmightthe usersdo? Whatabouttheadvertisers? 2.
Implementacovariateshiftdetector.
Hint: buildaclassifier.
3.
Implementacovariateshiftcorrector.
4.
Besides distribution shift, what else could affect how the empirical risk approximates therisk? Discussions101.
101 5 Multilayer Perceptrons Inthischapter, wewillintroduceyourfirsttrulydeepnetwork.
Thesimplestdeepnetworks arecalledmultilayerperceptrons, andtheyconsistofmultiplelayersofneuronseachfully connected to those in the layer below (from which they receive input) and those above (whichthey, inturn, influence).
Althoughautomaticdifferentiationsignificantlysimplifies theimplementationofdeeplearningalgorithms, wewilldivedeepintohowthesegradi- entsarecalculatedindeepnetworks.
Thenwewillbereadytodiscussissuesrelatingto numerical stability and parameter initialization that are key to successfully training deep networks.
Whenwetrainsuchhigh-capacitymodelsweruntheriskofoverfitting.
Thus, wewillrevisitregularizationandgeneralizationfordeepnetworks.
Throughout, weaimto giveyouafirmgraspnotjustoftheconceptsbutalsoofthepracticeofusingdeepnetworks.
Attheendofthischapter, weapplywhatwehaveintroducedsofartoarealcase: house priceprediction.
Wepuntmattersrelatingtothecomputationalperformance, scalability, andefficiencyofourmodelstosubsequentchapters.
5.1 Multilayer Perceptrons In Section4.1, weintroducedsoftmaxregression, implementingthealgorithmfromscratch (Section4.4)andusinghigh-level APIs(Section4.5).
Thisallowedustotrainclassifiersca- pableofrecognizing10categoriesofclothingfromlow-resolutionimages.
Alongtheway, we learned how to wrangle data, coerce our outputs into a valid probability distribution, applyanappropriatelossfunction, andminimizeitwithrespecttoourmodelâ€™sparameters.
Now that we have mastered these mechanics in the context of simple linear models, we canlaunchourexplorationofdeepneuralnetworks, thecomparativelyrichclassofmodels withwhichthisbookisprimarilyconcerned.
%matplotlib inline import torch from d2l import torch as d2l 5.1.1 Hidden Layers Wedescribedaffinetransformationsin Section3.1.1aslineartransformationswithadded bias.
Tobegin, recallthemodelarchitecturecorrespondingtooursoftmaxregressionex- 167 168 Multilayer Perceptrons ample, illustrated in .1.1.
This model maps inputs directly to outputs via a single affinetransformation, followedbyasoftmaxoperation.
Ifourlabelstrulywererelatedto the input data by a simple affine transformation, then this approach would be sufficient.
However, linearity(inaffinetransformations)isastrongassumption.
Limitationsof Linear Models For example, linearity implies the weaker assumption of monotonicity, i.
e., that any in- crease in our feature must either always cause an increase in our modelâ€™s output (if the corresponding weight is positive), or always cause a decrease in our modelâ€™s output (if the corresponding weight is negative).
Sometimes that makes sense.
For example, if we weretryingtopredictwhetheranindividualwillrepayaloan, wemightreasonablyassume thatallotherthingsbeingequal, anapplicantwithahigherincomewouldalwaysbemore likely to repay than one with a lower income.
While monotonic, this relationship likely isnotlinearlyassociatedwiththeprobabilityofrepayment.
Anincreaseinincomefrom $0 to $50,000 likely corresponds to a bigger increase in likelihood of repayment than an increasefrom$1millionto$1.05million.
Onewaytohandlethismightbetopostprocess our outcome such that linearity becomes more plausible, by using the logistic map (and thusthelogarithmoftheprobabilityofoutcome).
Notethatwecaneasilycomeupwithexamplesthatviolatemonotonicity.
Sayforexample that we want to predict health as a function of body temperature.
For individuals with a normalbodytemperatureabove37Â°C(98.6Â°F), highertemperaturesindicategreaterrisk.
However, ifthebodytemperaturesdropsbelow37Â°C, lowertemperaturesindicategreater risk! Again, wemightresolvetheproblemwithsomecleverpreprocessing, suchasusing thedistancefrom37Â°Casafeature.
Butwhataboutclassifyingimagesofcatsanddogs? Shouldincreasingtheintensityofthe pixelatlocation(13,17)alwaysincrease(oralwaysdecrease)thelikelihoodthattheimage depictsadog? Relianceonalinearmodelcorrespondstotheimplicitassumptionthatthe onlyrequirementfordifferentiatingcatsanddogsistoassessthebrightnessofindividual pixels.
Thisapproachisdoomedtofailinaworldwhereinvertinganimagepreservesthe category.
And yet despite the apparent absurdity of linearity here, as compared with our previous examples, itislessobviousthatwecouldaddresstheproblemwithasimplepreprocessing fix.
Thatis, becausethesignificanceofanypixeldependsincomplexwaysonitscontext (thevaluesofthesurroundingpixels).
Whiletheremightexistarepresentationofourdata thatwouldtakeintoaccounttherelevantinteractionsamongourfeatures, ontopofwhich alinearmodelwouldbesuitable, wesimplydonotknowhowtocalculateitbyhand.
With deepneuralnetworks, weusedobservationaldatatojointlylearnbotharepresentationvia hiddenlayersandalinearpredictorthatactsuponthatrepresentation.
This problem of nonlinearity has been studied for at least a century (Fisher, 1925).
For instance, decisiontreesintheirmostbasicformuseasequenceofbinarydecisionstode- cide upon class membership (Quinlan, 1993).
Likewise, kernel methods have been used formanydecadestomodelnonlineardependencies(Aronszajn,1950).
Thishasfoundits 169 Multilayer Perceptrons wayintononparametricsplinemodels(Wahba,1990)andkernelmethods(SchÃ¶lkopfand Smola, 2002).
It is also something that the brain solves quite naturally.
After all, neu- ronsfeedintootherneuronswhich, inturn, feedintootherneuronsagain(RamÃ³ny Cajal and Azoulay, 1894).
Consequently we have a sequence of relatively simple transforma- tions.
Incorporating Hidden Layers We can overcome the limitations of linear models by incorporating one or more hidden layers.
The easiest way to do this is to stack many fully connected layers on top of one another.
Eachlayerfeedsintothelayeraboveit, untilwegenerateoutputs.
Wecanthinkof thefirst ğ¿ 1layersasourrepresentationandthefinallayerasourlinearpredictor.
This architecture is commonly called a multilayer perceptron, often abbreviated as MLP (.1.1).
t .1.1 An MLPwithahiddenlayeroffivehiddenunits.
This MLP has four inputs, three outputs, and its hidden layer contains five hidden units.
Sincetheinputlayerdoesnotinvolveanycalculations, producingoutputswiththisnetwork requires implementing the computations for both the hidden and output layers; thus, the number of layers in this MLP is two.
Note that both layers are fully connected.
Every inputinfluenceseveryneuroninthehiddenlayer, andeachoftheseinturninfluencesevery neuronintheoutputlayer.
Alas, wearenotquitedoneyet.
From Linearto Nonlinear Asbefore, wedenotebythematrix X2Rğ‘› ğ‘‘ aminibatchofğ‘›exampleswhereeachexam- plehasğ‘‘ inputs(features).
Foraone-hidden-layer MLPwhosehiddenlayerhas â„hidden units, wedenoteby H 2 Rğ‘› â„ theoutputsofthehiddenlayer, whicharehiddenrepresen- tations.
Sincethehiddenandoutputlayersarebothfullyconnected, wehavehidden-layer weights Wâ€1â€ 2Rğ‘‘ â„ andbiasesbâ€1â€ 2R1 â„ andoutput-layerweights Wâ€2â€ 2Râ„ ğ‘ and biasesbâ€2â€ 2 R1 ğ‘ .
Thisallowsustocalculatetheoutputs O 2 Rğ‘› ğ‘ oftheone-hidden- layer MLPasfollows: H=XW â€1â€ â€šb â€1â€, (5.1.1) O=HW â€2â€ â€šb â€2â€.
Note that after adding the hidden layer, our model now requires us to track and update additionalsetsofparameters.
Sowhathavewegainedinexchange? Youmightbesurprised 170 Multilayer Perceptrons tofindoutthatâ€”inthemodeldefinedaboveâ€”wegainnothingforourtroubles! Thereason isplain.
Thehiddenunitsabovearegivenbyanaffinefunctionoftheinputs, andtheoutputs (pre-softmax)arejustanaffinefunctionofthehiddenunits.
Anaffinefunctionofanaffine function is itself an affine function.
Moreover, our linear model was already capable of representinganyaffinefunction.
Toseethisformallywecanjustcollapseoutthehiddenlayerintheabovedefinition, yielding anequivalentsingle-layermodelwithparameters W = Wâ€1â€Wâ€2â€ andb = bâ€1â€Wâ€2â€ â€š bâ€2â€ : O= â€XW â€1â€ â€šb â€1â€â€W â€2â€ â€šb â€2â€ =XW â€1â€ W â€2â€ â€šb â€1â€ W â€2â€ â€šb â€2â€ =XWâ€šb.
(5.1.2) In order to realize the potential of multilayer architectures, we need one more key ingre- dient: a nonlinear activation function ğœ to be applied to each hidden unit following the affinetransformation.
Forinstance, apopularchoiceisthe Re LU(rectifiedlinearunit)ac- tivation function (Nair and Hinton, 2010) ğœâ€ğ‘¥â€ = maxâ€0,ğ‘¥â€ operating on its arguments elementwise.
Theoutputsofactivationfunctions ğœâ€ â€ arecalledactivations.
Ingeneral, withactivationfunctionsinplace, itisnolongerpossibletocollapseour MLPintoalinear model: H=ğœâ€XW â€1â€ â€šb â€1â€â€, (5.1.3) O=HW â€2â€ â€šb â€2â€.
Since each row in X corresponds to an example in the minibatch, with some abuse of notation, wedefinethenonlinearityğœtoapplytoitsinputsinarowwisefashion, i.
e., one example at a time.
Note that we used the same notation for softmax when we denoted a rowwiseoperationin Section4.1.1.
Quitefrequentlytheactivationfunctionsweuseapply notmerelyrowwisebutelementwise.
Thatmeansthataftercomputingthelinearportionof thelayer, wecancalculateeachactivationwithoutlookingatthevaluestakenbytheother hiddenunits.
To build more general MLPs, we can continue stacking such hidden layers, e.
g., Hâ€1â€ = ğœ â€XWâ€1â€â€šbâ€1â€â€and Hâ€2â€ =ğœ â€Hâ€1â€Wâ€2â€â€šbâ€2â€â€, oneatopanother, yieldingevermore 1 2 expressivemodels.
Universal Approximators Weknowthatthebrainiscapableofverysophisticatedstatisticalanalysis.
Assuch, itis worthasking, justhowpowerfuladeepnetworkcouldbe.
Thisquestionhasbeenanswered multipletimes, e.
g., in Cybenko(1989)inthecontextof MLPs, andin Micchelli(1984)in thecontextofreproducingkernel Hilbertspacesinawaythatcouldbeseenasradialbasis function(RBF)networkswithasinglehiddenlayer.
These(andrelatedresults)suggestthat even with a single-hidden-layer network, given enough nodes (possibly absurdly many), and the right set of weights, we can model any function.
Actually learning that function is the hard part, though.
You might think of your neural network as being a bit like the C programming language.
The language, like any other modern language, is capable of 171 Multilayer Perceptrons expressing any computable program.
But actually coming up with a program that meets yourspecificationsisthehardpart.
Moreover, justbecauseasingle-hidden-layernetworkcanlearnanyfunctiondoesnotmean that you should try to solve all of your problems with one.
In fact, in this case kernel methodsarewaymoreeffective, sincetheyarecapableofsolvingtheproblemexactlyeven in infinite dimensional spaces (Kimeldorf and Wahba, 1971, SchÃ¶lkopf et al., 2001).
In fact, we can approximate many functions much more compactly by using deeper (rather thanwider)networks(Simonyanand Zisserman,2014).
Wewilltouchuponmorerigorous argumentsinsubsequentchapters.
5.1.2 Activation Functions Activationfunctionsdecidewhetheraneuronshouldbeactivatedornotbycalculatingthe weighted sum and further adding bias to it.
They are differentiable operators for trans- forminginputsignalstooutputs, whilemostofthemaddnonlinearity.
Becauseactivation functionsarefundamentaltodeeplearning, letâ€™sbrieflysurveysomecommonones.
Re LUFunction The most popular choice, due to both simplicity of implementation and its good perfor- manceonavarietyofpredictivetasks, istherectifiedlinearunit(Re LU)(Nairand Hinton, 2010).
Re LU provides a very simple nonlinear transformation.
Given an element ğ‘¥, the functionisdefinedasthemaximumofthatelementand0: Re LUâ€ğ‘¥â€ =maxâ€ğ‘¥,0â€.
(5.1.4) Informally, the Re LUfunctionretainsonlypositiveelementsanddiscardsallnegativeel- ementsbysettingthecorrespondingactivationsto0.
Togainsomeintuition, wecanplot thefunction.
Asyoucansee, theactivationfunctionispiecewiselinear.
x = torch.
arange(-8.0, 8.0, 0.1, requires_grad=True) y = torch.
relu(x) d2l.
plot(x.
detach(), y.
detach(), 'x', 'relu(x)', figsize=(5, 2.5)) Whentheinputisnegative, thederivativeofthe Re LUfunctionis0, andwhentheinput is positive, the derivative of the Re LU function is 1.
Note that the Re LU function is not 172 Multilayer Perceptrons differentiablewhentheinputtakesvaluepreciselyequalto0.
Inthesecases, wedefaultto theleft-hand-side derivativeand saythat the derivativeis 0 when the inputis 0.
Wecan getawaywiththisbecausetheinputmayneveractuallybezero(mathematicianswouldsay thatitisnondifferentiableona setofmeasurezero).
Thereisan oldadagethatifsubtle boundary conditions matter, we are probably doing (real) mathematics, not engineering.
Thatconventionalwisdommayapplyhere, oratleast, thefactthatwearenotperforming constrainedoptimization(Mangasarian, 1965, Rockafellar,1970).
Weplotthederivative ofthe Re LUfunctionbelow.
y.
backward(torch.
ones_like(x), retain_graph=True) d2l.
plot(x.
detach(), x.
grad, 'x', 'grad of relu', figsize=(5, 2.5)) Thereasonforusing Re LUisthatitsderivativesareparticularlywellbehaved: eitherthey vanishortheyjustlettheargumentthrough.
Thismakesoptimizationbetterbehavedand it mitigated the well-documented problem of vanishing gradients that plagued previous versionsofneuralnetworks(moreonthislater).
Notethattherearemanyvariantstothe Re LUfunction, includingtheparametrized Re LU (p Re LU) function (He et al., 2015).
This variation adds a linear term to Re LU, so some informationstillgetsthrough, evenwhentheargumentisnegative: p Re LUâ€ğ‘¥â€ =maxâ€0,ğ‘¥â€â€šğ›¼minâ€0,ğ‘¥â€.
(5.1.5) Sigmoid Function Thesigmoidfunctiontransformsthoseinputswhosevalueslieinthedomain R, tooutputs thatlieontheinterval(0,1).
Forthatreason, thesigmoidisoftencalledasquashingfunc- tion: itsquashesanyinputintherange(-inf, inf)tosomevalueintherange(0,1): 1 sigmoidâ€ğ‘¥â€ = .
(5.1.6) 1â€šexpâ€ ğ‘¥â€ In the earliest neural networks, scientists were interested in modeling biological neurons that either fire or do not fire.
Thus the pioneers of this field, going all the way back to Mc Cullochand Pitts, theinventorsoftheartificialneuron, focusedonthresholdingunits (Mc Culloch and Pitts, 1943).
A thresholding activation takes value 0 when its input is belowsomethresholdandvalue1whentheinputexceedsthethreshold.
173 Multilayer Perceptrons Whenattentionshiftedtogradient-basedlearning, thesigmoidfunctionwasanaturalchoice becauseitisasmooth, differentiableapproximationtoathresholdingunit.
Sigmoidsare stillwidelyusedasactivationfunctionsontheoutputunitswhenwewanttointerpretthe outputsasprobabilitiesforbinaryclassificationproblems: youcanthinkofthesigmoidasa specialcaseofthesoftmax.
However, thesigmoidhaslargelybeenreplacedbythesimpler andmoreeasilytrainable Re LUformostuseinhiddenlayers.
Muchofthishastodowith the fact that the sigmoid poses challenges for optimization (Le Cun et al., 1998) since its gradientvanishesforlargepositiveandnegativearguments.
Thiscanleadtoplateausthat are difficult to escape from.
Nonetheless sigmoids are important.
In later chapters (e.
g., Section 10.1) on recurrent neural networks, we will describe architectures that leverage sigmoidunitstocontroltheflowofinformationacrosstime.
Below, weplotthesigmoidfunction.
Notethatwhentheinputiscloseto0, thesigmoid functionapproachesalineartransformation.
y = torch.
sigmoid(x) d2l.
plot(x.
detach(), y.
detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5)) Thederivativeofthesigmoidfunctionisgivenbythefollowingequation: ğ‘‘ expâ€ ğ‘¥â€ sigmoidâ€ğ‘¥â€ = =sigmoidâ€ğ‘¥â€â€1 sigmoidâ€ğ‘¥â€â€.
(5.1.7) ğ‘‘ğ‘¥ â€1â€šexpâ€ ğ‘¥â€â€2 Thederivativeofthesigmoidfunctionisplottedbelow.
Notethatwhentheinputis0, the derivativeofthesigmoidfunctionreachesamaximumof0.25.
Astheinputdivergesfrom 0ineitherdirection, thederivativeapproaches0.
# Clear out previous gradients x.
grad.
data.
zero_() y.
backward(torch.
ones_like(x), retain_graph=True) d2l.
plot(x.
detach(), x.
grad, 'x', 'grad of sigmoid', figsize=(5, 2.5)) Tanh Function Likethesigmoidfunction, thetanh(hyperbolictangent)functionalsosquashesitsinputs, transformingthemintoelementsontheintervalbetween 1and1: 1 expâ€ 2ğ‘¥â€ tanhâ€ğ‘¥â€ = .
(5.1.8) 1â€šexpâ€ 2ğ‘¥â€ 174 Multilayer Perceptrons Weplotthetanhfunctionbelow.
Notethatasinputnears0, thetanhfunctionapproachesa lineartransformation.
Althoughtheshapeofthefunctionissimilartothatofthesigmoid function, thetanhfunctionexhibitspointsymmetryabouttheoriginofthecoordinatesys- tem(Kalmanand Kwasny,1992).
y = torch.
tanh(x) d2l.
plot(x.
detach(), y.
detach(), 'x', 'tanh(x)', figsize=(5, 2.5)) Thederivativeofthetanhfunctionis: ğ‘‘ tanhâ€ğ‘¥â€ =1 tanh2â€ğ‘¥â€.
(5.1.9) ğ‘‘ğ‘¥ Itisplottedbelow.
Astheinputnears0, thederivativeofthetanhfunctionapproachesa maximumof1.
Andaswesawwiththesigmoidfunction, asinputmovesawayfrom0in eitherdirection, thederivativeofthetanhfunctionapproaches0.
# Clear out previous gradients x.
grad.
data.
zero_() y.
backward(torch.
ones_like(x), retain_graph=True) d2l.
plot(x.
detach(), x.
grad, 'x', 'grad of tanh', figsize=(5, 2.5)) 5.1.3 Summaryand Discussion Wenowknowhowtoincorporatenonlinearitiestobuildexpressivemultilayerneuralnet- workarchitectures.
Asasidenote, yourknowledgealreadyputsyouincommandofasim- ilartoolkittoapractitionercirca1990.
Insomeways, youhaveanadvantageoveranyone 175 Multilayer Perceptrons workingbackthen, becauseyoucanleveragepowerfulopen-sourcedeeplearningframe- works to build models rapidly, using only a few lines of code.
Previously, training these networksrequiredresearcherstocodeuplayersandderivativesexplicitlyin C, Fortran, or even Lisp(inthecaseof Le Net).
Asecondarybenefitisthat Re LUissignificantlymoreamenabletooptimizationthanthe sigmoidorthetanhfunction.
Onecouldarguethatthiswasoneofthekeyinnovationsthat helpedtheresurgenceofdeeplearningoverthepastdecade.
Note, though, thatresearchin activationfunctionshasnotstopped.
Forinstance, the GELU(Gaussianerrorlinearunit) activationfunctionğ‘¥Î¦â€ğ‘¥â€by Hendrycksand Gimpel(2016)(Î¦â€ğ‘¥â€isthestandard Gaussian cumulativedistributionfunction)andthe Swishactivationfunctionğœâ€ğ‘¥â€ =ğ‘¥sigmoidâ€ğ›½ğ‘¥â€ asproposedin Ramachandranetal.
(2017)canyieldbetteraccuracyinmanycases.
5.1.4 Exercises 1.
Showthataddinglayerstoalinear deepnetwork, i.
e., anetworkwithoutnonlinearity ğœ can never increase the expressive power of the network.
Give an example where it activelyreducesit.
2.
Computethederivativeofthep Re LUactivationfunction.
3.
Computethederivativeofthe Swishactivationfunctionğ‘¥sigmoidâ€ğ›½ğ‘¥â€.
4.
Show that an MLP using only Re LU (or p Re LU) constructs a continuous piecewise linearfunction.
5.
Sigmoidandtanhareverysimilar.
1.
Showthattanhâ€ğ‘¥â€â€š1=2sigmoidâ€2ğ‘¥â€.
2.
Prove that the function classes parametrized by both nonlinearities are identical.
Hint: affinelayershavebiasterms, too.
6.
Assumethatwehaveanonlinearitythatappliestooneminibatchatatime, suchasthe batchnormalization(Ioffeand Szegedy,2015).
Whatkindsofproblemsdoyouexpect thistocause? 102 7.
Provideanexamplewherethegradientsvanishforthesigmoidactivationfunction.
Discussions102.
176 Multilayer Perceptrons 5.2 Implementation of Multilayer Perceptrons Multilayerperceptrons(MLPs)arenotmuchmorecomplextoimplementthansimplelinear models.
Thekeyconceptualdifferenceisthatwenowconcatenatemultiplelayers.
import torch from torch import nn from d2l import torch as d2l 5.2.1 Implementationfrom Scratch Letâ€™sbeginagainbyimplementingsuchanetworkfromscratch.
Initializing Model Parameters Recall that Fashion-MNIST contains 10 classes, and that each image consists of a 28 28 = 784gridofgrayscalepixelvalues.
Asbeforewewilldisregardthespatialstructure amongthepixelsfornow, sowecanthinkofthisasaclassificationdatasetwith784input featuresand10classes.
Tobegin, wewillimplementan MLPwithonehiddenlayerand256 hiddenunits.
Boththenumberoflayersandtheirwidthareadjustable(theyareconsidered hyperparameters).
Typically, wechoosethelayerwidthstobedivisiblebylargerpowersof 2.
Thisiscomputationallyefficientduetothewaymemoryisallocatedandaddressedin hardware.
Again, wewillrepresentourparameterswithseveraltensors.
Notethatforeverylayer, we mustkeeptrackofoneweightmatrixandonebiasvector.
Asalways, weallocatememory forthegradientsofthelosswithrespecttotheseparameters.
In the code below we use nn.
Parameter to automatically register a class attribute as a parametertobetrackedbyautograd(Section2.5).
class MLPScratch(d2l.
Classifier): def __init__(self, num_inputs, num_outputs, num_hiddens, lr, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
W1 = nn.
Parameter(torch.
randn(num_inputs, num_hiddens) * sigma) self.
b1 = nn.
Parameter(torch.
zeros(num_hiddens)) self.
W2 = nn.
Parameter(torch.
randn(num_hiddens, num_outputs) * sigma) self.
b2 = nn.
Parameter(torch.
zeros(num_outputs)) Model To make sure we know how everything works, we will implement the Re LU activation ourselvesratherthaninvokingthebuilt-inrelufunctiondirectly.
177 Implementationof Multilayer Perceptrons def relu(X): a = torch.
zeros_like(X) return torch.
max(X, a) Sincewearedisregardingspatialstructure, wereshapeeachtwo-dimensionalimageinto aflatvectoroflengthnum_inputs.
Finally, weimplementourmodelwithjustafewlines ofcode.
Sinceweusetheframeworkbuilt-inautogradthisisallthatittakes.
@d2l.
add_to_class(MLPScratch) def forward(self, X): X = X.
reshape((-1, self.
num_inputs)) H = relu(torch.
matmul(X, self.
W1) + self.
b1) return torch.
matmul(H, self.
W2) + self.
b2 Training Fortunately, the training loop for MLPs is exactly the same as for softmax regression.
Wedefinethemodel, data, andtrainer, thenfinallyinvokethefitmethodonmodeland data.
model = MLPScratch(num_inputs=784, num_outputs=10, num_hiddens=256, lr=0.1) data = d2l.
Fashion MNIST(batch_size=256) trainer = d2l.
Trainer(max_epochs=10) trainer.
fit(model, data) 5.2.2 Concise Implementation As you might expect, by relying on the high-level APIs, we can implement MLPs even moreconcisely.
Model Comparedwithourconciseimplementationofsoftmaxregressionimplementation(Section 4.5), theonlydifferenceisthatweaddtwofullyconnectedlayerswherewepreviouslyadded onlyone.
Thefirstisthehiddenlayer, thesecondistheoutputlayer.
178 Multilayer Perceptrons class MLP(d2l.
Classifier): def __init__(self, num_outputs, num_hiddens, lr): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential(nn.
Flatten(), nn.
Lazy Linear(num_hiddens), nn.
Re LU(), nn.
Lazy Linear(num_outputs)) Previously, we defined forward methods for models to transform input using the model parameters.
These operations are essentially a pipeline: you take an input and apply a transformation (e.
g., matrix multiplication with weights followed by bias addition), then repetitively use the output of the current transformation as input to the next transforma- tion.
However, you may have noticed that no forward method is defined here.
In fact, MLPinheritstheforwardmethodfromthe Moduleclass(Section3.2.2)tosimplyinvoke self.
net(X)(Xisinput), whichisnowdefinedasasequenceoftransformationsviathe Sequentialclass.
The Sequentialclassabstractstheforwardprocessenablingustofo- cus on the transformations.
We will further discuss how the Sequential class works in Section6.1.2.
Training Thetrainingloopisexactlythesameaswhenweimplementedsoftmaxregression.
This modularityenablesustoseparatemattersconcerningthemodelarchitecturefromorthog- onalconsiderations.
model = MLP(num_outputs=10, num_hiddens=256, lr=0.1) trainer.
fit(model, data) 5.2.3 Summary Nowthatwehavemorepracticeindesigningdeepnetworks, thestepfromasingletomul- tiple layers of deep networks does not pose such a significant challenge any longer.
In particular, wecanreusethetrainingalgorithmanddataloader.
Note, though, thatimple- menting MLPsfromscratchisnonethelessmessy: namingandkeepingtrackofthemodel parameters makes it difficult to extend models.
For instance, imagine wanting to insert anotherlayerbetweenlayers42and43.
Thismightnowbelayer42b, unlesswearewilling 179 Implementationof Multilayer Perceptrons toperformsequentialrenaming.
Moreover, ifweimplementthenetworkfromscratch, it is much more difficult for the framework to perform meaningful performance optimiza- tions.
Nonetheless, youhavenow reachedthe state of the art of the late 1980s when fullycon- necteddeepnetworkswerethemethodofchoiceforneuralnetworkmodeling.
Ournext conceptualstepwillbetoconsiderimages.
Beforewedoso, weneedtoreviewanumber ofstatisticalbasicsanddetailsonhowtocomputemodelsefficiently.
5.2.4 Exercises 1.
Changethenumberofhiddenunitsnum_hiddensandplothowitsnumberaffectsthe accuracyofthemodel.
Whatisthebestvalueofthishyperparameter? 2.
Tryaddingahiddenlayertoseehowitaffectstheresults.
3.
Whyisitabadideatoinsertahiddenlayerwithasingleneuron? Whatcouldgowrong? 4.
Howdoeschangingthelearningratealteryourresults? Withallotherparametersfixed, whichlearningrategivesyouthebestresults? Howdoesthisrelatetothenumberof epochs? 5.
Letâ€™s optimize over all hyperparameters jointly, i.
e., learning rate, number of epochs, numberofhiddenlayers, andnumberofhiddenunitsperlayer.
1.
Whatisthebestresultyoucangetbyoptimizingoverallofthem? 2.
Whyitismuchmorechallengingtodealwithmultiplehyperparameters? 3.
Describeanefficientstrategyforoptimizingovermultipleparametersjointly.
6.
Comparethespeedoftheframeworkandthefrom-scratchimplementationforachal- lengingproblem.
Howdoesitchangewiththecomplexityofthenetwork? 7.
Measure the speed of tensorâ€“matrix multiplications for well-aligned and misaligned matrices.
Forinstance, testformatriceswithdimension1024, 1025, 1026, 1028, and 1032.
1.
Howdoesthischangebetween GPUsand CPUs? 103 2.
Determinethememorybuswidthofyour CPUand GPU.
8.
Tryoutdifferentactivationfunctions.
Whichoneworksbest? 9.
Isthereadifferencebetweenweightinitializationsofthenetwork? Doesitmatter? Discussions103.
180 Multilayer Perceptrons 5.3 Forward Propagation, Backward Propagation, and Computational Graphs Sofar, wehavetrainedourmodelswithminibatchstochasticgradientdescent.
However, whenweimplementedthealgorithm, weonlyworriedaboutthecalculationsinvolvedin forwardpropagationthroughthemodel.
Whenitcametimetocalculatethegradients, we justinvokedthebackpropagationfunctionprovidedbythedeeplearningframework.
Theautomatic calculationof gradientsprofoundlysimplifies theimplementation ofdeep learningalgorithms.
Beforeautomaticdifferentiation, evensmallchangestocomplicated models required recalculating complicated derivatives by hand.
Surprisingly often, aca- demic papers had to allocate numerous pages to deriving update rules.
While we must continuetorelyonautomaticdifferentiationsowecanfocusontheinterestingparts, you oughttoknowhowthesegradientsarecalculatedunderthehoodifyouwanttogobeyond ashallowunderstandingofdeeplearning.
Inthissection, wetakeadeepdiveintothedetailsofbackwardpropagation(morecom- monlycalledbackpropagation).
Toconveysomeinsightforboththetechniquesandtheir implementations, werelyonsomebasicmathematicsandcomputationalgraphs.
Tostart, wefocusourexpositiononaone-hidden-layer MLPwithweightdecay(â„“ regularization, 2 tobedescribedinsubsequentchapters).
5.3.1 Forward Propagation Forwardpropagation(orforwardpass)referstothecalculationandstorageofintermediate variables(includingoutputs)foraneuralnetworkinorderfromtheinputlayertotheoutput layer.
We now work step-by-step through the mechanics of a neural network with one hiddenlayer.
Thismayseemtediousbutintheeternalwordsoffunkvirtuoso James Brown, youmustâ€œpaythecosttobethebossâ€.
Forthesakeofsimplicity, letâ€™sassumethattheinputexampleisx2Rğ‘‘ andthatourhidden layerdoesnotincludeabiasterm.
Heretheintermediatevariableis: z=W â€1â€ x, (5.3.1) where Wâ€1â€ 2 Râ„ ğ‘‘ istheweightparameterofthehiddenlayer.
Afterrunningtheinter- mediatevariablez2Râ„ throughtheactivationfunctionğœ™weobtainourhiddenactivation vectoroflengthâ„: h= ğœ™â€zâ€.
(5.3.2) Thehiddenlayeroutputhisalsoanintermediatevariable.
Assumingthattheparameters oftheoutputlayerpossessonlyaweightof Wâ€2â€ 2 Rğ‘ â„ , wecanobtainanoutputlayer variablewithavectoroflengthğ‘: o=W â€2â€ h.
(5.3.3) 181 Forward Propagation, Backward Propagation, and Computational Graphs Assumingthatthelossfunctionisğ‘™ andtheexamplelabelis ğ‘¦, wecanthencalculatethe losstermforasingledataexample, ğ¿ =ğ‘™â€o,ğ‘¦â€.
(5.3.4) Aswewillseethedefinitionofâ„“ regularizationtobeintroducedlater, giventhehyperpa- 2 rameterğœ†, theregularizationtermis ğœ† ğ‘  = k W â€1â€k2 â€šk W â€2â€k2 , (5.3.5) 2 F F wherethe Frobeniusnormofthematrixissimplytheâ„“ normappliedafterflatteningthe 2 matrixintoavector.
Finally, themodelâ€™sregularizedlossonagivendataexampleis: ğ½ = ğ¿â€šğ‘ .
(5.3.6) Werefertoğ½ astheobjectivefunctioninthefollowingdiscussion.
5.3.2 Computational Graphof Forward Propagation Plottingcomputationalgraphshelpsusvisualizethedependenciesofoperatorsandvari- ableswithinthecalculation.
.3.1containsthegraphassociatedwiththesimplenet- workdescribedabove, wheresquaresdenotevariablesand circlesdenoteoperators.
The lower-left corner signifies the input and the upper-right corner is the output.
Notice that the directions of the arrows (which illustrate data flow) are primarily rightward and up- ward.
t .3.1 Computationalgraphofforwardpropagation.
5.3.3 Backpropagation Backpropagationreferstothemethodofcalculatingthegradientofneuralnetworkparam- eters.
In short, the method traverses the network in reverse order, from the output to the inputlayer, accordingtothechainrulefromcalculus.
Thealgorithmstoresanyinterme- diatevariables(partialderivatives)requiredwhilecalculatingthegradientwithrespectto someparameters.
Assumethatwehavefunctions Y = ğ‘“â€Xâ€ and Z = ğ‘”â€Yâ€, inwhichthe inputandtheoutput X, Y, Zaretensorsofarbitraryshapes.
Byusingthechainrule, wecan computethederivativeof Zwithrespectto Xvia ğœ•Z ğœ•Z ğœ•Y =prod , .
(5.3.7) ğœ•X ğœ•Y ğœ•X Here we use the prod operator to multiply its arguments after the necessary operations, such as transposition and swapping input positions, have been carried out.
For vectors, thisisstraightforward: itissimplymatrixâ€“matrixmultiplication.
Forhigherdimensional 182 Multilayer Perceptrons tensors, we use the appropriate counterpart.
The operator prod hides all the notational overhead.
Recallthattheparametersofthesimplenetworkwithonehiddenlayer, whosecomputa- tionalgraphisin.3.1, are Wâ€1â€ and Wâ€2â€ .
Theobjectiveofbackpropagationisto calculatethegradientsğœ•ğ½ ğœ•Wâ€1â€ andğœ•ğ½ ğœ•Wâ€2â€ .
Toaccomplishthis, weapplythechain ruleandcalculate, inturn, thegradientofeachintermediatevariableandparameter.
The orderofcalculationsarereversedrelativetothoseperformedinforwardpropagation, since weneedtostartwiththeoutcomeofthecomputationalgraphandworkourwaytowards theparameters.
Thefirststepistocalculatethegradientsoftheobjectivefunctionğ½ = ğ¿â€šğ‘  withrespecttothelosstermğ¿andtheregularizationtermğ‘ : ğœ•ğ½ ğœ•ğ½ =1and =1.
(5.3.8) ğœ•ğ¿ ğœ•ğ‘  Next, we compute the gradient of the objective function with respect to variable of the outputlayeroaccordingtothechainrule: ğœ•ğ½ ğœ•ğ½ ğœ•ğ¿ ğœ•ğ¿ =prod , = 2Rğ‘.
(5.3.9) ğœ•o ğœ•ğ¿ ğœ•o ğœ•o Next, we calculate the gradients of the regularization term with respect to both parame- ters: ğœ•ğ‘  ğœ•ğ‘  =ğœ†W â€1â€ and =ğœ†W â€2â€.
(5.3.10) ğœ•Wâ€1â€ ğœ•Wâ€2â€ Now we are able to calculate the gradient ğœ•ğ½ ğœ•Wâ€2â€ 2 Rğ‘ â„ of the model parameters closesttotheoutputlayer.
Usingthechainruleyields: ğœ•ğ½ ğœ•ğ½ ğœ•o ğœ•ğ½ ğœ•ğ‘  ğœ•ğ½ =prod , â€šprod , = h >â€šğœ†W â€2â€.
(5.3.11) ğœ•Wâ€2â€ ğœ•o ğœ•Wâ€2â€ ğœ•ğ‘  ğœ•Wâ€2â€ ğœ•o To obtain the gradient with respect to Wâ€1â€ we need to continue backpropagation along theoutputlayertothehiddenlayer.
Thegradientwithrespecttothehiddenlayeroutput ğœ•ğ½ ğœ•h2Râ„ isgivenby ğœ•ğ½ =prod ğœ•ğ½ , ğœ•o =W â€2â€>ğœ•ğ½ .
(5.3.12) ğœ•h ğœ•o ğœ•h ğœ•o Sincetheactivationfunctionğœ™applieselementwise, calculatingthegradientğœ•ğ½ ğœ•z 2 Râ„ oftheintermediatevariablezrequiresthatweusetheelementwisemultiplicationoperator, whichwedenoteby : ğœ•ğ½ ğœ•ğ½ ğœ•h ğœ•ğ½ =prod , = ğœ™0â€zâ€.
(5.3.13) ğœ•z ğœ•h ğœ•z ğœ•h Finally, wecanobtainthegradientğœ•ğ½ ğœ•Wâ€1â€ 2 Râ„ ğ‘‘ ofthemodelparametersclosestto theinputlayer.
Accordingtothechainrule, weget ğœ•ğ½ ğœ•ğ½ ğœ•z ğœ•ğ½ ğœ•ğ‘  ğœ•ğ½ =prod , â€šprod , = x >â€šğœ†W â€1â€.
(5.3.14) ğœ•Wâ€1â€ ğœ•z ğœ•Wâ€1â€ ğœ•ğ‘  ğœ•Wâ€1â€ ğœ•z 183 Forward Propagation, Backward Propagation, and Computational Graphs 5.3.4 Training Neural Networks Whentrainingneuralnetworks, forwardandbackwardpropagationdependoneachother.
In particular, for forward propagation, we traverse the computational graph in the direc- tion of dependencies and compute all the variables on its path.
These are then used for backpropagationwherethecomputeorderonthegraphisreversed.
Taketheaforementionedsimplenetworkasanillustrativeexample.
Ontheonehand, com- putingtheregularizationterm(5.3.5)duringforwardpropagationdependsonthecurrent valuesofmodelparameters Wâ€1â€ and Wâ€2â€ .
Theyaregivenbytheoptimizationalgorithm accordingtobackpropagationinthemostrecentiteration.
Ontheotherhand, thegradient calculationfortheparameter(5.3.11)duringbackpropagationdependsonthecurrentvalue ofthehiddenlayeroutputh, whichisgivenbyforwardpropagation.
Thereforewhentrainingneuralnetworks, oncemodelparametersareinitialized, wealter- nate forward propagation with backpropagation, updating model parameters using gradi- entsgivenbybackpropagation.
Notethatbackpropagationreusesthestoredintermediate valuesfromforwardpropagationtoavoidduplicatecalculations.
Oneoftheconsequences isthatweneedtoretaintheintermediatevaluesuntilbackpropagationiscomplete.
Thisis alsooneofthereasonswhytrainingrequiressignificantlymorememorythanplainpredic- tion.
Besides, thesizeofsuchintermediatevaluesisroughlyproportionaltothenumberof networklayersandthebatchsize.
Thus, trainingdeepernetworksusinglargerbatchsizes moreeasilyleadstoout-of-memoryerrors.
5.3.5 Summary Forward propagation sequentially calculates and stores intermediate variables within the computationalgraphdefinedbytheneuralnetwork.
Itproceedsfromtheinputtotheout- putlayer.
Backpropagationsequentiallycalculatesandstoresthegradientsofintermediate variables and parameters within the neural networkin the reversedorder.
When training deep learning models, forward propagation and backpropagation are interdependent, and trainingrequiressignificantlymorememorythanprediction.
5.3.6 Exercises 1.
Assume that the inputs X to some scalar function ğ‘“ are ğ‘› ğ‘š matrices.
What is the dimensionalityofthegradientof ğ‘“ withrespectto X? 2.
Addabiastothehiddenlayerofthemodeldescribedinthissection(youdonotneed toincludebiasintheregularizationterm).
1.
Drawthecorrespondingcomputationalgraph.
2.
Derivetheforwardandbackwardpropagationequations.
3.
Computethememoryfootprintfortrainingandpredictioninthemodeldescribedinthis section.
4.
Assumethatyouwanttocomputesecondderivatives.
Whathappenstothecomputa- tionalgraph? Howlongdoyouexpectthecalculationtotake? 184 Multilayer Perceptrons 5.
Assumethatthecomputationalgraphistoolargeforyour GPU.
1.
Canyoupartitionitovermorethanone GPU? 2.
Whataretheadvantagesanddisadvantagesovertrainingonasmallerminibatch? Discussions104.
104 5.4 Numerical Stability and Initialization Thusfar, everymodelthatwehaveimplementedrequiredthatweinitializeitsparameters accordingtosomepre-specifieddistribution.
Untilnow, wetooktheinitializationscheme forgranted, glossingoverthedetailsofhowthesechoicesaremade.
Youmighthaveeven gottentheimpressionthatthesechoicesarenotespeciallyimportant.
Onthecontrary, the choice of initialization scheme plays a significant role in neural network learning, and it canbecrucialformaintainingnumericalstability.
Moreover, thesechoicescanbetiedup in interesting ways with the choice of the nonlinear activation function.
Which function wechooseandhowweinitializeparameterscandeterminehowquicklyouroptimization algorithmconverges.
Poorchoicesherecancauseustoencounterexplodingorvanishing gradients while training.
In this section, we delve into these topics in greater detail and discuss some useful heuristics that you will find useful throughout your career in deep learning.
%matplotlib inline import torch from d2l import torch as d2l 5.4.1 Vanishingand Exploding Gradients Consideradeepnetworkwithğ¿layers, inputxandoutputo.
Witheachlayerğ‘™ definedby atransformation ğ‘“ ğ‘™ parametrizedbyweights Wâ€ğ‘™â€ , whosehiddenlayeroutputishâ€ğ‘™â€ (let hâ€0â€ =x), ournetworkcanbeexpressedas: h â€ğ‘™â€ = ğ‘“ ğ‘™ â€h â€ğ‘™ 1â€â€andthuso= ğ‘“ ğ¿ ğ‘“ 1 â€xâ€.
(5.4.1) Ifallthehiddenlayeroutputandtheinputarevectors, wecanwritethegradientofowith respecttoanysetofparameters Wâ€ğ‘™â€ asfollows: ğœ• Wâ€ğ‘™â€o= | ğœ• h â€ ğ¿ { 1z â€h â€ ğ¿ } â€ | ğœ• h â€ ğ‘™ â€ { h z â€ ğ‘™ â€š 1 } â€ | ğœ• W { â€ğ‘™â€ z h â€ ğ‘™ } â€.
(5.4.2) Mâ€ğ¿â€d=ef Mâ€ğ‘™â€š1â€d=ef vâ€ğ‘™â€d=ef In other words, this gradient is the product of ğ¿ ğ‘™ matrices Mâ€ğ¿â€ Mâ€ğ‘™â€š1â€ and the gradientvectorvâ€ğ‘™â€ .
Thuswearesusceptibletothesameproblemsofnumericalunderflow thatoftencropupwhenmultiplyingtogethertoomanyprobabilities.
Whendealingwith probabilities, a common trick is to switch into log-space, i.
e., shifting pressure from the 185 Numerical Stabilityand Initialization mantissatotheexponentofthenumericalrepresentation.
Unfortunately, ourproblemabove ismoreserious: initiallythematrices Mâ€ğ‘™â€ mayhaveawidevarietyofeigenvalues.
They mightbesmallorlarge, andtheirproductmightbeverylargeorverysmall.
The risks posed by unstable gradients go beyond numerical representation.
Gradients of unpredictablemagnitudealsothreatenthestabilityofouroptimizationalgorithms.
Wemay befacingparameterupdatesthatareeither(i)excessivelylarge, destroyingourmodel(the exploding gradient problem); or (ii) excessively small (the vanishing gradient problem), renderinglearningimpossibleasparametershardlymoveoneachupdate.
Vanishing Gradients Onefrequentculpritcausingthevanishinggradientproblemisthechoiceoftheactivation functionğœ thatisappendedfollowingeachlayerâ€™slinearoperations.
Historically, thesig- moidfunction1 â€1â€šexpâ€ ğ‘¥â€â€(introducedin Section5.1)waspopularbecauseitresembles athresholdingfunction.
Sinceearlyartificialneuralnetworkswereinspiredbybiological neuralnetworks, theideaofneuronsthatfireeitherfullyornotatall(likebiologicalneu- rons) seemed appealing.
Letâ€™s take a closer look at the sigmoid to see why it can cause vanishinggradients.
x = torch.
arange(-8.0, 8.0, 0.1, requires_grad=True) y = torch.
sigmoid(x) y.
backward(torch.
ones_like(x)) legend=['sigmoid', 'gradient'], figsize=(4.5, 2.5)) Asyoucansee, thesigmoidâ€™sgradientvanishesbothwhenitsinputsarelargeandwhen theyaresmall.
Moreover, whenbackpropagatingthroughmanylayers, unlessweareinthe Goldilockszone, wheretheinputstomanyofthesigmoidsareclosetozero, thegradients of the overall product may vanish.
When our network boasts many layers, unless we are careful, thegradientwilllikelybecutoffatsomelayer.
Indeed, thisproblemusedtoplague deep network training.
Consequently, Re LUs, which are more stable (but less neurally plausible), haveemergedasthedefaultchoiceforpractitioners.
186 Multilayer Perceptrons Exploding Gradients Theoppositeproblem, whengradientsexplode, canbesimilarlyvexing.
Toillustratethis abitbetter, wedraw100Gaussianrandommatricesandmultiplythemwithsomeinitial matrix.
Forthescalethatwepicked(thechoiceofthevarianceğœ2 =1), thematrixproduct explodes.
Whenthishappensbecauseoftheinitializationofadeepnetwork, wehaveno chanceofgettingagradientdescentoptimizertoconverge.
M = torch.
normal(0, 1, size=(4, 4)) print('a single matrix \n', M) for i in range(100): M = M @ torch.
normal(0, 1, size=(4, 4)) print('after multiplying 100 matrices\n', M) a single matrix tensor([[-0.8755, -1.2171, 1.3316, 0.1357], [ 0.4399, 1.4073, -1.9131, -0.4608], [-2.1420, 0.3643, -0.5267, 1.0277], [-0.1734, -0.7549, 2.3024, 1.3085]]) after multiplying 100 matrices tensor([[-2.9185e+23, 1.3915e+25, -1.1865e+25, 1.4354e+24], [ 4.9142e+23, -2.3430e+25, 1.9979e+25, -2.4169e+24], [ 2.6578e+23, -1.2672e+25, 1.0805e+25, -1.3072e+24], [-5.2223e+23, 2.4899e+25, -2.1231e+25, 2.5684e+24]]) Breakingthe Symmetry Anotherprobleminneuralnetworkdesignisthesymmetryinherentintheirparametriza- tion.
Assumethatwehaveasimple MLPwithonehiddenlayerandtwounits.
Inthiscase, wecouldpermutetheweights Wâ€1â€ ofthefirstlayerandlikewisepermutetheweightsof the output layer to obtain the same function.
There is nothing special differentiating the firstandsecondhiddenunits.
Inotherwords, wehavepermutationsymmetryamongthe hiddenunitsofeachlayer.
This is more than just a theoretical nuisance.
Consider the aforementioned one-hidden- layer MLPwithtwohiddenunits.
Forillustration, supposethattheoutputlayertransforms thetwohiddenunitsintoonlyoneoutputunit.
Imaginewhatwouldhappenifweinitialized alltheparametersofthehiddenlayeras Wâ€1â€ =ğ‘forsomeconstantğ‘.
Inthiscase, during forwardpropagationeitherhiddenunittakesthesameinputsandparametersproducingthe sameactivationwhichisfedtotheoutputunit.
Duringbackpropagation, differentiatingthe output unit with respect to parameters Wâ€1â€ gives a gradient all of whose elements take thesamevalue.
Thus, aftergradient-basediteration(e.
g., minibatchstochasticgradientde- scent), alltheelementsof Wâ€1â€ stilltakethesamevalue.
Suchiterationswouldneverbreak thesymmetryontheirownandwemightneverbeabletorealizethenetworkâ€™sexpressive power.
Thehiddenlayerwouldbehaveasifithadonlyasingleunit.
Notethatwhilemini- batch stochastic gradient descent would not break this symmetry, dropout regularization (tobeintroducedlater)would! 187 Numerical Stabilityand Initialization 5.4.2 Parameter Initialization One way of addressingâ€”or at least mitigatingâ€”the issues raised above is through care- ful initialization.
As we will see later, additional care during optimization and suitable regularizationcanfurtherenhancestability.
Default Initialization Intheprevioussections, e.
g., in Section3.5, weusedanormaldistributiontoinitializethe valuesofourweights.
Ifwedonotspecifytheinitializationmethod, theframeworkwill useadefaultrandominitializationmethod, whichoftenworkswellinpracticeformoderate problemsizes.
Xavier Initialization Letâ€™slookatthescaledistributionofanoutput ğ‘œ ğ‘– forsomefullyconnectedlayerwithout nonlinearities.
Withğ‘› in inputsğ‘¥ ğ‘— andtheirassociatedweightsğ‘¤ ğ‘–ğ‘— forthislayer, anoutput isgivenby ğ‘› in ğ‘œ ğ‘– = ğ‘¤ ğ‘–ğ‘— ğ‘¥ ğ‘— .
(5.4.3) ğ‘—=1 Theweightsğ‘¤ ğ‘–ğ‘—arealldrawnindependentlyfromthesamedistribution.
Furthermore, letâ€™s assumethatthisdistributionhaszeromeanandvarianceğœ2.
Notethatthisdoesnotmean thatthedistributionhastobe Gaussian, justthatthemeanandvarianceneedtoexist.
For now, letâ€™sassumethattheinputstothelayerğ‘¥ ğ‘—alsohavezeromeanandvarianceğ›¾2andthat theyareindependentofğ‘¤ ğ‘–ğ‘— andindependentofeachother.
Inthiscase, wecancompute themeanofğ‘œ ğ‘–: ğ‘› in ğ¸Â»ğ‘œ ğ‘– â€¦ = ğ¸Â»ğ‘¤ ğ‘–ğ‘— ğ‘¥ ğ‘— â€¦ ğ‘—=1 ğ‘› in (5.4.4) = ğ¸Â»ğ‘¤ ğ‘–ğ‘— â€¦ğ¸Â»ğ‘¥ ğ‘— â€¦ ğ‘—=1 =0, andthevariance: VarÂ»ğ‘œ ğ‘– â€¦ = ğ¸Â»ğ‘œ2 ğ‘– â€¦ â€ğ¸Â»ğ‘œ ğ‘– â€¦â€2 ğ‘› in = ğ¸Â»ğ‘¤2 ğ‘¥2â€¦ 0 ğ‘–ğ‘— ğ‘— ğ‘—=1 (5.4.5) ğ‘› in = ğ¸Â»ğ‘¤2 â€¦ğ¸Â»ğ‘¥2â€¦ ğ‘–ğ‘— ğ‘— ğ‘—=1 =ğ‘› ğœ2ğ›¾2.
in One way to keep the variance fixed is to set ğ‘› ğœ2 = 1.
Now consider backpropagation.
in There we face a similar problem, albeit with gradients being propagated from the layers 188 Multilayer Perceptrons closertotheoutput.
Usingthesamereasoningasforforwardpropagation, weseethatthe gradientsâ€™ variance can blow up unless ğ‘› ğœ2 = 1, where ğ‘› is the number of outputs out out of this layer.
This leaves us in a dilemma: we cannot possibly satisfy both conditions simultaneously.
Instead, wesimplytrytosatisfy: r 1 2 â€ğ‘› â€šğ‘› â€ğœ2 =1orequivalentlyğœ = .
(5.4.6) 2 in out ğ‘› â€šğ‘› in out Thisisthereasoningunderlyingthenow-standardandpracticallybeneficial Xavierinitial- ization, namedafterthefirstauthorofitscreators(Glorotand Bengio,2010).
Typically, the Xavierinitializationsamplesweightsfroma Gaussiandistributionwithzeromeanandvari- anceğœ2 = 2 .
Wecanalsoadaptthistochoosethevariancewhensamplingweights ğ‘› â€šğ‘› in out fromauniformdistribution.
Notethattheuniformdistributionğ‘ˆâ€ ğ‘,ğ‘â€ hasvariance ğ‘2 .
3 Plugging ğ‘2 intoourconditiononğœ2promptsustoinitializeaccordingto 3 s s ' 6 6 â€œ ğ‘ˆâ€º , fi.
(5.4.7) ğ‘› â€šğ‘› ğ‘› â€šğ‘› Â« in out in outâ€¹ Thoughtheassumptionfornonexistenceofnonlinearitiesintheabovemathematicalrea- soningcanbeeasilyviolatedinneuralnetworks, the Xavierinitializationmethodturnsout toworkwellinpractice.
Beyond Thereasoningabovebarelyscratchesthesurfaceofmodernapproachestoparameterini- tialization.
Adeeplearningframeworkoftenimplementsoveradozendifferentheuristics.
Moreover, parameter initialization continues to be a hot area of fundamental research in deeplearning.
Amongtheseareheuristicsspecializedfortied(shared)parameters, super- resolution, sequencemodels, andothersituations.
Forinstance, Xiaoetal.
(2018)demon- stratedthepossibilityoftraining10,000-layerneuralnetworkswithoutarchitecturaltricks byusingacarefully-designedinitializationmethod.
Ifthetopicinterestsyouwesuggestadeepdiveintothismoduleâ€™sofferings, readingthe papersthatproposedandanalyzedeachheuristic, andthenexploringthelatestpublications onthetopic.
Perhapsyouwillstumbleacrossoreveninventacleverideaandcontribute animplementationtodeeplearningframeworks.
5.4.3 Summary Vanishing and exploding gradients are common issues in deep networks.
Great care in parameter initialization is required to ensure that gradients and parameters remain well controlled.
Initializationheuristicsareneededtoensurethattheinitialgradientsareneither toolargenortoosmall.
Randominitializationiskeytoensuringthatsymmetryisbroken before optimization.
Xavier initialization suggests that, for each layer, variance of any outputisnotaffectedbythenumberofinputs, andvarianceofanygradientisnotaffectedby thenumberofoutputs.
Re LUactivationfunctionsmitigatethevanishinggradientproblem.
Thiscanaccelerateconvergence.
189 Generalizationin Deep Learning 5.4.4 Exercises 1.
Canyoudesignothercaseswhereaneuralnetworkmightexhibitsymmetrythatneeds breaking, besidesthepermutationsymmetryinan MLPâ€™slayers? 2.
Canweinitializeallweightparametersinlinearregressionorinsoftmaxregressionto thesamevalue? 3.
Lookupanalyticboundsontheeigenvaluesoftheproductoftwomatrices.
Whatdoes thistellyouaboutensuringthatgradientsarewellconditioned? 4.
Ifweknowthatsometermsdiverge, canwefixthisafterthefact? Lookatthepaperon layerwiseadaptiveratescalingforinspiration(Youetal.,2017).
Discussions105.
105 5.5 Generalization in Deep Learning In Chapter 3 and Chapter 4, we tackled regression and classification problems by fitting linearmodelstotrainingdata.
Inbothcases, weprovidedpracticalalgorithmsforfinding the parameters that maximized the likelihood of the observed training labels.
And then, towardstheendofeachchapter, werecalledthatfittingthetrainingdatawasonlyanin- termediate goal.
Our real quest all along was to discover general patterns on the basis of which we can make accurate predictions even on new examples drawn from the same underlyingpopulation.
Machinelearningresearchersareconsumersofoptimizationalgo- rithms.
Sometimes, we must even develop new optimization algorithms.
But at the end of the day, optimization is merely a means to an end.
At its core, machine learning is a statisticaldisciplineandwewishtooptimizetraininglossonlyinsofarassomestatistical principle(knownorunknown)leadstheresultingmodelstogeneralizebeyondthetraining set.
Onthebrightside, itturnsoutthatdeepneuralnetworkstrainedbystochasticgradientde- scent generalize remarkably well across myriad prediction problems, spanning computer vision; natural language processing; time series data; recommender systems; electronic health records; protein folding; value function approximation in video games and board games; andnumerousotherdomains.
Onthedownside, ifyouwerelookingforastraight- forwardaccountofeithertheoptimizationstory(whywecanfitthemtotrainingdata)or thegeneralizationstory(whytheresultingmodelsgeneralizetounseenexamples), thenyou might want to pour yourself a drink.
While our procedures for optimizing linear models andthestatisticalpropertiesofthesolutionsarebothdescribedwellbyacomprehensive body of theory, our understanding of deep learning still resembles the wild west on both fronts.
Boththetheoryandpracticeofdeeplearningarerapidlyevolving, withtheoristsadopting new strategies to explain whatâ€™s going on, even as practitioners continue to innovate at 190 Multilayer Perceptrons ablisteringpace, buildingarsenalsofheuristicsfortrainingdeepnetworksandabodyof intuitionsandfolkknowledgethatprovideguidancefordecidingwhichtechniquestoapply inwhichsituations.
The summary of the present moment is that the theory of deep learning has produced promisinglinesofattackandscatteredfascinatingresults, butstillappearsfarfromacom- prehensiveaccountofboth(i)whyweareabletooptimizeneuralnetworksand(ii)how modelslearnedbygradientdescentmanagetogeneralizesowell, evenonhigh-dimensional tasks.
However, inpractice,(i)isseldomaproblem(wecanalwaysfindparametersthatwill fitallofourtrainingdata)andthusunderstandinggeneralizationisfarthebiggerproblem.
On the other hand, even absent the comfort of a coherent scientific theory, practitioners havedevelopedalargecollectionoftechniquesthatmayhelpyoutoproducemodelsthat generalize well in practice.
While no pithy summary can possibly do justice to the vast topicofgeneralizationindeeplearning, andwhiletheoverallstateofresearchisfarfrom resolved, wehope, inthissection, topresentabroadoverviewofthestateofresearchand practice.
5.5.1 Revisiting Overfittingand Regularization According to the â€œno free lunchâ€ theorem of Wolpert and Macready (1995), any learn- ing algorithm generalizes better on data with certain distributions, and worse with other distributions.
Thus, given a finite training set, a model relies on certain assumptions: to achievehuman-levelperformanceitmaybeusefultoidentifyinductivebiasesthatreflect howhumansthinkabouttheworld.
Suchinductivebiasesshowpreferencesforsolutions withcertainproperties.
Forexample, adeep MLPhasaninductivebiastowardsbuilding upacomplicatedfunctionbythecompositionofsimplerfunctions.
With machine learning models encoding inductive biases, our approach to training them typicallyconsistsoftwophases: (i)fitthetrainingdata; and(ii)estimatethegeneralization error(thetrueerrorontheunderlyingpopulation)byevaluatingthemodelonholdoutdata.
Thedifferencebetweenourfitonthetrainingdataandourfitonthetestdataiscalledthe generalizationgapandwhenthisislarge, wesaythatourmodelsoverfittothetrainingdata.
In extreme cases of overfitting, we might exactly fit the training data, even when the test errorremainssignificant.
Andintheclassicalview, theinterpretationisthatourmodelsare toocomplex, requiringthatweeithershrinkthenumberoffeatures, thenumberofnonzero parameters learned, or the size of the parameters as quantified.
Recall the plot of model Howeverdeeplearningcomplicatesthispictureincounterintuitiveways.
First, forclassifi- cationproblems, ourmodelsaretypicallyexpressiveenoughtoperfectlyfiteverytraining example, evenindatasetsconsistingofmillions(Zhangetal.,2021).
Intheclassicalpic- ture, wemightthinkthatthissettingliesonthefarrightextremeofthemodelcomplexity axis, andthatanyimprovementsingeneralizationerrormustcomebywayofregulariza- tion, eitherbyreducingthecomplexityofthemodelclass, orbyapplyingapenalty, severely constrainingthesetofvaluesthatourparametersmighttake.
Butthatiswherethingsstart togetweird.
191 Generalizationin Deep Learning Strangely, formanydeeplearningtasks(e.
g., imagerecognitionandtextclassification)we aretypicallychoosingamongmodelarchitectures, allofwhichcanachievearbitrarilylow training loss (and zero training error).
Because all models under consideration achieve zerotrainingerror, theonlyavenueforfurthergainsistoreduceoverfitting.
Evenstranger, it is often the case that despite fitting the training data perfectly, we can actually reduce the generalization error further by making the model even more expressive, e.
g., adding layers, nodes, ortrainingforalargernumberofepochs.
Strangeryet, thepatternrelating thegeneralizationgaptothecomplexityofthemodel(ascaptured, forexample, inthedepth orwidthofthenetworks)canbenon-monotonic, withgreatercomplexityhurtingatfirst butsubsequentlyhelpinginaso-calledâ€œdouble-descentâ€pattern(Nakkiranetal., 2021).
Thus the deep learning practitioner possesses a bag of tricks, some of which seemingly restrictthemodelinsomefashionandothersthatseeminglymakeitevenmoreexpressive, andallofwhich, insomesense, areappliedtomitigateoverfitting.
Complicatingthingsevenfurther, whiletheguaranteesprovidedbyclassicallearningthe- ory can be conservative even for classical models, they appear powerless to explain why itisthatdeepneuralnetworksgeneralizeinthefirstplace.
Becausedeepneuralnetworks arecapableoffittingarbitrarylabelsevenforlargedatasets, anddespitetheuseoffamil- iarmethodssuchasâ„“ regularization, traditionalcomplexity-basedgeneralizationbounds, 2 e.
g., those based on the VC dimension or Rademacher complexity of a hypothesis class cannotexplainwhyneuralnetworksgeneralize.
5.5.2 Inspirationfrom Nonparametrics Approachingdeeplearningforthefirsttime, itistemptingtothinkofthemasparametric models.
Afterall, themodelsdohavemillionsofparameters.
Whenweupdatethemodels, weupdatetheirparameters.
Whenwesavethemodels, wewritetheirparameterstodisk.
However, mathematicsandcomputerscienceareriddledwithcounterintuitivechangesof perspective, and surprising isomorphisms between seemingly different problems.
While neuralnetworksclearlyhaveparameters, insomewaysitcanbemorefruitfultothinkof themasbehavinglikenonparametricmodels.
Sowhatpreciselymakesamodelnonpara- metric? While the name covers a diverse set of approaches, one common theme is that nonparametric methods tend to have a level of complexity that grows as the amount of availabledatagrows.
Perhapsthesimplestexampleofanonparametricmodelistheğ‘˜-nearestneighboralgorithm (we will cover more nonparametric models later, for example in Section 11.2).
Here, at training time, the learner simply memorizes the dataset.
Then, at prediction time, when confrontedwithanewpointx, thelearnerlooksupthe ğ‘˜ nearestneighbors(the ğ‘˜ points x0 thatminimizesomedistanceğ‘‘â€x, x0â€).
When ğ‘˜ = 1, thisalgorithmiscalled1-nearest ğ‘– ğ‘– neighbors, and the algorithm will always achieve a training error of zero.
That however, doesnotmeanthatthealgorithmwillnotgeneralize.
Infact, itturnsoutthatundersome mild conditions, the 1-nearest neighbor algorithm is consistent (eventually converging to theoptimalpredictor).
Notethat1-nearestneighborrequiresthatwespecifysomedistancefunctionğ‘‘, orequiva- lently, thatwespecifysomevector-valuedbasisfunctionğœ™â€xâ€forfeaturizingourdata.
For 192 Multilayer Perceptrons anychoiceofthedistancemetric, wewillachievezerotrainingerrorandeventuallyreach anoptimalpredictor, butdifferentdistancemetricsğ‘‘encodedifferentinductivebiasesand withafiniteamountofavailabledatawillyielddifferentpredictors.
Differentchoicesof thedistancemetricğ‘‘representdifferentassumptionsabouttheunderlyingpatternsandthe performanceofthedifferentpredictorswilldependonhowcompatibletheassumptionsare withtheobserveddata.
Inasense, becauseneuralnetworksareover-parametrized, possessingmanymoreparame- tersthanareneededtofitthetrainingdata, theytendtointerpolatethetrainingdata(fitting it perfectly) and thus behave, in some ways, more like nonparametric models.
More re- cent theoretical research has established deep connection between large neural networks and nonparametric methods, notably kernel methods.
In particular, Jacot et al.
(2018) demonstratedthatinthelimit, asmultilayerperceptronswithrandomlyinitializedweights growinfinitelywide, theybecomeequivalentto(nonparametric)kernelmethodsforaspe- cific choice of the kernel function (essentially, a distance function), which they call the neural tangent kernel.
While current neural tangent kernel models may not fully explain thebehaviorofmoderndeepnetworks, theirsuccessasananalyticaltoolunderscoresthe usefulnessofnonparametricmodelingforunderstandingthebehaviorofover-parametrized deepnetworks.
5.5.3 Early Stopping While deep neural networks are capable of fitting arbitrary labels, even when labels are assigned incorrectly or randomly (Zhang et al., 2021), this capability only emerges over many iterations of training.
A new line of work (Rolnick et al., 2017) has revealed that inthesettingoflabelnoise, neuralnetworkstendtofitcleanlylabeleddatafirstandonly subsequentlytointerpolatethemislabeleddata.
Moreover, ithasbeenestablishedthatthis phenomenontranslatesdirectlyintoaguaranteeongeneralization: wheneveramodelhas fittedthecleanlylabeleddatabutnotrandomlylabeledexamplesincludedinthetraining set, ithasinfactgeneralized(Gargetal.,2021).
Togetherthesefindingshelptomotivateearlystopping, aclassictechniqueforregularizing deepneuralnetworks.
Here, ratherthandirectlyconstrainingthevaluesoftheweights, one constrains the number of epochs of training.
The most common way to determine the stoppingcriterionistomonitorvalidationerrorthroughouttraining(typicallybychecking onceaftereachepoch)andtocutofftrainingwhenthevalidationerrorhasnotdecreased bymorethansomesmallamountğœ– forsomenumberofepochs.
Thisissometimescalleda patiencecriterion.
Aswellasthepotentialtoleadtobettergeneralizationinthesettingof noisylabels, anotherbenefitofearlystoppingisthetimesaved.
Oncethepatiencecriterion is met, one can terminate training.
For large models that might require days of training simultaneouslyacrosseightormore GPUs, well-tunedearlystoppingcansaveresearchers daysoftimeandcansavetheiremployersmanythousandsofdollars.
Notably, whenthereisnolabelnoiseanddatasetsarerealizable(theclassesaretrulysep- arable, e.
g., distinguishingcatsfromdogs), earlystoppingtendsnottoleadtosignificant improvementsingeneralization.
Ontheotherhand, whenthereislabelnoise, orintrinsic 193 Generalizationin Deep Learning variabilityinthelabel(e.
g., predictingmortalityamongpatients), earlystoppingiscrucial.
Trainingmodelsuntiltheyinterpolatenoisydataistypicallyabadidea.
5.5.4 Classical Regularization Methodsfor Deep Networks In Chapter3, wedescribedseveralclassicalregularizationtechniquesforconstrainingthe complexity of our models.
In particular, Section 3.7 introduced a method called weight decay, whichconsistsofaddingaregularizationtermtothelossfunctioninordertopenalize largevaluesoftheweights.
Dependingonwhichweightnormispenalizedthistechnique is known either as ridge regularization (for â„“ penalty) or lasso regularization (for an â„“ 2 1 penalty).
Intheclassicalanalysisoftheseregularizers, theyareconsideredassufficiently restrictiveonthevaluesthattheweightscantaketopreventthemodelfromfittingarbitrary labels.
In deep learning implementations, weight decay remains a popular tool.
However, re- searchershavenotedthattypicalstrengthsofâ„“ regularizationareinsufficienttopreventthe 2 networksfrominterpolatingthedata(Zhangetal.,2021)andthusthebenefitsifinterpreted asregularizationmightonlymakesenseincombinationwiththeearlystoppingcriterion.
Absentearlystopping, itispossiblethatjustlikethenumberoflayersornumberofnodes (indeeplearning)orthedistancemetric(in1-nearestneighbor), thesemethodsmayleadto bettergeneralizationnotbecausetheymeaningfullyconstrainthepoweroftheneuralnet- workbutratherbecausetheysomehowencodeinductivebiasesthatarebettercompatible withthepatternsfoundindatasetsofinterests.
Thus, classicalregularizersremainpopular indeeplearningimplementations, evenifthetheoreticalrationalefortheirefficacymaybe radicallydifferent.
Notably, deeplearningresearchershavealsobuiltontechniquesfirstpopularizedinclassi- calregularizationcontexts, suchasaddingnoisetomodelinputs.
Inthenextsectionwewill introducethefamousdropouttechnique(inventedby Srivastavaetal.
(2014)), whichhas becomeamainstayofdeeplearning, evenasthetheoreticalbasisforitsefficacyremains similarlymysterious.
5.5.5 Summary Unlikeclassicallinearmodels, whichtendtohavefewerparametersthanexamples, deep networkstendtobeover-parametrized, andformosttasksarecapableofperfectlyfitting thetrainingset.
Thisinterpolationregimechallengesmanyhardfast-heldintuitions.
Func- tionally, neural networks look like parametric models.
But thinking of them as nonpara- metric models can sometimes be a more reliable source of intuition.
Because it is often the case that all deep networks under consideration are capable of fitting all of the train- inglabels, nearlyallgainsmustcomebymitigatingoverfitting(closingthegeneralization gap).
Paradoxically, theinterventionsthatreducethegeneralizationgapsometimesappear toincreasemodelcomplexityandatothertimesappeartodecreasecomplexity.
However, thesemethodsseldomdecreasecomplexitysufficientlyforclassicaltheorytoexplainthe generalizationofdeepnetworks, andwhycertainchoicesleadtoimprovedgeneralization remains for the most part a massive open question despite the concerted efforts of many brilliantresearchers.
194 Multilayer Perceptrons 5.5.6 Exercises 1.
Inwhatsensedotraditionalcomplexity-basedmeasuresfailtoaccountforgeneralization ofdeepneuralnetworks? 2.
Whymightearlystoppingbeconsideredaregularizationtechnique? 3.
Howdoresearcherstypicallydeterminethestoppingcriterion? 4.
What important factor seems to differentiate cases when early stopping leads to big improvementsingeneralization? 5.
Beyondgeneralization, describeanotherbenefitofearlystopping.
106 Discussions106.
5.6 Dropout Letâ€™sthinkbrieflyaboutwhatweexpectfromagoodpredictivemodel.
Wewantittope- form well on unseen data.
Classical generalization theory suggests that to close the gap between train and test performance, we should aim for a simple model.
Simplicity can comeintheformofasmallnumberofdimensions.
Weexploredthiswhendiscussingthe monomialbasisfunctionsoflinearmodelsin Section3.6.
Additionally, aswesawwhen discussingweightdecay(â„“ regularization)in Section3.7, the(inverse)normoftheparam- 2 eters also represents a useful measure of simplicity.
Another useful notion of simplicity issmoothness, i.
e., thatthefunctionshouldnotbesensitivetosmallchangestoitsinputs.
Forinstance, whenweclassifyimages, wewouldexpectthataddingsomerandomnoiseto thepixelsshouldbemostlyharmless.
Bishop(1995)formalizedthisideawhenheprovedthattrainingwithinputnoiseisequiva- lentto Tikhonovregularization.
Thisworkdrewaclearmathematicalconnectionbetween therequirementthatafunctionbesmooth(andthussimple), andtherequirementthatitbe resilienttoperturbationsintheinput.
Then, Srivastavaetal.
(2014)developedacleverideaforhowtoapply Bishopâ€™sideatothe internallayersofanetwork, too.
Theiridea, calleddropout, involvesinjectingnoisewhile computing each internal layer during forward propagation, and it has become a standard techniquefortrainingneuralnetworks.
Themethodiscalleddropoutbecauseweliterally drop out some neurons during training.
Throughout training, on each iteration, standard dropoutconsistsofzeroingoutsomefractionofthenodesineachlayerbeforecalculating thesubsequentlayer.
Tobeclear, weareimposingourownnarrativewiththelinkto Bishop.
Theoriginalpa- per on dropout offers intuition through a surprising analogy to sexual reproduction.
The authorsarguethatneuralnetworkoverfittingischaracterizedbyastateinwhicheachlayer 195 Dropout relies on a specific pattern of activations in the previous layer, calling this condition co- adaptation.
Dropout, they claim, breaks up co-adaptation just as sexual reproduction is argued to break up co-adapted genes.
While such an justification of this theory is cer- tainlyupfordebate, thedropouttechniqueitselfhasprovedenduring, andvariousformsof dropoutareimplementedinmostdeeplearninglibraries.
Thekeychallengeishowtoinjectthisnoise.
Oneideaistoinjectitinanunbiasedmanner sothattheexpectedvalueofeachlayerâ€”whilefixingtheothersâ€”equalsthevalueitwould havetakenabsentnoise.
In Bishopâ€™swork, headded Gaussiannoisetotheinputstoalinear model.
Ateachtrainingiteration, headdednoisesampledfromadistributionwithmean zeroğœ– Nâ€0,ğœ2â€ totheinputx, yieldingaperturbedpointx0 = xâ€šğœ–.
Inexpectation, ğ¸Â»x0â€¦ =x.
Instandarddropoutregularization, onezerosoutsomefractionofthenodesineachlayer andthendebiaseseachlayerbynormalizingbythefractionofnodesthatwereretained(not droppedout).
Inotherwords, withdropoutprobabilityğ‘, eachintermediateactivationâ„is replacedbyarandomvariableâ„0 asfollows: ( 0 withprobability ğ‘ â„0 = (5.6.1) â„ otherwise 1 ğ‘ Bydesign, theexpectationremainsunchanged, i.
e.,ğ¸Â»â„0â€¦ = â„.
import torch from torch import nn from d2l import torch as d2l 5.6.1 Dropoutin Practice Recallthe MLPwithahiddenlayerandfivehiddenunitsfrom.1.1.
Whenweapply dropouttoahiddenlayer, zeroingouteachhiddenunitwithprobability ğ‘, theresultcan beviewedasanetworkcontainingonlyasubsetoftheoriginalneurons.
In.6.1, â„ 2 andâ„ areremoved.
Consequently, thecalculationoftheoutputsnolongerdependsonâ„ 5 2 orâ„ andtheirrespectivegradientalsovanisheswhenperformingbackpropagation.
Inthis 5 way, thecalculationoftheoutputlayercannotbeoverlydependentonanyoneelementof â„ ,...,â„ .
1 5 t .6.1 MLPbeforeandafterdropout.
196 Multilayer Perceptrons Typically, we disable dropout at test time.
Given a trained model and a new example, we do not drop out any nodes and thus do not need to normalize.
However, there are someexceptions: someresearchersusedropoutattesttimeasaheuristicforestimatingthe uncertainty of neural network predictions: if the predictions agree across many different dropoutoutputs, thenwemightsaythatthenetworkismoreconfident.
5.6.2 Implementationfrom Scratch Toimplementthedropoutfunctionforasinglelayer, wemustdrawasmanysamplesfroma Bernoulli(binary)randomvariableasourlayerhasdimensions, wheretherandomvariable takesvalue1(keep)withprobability1 ğ‘and0(drop)withprobability ğ‘.
Oneeasyway toimplementthisistofirstdrawsamplesfromtheuniformdistributionğ‘ˆÂ»0,1â€¦.
Thenwe cankeepthosenodesforwhichthecorrespondingsampleisgreaterthan ğ‘, droppingthe rest.
Inthefollowingcode, weimplementadropout_layerfunctionthatdropsouttheelements inthetensorinput Xwithprobabilitydropout, rescalingtheremainderasdescribedabove: dividingthesurvivorsby1.0-dropout.
def dropout_layer(X, dropout): assert 0 <= dropout <= 1 if dropout == 1: return torch.
zeros_like(X) mask = (torch.
rand(X.
shape) > dropout).
float() return mask * X / (1.0 - dropout) Wecantestoutthedropout_layerfunctiononafewexamples.
Inthefollowinglinesof code, wepassourinput Xthroughthedropoutoperation, withprobabilities0,0.5, and1, respectively.
X = torch.
arange(16, dtype = torch.
float32).
reshape((2, 8)) print('dropout_p = 0:', dropout_layer(X, 0)) print('dropout_p = 0.5:', dropout_layer(X, 0.5)) print('dropout_p = 1:', dropout_layer(X, 1)) Definingthe Model Themodelbelowappliesdropouttotheoutputofeachhiddenlayer(followingtheactivation function).
Wecansetdropoutprobabilitiesforeachlayerseparately.
Acommonchoiceis tosetalowerdropoutprobabilityclosertotheinputlayer.
Weensurethatdropoutisonly activeduringtraining.
197 Dropout class Dropout MLPScratch(d2l.
Classifier): def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2, dropout_1, dropout_2, lr): super().__init__() self.
save_hyperparameters() self.
lin1 = nn.
Lazy Linear(num_hiddens_1) self.
lin2 = nn.
Lazy Linear(num_hiddens_2) self.
lin3 = nn.
Lazy Linear(num_outputs) self.
relu = nn.
Re LU() def forward(self, X): H1 = self.
relu(self.
lin1(X.
reshape((X.
shape[0], -1)))) if self.
training: H1 = dropout_layer(H1, self.
dropout_1) H2 = self.
relu(self.
lin2(H1)) if self.
training: H2 = dropout_layer(H2, self.
dropout_2) return self.
lin3(H2) Training Thefollowingissimilartothetrainingof MLPsdescribedpreviously.
hparams = {'num_outputs':10, 'num_hiddens_1':256, 'num_hiddens_2':256, 'dropout_1':0.5, 'dropout_2':0.5, 'lr':0.1} model = Dropout MLPScratch(**hparams) data = d2l.
Fashion MNIST(batch_size=256) trainer = d2l.
Trainer(max_epochs=10) trainer.
fit(model, data) 5.6.3 Concise Implementation Withhigh-level APIs, allweneedtodoisadda Dropoutlayeraftereachfullyconnected layer, passing in the dropout probability as the only argument to its constructor.
During training, the Dropoutlayerwillrandomlydropoutoutputsofthepreviouslayer(orequiv- alently, theinputstothesubsequentlayer)accordingtothespecifieddropoutprobability.
Whennotintrainingmode, the Dropoutlayersimplypassesthedatathroughduringtest- ing.
198 Multilayer Perceptrons class Dropout MLP(d2l.
Classifier): def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2, dropout_1, dropout_2, lr): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nn.
Flatten(), nn.
Lazy Linear(num_hiddens_1), nn.
Re LU(), nn.
Dropout(dropout_1), nn.
Lazy Linear(num_hiddens_2), nn.
Re LU(), nn.
Dropout(dropout_2), nn.
Lazy Linear(num_outputs)) Next, wetrainthemodel.
model = Dropout MLP(**hparams) trainer.
fit(model, data) 5.6.4 Summary Beyondcontrollingthenumberofdimensionsandthesizeoftheweightvector, dropoutis yetanothertoolforavoidingoverfitting.
Oftentoolsareusedjointly.
Notethatdropoutis usedonlyduringtraining: itreplacesanactivationâ„witharandomvariablewithexpected valueâ„.
5.6.5 Exercises 1.
What happens if you change the dropout probabilities for the first and second layers? In particular, what happens if you switch the ones for both layers? Design an experi- menttoanswerthesequestions, describeyourresultsquantitatively, andsummarizethe qualitativetakeaways.
2.
Increase the number of epochs and compare the results obtained when using dropout withthosewhennotusingit.
3.
Whatisthevarianceoftheactivationsineachhiddenlayerwhendropoutisandisnot applied? Drawaplottoshowhowthisquantityevolvesovertimeforbothmodels.
4.
Whyisdropoutnottypicallyusedattesttime? 5.
Usingthemodelinthissectionasanexample, comparetheeffectsofusingdropoutand 199 Predicting House Priceson Kaggle weightdecay.
Whathappenswhendropoutandweightdecayareusedatthesametime? Aretheresultsadditive? Aretherediminishedreturns(orworse)? Dotheycanceleach otherout? 6.
Whathappensifweapplydropouttotheindividualweightsoftheweightmatrixrather thantheactivations? 7.
Inventanothertechniqueforinjectingrandomnoiseateachlayerthatisdifferentfrom thestandarddropouttechnique.
Canyoudevelopamethodthatoutperformsdropouton the Fashion-MNISTdataset(forafixedarchitecture)? Discussions107.
107 5.7 Predicting House Prices on Kaggle Nowthatwehaveintroducedsomebasictoolsforbuildingandtrainingdeepnetworksand regularizing them with techniques including weight decay and dropout, we are ready to putallthisknowledgeintopracticebyparticipatingina Kagglecompetition.
Thehouse pricepredictioncompetitionisagreatplacetostart.
Thedataisfairlygenericanddonot exhibit exotic structure that might require specialized models (as audio or video might).
This dataset, collected by De Cock (2011), covers house prices in Ames, Iowa from the period2006â€“2010.
Itisconsiderablylargerthanthefamous Bostonhousingdataset108 of 108 Harrisonand Rubinfeld(1978), boastingbothmoreexamplesandmorefeatures.
Inthissection, wewillwalkyouthroughdetailsofdatapreprocessing, modeldesign, and hyperparameterselection.
Wehopethatthroughahands-onapproach, youwillgainsome intuitionsthatwillguideyouinyourcareerasadatascientist.
%matplotlib inline import pandas as pd import torch from torch import nn from d2l import torch as d2l 5.7.1 Downloading Data Throughoutthebook, wewilltrainandtestmodelsonvariousdownloadeddatasets.
Here, weimplementtwoutilityfunctionsfordownloadingandextractingziportarfiles.
Again, weskipimplementationdetailsofsuchutilityfunctions.
def download(url, folder, sha1_hash=None): """Download a file to folder and return the local filepath.""" def extract(filename, folder): """Extract a zip/tar file into folder.""" 200 Multilayer Perceptrons 5.7.2 Kaggle Kaggle109 is a popular platform that hosts machine learning competitions.
Each com- 109 petitioncentersonadatasetandmanyaresponsoredbystakeholderswhoofferprizesto the winning solutions.
The platform helps users to interact via forums and shared code, fosteringbothcollaborationandcompetition.
Whileleaderboardchasingoftenspiralsout ofcontrol, withresearchersfocusingmyopicallyonpreprocessingstepsratherthanasking fundamentalquestions, thereisalsotremendousvalueintheobjectivityofaplatformthat facilitates direct quantitative comparisons among competing approaches as well as code sharingsothateveryonecanlearnwhatdidanddidnotwork.
Ifyouwanttoparticipatein a Kagglecompetition, youwillfirstneedtoregisterforanaccount(see.7.1).
t .7.1 The Kagglewebsite.
On the house price prediction competition page, as illustrated in .7.2, you can find thedataset(undertheâ€œDataâ€tab), submitpredictions, andseeyourranking, The URLis righthere: https://www.
kaggle.
com/c/house-prices-advanced-regression-techniques t .7.2 Thehousepricepredictioncompetitionpage.
5.7.3 Accessingand Readingthe Dataset 201 Predicting House Priceson Kaggle Notethatthecompetitiondataisseparatedintotrainingandtestsets.
Eachrecordincludes thepropertyvalueofthehouseandattributessuchasstreettype, yearofconstruction, roof type, basement condition, etc.
The features consist of various data types.
For example, theyearofconstructionisrepresentedbyaninteger, therooftypebydiscretecategorical assignments, andotherfeaturesbyfloatingpointnumbers.
Andhereiswhererealitycom- plicatesthings: forsomeexamples, somedataisaltogethermissingwiththemissingvalue markedsimplyasâ€œnaâ€.
Thepriceofeachhouseisincludedforthetrainingsetonly(itis acompetitionafterall).
Wewillwanttopartitionthetrainingsettocreateavalidationset, butweonlygettoevaluateourmodelsontheofficialtestsetafteruploadingpredictionsto Kaggle.
Theâ€œDataâ€tabonthecompetitiontabin.7.2haslinksfordownloadingthe data.
To get started, we will read in and process the data using pandas, which we introduced in Section2.2.
Forconvenience, wecandownloadandcachethe Kagglehousingdataset.
Ifafilecorrespondingtothisdatasetalreadyexistsinthecachedirectoryandits SHA-1 matchessha1_hash, ourcodewillusethecachedfiletoavoidcloggingupyour Internet withredundantdownloads.
class Kaggle House(d2l.
Data Module): def __init__(self, batch_size, train=None, val=None): super().__init__() self.
save_hyperparameters() if self.
train is None: self.
raw_train = pd.
read_csv(d2l.
download( d2l.
DATA_URL + 'kaggle_house_pred_train.
csv', self.
root, sha1_hash='585e9cc93e70b39160e7921475f9bcd7d31219ce')) self.
raw_val = pd.
read_csv(d2l.
download( d2l.
DATA_URL + 'kaggle_house_pred_test.
csv', self.
root, sha1_hash='fa19780a7b011d9b009e8bff8e99922a8ee2eb90')) Thetrainingdatasetincludes1460examples,80features, andonelabel, whilethevalidation datacontains1459examplesand80features.
data = Kaggle House(batch_size=64) print(data.
raw_train.
shape) print(data.
raw_val.
shape) Downloading ../data/kaggle_house_pred_train.
csv from http://d2l-data.
s3- Downloading ../data/kaggle_house_pred_test.
csv from http://d2l-data.
s3- (1460, 81) (1459, 80) 5.7.4 Data Preprocessing Letâ€™stakealookatthefirstfourandfinaltwofeaturesaswellasthelabel(Sale Price)from thefirstfourexamples.
202 Multilayer Perceptrons print(data.
raw_train.
iloc[:4, [0, 1, 2, 3, -3, -2, -1]]) Id MSSub Class MSZoning Lot Frontage Sale Type Sale Condition Sale Price 0 1 60 RL 65.0 WD Normal 208500 1 2 20 RL 80.0 WD Normal 181500 2 3 60 RL 68.0 WD Normal 223500 3 4 70 RL 60.0 WD Abnorml 140000 We can see that in each example, the first feature is the identifier.
This helps the model determineeachtrainingexample.
Whilethisisconvenient, itdoesnotcarryanyinformation forpredictionpurposes.
Hence, wewillremoveitfromthedatasetbeforefeedingthedata intothemodel.
Furthermore, givenawidevarietyofdatatypes, wewillneedtopreprocess thedatabeforewecanstartmodeling.
Letâ€™s start with the numerical features.
First, we apply a heuristic, replacing all missing valuesbythecorrespondingfeatureâ€™smean.
Then, toputallfeaturesonacommonscale, westandardizethedatabyrescalingfeaturestozeromeanandunitvariance: ğ‘¥ ğœ‡ ğ‘¥ , (5.7.1) ğœ whereğœ‡andğœdenotemeanandstandarddeviation, respectively.
Toverifythatthisindeed transforms our feature (variable) such that it has zero mean and unit variance, note that ğ¸Â»ğ‘¥ ğœ‡â€¦ = ğœ‡ ğœ‡ = 0andthat ğ¸Â»â€ğ‘¥ ğœ‡â€2â€¦ = â€ğœ2 â€š ğœ‡2â€ 2ğœ‡2 â€š ğœ‡2 = ğœ2.
Intuitively, we ğœ ğœ standardizethedatafortworeasons.
First, itprovesconvenientforoptimization.
Second, becausewedonotknowaprioriwhichfeatureswillberelevant, wedonotwanttopenalize coefficientsassignedtoonefeaturemorethananyother.
Nextwedealwithdiscretevalues.
Theseincludefeaturessuchasâ€œMSZoningâ€.
Wereplace thembyaone-hotencodinginthesamewaythatweearliertransformedmulticlasslabels intovectors(see Section4.1.1).
Forinstance,â€œMSZoningâ€assumesthevaluesâ€œRLâ€and â€œRMâ€.
Dropping the â€œMSZoningâ€ feature, two new indicator features â€œMSZoning_RLâ€ and â€œMSZoning_RMâ€ are created with values being either 0 or 1.
According to one-hot encoding, if the original value of â€œMSZoningâ€ is â€œRLâ€, then â€œMSZoning_RLâ€ is 1 and â€œMSZoning_RMâ€is0.
Thepandaspackagedoesthisautomaticallyforus.
@d2l.
add_to_class(Kaggle House) def preprocess(self): # Remove the ID and label columns label = 'Sale Price' features = pd.
concat( (self.
raw_train.
drop(columns=['Id', label]), self.
raw_val.
drop(columns=['Id']))) # Standardize numerical columns numeric_features = features.
dtypes[features.
dtypes!='object'].
index features[numeric_features] = features[numeric_features].
apply( lambda x: (x - x.
mean()) / (x.
std())) # Replace NAN numerical features by 0 features[numeric_features] = features[numeric_features].
fillna(0) (continuesonnextpage) 203 Predicting House Priceson Kaggle (continuedfrompreviouspage) # Replace discrete features by one-hot encoding features = pd.
get_dummies(features, dummy_na=True) # Save preprocessed features self.
train = features[: self.
raw_train.
shape[0]].
copy() self.
train[label] = self.
raw_train[label] self.
val = features[self.
raw_train.
shape[0]:].
copy() Youcanseethatthisconversionincreasesthenumberoffeaturesfrom79to331(excluding IDandlabelcolumns).
data.
preprocess() data.
train.
shape (1460, 331) 5.7.5 Error Measure Togetstartedwewilltrainalinearmodelwithsquaredloss.
Notsurprisingly, ourlinear modelwillnotleadtoacompetition-winningsubmissionbutitdoesprovideasanitycheck to see whether there is meaningful information in the data.
If we cannot do better than randomguessinghere, thentheremightbeagoodchancethatwehaveadataprocessing bug.
Andifthingswork, thelinearmodelwillserveasabaselinegivingussomeintuition about how close the simple model gets to the best reported models, giving us a sense of howmuchgainweshouldexpectfromfanciermodels.
With house prices, as with stock prices, we care about relative quantities more than ab- solute quantities.
Thus we tend to care more about the relative error ğ‘¦ ğ‘¦Ë† than about the ğ‘¦ absoluteerrorğ‘¦ ğ‘¦Ë†.
Forinstance, ifourpredictionisoffby$100,000whenestimatingthe priceofahouseinrural Ohio, wherethevalueofatypicalhouseis$125,000, thenweare probably doing a horrible job.
On the other hand, if we err by this amount in Los Altos Hills, California, thismightrepresentastunninglyaccurateprediction(there, themedian housepriceexceeds$4million).
Onewaytoaddressthisproblemistomeasurethediscrepancyinthelogarithmoftheprice estimates.
Infact, thisisalsotheofficialerrormeasureusedbythecompetitiontoevaluate thequalityofsubmissions.
Afterall, asmallvalueğ›¿forjlogğ‘¦ logğ‘¦Ë†j ğ›¿translatesinto ğ‘’ ğ›¿ ğ‘¦Ë† ğ‘’ğ›¿ .
Thisleadstothefollowingroot-mean-squared-errorbetweenthelogarithm ğ‘¦ ofthepredictedpriceandthelogarithmofthelabelprice: vt ğ‘› 1 ğ‘› â€logğ‘¦ ğ‘– logğ‘¦Ë†ğ‘– â€2.
(5.7.2) ğ‘–=1 @d2l.
add_to_class(Kaggle House) def get_dataloader(self, train): (continuesonnextpage) 204 Multilayer Perceptrons (continuedfrompreviouspage) label = 'Sale Price' data = self.
train if train else self.
val if label not in data: return get_tensor = lambda x: torch.
tensor(x.
values.
astype(float), dtype=torch.
float32) # Logarithm of prices tensors = (get_tensor(data.
drop(columns=[label])), # X torch.
log(get_tensor(data[label])).
reshape((-1, 1))) # Y return self.
get_tensorloader(tensors, train) 5.7.6 ğ¾-Fold Cross-Validation Youmightrecallthatweintroducedcross-validationin Section3.6.3, wherewediscussed howtodealwithmodelselection.
Wewillputthistogoodusetoselectthemodeldesign andtoadjustthehyperparameters.
Wefirstneedafunctionthatreturnstheğ‘–th foldofthe dataina ğ¾-foldcross-validationprocedure.
Itproceedsbyslicingouttheğ‘–th segmentas validationdataandreturningtherestastrainingdata.
Notethatthisisnotthemostefficient wayofhandlingdataandwewoulddefinitelydosomethingmuchsmarterifourdatasetwas considerablylarger.
Butthisaddedcomplexitymightobfuscateourcodeunnecessarilyso wecansafelyomitithereowingtothesimplicityofourproblem.
def k_fold_data(data, k): rets = [] fold_size = data.
train.
shape[0] // k for j in range(k): idx = range(j * fold_size, (j+1) * fold_size) rets.
append(Kaggle House(data.
batch_size, data.
train.
drop(index=idx), data.
train.
loc[idx])) return rets Theaveragevalidationerrorisreturnedwhenwetrainğ¾timesintheğ¾-foldcross-validation.
def k_fold(trainer, data, k, lr): val_loss, models = [], [] for i, data_fold in enumerate(k_fold_data(data, k)): model = d2l.
Linear Regression(lr) model.
board.
yscale='log' if i != 0: model.
board.
display = False trainer.
fit(model, data_fold) val_loss.
append(float(model.
board.
data['val_loss'][-1].
y)) models.
append(model) print(f'average validation log mse = {sum(val_loss)/len(val_loss)}') return models 5.7.7 Model Selection Inthisexample, wepickanuntunedsetofhyperparametersandleaveituptothereaderto improvethemodel.
Findingagoodchoicecantaketime, dependingonhowmanyvariables oneoptimizesover.
Withalargeenoughdataset, andthenormalsortsofhyperparameters, 205 Predicting House Priceson Kaggle ğ¾-foldcross-validationtendstobereasonablyresilientagainstmultipletesting.
However, ifwetryanunreasonablylargenumberofoptionswemightfindthatourvalidationperfor- manceisnolongerrepresentativeofthetrueerror.
trainer = d2l.
Trainer(max_epochs=10) models = k_fold(trainer, data, k=5, lr=0.01) average validation log mse = 0.17325432986021042 Noticethatsometimesthenumberoftrainingerrorsforasetofhyperparameterscanbevery low, even as the number of errors on ğ¾-fold cross-validation grows considerably higher.
Thisindicatesthatweareoverfitting.
Throughouttrainingyouwillwanttomonitorboth numbers.
Lessoverfittingmightindicatethatourdatacansupportamorepowerfulmodel.
Massive overfitting might suggest that we can gain by incorporating regularization tech- niques.
5.7.8 Submitting Predictionson Kaggle Nowthatweknowwhatagoodchoiceofhyperparametersshouldbe, wemightcalculate theaveragepredictionsonthetestsetbyalltheğ¾ models.
Savingthepredictionsinacsv filewillsimplifyuploadingtheresultsto Kaggle.
Thefollowingcodewillgenerateafile calledsubmission.
csv.
â†©! float32)) for model in models] # Taking exponentiation of predictions in the logarithm scale ensemble_preds = torch.
exp(torch.
cat(preds, 1)).
mean(1) submission = pd.
Data Frame({'Id': data.
raw_val.
Id, 'Sale Price': ensemble_preds.
detach().
numpy()}) submission.
to_csv('submission.
csv', index=False) Next, asdemonstratedin.7.3, wecansubmitourpredictionson Kaggleandseehow they compare with the actual house prices (labels) on the test set.
The steps are quite simple: Logintothe Kagglewebsiteandvisitthehousepricepredictioncompetitionpage.
206 Multilayer Perceptrons Clicktheâ€œSubmit Predictionsâ€orâ€œLate Submissionâ€button.
Clicktheâ€œUpload Submission Fileâ€buttoninthedashedboxatthebottomofthepage andselectthepredictionfileyouwishtoupload.
Clicktheâ€œMake Submissionâ€buttonatthebottomofthepagetoviewyourresults.
t .7.3 Submittingdatato Kaggle 5.7.9 Summaryand Discussion Realdataoftencontainsamixofdifferentdatatypesandneedstobepreprocessed.
Rescal- ingreal-valueddatatozeromeanandunitvarianceisagooddefault.
Soisreplacingmiss- ingvalueswiththeirmean.
Furthermore, transformingcategoricalfeaturesintoindicator featuresallowsustotreatthemlikeone-hotvectors.
Whenwetendtocaremoreaboutthe relative error than about the absolute error, we can measure the discrepancy in the loga- rithm of the prediction.
To select the model and adjust the hyperparameters, we can use ğ¾-foldcross-validation.
5.7.10 Exercises 1.
Submityourpredictionsforthissectionto Kaggle.
Howgoodarethey? 2.
Isitalwaysagoodideatoreplacemissingvaluesbyamean? Hint: canyouconstructa situationwherethevaluesarenotmissingatrandom? 3.
Improvethescorebytuningthehyperparametersthroughğ¾-foldcross-validation.
4.
Improvethescorebyimprovingthemodel(e.
g., layers, weightdecay, anddropout).
5.
What happens if we do not standardize the continuous numerical features as we have doneinthissection? 110 Discussions110.
6 Buildersâ€™ Guide Alongside giant datasets and powerful hardware, great software tools have played an in- dispensable role in the rapid progress of deep learning.
Starting with the pathbreaking Theano library released in 2007, flexible open-source tools have enabled researchers to rapidly prototype models, avoiding repetitive work when recycling standard components whilestillmaintainingtheabilitytomakelow-levelmodifications.
Overtime, deeplearn- ingâ€™slibrarieshaveevolvedtoofferincreasinglycoarseabstractions.
Justassemiconductor designers went from specifying transistors to logical circuits to writing code, neural net- worksresearchershavemovedfromthinkingaboutthebehaviorofindividualartificialneu- ronstoconceivingofnetworksintermsofwholelayers, andnowoftendesignarchitectures withfarcoarserblocksinmind.
So far, we have introduced some basic machine learning concepts, ramping up to fully- functionaldeeplearningmodels.
Inthelastchapter, weimplementedeachcomponentof an MLP from scratch and even showed how to leverage high-level APIs to roll out the same models effortlessly.
To get you that far that fast, we called upon the libraries, but skipped over more advanced details about how they work.
In this chapter, we will peel back the curtain, digging deeper into the key components of deep learning computation, namely model construction, parameter access and initialization, designing custom layers andblocks, readingandwritingmodelstodisk, andleveraging GPUstoachievedramatic speedups.
Theseinsightswillmoveyoufromendusertopoweruser, givingyouthetools neededtoreapthebenefitsofamaturedeeplearninglibrarywhileretainingtheflexibilityto implementmorecomplexmodels, includingthoseyouinventyourself! Whilethischapter doesnotintroduceanynewmodelsordatasets, theadvancedmodelingchaptersthatfollow relyheavilyonthesetechniques.
6.1 Layers and Modules Whenwefirstintroducedneuralnetworks, wefocusedonlinearmodelswithasingleout- put.
Here, theentiremodelconsistsofjustasingleneuron.
Notethatasingleneuron(i) takessomesetofinputs;(ii)generatesacorrespondingscalaroutput; and(iii)hasasetof associatedparametersthatcanbeupdatedtooptimizesomeobjectivefunctionofinterest.
Then, once we started thinking about networks with multiple outputs, we leveraged vec- torizedarithmetictocharacterizeanentirelayerofneurons.
Justlikeindividualneurons, 207 208 Buildersâ€™Guide layers(i)takeasetofinputs,(ii)generatecorrespondingoutputs, and(iii)aredescribedby asetoftunableparameters.
Whenweworkedthroughsoftmaxregression, asinglelayer was itself the model.
However, even when we subsequently introduced MLPs, we could stillthinkofthemodelasretainingthissamebasicstructure.
Interestingly, for MLPs, boththeentiremodelanditsconstituentlayerssharethisstructure.
Theentiremodeltakesinrawinputs(thefeatures), generatesoutputs(thepredictions), and possesses parameters (the combined parameters from all constituent layers).
Likewise, eachindividuallayeringestsinputs(suppliedbythepreviouslayer)generatesoutputs(the inputstothesubsequentlayer), andpossessesasetoftunableparametersthatareupdated accordingtothesignalthatflowsbackwardsfromthesubsequentlayer.
Whileyoumightthinkthatneurons, layers, andmodelsgiveusenoughabstractionstogo aboutourbusiness, itturnsoutthatweoftenfinditconvenienttospeakaboutcomponents thatarelargerthananindividuallayerbutsmallerthantheentiremodel.
Forexample, the Res Net-152architecture, whichiswildlypopularincomputervision, possesseshundredsof layers.
Theselayersconsistofrepeatingpatternsofgroupsoflayers.
Implementingsuch a network one layer at a time can grow tedious.
This concern is not just hypotheticalâ€” such design patterns are common in practice.
The Res Net architecture mentioned above wonthe2015Image Netand COCOcomputervisioncompetitionsforbothrecognitionand detection(Heetal.,2016)andremainsago-toarchitectureformanyvisiontasks.
Similar architecturesinwhichlayersarearrangedinvariousrepeatingpatternsarenowubiquitous inotherdomains, includingnaturallanguageprocessingandspeech.
Toimplementthesecomplexnetworks, weintroducetheconceptofaneuralnetworkmod- ule.
A module could describe a single layer, a component consisting of multiple layers, ortheentiremodelitself! Onebenefitofworkingwiththemoduleabstractionisthatthey By defining code to generate modules of arbitrary complexity on demand, we can write surprisinglycompactcodeandstillimplementcomplexneuralnetworks.
t .1.1 Multiplelayersarecombinedintomodules, formingrepeatingpatternsoflargermodels.
From a programming standpoint, a module is represented by a class.
Any subclass of it must define a forward propagation method that transforms its input into output and must storeanynecessaryparameters.
Notethatsomemodulesdonotrequireanyparametersat 209 Layersand Modules all.
Finallyamodulemustpossessabackpropagationmethod, forpurposesofcalculating gradients.
Fortunately, duetosomebehind-the-scenesmagicsuppliedbytheautodifferen- tiation(introducedin Section2.5)whendefiningourownmodule, weonlyneedtoworry aboutparametersandtheforwardpropagationmethod.
import torch from torch import nn from torch.
nn import functional as F Tobegin, werevisitthecodethatweusedtoimplement MLPs(Section5.1).
Thefollow- ing code generates a network with one fully connected hidden layer with 256 units and Re LUactivation, followedbyafullyconnectedoutputlayerwithtenunits(noactivation function).
net = nn.
Sequential(nn.
Lazy Linear(256), nn.
Re LU(), nn.
Lazy Linear(10)) X = torch.
rand(2, 20) net(X).
shape torch.
Size([2, 10]) Inthisexample, weconstructedourmodelbyinstantiatingannn.
Sequential, withlayers intheorderthattheyshouldbeexecutedpassedasarguments.
Inshort, nn.
Sequential definesaspecialkindof Module, theclassthatpresentsamodulein Py Torch.
Itmaintains anorderedlistofconstituent Modules.
Notethateachofthetwofullyconnectedlayersisan instanceofthe Linearclasswhichisitselfasubclassof Module.
Theforwardpropagation (forward) method is also remarkably simple: it chains each module in the list together, passingtheoutputofeachasinputtothenext.
Notethatuntilnow, wehavebeeninvok- ing our models via the construction net(X) to obtain their outputs.
This is actually just shorthandfornet.__call__(X).
6.1.1 ACustom Module Perhaps the easiest way to develop intuition about how a module works is to implement oneourselves.
Beforewedothat, webrieflysummarizethebasicfunctionalitythateach modulemustprovide: 1.
Ingestinputdataasargumentstoitsforwardpropagationmethod.
2.
Generate an output by having the forward propagation method return a value.
Note thattheoutputmayhaveadifferentshapefromtheinput.
Forexample, thefirstfully connectedlayerinourmodelaboveingestsaninputofarbitrarydimensionbutreturns anoutputofdimension256.
3.
Calculatethegradientofitsoutputwithrespecttoitsinput, whichcanbeaccessedvia itsbackpropagationmethod.
Typicallythishappensautomatically.
210 Buildersâ€™Guide 4.
Storeandprovideaccesstothoseparametersnecessaryforexecutingtheforwardprop- agationcomputation.
5.
Initializemodelparametersasneeded.
In the following snippet, we code up a module from scratch corresponding to an MLP withonehiddenlayerwith256hiddenunits, anda10-dimensionaloutputlayer.
Notethat the MLP class below inherits the class that represents a module.
We will heavily rely on theparentclassâ€™smethods, supplyingonlyourownconstructor(the__init__methodin Python)andtheforwardpropagationmethod.
class MLP(nn.
Module): def __init__(self): # Call the constructor of the parent class nn.
Module to perform # the necessary initialization super().__init__() self.
hidden = nn.
Lazy Linear(256) self.
out = nn.
Lazy Linear(10) # Define the forward propagation of the model, that is, how to return the # required model output based on the input X def forward(self, X): return self.
out(F.
relu(self.
hidden(X))) Letâ€™s first focus on the forward propagation method.
Note that it takes X as input, calcu- latesthehiddenrepresentationwiththeactivationfunctionapplied, andoutputsitslogits.
Inthis MLPimplementation, bothlayersareinstancevariables.
Toseewhythisisreason- able, imagineinstantiatingtwo MLPs, net1andnet2, andtrainingthemondifferentdata.
Naturally, wewouldexpectthemtorepresenttwodifferentlearnedmodels.
Weinstantiatethe MLPâ€™slayersintheconstructorandsubsequentlyinvoketheselayerson eachcalltotheforwardpropagationmethod.
Noteafewkeydetails.
First, ourcustomized __init__methodinvokestheparentclassâ€™s__init__methodviasuper().__init__() sparing us the pain of restating boilerplate code applicable to most modules.
We then instantiateourtwofullyconnectedlayers, assigningthemtoself.
hiddenandself.
out.
Notethatunlessweimplementanewlayer, weneednotworryaboutthebackpropagation methodorparameterinitialization.
Thesystemwillgeneratethesemethodsautomatically.
Letâ€™strythisout.
net = MLP() net(X).
shape torch.
Size([2, 10]) Akeyvirtueofthemoduleabstractionisitsversatility.
Wecansubclassamoduletocreate layers(suchasthefullyconnectedlayerclass), entiremodels(suchasthe MLPclassabove), orvariouscomponentsofintermediatecomplexity.
Weexploitthisversatilitythroughout thecomingchapters, suchaswhenaddressingconvolutionalneuralnetworks.
211 Layersand Modules 6.1.2 The Sequential Module Wecannowtakeacloserlookathowthe Sequentialclassworks.
Recallthat Sequen- tial was designed to daisy-chain other modules together.
To build our own simplified My Sequential, wejustneedtodefinetwokeymethods: 1.
Amethodforappendingmodulesonebyonetoalist.
2.
Aforwardpropagationmethodforpassinganinputthroughthechainofmodules, inthe sameorderastheywereappended.
Thefollowing My Sequentialclassdeliversthesamefunctionalityofthedefault Sequen- tialclass.
class My Sequential(nn.
Module): def __init__(self, *args): super().__init__() for idx, module in enumerate(args): self.
add_module(str(idx), module) def forward(self, X): for module in self.
children(): X = module(X) return X Inthe__init__method, weaddeverymodulebycallingtheadd_modulesmethod.
These modulescanbeaccessedbythechildrenmethodatalaterdate.
Inthiswaythesystem knowstheaddedmodules, anditwillproperlyinitializeeachmoduleâ€™sparameters.
Whenour My Sequentialâ€™sforwardpropagationmethodisinvoked, eachaddedmoduleis executedintheorderinwhichtheywereadded.
Wecannowreimplementan MLPusing our My Sequentialclass.
net = My Sequential(nn.
Lazy Linear(256), nn.
Re LU(), nn.
Lazy Linear(10)) net(X).
shape torch.
Size([2, 10]) Note that this use of My Sequential is identical to the code we previously wrote for the Sequentialclass(asdescribedin Section5.1).
6.1.3 Executing Codeinthe Forward Propagation Method The Sequentialclassmakesmodelconstructioneasy, allowingustoassemblenewarchi- tectureswithouthavingtodefineourownclass.
However, notallarchitecturesaresimple daisychains.
Whengreaterflexibilityisrequired, wewillwanttodefineourownblocks.
Forexample, wemightwanttoexecute Pythonâ€™scontrolflowwithintheforwardpropaga- tionmethod.
Moreover, wemightwanttoperformarbitrarymathematicaloperations, not simplyrelyingonpredefinedneuralnetworklayers.
212 Buildersâ€™Guide Youmayhavenoticedthatuntilnow, alloftheoperationsinournetworkshaveactedupon ournetworkâ€™sactivationsanditsparameters.
Sometimes, however, wemightwanttoin- corporatetermsthatareneithertheresultofpreviouslayersnorupdatableparameters.
We call these constant parameters.
Say for example that we want a layer that calculates the function ğ‘“â€x, wâ€ =ğ‘ w>x, wherexistheinput, wisourparameter, andğ‘issomespeci- fiedconstantthatisnotupdatedduringoptimization.
Soweimplementa Fixed Hidden MLP classasfollows.
class Fixed Hidden MLP(nn.
Module): def __init__(self): super().__init__() # Random weight parameters that will not compute gradients and # therefore keep constant during training self.
rand_weight = torch.
rand((20, 20)) self.
linear = nn.
Lazy Linear(20) def forward(self, X): X = self.
linear(X) X = F.
relu(X @ self.
rand_weight + 1) # Reuse the fully connected layer.
This is equivalent to sharing # parameters with two fully connected layers X = self.
linear(X) # Control flow while X.
abs().
sum() > 1: X /= 2 return X.
sum() Inthismodel, weimplementahiddenlayerwhoseweights(self.
rand_weight)areini- tializedrandomlyatinstantiationandarethereafterconstant.
Thisweightisnotamodel parameterandthusitis neverupdatedbybackpropagation.
The networkthenpassesthe outputofthisâ€œfixedâ€layerthroughafullyconnectedlayer.
Notethatbeforereturningtheoutput, ourmodeldidsomethingunusual.
Weranawhile- loop, testingontheconditionitsâ„“ normislargerthan1, anddividingouroutputvector 1 by2untilitsatisfiedthecondition.
Finally, wereturnedthesumoftheentriesin X.
Toour knowledge, nostandardneuralnetworkperformsthisoperation.
Notethatthisparticular operationmaynotbeusefulinanyreal-worldtask.
Ourpointisonlytoshowyouhowto integratearbitrarycodeintotheflowofyourneuralnetworkcomputations.
net = Fixed Hidden MLP() net(X) tensor(-0.3836, grad_fn=<Sum Backward0>) We can mix and match various ways of assembling modules together.
In the following example, wenestmodulesinsomecreativeways.
class Nest MLP(nn.
Module): (continuesonnextpage) 213 Parameter Management (continuedfrompreviouspage) def __init__(self): super().__init__() self.
net = nn.
Sequential(nn.
Lazy Linear(64), nn.
Re LU(), nn.
Lazy Linear(32), nn.
Re LU()) self.
linear = nn.
Lazy Linear(16) def forward(self, X): return self.
linear(self.
net(X)) chimera = nn.
Sequential(Nest MLP(), nn.
Lazy Linear(20), Fixed Hidden MLP()) chimera(X) tensor(0.0679, grad_fn=<Sum Backward0>) 6.1.4 Summary Individuallayerscanbemodules.
Manylayerscancompriseamodule.
Manymodulescan compriseamodule.
Amodulecancontaincode.
Modulestakecareoflotsofhousekeeping, includingparam- eterinitializationandbackpropagation.
Sequentialconcatenationsoflayersandmodules arehandledbythe Sequentialmodule.
6.1.5 Exercises 1.
Whatkindsofproblemswilloccurifyouchange My Sequentialtostoremodulesina Pythonlist? 2.
Implement a module that takes two modules as an argument, say net1 and net2 and returns the concatenated output of both networks in the forward propagation.
This is alsocalledaparallelmodule.
3.
Assumethatyouwanttoconcatenatemultipleinstancesofthesamenetwork.
Imple- mentafactoryfunctionthatgeneratesmultipleinstancesofthesamemoduleandbuild alargernetworkfromit.
111 Discussions111.
6.2 Parameter Management Oncewehavechosenanarchitectureandsetourhyperparameters, weproceedtothetrain- ingloop, whereourgoalistofindparametervaluesthatminimizeourlossfunction.
After training, wewillneedtheseparametersinordertomakefuturepredictions.
Additionally, we will sometimes wish to extract the parameters perhaps to reuse them in some other 214 Buildersâ€™Guide context, tosaveourmodeltodisksothatitmaybeexecutedinothersoftware, orforex- aminationinthehopeofgainingscientificunderstanding.
Mostof the time, wewill beable to ignore the nitty-gritty details of howparameters are declared and manipulated, relying on deep learning frameworks to do the heavy lifting.
However, when we move away from stacked architectures with standard layers, we will sometimes need to get into the weeds of declaring and manipulating parameters.
In this section, wecoverthefollowing: Accessingparametersfordebugging, diagnostics, andvisualizations.
Sharingparametersacrossdifferentmodelcomponents.
import torch from torch import nn Westartbyfocusingonan MLPwithonehiddenlayer.
net = nn.
Sequential(nn.
Lazy Linear(8), nn.
Re LU(), nn.
Lazy Linear(1)) X = torch.
rand(size=(2, 4)) net(X).
shape torch.
Size([2, 1]) 6.2.1 Parameter Access Letâ€™sstartwithhowtoaccessparametersfromthemodelsthatyoualreadyknow.
Whenamodelisdefinedviathe Sequentialclass, wecanfirstaccessanylayerbyindexing intothemodelasthoughitwerealist.
Eachlayerâ€™sparametersareconvenientlylocatedin itsattribute.
Wecaninspecttheparametersofthesecondfullyconnectedlayerasfollows.
net[2].
state_dict() Ordered Dict([('weight', â†©!0.2322, 0.0822]])), ('bias', tensor([0.0709]))]) Wecanseethatthisfullyconnectedlayercontainstwoparameters, correspondingtothat layerâ€™sweightsandbiases, respectively.
215 Parameter Management Targeted Parameters Notethateachparameterisrepresentedasaninstanceoftheparameterclass.
Todoany- thingusefulwiththeparameters, wefirstneedtoaccesstheunderlyingnumericalvalues.
There are several ways to do this.
Some are simpler while others are more general.
The following code extracts the bias from the second neural network layer, which returns a parameterclassinstance, andfurtheraccessesthatparameterâ€™svalue.
type(net[2].
bias), net[2].
bias.
data (torch.
nn.
parameter.
Parameter, tensor([0.0709])) Parametersarecomplexobjects, containingvalues, gradients, andadditionalinformation.
Thatiswhyweneedtorequestthevalueexplicitly.
Inadditiontothevalue, eachparameteralsoallowsustoaccessthegradient.
Becausewe havenotinvokedbackpropagationforthisnetworkyet, itisinitsinitialstate.
net[2].
weight.
grad == None True All Parametersat Once When we need to perform operations on all parameters, accessing them one-by-one can growtedious.
Thesituationcangrowespeciallyunwieldywhenweworkwithmorecom- plex, e.
g., nested, modules, sincewewouldneedtorecursethroughtheentiretreetoextract eachsub-moduleâ€™sparameters.
Belowwedemonstrateaccessingtheparametersofalllay- ers.
[(name, param.
shape) for name, param in net.
named_parameters()] [('0.
weight', torch.
Size([8, 4])), ('0.
bias', torch.
Size([8])), ('2.
weight', torch.
Size([1, 8])), ('2.
bias', torch.
Size([1]))] 6.2.2 Tied Parameters Often, wewanttoshareparametersacrossmultiplelayers.
Letâ€™sseehowtodothiselegantly.
Inthefollowingweallocateafullyconnectedlayerandthenuseitsparametersspecifically tosetthoseofanotherlayer.
Hereweneedtoruntheforwardpropagationnet(X)before accessingtheparameters.
216 Buildersâ€™Guide # We need to give the shared layer a name so that we can refer to its # parameters shared = nn.
Lazy Linear(8) net = nn.
Sequential(nn.
Lazy Linear(8), nn.
Re LU(), shared, nn.
Re LU(), shared, nn.
Re LU(), nn.
Lazy Linear(1)) net(X) # Check whether the parameters are the same print(net[2].
weight.
data[0] == net[4].
weight.
data[0]) net[2].
weight.
data[0, 0] = 100 # Make sure that they are actually the same object rather than just having the # same value print(net[2].
weight.
data[0] == net[4].
weight.
data[0]) tensor([True, True, True, True, True, True, True, True]) tensor([True, True, True, True, True, True, True, True]) This example shows that the parameters of the second and third layer are tied.
They are notjustequal, theyarerepresentedbythesameexacttensor.
Thus, ifwechangeoneofthe parameters, theotheronechanges, too.
You might wonder, when parameters are tied what happens to the gradients? Since the modelparameterscontaingradients, thegradientsofthesecondhiddenlayerandthethird hiddenlayerareaddedtogetherduringbackpropagation.
6.2.3 Summary Wehaveseveralwaysofaccessingandtyingmodelparameters.
6.2.4 Exercises 1.
Usethe Nest MLPmodeldefinedin Section6.1andaccesstheparametersofthevarious layers.
2.
Constructan MLPcontainingasharedparameterlayerandtrainit.
Duringthetraining process, observethemodelparametersandgradientsofeachlayer.
3.
Whyissharingparametersagoodidea? Discussions112.
112 6.3 Parameter Initialization Nowthatweknowhowtoaccesstheparameters, letâ€™slookathowtoinitializethemprop- erly.
We discussed the need for proper initialization in Section 5.4.
The deep learning 217 Parameter Initialization frameworkprovidesdefaultrandominitializationstoitslayers.
However, weoftenwantto initializeourweightsaccordingtovariousotherprotocols.
Theframeworkprovidesmost commonlyusedprotocols, andalsoallowstocreateacustominitializer.
import torch from torch import nn Bydefault, Py Torchinitializesweightandbiasmatricesuniformlybydrawingfromarange thatiscomputedaccordingtotheinputandoutputdimension.
Py Torchâ€™snn.
initmodule providesavarietyofpresetinitializationmethods.
net = nn.
Sequential(nn.
Lazy Linear(8), nn.
Re LU(), nn.
Lazy Linear(1)) X = torch.
rand(size=(2, 4)) net(X).
shape torch.
Size([2, 1]) 6.3.1 Built-in Initialization Letâ€™sbeginbycallingonbuilt-ininitializers.
Thecodebelowinitializesallweightparame- tersas Gaussianrandomvariableswithstandarddeviation0.01, whilebiasparametersare clearedtozero.
def init_normal(module): if type(module) == nn.
Linear: nn.
init.
normal_(module.
weight, mean=0, std=0.01) nn.
init.
zeros_(module.
bias) net.
apply(init_normal) net[0].
weight.
data[0], net[0].
bias.
data[0] Wecanalsoinitializealltheparameterstoagivenconstantvalue(say,1).
def init_constant(module): if type(module) == nn.
Linear: nn.
init.
constant_(module.
weight, 1) nn.
init.
zeros_(module.
bias) net.
apply(init_constant) net[0].
weight.
data[0], net[0].
bias.
data[0] Wecanalsoapplydifferentinitializersforcertainblocks.
Forexample, belowweinitialize 218 Buildersâ€™Guide thefirstlayerwiththe Xavierinitializerandinitializethesecondlayertoaconstantvalue of42.
def init_xavier(module): if type(module) == nn.
Linear: nn.
init.
xavier_uniform_(module.
weight) def init_42(module): if type(module) == nn.
Linear: nn.
init.
constant_(module.
weight, 42) net[0].
apply(init_xavier) net[2].
apply(init_42) print(net[0].
weight.
data[0]) print(net[2].
weight.
data) tensor([-0.0974, 0.1707, 0.5840, -0.5032]) Custom Initialization Sometimes, theinitializationmethodsweneedarenotprovidedbythedeeplearningframe- work.
Intheexamplebelow, wedefineaninitializerforanyweightparameterğ‘¤usingthe followingstrangedistribution: 8>>>< ğ‘ˆâ€5,10â€ withprobability 1 4 ğ‘¤ 0 withprobability 1 (6.3.1) >>> 2 :ğ‘ˆâ€ 10, 5â€ withprobability 1 4 Again, weimplementamy_initfunctiontoapplytonet.
def my_init(module): if type(module) == nn.
Linear: print("Init", *[(name, param.
shape) for name, param in module.
named_parameters()][0]) nn.
init.
uniform_(module.
weight, -10, 10) net.
apply(my_init) net[0].
weight[:2] Init weight torch.
Size([8, 4]) Init weight torch.
Size([1, 8]) tensor([[ 0.0000, -7.6364, -0.0000, -6.1206], [ 9.3516, -0.0000, 5.1208, -8.4003]], grad_fn=<Slice Backward0>) Notethatwealwayshavetheoptionofsettingparametersdirectly.
219 Lazy Initialization net[0].
weight.
data[:] += 1 net[0].
weight.
data[0, 0] = 42 net[0].
weight.
data[0] tensor([42.0000, -6.6364, 1.0000, -5.1206]) 6.3.2 Summary Wecaninitializeparametersusingbuilt-inandcustominitializers.
6.3.3 Exercises Lookuptheonlinedocumentationformorebuilt-ininitializers.
Discussions113.
113 6.4 Lazy Initialization Sofar, itmightseemthatwegotawaywithbeingsloppyinsettingupournetworks.
Specif- ically, we did the following unintuitive things, which might not seem like they should work: Wedefinedthenetworkarchitectureswithoutspecifyingtheinputdimensionality.
Weaddedlayerswithoutspecifyingtheoutputdimensionofthepreviouslayer.
We even â€œinitializedâ€ these parameters before providing enough information to deter- minehowmanyparametersourmodelsshouldcontain.
Youmightbesurprisedthatourcoderunsatall.
Afterall, thereisnowaythedeeplearning frameworkcouldtellwhattheinputdimensionalityofanetworkwouldbe.
Thetrickhere isthattheframeworkdefersinitialization, waitinguntilthefirsttimewepassdatathrough themodel, toinferthesizesofeachlayeronthefly.
Later on, when working with convolutional neural networks, this technique will become evenmoreconvenientsincetheinputdimensionality(e.
g., theresolutionofanimage)will affect the dimensionality of each subsequent layer.
Hence the ability to set parameters withouttheneedtoknow, atthetimeofwritingthecode, thevalueofthedimensioncan greatlysimplifythetaskofspecifyingandsubsequentlymodifyingourmodels.
Next, we godeeperintothemechanicsofinitialization.
import torch from torch import nn from d2l import torch as d2l 220 Buildersâ€™Guide Tobegin, letâ€™sinstantiatean MLP.
net = nn.
Sequential(nn.
Lazy Linear(256), nn.
Re LU(), nn.
Lazy Linear(10)) Atthispoint, thenetworkcannotpossiblyknowthedimensionsoftheinputlayerâ€™sweights becausetheinputdimensionremainsunknown.
Consequently the framework has not yet initialized any parameters.
We confirm by at- temptingtoaccesstheparametersbelow.
net[0].
weight <Uninitialized Parameter> Nextletâ€™spassdatathroughthenetworktomaketheframeworkfinallyinitializeparame- ters.
X = torch.
rand(2, 20) net(X) net[0].
weight.
shape torch.
Size([256, 20]) Assoonasweknowtheinputdimensionality,20, theframeworkcanidentifytheshapeof thefirstlayerâ€™sweightmatrixbyplugginginthevalueof20.
Havingrecognizedthefirst layerâ€™sshape, theframeworkproceedstothesecondlayer, andsoonthroughthecomputa- tionalgraphuntilallshapesareknown.
Notethatinthiscase, onlythefirstlayerrequires lazy initialization, but the framework initializes sequentially.
Once all parameter shapes areknown, theframeworkcanfinallyinitializetheparameters.
Thefollowingmethodpassesindummyinputsthroughthenetworkforadryruntoinfer allparametershapesandsubsequentlyinitializestheparameters.
Itwillbeusedlaterwhen defaultrandominitializationsarenotdesired.
@d2l.
add_to_class(d2l.
Module) #@save def apply_init(self, inputs, init=None): self.
forward(*inputs) if init is not None: self.
net.
apply(init) 6.4.1 Summary Lazy initialization can be convenient, allowing the framework to infer parameter shapes automatically, makingiteasytomodifyarchitecturesandeliminatingonecommonsource of errors.
We can pass data through the model to make the framework finally initialize parameters.
221 Custom Layers 6.4.2 Exercises 1.
Whathappensifyouspecifytheinputdimensionstothefirstlayerbutnottosubsequent layers? Doyougetimmediateinitialization? 2.
Whathappensifyouspecifymismatchingdimensions? 3.
Whatwouldyouneedtodoifyouhaveinputofvaryingdimensionality? Hint: lookat theparametertying.
114 Discussions114.
6.5 Custom Layers Onefactorbehinddeeplearningâ€™ssuccessistheavailabilityofawiderangeoflayersthat can be composed in creative ways to design architectures suitable for a wide variety of tasks.
Forinstance, researchershaveinventedlayersspecificallyforhandlingimages, text, loopingoversequentialdata, andperformingdynamicprogramming.
Soonerorlater, you willneedalayerthatdoesnotexistyetinthedeeplearningframework.
Inthesecases, you mustbuildacustomlayer.
Inthissection, weshowyouhow.
import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 6.5.1 Layerswithout Parameters To start, we construct a custom layer that does not have any parameters of its own.
This shouldlookfamiliarifyourecallourintroductiontomodulesin Section6.1.
Thefollowing Centered Layerclasssimplysubtractsthemeanfromitsinput.
Tobuildit, wesimplyneed toinheritfromthebaselayerclassandimplementtheforwardpropagationfunction.
class Centered Layer(nn.
Module): def __init__(self): super().__init__() def forward(self, X): return X - X.
mean() Letâ€™sverifythatourlayerworksasintendedbyfeedingsomedatathroughit.
layer = Centered Layer() layer(torch.
tensor([1.0, 2, 3, 4, 5])) 222 Buildersâ€™Guide We can now incorporate our layer as a component in constructing more complex mod- els.
net = nn.
Sequential(nn.
Lazy Linear(128), Centered Layer()) Asanextrasanitycheck, wecansendrandomdatathroughthenetworkandcheckthatthe meanisinfact0.
Becausewearedealingwithfloatingpointnumbers, wemaystillseea verysmallnonzeronumberduetoquantization.
Y = net(torch.
rand(4, 8)) Y.
mean() tensor(-6.5193e-09, grad_fn=<Mean Backward0>) 6.5.2 Layerswith Parameters Nowthatweknowhowtodefinesimplelayers, letâ€™smoveontodefininglayerswithpa- rameters that can be adjusted through training.
We can use built-in functions to create parameters, whichprovidesomebasichousekeepingfunctionality.
Inparticular, theygov- ernaccess, initialization, sharing, saving, andloadingmodelparameters.
Thisway, among other benefits, we will not need to write custom serialization routines for every custom layer.
Now letâ€™s implement our own version of the fully connected layer.
Recall that this layer requirestwoparameters, onetorepresenttheweightandtheotherforthebias.
Inthisim- plementation, webakeinthe Re LUactivationasadefault.
Thislayerrequirestwoinput arguments: in_unitsandunits, whichdenotethenumberofinputsandoutputs, respec- tively.
class My Linear(nn.
Module): def __init__(self, in_units, units): super().__init__() self.
weight = nn.
Parameter(torch.
randn(in_units, units)) self.
bias = nn.
Parameter(torch.
randn(units,)) def forward(self, X): return F.
relu(linear) Next, weinstantiatethe My Linearclassandaccessitsmodelparameters.
linear = My Linear(5, 3) linear.
weight 223 File I/O Parameter containing: tensor([[ 0.4783, 0.4284, -0.0899], [-0.6347, 0.2913, -0.0822], [-0.4325, -0.1645, -0.3274], [ 1.1898, 0.6482, -1.2384], [-0.1479, 0.0264, -0.9597]], requires_grad=True) Wecandirectlycarryoutforwardpropagationcalculationsusingcustomlayers.
linear(torch.
rand(2, 5)) tensor([[0.0000, 0.9316, 0.0000], [0.1808, 1.4208, 0.0000]]) Wecanalsoconstructmodelsusingcustomlayers.
Oncewehavethatwecanuseitjust likethebuilt-infullyconnectedlayer.
net = nn.
Sequential(My Linear(64, 8), My Linear(8, 1)) net(torch.
rand(2, 64)) tensor([[ 0.0000], [13.0800]]) 6.5.3 Summary We can design custom layers via the basic layer class.
This allows us to define flexible new layers that behave differently from any existing layers in the library.
Once defined, customlayerscanbeinvokedinarbitrarycontextsandarchitectures.
Layerscanhavelocal parameters, whichcanbecreatedthroughbuilt-infunctions.
6.5.4 Exercises 1.
D Ë esignalayerthattakesaninputandcomputesatensorreduction, i.
e., itreturns ğ‘¦ ğ‘˜ = ğ‘–,ğ‘— ğ‘Š ğ‘–ğ‘—ğ‘˜ ğ‘¥ ğ‘– ğ‘¥ ğ‘—.
2.
Designalayerthatreturnstheleadinghalfofthe Fouriercoefficientsofthedata.
Discussions115.
115 6.6 File I/O Sofarwehavediscussedhowtoprocessdataandhowtobuild, train, andtestdeeplearn- ingmodels.
However, atsomepointwewillhopefullybehappyenoughwiththelearned 224 Buildersâ€™Guide modelsthatwewillwanttosavetheresultsforlateruseinvariouscontexts(perhapseven tomakepredictionsindeployment).
Additionally, whenrunningalongtrainingprocess, thebestpracticeistoperiodicallysaveintermediateresults(checkpointing)toensurethat we do not lose several daysâ€™ worth of computation if we trip over the power cord of our server.
Thus it is time to learn how to load and store both individual weight vectors and entiremodels.
Thissectionaddressesbothissues.
import torch from torch import nn from torch.
nn import functional as F 6.6.1 Loadingand Saving Tensors For individual tensors, we can directly invoke the load and save functions to read and writethemrespectively.
Bothfunctionsrequirethatwesupplyaname, andsaverequires asinputthevariabletobesaved.
x = torch.
arange(4) torch.
save(x, 'x-file') Wecannowreadthedatafromthestoredfilebackintomemory.
x2 = torch.
load('x-file') x2 tensor([0, 1, 2, 3]) Wecanstorealistoftensorsandreadthembackintomemory.
y = torch.
zeros(4) torch.
save([x, y],'x-files') x2, y2 = torch.
load('x-files') (x2, y2) (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.])) Wecanevenwriteandreadadictionarythatmapsfromstringstotensors.
Thisisconve- nientwhenwewanttoreadorwritealltheweightsinamodel.
mydict = {'x': x, 'y': y} torch.
save(mydict, 'mydict') mydict2 = torch.
load('mydict') mydict2 225 File I/O {'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])} 6.6.2 Loadingand Saving Model Parameters Savingindividualweightvectors(orothertensors)isuseful, butitgetsverytediousifwe wanttosave(andlaterload)anentiremodel.
Afterall, wemighthavehundredsofparam- eter groups sprinkled throughout.
For this reason the deep learning framework provides built-infunctionalitiestoloadandsaveentirenetworks.
Animportantdetailtonoteisthat thissavesmodelparametersandnottheentiremodel.
Forexample, ifwehavea3-layer MLP, weneedtospecifythearchitectureseparately.
Thereasonforthisisthatthemodels themselvescancontainarbitrarycode, hencetheycannotbeserializedasnaturally.
Thus, inordertoreinstateamodel, weneedtogeneratethearchitectureincodeandthenloadthe parametersfromdisk.
Letâ€™sstartwithourfamiliar MLP.
class MLP(nn.
Module): def __init__(self): super().__init__() self.
hidden = nn.
Lazy Linear(256) self.
output = nn.
Lazy Linear(10) def forward(self, x): return self.
output(F.
relu(self.
hidden(x))) net = MLP() X = torch.
randn(size=(2, 20)) Y = net(X) Next, westoretheparametersofthemodelasafilewiththenameâ€œmlp.
paramsâ€.
torch.
save(net.
state_dict(), 'mlp.
params') To recover the model, we instantiate a clone of the original MLP model.
Instead of ran- domlyinitializingthemodelparameters, wereadtheparametersstoredinthefiledirectly.
clone = MLP() clone.
load_state_dict(torch.
load('mlp.
params')) clone.
eval() MLP( (hidden): Lazy Linear(in_features=0, out_features=256, bias=True) (output): Lazy Linear(in_features=0, out_features=10, bias=True) ) Sincebothinstanceshavethesamemodelparameters, thecomputationalresultofthesame input Xshouldbethesame.
Letâ€™sverifythis.
226 Buildersâ€™Guide Y_clone = clone(X) Y_clone == Y tensor([[True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, True]]) 6.6.3 Summary The save and load functions can be used to perform file I/O for tensor objects.
We can saveandloadtheentiresetsofparametersforanetworkviaaparameterdictionary.
Saving thearchitecturehastobedoneincoderatherthaninparameters.
6.6.4 Exercises 1.
Even if there is no need to deploy trained models to a different device, what are the practicalbenefitsofstoringmodelparameters? 2.
Assumethatwewanttoreuseonlypartsofanetworktobeincorporatedintoanetwork havingadifferentarchitecture.
Howwouldyougoaboutusing, saythefirsttwolayers fromapreviousnetworkinanewnetwork? 3.
Howwouldyougoaboutsavingthenetworkarchitectureandparameters? Whatrestric- tionswouldyouimposeonthearchitecture? Discussions116.
116 6.7 GPUs In tab_intro_decade, we illustrated the rapid growth of computation over the past two decades.
Inanutshell, GPUperformancehasincreasedbyafactorof1000everydecade since 2000.
This offers great opportunities but it also suggests that there was significant demandforsuchperformance.
Inthissection, webegintodiscusshowtoharnessthiscomputationalperformanceforyour research.
Firstbyusingasingle GPUandatalaterpoint, howtousemultiple GPUsand multipleservers(withmultiple GPUs).
Specifically, we will discuss how to use a single NVIDIA GPU for calculations.
First, make sure you have at least one NVIDIA GPU installed.
Then, download the NVIDIA 117 driverand CUDA117 andfollowthepromptstosettheappropriatepath.
Oncetheseprepa- rations are complete, the nvidia-smi command can be used to view the graphics card information.
In Py Torch, everyarrayhasadevice; weoftenreferitasacontext.
Sofar, bydefault, all 227 GPUs variablesandassociatedcomputationhavebeenassignedtothe CPU.
Typically, othercon- textsmightbevarious GPUs.
Thingscangetevenhairierwhenwedeployjobsacrossmul- tipleservers.
Byassigningarraystocontextsintelligently, wecanminimizethetimespent transferringdatabetweendevices.
Forexample, whentrainingneuralnetworksonaserver witha GPU, wetypicallypreferforthemodelâ€™sparameterstoliveonthe GPU.
To run the programs in this section, you need at least two GPUs.
Note that this might be extravagant for most desktop computers but it is easily available in the cloud, e.
g., by usingthe AWSEC2multi-GPUinstances.
Almostallothersectionsdonotrequiremultiple GPUs, butherewesimplywishtoillustratedataflowbetweendifferentdevices.
import torch from torch import nn from d2l import torch as d2l 6.7.1 Computing Devices Wecanspecifydevices, suchas CPUsand GPUs, forstorageandcalculation.
Bydefault, tensorsarecreatedinthemainmemoryandthenthe CPUisusedforcalculations.
In Py Torch, the CPU and GPU can be indicated by torch.
device('cpu') and torch.
device('cuda').
It should be noted that the cpu device means all physical CPUs and memory.
Thismeansthat Py Torchâ€™scalculationswilltrytouseall CPUcores.
However, a gpudeviceonlyrepresentsonecardandthecorrespondingmemory.
Iftherearemultiple GPUs, weusetorch.
device(f'cuda:{i}')torepresenttheğ‘–th GPU(ğ‘–startsat0).
Also, gpu:0andgpuareequivalent.
def cpu(): #@save """Get the CPU device.""" return torch.
device('cpu') def gpu(i=0): #@save """Get a GPU device.""" return torch.
device(f'cuda:{i}') cpu(), gpu(), gpu(1) (device(type='cpu'), device(type='cuda', index=0), device(type='cuda', index=1)) Wecanquerythenumberofavailable GPUs.
def num_gpus(): #@save """Get the number of available GPUs.""" return torch.
cuda.
device_count() num_gpus() 228 Buildersâ€™Guide 2 Now we define two convenient functions that allow us to run code even if the requested GPUsdonotexist.
def try_gpu(i=0): #@save """Return gpu(i) if exists, otherwise return cpu().""" if num_gpus() >= i + 1: return gpu(i) return cpu() def try_all_gpus(): #@save """Return all available GPUs, or [cpu(),] if no GPU exists.""" return [gpu(i) for i in range(num_gpus())] try_gpu(), try_gpu(10), try_all_gpus() (device(type='cuda', index=0), device(type='cpu'), [device(type='cuda', index=0), device(type='cuda', index=1)]) 6.7.2 Tensorsand GPUs Bydefault, tensorsare createdonthe CPU.
Wecanquery thedevicewhere thetensoris located.
x = torch.
tensor([1, 2, 3]) x.
device device(type='cpu') Itisimportanttonotethatwheneverwewanttooperateonmultipleterms, theyneedtobe onthesamedevice.
Forinstance, ifwesumtwotensors, weneedtomakesurethatboth arguments live on the same deviceâ€”otherwise the framework would not know where to storetheresultorevenhowtodecidewheretoperformthecomputation.
Storageonthe GPU Thereareseveralwaystostoreatensoronthe GPU.
Forexample, wecanspecifyastor- agedevicewhencreatingatensor.
Next, wecreatethetensorvariable Xonthefirstgpu.
The tensor created on a GPU only consumes the memory of this GPU.
We can use the nvidia-smicommandtoview GPUmemoryusage.
Ingeneral, weneedtomakesurethat wedonotcreatedatathatexceedsthe GPUmemorylimit.
X = torch.
ones(2, 3, device=try_gpu()) X 229 GPUs tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:0') Assumingthatyouhaveatleasttwo GPUs, thefollowingcodewillcreatearandomtensor, Y, onthesecond GPU.
Y = torch.
rand(2, 3, device=try_gpu(1)) Y tensor([[0.0022, 0.5723, 0.2890], [0.1456, 0.3537, 0.7359]], device='cuda:1') Copying If we want to compute X + Y, we need to decide where to perform this operation.
For instance, as shown in .7.1, we can transfer X to the second GPU and perform the operation there.
Do not simply add X and Y, since this will result in an exception.
The runtimeenginewouldnotknowwhattodo: itcannotfinddataonthesamedeviceandit fails.
Since Y lives on the second GPU, we need to move X there before we can add the two.
t .7.1 Copydatatoperformanoperationonthesamedevice.
Z = X.
cuda(1) print(X) print(Z) tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:0') tensor([[1., 1., 1.], [1., 1., 1.]], device='cuda:1') Nowthatthedata(both Zand Y)areonthesame GPU), wecanaddthemup.
Y + Z tensor([[1.0022, 1.5723, 1.2890], [1.1456, 1.3537, 1.7359]], device='cuda:1') 230 Buildersâ€™Guide Butwhatifyourvariable Zalreadylivedonyoursecond GPU? Whathappensifwestillcall Z.
cuda(1)? Itwillreturn Zinsteadofmakingacopyandallocatingnewmemory.
Z.
cuda(1) is Z True Side Notes Peopleuse GPUstodomachinelearningbecausetheyexpectthemtobefast.
Buttrans- ferringvariablesbetweendevicesisslow: muchslowerthancomputation.
Sowewantyou tobe100%certainthatyouwanttodosomethingslowbeforeweletyoudoit.
Ifthedeep learning framework just did the copy automatically without crashing then you might not realizethatyouhadwrittensomeslowcode.
Transferringdataisnotonlyslow, italsomakesparallelizationalotmoredifficult, since we have to wait for data to be sent (or rather to be received) before we can proceed with moreoperations.
Thisiswhycopyoperationsshouldbetakenwithgreatcare.
Asaruleof thumb, manysmalloperationsaremuchworsethanonebigoperation.
Moreover, several operationsatatimearemuchbetterthanmanysingleoperationsinterspersedinthecode unlessyouknowwhatyouaredoing.
Thisisthecasesincesuchoperationscanblockif onedevicehastowaitfortheotherbeforeitcandosomethingelse.
Itisabitlikeordering yourcoffeeinaqueueratherthanpre-orderingitbyphoneandfindingoutthatitisready whenyouare.
Last, whenweprinttensorsorconverttensorstothe Num Pyformat, ifthedataisnotinthe mainmemory, theframeworkwillcopyittothemainmemoryfirst, resultinginadditional transmissionoverhead.
Evenworse, itisnowsubjecttothedreadedglobalinterpreterlock thatmakeseverythingwaitfor Pythontocomplete.
6.7.3 Neural Networksand GPUs Similarly, aneuralnetworkmodelcanspecifydevices.
Thefollowingcodeputsthemodel parametersonthe GPU.
net = nn.
Sequential(nn.
Lazy Linear(1)) net = net.
to(device=try_gpu()) Wewillseemanymoreexamplesofhowtorunmodelson GPUsinthefollowingchapters, simplybecausethemodelswillbecomesomewhatmorecomputationallyintensive.
Forexample, whentheinputisatensoronthe GPU, themodelwillcalculatetheresulton thesame GPU.
net(X) 231 GPUs tensor([[0.7802], [0.7802]], device='cuda:0', grad_fn=<Addmm Backward0>) Letâ€™sconfirmthatthemodelparametersarestoredonthesame GPU.
net[0].
weight.
data.
device device(type='cuda', index=0) Letthetrainersupport GPU.
@d2l.
add_to_class(d2l.
Trainer) #@save def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0): self.
save_hyperparameters() self.
gpus = [d2l.
gpu(i) for i in range(min(num_gpus, d2l.
num_gpus()))] @d2l.
add_to_class(d2l.
Trainer) #@save def prepare_batch(self, batch): if self.
gpus: batch = [a.
to(self.
gpus[0]) for a in batch] return batch @d2l.
add_to_class(d2l.
Trainer) #@save def prepare_model(self, model): model.
trainer = self model.
board.
xlim = [0, self.
max_epochs] if self.
gpus: model.
to(self.
gpus[0]) self.
model = model Inshort, aslongasalldataandparametersareonthesamedevice, wecanlearnmodels efficiently.
Inthefollowingchapterswewillseeseveralsuchexamples.
6.7.4 Summary Wecanspecifydevicesforstorageandcalculation, suchasthe CPUor GPU.
Bydefault, data is created in the main memory and then uses the CPU for calculations.
The deep learningframeworkrequiresallinputdataforcalculationtobeonthesamedevice, beit CPUorthesame GPU.
Youcanlosesignificantperformancebymovingdatawithoutcare.
A typical mistake is as follows: computing the loss for every minibatch on the GPU and reportingitbacktotheuseronthecommandline(orloggingitina Num Pyndarray)will triggeraglobalinterpreterlockwhichstallsall GPUs.
Itismuchbettertoallocatememory forlogginginsidethe GPUandonlymovelargerlogs.
6.7.5 Exercises 1.
Tryalargercomputationtask, suchasthemultiplicationoflargematrices, andseethe differenceinspeedbetweenthe CPUand GPU.
Whataboutataskwithasmallnumber ofcalculations? 232 Buildersâ€™Guide 2.
Howshouldwereadandwritemodelparametersonthe GPU? 3.
Measurethetimeittakestocompute1000matrixâ€“matrixmultiplicationsof100 100 matricesandlogthe Frobeniusnormoftheoutputmatrixoneresultatatime.
Compare itwithkeepingalogonthe GPUandtransferringonlythefinalresult.
4.
Measurehowmuchtimeittakestoperformtwomatrixâ€“matrixmultiplicationsontwo GPUsatthesametime.
Compareitwithcomputingininsequenceonone GPU.
Hint: youshouldseealmostlinearscaling.
Discussions118.
118 7 Convolutional Neural Networks Image data is represented as a two-dimensional grid of pixels, be the image monochro- maticorincolor.
Accordinglyeachpixelcorrespondstooneormultiplenumericalvalues respectively.
So far we have ignored this rich structure and treated images as vectors of numbersbyflatteningthem, irrespectiveofthespatialrelationbetweenpixels.
Thisdeeply unsatisfyingapproachwasnecessaryinordertofeedtheresultingone-dimensionalvectors throughafullyconnected MLP.
Because these networks are invariant to the order of the features, we could get similar results regardless of whether we preserve an order corresponding to the spatial structure ofthepixelsorifwepermutethecolumnsofourdesignmatrixbeforefittingthe MLPâ€™s parameters.
Ideally, wewouldleverageourpriorknowledgethatnearbypixelsaretypically relatedtoeachother, tobuildefficientmodelsforlearningfromimagedata.
This chapter introduces convolutional neural networks (CNNs) (Le Cun et al., 1995), a powerful family of neural networks that are designed for precisely this purpose.
CNN- basedarchitecturesarenowubiquitousinthefieldofcomputervision.
Forinstance, onthe Imagnetcollection(Dengetal.,2009)itwasonlytheuseofconvolutionalneuralnetworks, inshort Convnets, thatprovidedsignificantperformanceimprovements(Krizhevskyetal., 2012).
Modern CNNs, astheyarecalledcolloquially, owetheirdesigntoinspirationsfrombiol- ogy, grouptheory, andahealthydoseofexperimentaltinkering.
Inadditiontotheirsample efficiencyinachievingaccuratemodels, CNNstendtobecomputationallyefficient, both becausetheyrequirefewerparametersthanfullyconnectedarchitecturesandbecausecon- volutions are easy to parallelize across GPU cores (Chetlur et al., 2014).
Consequently, practitioners often apply CNNs whenever possible, and increasingly they have emerged ascrediblecompetitorsevenontaskswithaone-dimensionalsequencestructure, suchas audio(Abdel-Hamidetal.,2014), text(Kalchbrenneretal.,2014), andtimeseriesanaly- sis(Le Cunetal.,1995), whererecurrentneuralnetworksareconventionallyused.
Some cleveradaptationsof CNNshavealsobroughtthemtobearongraph-structureddata(Kipf and Welling,2016)andinrecommendersystems.
First, wewilldivemoredeeplyintothemotivationforconvolutionalneuralnetworks.
This isfollowedbyawalkthroughthebasicoperationsthatcomprisethebackboneofallcon- volutionalnetworks.
Theseincludetheconvolutionallayersthemselves, nitty-grittydetails includingpaddingandstride, thepoolinglayersusedtoaggregateinformationacrossad- jacentspatialregions, theuseofmultiplechannelsateachlayer, andacarefuldiscussion 233 234 Convolutional Neural Networks ofthestructureofmodernarchitectures.
Wewillconcludethechapterwithafullworking exampleof Le Net, thefirstconvolutionalnetworksuccessfullydeployed, longbeforethe riseofmoderndeeplearning.
Inthenextchapter, wewilldiveintofullimplementationsof somepopularandcomparativelyrecent CNNarchitectureswhosedesignsrepresentmost ofthetechniquescommonlyusedbymodernpractitioners.
7.1 From Fully Connected Layers to Convolutions Tothisday, themodelsthatwehavediscussedsofarremainappropriateoptionswhenwe are dealing with tabular data.
By tabular, we mean that the data consist of rows corre- spondingtoexamplesandcolumnscorrespondingtofeatures.
Withtabulardata, wemight anticipatethatthepatternsweseekcouldinvolveinteractionsamongthefeatures, butwe donotassumeanystructureaprioriconcerninghowthefeaturesinteract.
Sometimes, we truly lack the knowledge to be able to guide the construction of fancier architectures.
Inthesecases, an MLPmaybethebestthatwecando.
However, forhigh- dimensionalperceptualdata, suchstructurelessnetworkscangrowunwieldy.
Forinstance, letâ€™sreturntoourrunningexampleofdistinguishingcatsfromdogs.
Saythat wedoathoroughjobindatacollection, collectinganannotateddatasetofone-megapixel photographs.
Thismeansthateachinputtothenetworkhasonemilliondimensions.
Even anaggressivereductiontoonethousandhiddendimensionswouldrequireafullyconnected layercharacterizedby106 103 =109parameters.
Unlesswehavelotsof GPUs, atalentfor distributedoptimization, andanextraordinaryamountofpatience, learningtheparameters ofthisnetworkmayturnouttobeinfeasible.
Acarefulreadermightobjecttothisargumentonthebasisthatonemegapixelresolution may not be necessary.
However, while we might be able to get away with one hundred thousandpixels, ourhiddenlayerofsize1000grosslyunderestimatesthenumberofhid- den units that it takes to learn good representations of images, so a practical system will stillrequirebillionsofparameters.
Moreover, learningaclassifierbyfittingsomanypa- rameters might require collecting an enormous dataset.
And yet today both humans and computersareabletodistinguishcatsfromdogsquitewell, seeminglycontradictingthese intuitions.
Thatisbecauseimagesexhibitrichstructurethatcanbeexploitedbyhumans and machine learning models alike.
Convolutional neural networks (CNNs) are one cre- ativewaythatmachinelearninghasembracedforexploitingsomeoftheknownstructure innaturalimages.
7.1.1 Invariance Imaginethatwewanttodetectanobjectinanimage.
Itseemsreasonablethatwhatever methodweusetorecognizeobjectsshouldnotbeoverlyconcernedwiththepreciselocation oftheobjectintheimage.
Ideally, oursystemshouldexploitthisknowledge.
Pigsusually do not fly and planes usually do not swim.
Nonetheless, we should still recognize a pig 235 From Fully Connected Layersto Convolutions wereonetoappearatthetopoftheimage.
Wecandrawsomeinspirationherefromthe childrenâ€™sgameâ€œWhereâ€™s Waldoâ€(whichitselfhasinspiredmanyreal-lifeimitations, such asthatdepictedin.1.1).
Thegameconsistsofanumberofchaoticscenesbursting with activities.
Waldo shows up somewhere in each, typically lurking in some unlikely location.
The readerâ€™s goal is to locate him.
Despite his characteristic outfit, this can be surprisinglydifficult, duetothelargenumberofdistractions.
However, what Waldolooks likedoesnotdependuponwhere Waldoislocated.
Wecouldsweeptheimagewitha Waldo detector that could assign a score to each patch, indicating the likelihood that the patch contains Waldo.
In fact, many object detection and segmentation algorithms are based on this approach (Long et al., 2015).
CNNs systematize this idea of spatial invariance, exploitingittolearnusefulrepresentationswithfewerparameters.
t .1.1 Canyoufind Waldo(imagecourtesyof William Murphy(Infomatique))? Wecannowmaketheseintuitionsmoreconcretebyenumeratingafewdesideratatoguide ourdesignofaneuralnetworkarchitecturesuitableforcomputervision: 1.
Intheearliestlayers, ournetworkshouldrespondsimilarlytothesamepatch, regardless of where it appears in the image.
This principle is called translation invariance (or translationequivariance).
2.
Theearliestlayersofthenetworkshouldfocusonlocalregions, withoutregardforthe contentsoftheimageindistantregions.
Thisisthelocalityprinciple.
Eventually, these localrepresentationscanbeaggregatedtomakepredictionsatthewholeimagelevel.
3.
As we proceed, deeper layers should be able to capture longer-range features of the image, inawaysimilartohigherlevelvisioninnature.
Letâ€™sseehowthistranslatesintomathematics.
7.1.2 Constrainingthe MLP Tostartoff, wecanconsideran MLPwithtwo-dimensionalimages Xasinputsandtheirim- mediatehiddenrepresentations Hsimilarlyrepresentedasmatrices(theyaretwo-dimensional 236 Convolutional Neural Networks tensors in code), where both X and H have the same shape.
Let that sink in.
We now imaginethatnotonlytheinputsbutalsothehiddenrepresentationspossessspatialstruc- ture.
LetÂ»Xâ€¦ ğ‘–,ğ‘— andÂ»Hâ€¦ ğ‘–,ğ‘— denotethepixelatlocationâ€ğ‘–, ğ‘—â€intheinputimageandhiddenrep- resentation, respectively.
Consequently, tohaveeachofthehiddenunitsreceiveinputfrom eachoftheinputpixels, wewouldswitchfromusingweightmatrices(aswedidpreviously in MLPs)torepresentingourparametersasfourth-orderweighttensors W.
Supposethat Ucontainsbiases, wecouldformallyexpressthefullyconnectedlayeras Â»Hâ€¦ ğ‘–,ğ‘— = Â»Uâ€¦ ğ‘–,ğ‘— â€š Â»Wâ€¦ ğ‘–,ğ‘—,ğ‘˜,ğ‘™ Â»Xâ€¦ ğ‘˜,ğ‘™ ğ‘˜ ğ‘™ (7.1.1) = Â»Uâ€¦ ğ‘–,ğ‘— â€š Â»Vâ€¦ ğ‘–,ğ‘—,ğ‘,ğ‘ Â»Xâ€¦ ğ‘–â€šğ‘,ğ‘—â€šğ‘ .
ğ‘ ğ‘ Theswitchfrom Wto Visentirelycosmeticfornowsincethereisaone-to-onecorrespon- dencebetweencoefficientsinbothfourth-ordertensors.
Wesimplyre-indexthesubscripts â€ğ‘˜,ğ‘™â€ suchthatğ‘˜ =ğ‘–â€šğ‘andğ‘™ = ğ‘— â€šğ‘.
Inotherwords, weset Â»Vâ€¦ ğ‘–,ğ‘—,ğ‘,ğ‘ = Â»Wâ€¦ ğ‘–,ğ‘—,ğ‘–â€šğ‘,ğ‘—â€šğ‘.
Theindicesğ‘andğ‘runoverbothpositiveandnegativeoffsets, coveringtheentireimage.
Foranygivenlocation(ğ‘–, ğ‘—)inthehiddenrepresentation Â»Hâ€¦ ğ‘–,ğ‘—, wecomputeitsvalueby summing over pixels in ğ‘¥, centered around â€ğ‘–, ğ‘—â€ and weighted by Â»Vâ€¦ ğ‘–,ğ‘—,ğ‘,ğ‘.
Before we carry on, letâ€™s consider the total number of parameters required for a single layer in this parametrization: a1000 1000image(1megapixel)ismappedtoa1000 1000hidden representation.
This requires 1012 parameters, far beyond what computers currently can handle.
Translation Invariance Nowletâ€™sinvokethefirstprincipleestablishedabove: translationinvariance(Zhangetal., 1988).
Thisimpliesthatashiftintheinput Xshouldsimplyleadtoashiftinthehidden representation H.
This is only possible if V and U do not actually depend on â€ğ‘–, ğ‘—â€.
As such, wehave Â»Vâ€¦ ğ‘–,ğ‘—,ğ‘,ğ‘ = Â»Vâ€¦ ğ‘,ğ‘ and Uisaconstant, sayğ‘¢.
Asaresult, wecansimplify thedefinitionfor H: Â»Hâ€¦ ğ‘–,ğ‘— =ğ‘¢â€š Â»Vâ€¦ ğ‘,ğ‘ Â»Xâ€¦ ğ‘–â€šğ‘,ğ‘—â€šğ‘ .
(7.1.2) ğ‘ ğ‘ Thisisaconvolution! Weareeffectivelyweightingpixelsatâ€ğ‘–â€šğ‘, ğ‘—â€šğ‘â€inthevicinityof locationâ€ğ‘–, ğ‘—â€withcoefficients Â»Vâ€¦ ğ‘,ğ‘ toobtainthevalue Â»Hâ€¦ ğ‘–,ğ‘—.
Notethat Â»Vâ€¦ ğ‘,ğ‘ needs many fewer coefficients than Â»Vâ€¦ ğ‘–,ğ‘—,ğ‘,ğ‘ since it no longer depends on the location within theimage.
Consequently, thenumberofparametersrequiredisnolonger1012 butamuch morereasonable4 106: westillhavethedependencyonğ‘,ğ‘ 2 â€ 1000,1000â€.
Inshort, wehavemadesignificantprogress.
Time-delayneuralnetworks(TDNNs)aresomeofthe firstexamplestoexploitthisidea(Waibeletal.,1989).
Locality Now letâ€™s invoke the second principle: locality.
As motivated above, we believe that we shouldnothavetolookveryfarawayfromlocation â€ğ‘–, ğ‘—â€ inordertogleanrelevantinfor- 237 From Fully Connected Layersto Convolutions mationtoassesswhatisgoingonat Â»Hâ€¦ ğ‘–,ğ‘—.
Thismeansthatoutsidesomerange jğ‘j > Î” orjğ‘j >Î”, weshouldset Â»Vâ€¦ ğ‘,ğ‘ =0.
Equivalently, wecanrewrite Â»Hâ€¦ ğ‘–,ğ‘— as Î” Î” Â»Hâ€¦ ğ‘–,ğ‘— =ğ‘¢â€š Â»Vâ€¦ ğ‘,ğ‘ Â»Xâ€¦ ğ‘–â€šğ‘,ğ‘—â€šğ‘ .
(7.1.3) ğ‘= Î”ğ‘= Î” Thisreducesthenumberofparametersfrom4 106to4Î”2, whereÎ”istypicallysmallerthan 10.
Assuch, wereducedthenumberofparametersbyanotherfourordersofmagnitude.
Note that (7.1.3), is what is called, in a nutshell, a convolutional layer.
Convolutional neuralnetworks(CNNs)areaspecialfamilyofneuralnetworksthatcontainconvolutional layers.
Inthedeeplearningresearchcommunity, Visreferredtoasaconvolutionkernel, afilter, orsimplythelayerâ€™sweightsthatarelearnableparameters.
Whilepreviously, wemighthaverequiredbillionsofparameterstorepresentjustasingle layerinanimage-processingnetwork, wenowtypicallyneedjustafewhundred, without altering the dimensionality of either the inputs or the hidden representations.
The price paidforthisdrasticreductioninparametersisthatourfeaturesarenowtranslationinvariant andthatourlayercanonlyincorporatelocalinformation, whendeterminingthevalueof eachhiddenactivation.
Alllearningdependsonimposinginductivebias.
Whenthatbias agreeswithreality, wegetsample-efficientmodelsthatgeneralizewelltounseendata.
But of course, if those biases do not agree with reality, e.
g., if images turned out not to be translationinvariant, ourmodelsmightstruggleeventofitourtrainingdata.
Thisdramaticreductioninparametersbringsustoourlastdesideratum, namelythatdeeper layersshouldrepresentlargerandmorecomplexaspectsofanimage.
Thiscanbeachieved byinterleavingnonlinearitiesandconvolutionallayersrepeatedly.
7.1.3 Convolutions Letâ€™sbrieflyreviewwhy(7.1.3)iscalledaconvolution.
Inmathematics, theconvolution betweentwofunctions(Rudin,1973), say ğ‘“,ğ‘” : Rğ‘‘ ! Risdefinedas â€ â€ğ‘“ ğ‘”â€â€xâ€ = ğ‘“â€zâ€ğ‘”â€x zâ€ğ‘‘z.
(7.1.4) Thatis, wemeasuretheoverlapbetween ğ‘“ andğ‘”whenonefunctionisâ€œflippedâ€andshifted byx.
Wheneverwehavediscreteobjects, theintegralturnsintoasum.
Forinstance, for vectorsfromthesetofsquare-summableinfinite-dimensionalvectorswithindexrunning over Zweobtainthefollowingdefinition: â€ğ‘“ ğ‘”â€â€ğ‘–â€ = ğ‘“â€ğ‘â€ğ‘”â€ğ‘– ğ‘â€.
(7.1.5) ğ‘ Fortwo-dimensionaltensors, wehaveacorrespondingsumwithindices â€ğ‘,ğ‘â€ for ğ‘“ and â€ğ‘– ğ‘, ğ‘— ğ‘â€forğ‘”, respectively: â€ğ‘“ ğ‘”â€â€ğ‘–, ğ‘—â€ = ğ‘“â€ğ‘,ğ‘â€ğ‘”â€ğ‘– ğ‘, ğ‘— ğ‘â€.
(7.1.6) ğ‘ ğ‘ Thislookssimilarto(7.1.3), withonemajordifference.
Ratherthanusing â€ğ‘–â€šğ‘, ğ‘— â€šğ‘â€, weareusingthedifferenceinstead.
Note, though, thatthisdistinctionismostlycosmetic 238 Convolutional Neural Networks in (7.1.3) more properly describes a cross-correlation.
We will come back to this in the followingsection.
7.1.4 Channels Returningtoour Waldodetector, letâ€™sseewhatthislookslike.
Theconvolutionallayerpicks windowsofagivensizeandweighsintensitiesaccordingtothefilter V, asdemonstrated in.1.2.
Wemightaimtolearnamodelsothatwherevertheâ€œwaldonessâ€ishighest, weshouldfindapeakinthehiddenlayerrepresentations.
t .1.2 Detect Waldo(imagecourtesyof William Murphy(Infomatique)).
There is just one problem with this approach.
So far, we blissfully ignored that images consist of three channels: red, green, and blue.
In sum, images are not two-dimensional objectsbutratherthird-ordertensors, characterizedbyaheight, width, andchannel, e.
g., withshape1024 1024 3pixels.
Whilethefirsttwooftheseaxesconcernspatialrelation- ships, thethirdcanberegardedasassigningamultidimensionalrepresentationtoeachpixel location.
We thus index X as Â»Xâ€¦ ğ‘–,ğ‘—,ğ‘˜.
The convolutional filter has to adapt accordingly.
Insteadof Â»Vâ€¦ ğ‘,ğ‘, wenowhave Â»Vâ€¦ ğ‘,ğ‘,ğ‘.
Moreover, justasourinputconsistsofathird-ordertensor, itturnsouttobeagoodidea tosimilarlyformulateourhiddenrepresentationsasthird-ordertensors H.
Inotherwords, ratherthanjusthavingasinglehiddenrepresentationcorrespondingtoeachspatiallocation, wewantanentirevectorofhiddenrepresentationscorrespondingtoeachspatiallocation.
Wecouldthinkofthehiddenrepresentationsascomprisinganumberoftwo-dimensional gridsstackedontopofeachother.
Asintheinputs, thesearesometimescalledchannels.
Theyarealsosometimescalledfeaturemaps, aseachprovidesaspatializedsetoflearned featuresforthesubsequentlayer.
Intuitively, youmightimaginethatatlowerlayersthatare closertoinputs, somechannelscouldbecomespecializedtorecognizeedgeswhileothers couldrecognizetextures.
Tosupportmultiplechannelsinbothinputs(X)andhiddenrepresentations(H), wecanadd 239 From Fully Connected Layersto Convolutions afourthcoordinateto V: Â»Vâ€¦ ğ‘,ğ‘,ğ‘,ğ‘‘.
Puttingeverythingtogetherwehave: Î” Î” Â»Hâ€¦ ğ‘–,ğ‘—,ğ‘‘ = Â»Vâ€¦ ğ‘,ğ‘,ğ‘,ğ‘‘ Â»Xâ€¦ ğ‘–â€šğ‘,ğ‘—â€šğ‘,ğ‘ , (7.1.7) ğ‘= Î”ğ‘= Î” ğ‘ whereğ‘‘indexestheoutputchannelsinthehiddenrepresentations H.
Thesubsequentcon- volutionallayerwillgoontotakeathird-ordertensor, H, asinput.
Wetake(7.1.7), because ofitsgenerality, asthedefinitionofaconvolutionallayerformultiplechannels, where V isakernelorfilterofthelayer.
Therearestillmanyoperationsthatweneedtoaddress.
Forinstance, weneedtofigureout howto combine all thehidden representations to a singleoutput, e.
g., whether thereis a Waldoanywhereintheimage.
Wealsoneedtodecidehowtocomputethingsefficiently, howtocombinemultiplelayers, appropriateactivationfunctions, andhowtomakereason- abledesignchoicestoyieldnetworksthatareeffectiveinpractice.
Weturntotheseissues intheremainderofthechapter.
7.1.5 Summaryand Discussion In this section we derived the structure of convolutional neural networks from first prin- ciples.
While it is unclear whether this was the route taken to the invention of CNNs, it is satisfying to know that they are the right choice when applying reasonable principles tohowimageprocessingandcomputervisionalgorithmsshouldoperate, atleastatlower levels.
Inparticular, translationinvarianceinimagesimpliesthatallpatchesofanimage willbetreatedinthesamemanner.
Localitymeansthatonlyasmallneighborhoodofpix- elswillbeusedtocomputethecorrespondinghiddenrepresentations.
Someoftheearliest referencesto CNNsareintheformofthe Neocognitron(Fukushima,1982).
Asecondprinciplethatweencounteredinourreasoningishowtoreducethenumberof parameters in a function class without limiting its expressive power, at least, whenever certainassumptionsonthemodelhold.
Wesawadramaticreductionofcomplexityasa resultofthisrestriction, turningcomputationallyandstatisticallyinfeasibleproblemsinto tractablemodels.
Addingchannelsallowedustobringbacksomeofthecomplexitythatwaslostduetothere- strictionsimposedontheconvolutionalkernelbylocalityandtranslationinvariance.
Note thatitisquitenaturaltoaddchannelsotherthanjustred, green, andblue.
Manysatellite images, inparticularforagricultureandmeteorology, havetenstohundredsofchannels, generatinghyperspectralimagesinstead.
Theyreportdataonmanydifferentwavelengths.
Inthefollowingwewillseehowtouseconvolutionseffectivelytomanipulatethedimen- sionalityoftheimagestheyoperateon, howtomovefromlocation-basedtochannel-based representations, andhowtodealwithlargenumbersofcategoriesefficiently.
7.1.6 Exercises 1.
Assume that the size of the convolution kernel is Î” = 0.
Show that in this case the convolution kernel implements an MLP independently for each set of channels.
This leadstothe Networkin Networkarchitectures(Linetal.,2013).
240 Convolutional Neural Networks 2.
Audiodataisoftenrepresentedasaone-dimensionalsequence.
1.
Whenmightyouwanttoimposelocalityandtranslationinvarianceforaudio? 2.
Derivetheconvolutionoperationsforaudio.
3.
Canyoutreataudiousingthesametoolsascomputervision? Hint: usethespectro- gram.
3.
Whymighttranslationinvariancenotbeagoodideaafterall? Giveanexample.
4.
Do you think that convolutional layers might also be applicable for text data? Which problemsmightyouencounterwithlanguage? 5.
Whathappenswithconvolutionswhenanobjectisattheboundaryofanimage? 6.
Provethattheconvolutionissymmetric, i.
e., ğ‘“ ğ‘” =ğ‘” ğ‘“.
Discussions119.
119 7.2 Convolutions for Images Nowthatweunderstandhowconvolutionallayersworkintheory, wearereadytoseehow they work in practice.
Building on our motivation of convolutional neural networks as efficient architectures for exploring structure in image data, we stick with images as our runningexample.
import torch from torch import nn from d2l import torch as d2l 7.2.1 The Cross-Correlation Operation Recallthatstrictlyspeaking, convolutionallayersareamisnomer, sincetheoperationsthey expressaremoreaccuratelydescribedascross-correlations.
Basedonourdescriptionsof convolutionallayersin Section7.1, insuchalayer, aninputtensorandakerneltensorare combinedtoproduceanoutputtensorthroughacross-correlationoperation.
Letâ€™signorechannelsfornowandseehowthisworkswithtwo-dimensionaldataandhidden representations.
In.2.1, theinputisatwo-dimensionaltensorwithaheightof3and widthof3.
Wemarktheshapeofthetensoras3 3or(3,3).
Theheightandwidthofthe kernelareboth2.
Theshapeofthekernelwindow(orconvolutionwindow)isgivenbythe heightandwidthofthekernel(hereitis2 2).
Inthetwo-dimensionalcross-correlationoperation, webeginwiththeconvolutionwindow positionedattheupper-leftcorneroftheinputtensorandslideitacrosstheinputtensor, bothfromlefttorightandtoptobottom.
Whentheconvolutionwindowslidestoacertain 241 Convolutionsfor Images t .2.1 Two-dimensionalcross-correlationoperation.
Theshadedportionsarethefirstoutput elementaswellastheinputandkerneltensorelementsusedfortheoutputcomputation: 0 0â€š1 1â€š3 2â€š4 3=19.
position, theinputsubtensorcontainedinthatwindowandthekerneltensoraremultiplied elementwise and the resulting tensor is summed up yielding a single scalar value.
This resultgivesthevalueoftheoutputtensoratthecorrespondinglocation.
Here, theoutput tensor has a height of 2 and width of 2 and the four elements are derived from the two- dimensionalcross-correlationoperation: 0 0â€š1 1â€š3 2â€š4 3=19, 1 0â€š2 1â€š4 2â€š5 3=25, (7.2.1) 3 0â€š4 1â€š6 2â€š7 3=37, 4 0â€š5 1â€š7 2â€š8 3=43.
Notethatalongeachaxis, theoutputsizeisslightlysmallerthantheinputsize.
Because the kernel has width and height greater than 1, we can only properly compute the cross- correlationforlocationswherethekernelfitswhollywithintheimage, theoutputsizeis givenbytheinputsizeğ‘› ğ‘› minusthesizeoftheconvolutionkernelğ‘˜ ğ‘˜ via h w h w â€ğ‘› ğ‘˜ â€š1â€ â€ğ‘› ğ‘˜ â€š1â€.
(7.2.2) h h w w This is the case since we need enough space to â€œshiftâ€ the convolution kernel across the image.
Laterwewillseehowtokeepthesizeunchangedbypaddingtheimagewithzeros arounditsboundarysothatthereisenoughspacetoshiftthekernel.
Next, weimplement thisprocessinthecorr2dfunction, whichacceptsaninputtensor Xandakerneltensor K andreturnsanoutputtensor Y.
def corr2d(X, K): #@save """Compute 2D cross-correlation.""" h, w = K.
shape Y = torch.
zeros((X.
shape[0] - h + 1, X.
shape[1] - w + 1)) for i in range(Y.
shape[0]): for j in range(Y.
shape[1]): Y[i, j] = (X[i: i + h, j: j + w] * K).
sum() return Y We can construct the input tensor X and the kernel tensor K from .2.1 to validate the output of the above implementation of the two-dimensional cross-correlation opera- tion.
(continuesonnextpage) 242 Convolutional Neural Networks (continuedfrompreviouspage) corr2d(X, K) tensor([[19., 25.], [37., 43.]]) 7.2.2 Convolutional Layers Aconvolutionallayercross-correlatestheinputandkernelandaddsascalarbiastoproduce anoutput.
Thetwoparametersofaconvolutionallayerarethekernelandthescalarbias.
When training models based on convolutional layers, we typically initialize the kernels randomly, justaswewouldwithafullyconnectedlayer.
Wearenowreadytoimplementatwo-dimensionalconvolutionallayerbasedonthecorr2d functiondefinedabove.
Inthe__init__constructormethod, wedeclareweightandbias asthetwomodelparameters.
Theforwardpropagationmethodcallsthecorr2dfunction andaddsthebias.
class Conv2D(nn.
Module): def __init__(self, kernel_size): super().__init__() self.
weight = nn.
Parameter(torch.
rand(kernel_size)) self.
bias = nn.
Parameter(torch.
zeros(1)) def forward(self, x): return corr2d(x, self.
weight) + self.
bias Inâ„ ğ‘¤convolutionoranâ„ ğ‘¤convolutionkernel, theheightandwidthoftheconvolution kernel are â„ and ğ‘¤, respectively.
We also refer to a convolutional layer with an â„ ğ‘¤ convolutionkernelsimplyasanâ„ ğ‘¤convolutionallayer.
7.2.3 Object Edge Detectionin Images Letâ€™stakeamomenttoparseasimpleapplicationofaconvolutionallayer: detectingthe edgeofanobjectinanimagebyfindingthelocationofthepixelchange.
First, weconstruct anâ€œimageâ€of6 8pixels.
Themiddlefourcolumnsareblack(0)andtherestarewhite (1).
X = torch.
ones((6, 8)) X[:, 2:6] = 0 X (continuesonnextpage) 243 Convolutionsfor Images (continuedfrompreviouspage) Next, we construct a kernel K with a height of 1 and a width of 2.
When we perform the cross-correlation operation with the input, if the horizontally adjacent elements are the same, the output is 0.
Otherwise, the output is nonzero.
Note that this kernel is a special case of a finite difference operator.
At location â€ğ‘–, ğ‘—â€ it computes ğ‘¥ ğ‘–,ğ‘— ğ‘¥ â€ğ‘–â€š1â€,ğ‘—, i.
e., itcomputesthedifferencebetweenthevaluesofhorizontallyadjacentpixels.
Thisis a discrete approximation of the first derivative in the horizontal direction.
After all, for a function ğ‘“â€ğ‘–, ğ‘—â€ its derivative ğœ• ğ‘– ğ‘“â€ğ‘–, ğ‘—â€ = limğœ–!0 ğ‘“â€ğ‘–,ğ‘—â€ ğœ– ğ‘“â€ğ‘–â€šğœ–,ğ‘—â€ .
Letâ€™s see how this worksinpractice.
K = torch.
tensor([[1.0, -1.0]]) Wearereadytoperformthecross-correlationoperationwitharguments X(ourinput)and K(ourkernel).
Asyoucansee, wedetect1fortheedgefromwhitetoblackand 1forthe edgefromblacktowhite.
Allotheroutputstakevalue0.
Y = corr2d(X, K) Y Wecannowapplythekerneltothetransposedimage.
Asexpected, itvanishes.
Thekernel Konlydetectsverticaledges.
corr2d(X.
t(), K) 7.2.4 Learninga Kernel 244 Convolutional Neural Networks Designinganedgedetectorbyfinitedifferences[1, -1]isneatifweknowthisisprecisely what we are looking for.
However, as we look at larger kernels, and consider successive layersofconvolutions, itmightbeimpossibletospecifypreciselywhateachfiltershould bedoingmanually.
Now letâ€™s see whether we can learn the kernel that generated Y from X by looking at the inputâ€“outputpairsonly.
Wefirstconstructaconvolutionallayerandinitializeitskernelas arandomtensor.
Next, ineachiteration, wewillusethesquarederrortocompare Ywiththe outputoftheconvolutionallayer.
Wecanthencalculatethegradienttoupdatethekernel.
For the sake of simplicity, in the following we use the built-in class for two-dimensional convolutionallayersandignorethebias.
# Construct a two-dimensional convolutional layer with 1 output channel and a # kernel of shape (1, 2).
For the sake of simplicity, we ignore the bias here conv2d = nn.
Lazy Conv2d(1, kernel_size=(1, 2), bias=False) # The two-dimensional convolutional layer uses four-dimensional input and # output in the format of (example, channel, height, width), where the batch # size (number of examples in the batch) and the number of channels are both 1 X = X.
reshape((1, 1, 6, 8)) Y = Y.
reshape((1, 1, 6, 7)) lr = 3e-2 # Learning rate for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 conv2d.
zero_grad() l.
sum().
backward() # Update the kernel conv2d.
weight.
data[:] -= lr * conv2d.
weight.
grad if (i + 1) % 2 == 0: print(f'epoch {i + 1}, loss {l.
sum():.3f}') epoch 2, loss 16.481 epoch 4, loss 5.069 epoch 6, loss 1.794 epoch 8, loss 0.688 epoch 10, loss 0.274 Notethattheerrorhasdroppedtoasmallvalueafter10iterations.
Nowwewilltakealook atthekerneltensorwelearned.
conv2d.
weight.
data.
reshape((1, 2)) tensor([[ 1.0398, -0.9328]]) Indeed, the learned kernel tensor is remarkably close to the kernel tensor K we defined earlier.
245 Convolutionsfor Images 7.2.5 Cross-Correlationand Convolution Recallourobservationfrom Section7.1ofthecorrespondencebetweenthecross-correlation andconvolutionoperations.
Hereletâ€™scontinuetoconsidertwo-dimensionalconvolutional layers.
Whatifsuchlayersperformstrictconvolutionoperationsasdefinedin(7.1.6)in- steadofcross-correlations? Inordertoobtaintheoutputofthestrictconvolutionoperation, weonlyneedtoflipthetwo-dimensionalkerneltensorbothhorizontallyandvertically, and thenperformthecross-correlationoperationwiththeinputtensor.
It is noteworthy that since kernels are learned from data in deep learning, the outputs of convolutionallayersremainunaffectednomattersuchlayersperformeitherthestrictcon- volutionoperationsorthecross-correlationoperations.
Toillustratethis, supposethataconvolutionallayerperformscross-correlationandlearns thekernelin.2.1, whichisheredenotedasthematrix K.
Assumingthatothercon- ditionsremainunchanged, whenthislayerinsteadperformsstrictconvolution, thelearned kernel K0 willbethesameas Kafter K0 isflippedbothhorizontallyandvertically.
That is to say, when the convolutional layer performs strict convolution for the input in Fig.
obtained.
Inkeepingwithstandardterminologyindeeplearningliterature, wewillcontinuetoreferto thecross-correlationoperationasaconvolutioneventhough, strictly-speaking, itisslightly different.
Furthermore, weusethetermelementtorefertoanentry(orcomponent)ofany tensorrepresentingalayerrepresentationoraconvolutionkernel.
7.2.6 Feature Mapand Receptive Field calledafeaturemap, asitcanberegardedasthelearnedrepresentations(features)inthe spatialdimensions(e.
g., widthandheight)tothesubsequentlayer.
In CNNs, foranyel- ement ğ‘¥ of some layer, its receptive field refers to all the elements (from all the previous layers)thatmayaffectthecalculationofğ‘¥ duringtheforwardpropagation.
Notethatthe receptivefieldmaybelargerthantheactualsizeoftheinput.
Letâ€™scontinuetouse.2.1toexplainthereceptivefield.
Giventhe2 2convolution kernel, thereceptivefieldoftheshadedoutputelement(ofvalue19)isthefourelements intheshadedportionoftheinput.
Nowletâ€™sdenotethe2 2outputas Y andconsidera deeper CNNwithanadditional2 2convolutionallayerthattakes Yasitsinput, outputting asingleelementğ‘§.
Inthiscase, thereceptivefieldofğ‘§on Yincludesallthefourelements of Y, whilethereceptivefieldontheinputincludesallthenineinputelements.
Thus, when anyelementinafeaturemapneedsalargerreceptivefieldtodetectinputfeaturesovera broaderarea, wecanbuildadeepernetwork.
Receptive fields derive their name from neurophysiology.
A series of experiments on a rangeofanimalsusingdifferentstimuli(Hubeland Wiesel,1959, Hubeland Wiesel,1962, Hubeland Wiesel,1968)exploredtheresponseofwhatiscalledthevisualcortexonsaid stimuli.
By and large they found that lower levels respond to edges and related shapes.
246 Convolutional Neural Networks Lateron, Field(1987)illustratedthiseffectonnaturalimageswith, whatcanonlybecalled, convolutionalkernels.
Wereprintakeyfigurein.2.2toillustratethestrikingsimi- larities.
t .2.2 Figureandcaptiontakenfrom Field(1987): Anexampleofcodingwithsixdifferent channels.
(Left)Examplesofthesixtypesofsensorassociatedwitheachchannel.
(Right) Convolutionoftheimagein(Middle)withthesixsensorsshownin(Left).
Theresponse oftheindividualsensorsisdeterminedbysamplingthesefilteredimagesatadistance proportionaltothesizeofthesensor(shownwithdots).
Thisdiagramshowstheresponse ofonlytheevensymmetricsensors.
Asitturnsout, thisrelationevenholdsforthefeaturescomputedbydeeperlayersofnet- workstrainedonimageclassificationtasks, asdemonstratedin, forexample, Kuzovkinet al.
(2018).
Sufficeittosay, convolutionshaveproventobeanincrediblypowerfultoolfor computervision, bothinbiologyandincode.
Assuch, itisnotsurprising(inhindsight) thattheyheraldedtherecentsuccessindeeplearning.
7.2.7 Summary The core computation required for a convolutional layer is a cross-correlation operation.
We saw that a simple nested for-loop is all that is required to compute its value.
If we havemultipleinputandmultipleoutputchannels, weareperformingamatrixâ€“matrixop- eration between channels.
As can be seen, the computation is straightforward and, most importantly, highlylocal.
Thisaffordssignificanthardwareoptimizationandmanyrecent resultsincomputervisionareonlypossiblebecauseofthat.
Afterall, itmeansthatchip designerscaninvestinfastcomputationratherthanmemorywhenitcomestooptimizing forconvolutions.
Whilethismaynotleadtooptimaldesignsforotherapplications, itdoes openthedoortoubiquitousandaffordablecomputervision.
247 Paddingand Stride In terms of convolutions themselves, they can be used for many purposes, for example detecting edges and lines, blurring images, or sharpening them.
Most importantly, it is not necessary that the statistician (or engineer) invents suitable filters.
Instead, we can simply learn them from data.
This replaces feature engineering heuristics by evidence- based statistics.
Lastly, and quite delightfully, these filters are not just advantageous for buildingdeepnetworksbuttheyalsocorrespondtoreceptivefieldsandfeaturemapsinthe brain.
Thisgivesusconfidencethatweareontherighttrack.
7.2.8 Exercises 1.
Constructanimage Xwithdiagonaledges.
1.
Whathappensifyouapplythekernel Kinthissectiontoit? 2.
Whathappensifyoutranspose X? 3.
Whathappensifyoutranspose K? 2.
Designsomekernelsmanually.
1.
Givenadirectionalvectorv = â€ğ‘£ ,ğ‘£ â€, deriveanedge-detectionkernelthatdetects 1 2 edgesorthogonaltov, i.
e., edgesinthedirectionâ€ğ‘£ , ğ‘£ â€.
2 1 2.
Deriveafinitedifferenceoperatorforthesecondderivative.
Whatistheminimum sizeoftheconvolutionalkernelassociatedwithit? Whichstructuresinimagesre- spondmoststronglytoit? 3.
Howwouldyoudesignablurkernel? Whymightyouwanttousesuchakernel? 4.
Whatistheminimumsizeofakerneltoobtainaderivativeoforderğ‘‘? 3.
Whenyoutrytoautomaticallyfindthegradientforthe Conv2Dclasswecreated, what kindoferrormessagedoyousee? 4.
Howdoyourepresentacross-correlationoperationasamatrixmultiplicationbychang- ingtheinputandkerneltensors? 120 Discussions120.
7.3 Padding and Stride Recalltheexampleofaconvolutionin.2.1.
Theinputhadbothaheightandwidthof 3andtheconvolutionkernelhadbothaheightandwidthof2, yieldinganoutputrepresen- tationwithdimension2 2.
Assumingthattheinputshapeisğ‘› ğ‘› andtheconvolution h w kernelshapeis ğ‘˜ ğ‘˜ , theoutputshapewillbe â€ğ‘› ğ‘˜ â€š1â€ â€ğ‘› ğ‘˜ â€š1â€: wecan h w h h w w onlyshifttheconvolutionkernelsofaruntilitrunsoutofpixelstoapplytheconvolution to.
248 Convolutional Neural Networks In the following we will explore a number of techniques, including padding and strided convolutions, thatoffermorecontroloverthesizeoftheoutput.
Asmotivation, notethat sincekernelsgenerallyhavewidthandheightgreaterthan1, afterapplyingmanysuccessive convolutions, wetendtowindupwithoutputsthatareconsiderablysmallerthanourinput.
Ifwestartwitha240 240pixelimage, tenlayersof5 5convolutionsreducetheimage to 200 200 pixels, slicing off 30% of the image and with it obliterating any interesting informationontheboundariesoftheoriginalimage.
Paddingisthemostpopulartoolfor handlingthisissue.
Inothercases, wemaywanttoreducethedimensionalitydrastically, e.
g., if we find the original input resolution to be unwieldy.
Strided convolutions are a populartechniquethatcanhelpintheseinstances.
import torch from torch import nn 7.3.1 Padding As described above, one tricky issue when applying convolutional layers is that we tend to lose pixels on the perimeter of our image.
Consider .3.1 that depicts the pixel utilizationasafunctionoftheconvolutionkernelsizeandthepositionwithintheimage.
Thepixelsinthecornersarehardlyusedatall.
t .3.1 Pixelutilizationforconvolutionsofsize1 1,2 2, and3 3respectively.
Sincewetypicallyusesmallkernels, foranygivenconvolutionwemightonlyloseafew pixelsbutthiscanaddupasweapplymanysuccessiveconvolutionallayers.
Onestraight- forwardsolutiontothisproblemistoaddextrapixelsoffilleraroundtheboundaryofour inputimage, thusincreasingtheeffectivesizeoftheimage.
Typically, wesetthevaluesof correspondingoutputthenincreasestoa4 4matrix.
Theshadedportionsarethefirstout- putelementaswellastheinputandkerneltensorelementsusedfortheoutputcomputation: 0 0â€š0 1â€š0 2â€š0 3=0.
t .3.2 Two-dimensionalcross-correlationwithpadding.
249 Paddingand Stride Ingeneral, ifweaddatotalofğ‘ rowsofpadding(roughlyhalfontopandhalfonbottom) h andatotalof ğ‘ columnsofpadding(roughlyhalfontheleftandhalfontheright), the w outputshapewillbe â€ğ‘› ğ‘˜ â€šğ‘ â€š1â€ â€ğ‘› ğ‘˜ â€šğ‘ â€š1â€.
(7.3.1) h h h w w w This means that the height and width of the output will increase by ğ‘ and ğ‘ , respec- h w tively.
In many cases, we will want to set ğ‘ = ğ‘˜ 1 and ğ‘ = ğ‘˜ 1 to give the input and h h w w outputthesameheightandwidth.
Thiswillmakeiteasiertopredicttheoutputshapeof eachlayerwhenconstructingthenetwork.
Assumingthatğ‘˜ isoddhere, wewillpad ğ‘ 2 h h rowsonbothsidesoftheheight.
Ifğ‘˜ iseven, onepossibilityistopaddğ‘ 2erowsonthe h h topoftheinputandbğ‘ 2crowsonthebottom.
Wewillpadbothsidesofthewidthinthe h sameway.
CNNscommonlyuseconvolutionkernelswithoddheightandwidthvalues, suchas1,3, 5, or7.
Choosingoddkernelsizeshasthebenefitthatwecanpreservethedimensionality whilepaddingwiththesamenumberofrowsontopandbottom, andthesamenumberof columnsonleftandright.
Moreover, thispracticeofusingoddkernelsandpaddingtopreciselypreservedimension- alityoffersaclericalbenefit.
Foranytwo-dimensionaltensor X, whenthekernelâ€™ssizeis oddandthenumberofpaddingrowsandcolumnsonallsidesarethesame, therebypro- ducinganoutputwiththesameheightandwidthastheinput, weknowthattheoutput Y[i, j]iscalculatedbycross-correlationoftheinputandconvolutionkernelwiththewindow centeredon X[i, j].
In the following example, we create a two-dimensional convolutional layer with a height andwidthof3andapply1pixelofpaddingonallsides.
Givenaninputwithaheightand widthof8, wefindthattheheightandwidthoftheoutputisalso8.
# We define a helper function to calculate convolutions.
It initializes the # convolutional layer weights and performs corresponding dimensionality # elevations and reductions on the input and output def comp_conv2d(conv2d, X): # (1, 1) indicates that batch size and the number of channels are both 1 X = X.
reshape((1, 1) + X.
shape) Y = conv2d(X) # Strip the first two dimensions: examples and channels return Y.
reshape(Y.
shape[2:]) # 1 row and column is padded on either side, so a total of 2 rows or columns # are added conv2d = nn.
Lazy Conv2d(1, kernel_size=3, padding=1) X = torch.
rand(size=(8, 8)) comp_conv2d(conv2d, X).
shape torch.
Size([8, 8]) 250 Convolutional Neural Networks Whentheheightandwidthoftheconvolutionkernelaredifferent, wecanmaketheoutput andinputhavethesameheightandwidthbysettingdifferentpaddingnumbersforheight andwidth.
# We use a convolution kernel with height 5 and width 3.
The padding on either # side of the height and width are 2 and 1, respectively conv2d = nn.
Lazy Conv2d(1, kernel_size=(5, 3), padding=(2, 1)) comp_conv2d(conv2d, X).
shape torch.
Size([8, 8]) 7.3.2 Stride Whencomputingthecross-correlation, westartwiththeconvolutionwindowattheupper- left corner of the input tensor, and then slide it over all locations both down and to the right.
Inthepreviousexamples, wedefaultedtoslidingoneelementatatime.
However, sometimes, either for computational efficiency or because we wish to downsample, we move our window more than one element at a time, skipping the intermediate locations.
Thisisparticularlyusefuliftheconvolutionkernelislargesinceitcapturesalargeareaof theunderlyingimage.
Werefertothenumberofrowsandcolumnstraversedperslideasstride.
Sofar, wehave usedstridesof1, bothforheightandwidth.
Sometimes, wemaywanttousealargerstride.
.3.3showsatwo-dimensionalcross-correlationoperationwithastrideof3vertically and2 horizontally.
Theshadedportionsaretheoutputelementsaswellastheinputand kerneltensorelementsusedfortheoutputcomputation: 0 0â€š0 1â€š1 2â€š2 3=8, 0 0â€š6 1â€š0 2â€š0 3=6.
Wecanseethatwhenthesecondelementofthefirstcolumnis generated, theconvolutionwindowslidesdownthreerows.
Theconvolutionwindowslides twocolumnstotherightwhenthesecondelementofthefirstrowisgenerated.
Whenthe convolution window continues to slide two columns to the right on the input, there is no outputbecausetheinputelementcannotfillthewindow(unlessweaddanothercolumnof padding).
t .3.3 Cross-correlationwithstridesof3and2forheightandwidth, respectively.
Ingeneral, whenthestridefortheheightisğ‘  andthestrideforthewidthisğ‘  , theoutput h w shapeis bâ€ğ‘› ğ‘˜ â€šğ‘ â€šğ‘  â€ ğ‘  c bâ€ğ‘› ğ‘˜ â€šğ‘ â€šğ‘  â€ ğ‘  c.
(7.3.2) h h h h h w w w w w Ifweset ğ‘ = ğ‘˜ 1and ğ‘ = ğ‘˜ 1, thentheoutputshapecanbesimplifiedto bâ€ğ‘› â€š h h w w h 251 Paddingand Stride ğ‘  1â€ ğ‘  c bâ€ğ‘› â€šğ‘  1â€ ğ‘  c.
Goingastepfurther, iftheinputheightandwidthare h h w w w divisible by the strides on the height and width, then the output shape will be â€ğ‘› ğ‘  â€ h h â€ğ‘› ğ‘  â€.
w w Below, wesetthestridesonboththeheightandwidthto2, thushalvingtheinputheight andwidth.
conv2d = nn.
Lazy Conv2d(1, kernel_size=3, padding=1, stride=2) comp_conv2d(conv2d, X).
shape torch.
Size([4, 4]) Letâ€™slookataslightlymorecomplicatedexample.
conv2d = nn.
Lazy Conv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4)) comp_conv2d(conv2d, X).
shape torch.
Size([2, 2]) 7.3.3 Summaryand Discussion Padding can increase the height and width of the output.
This is often used to give the outputthesameheightandwidthastheinputtoavoidundesirableshrinkageoftheoutput.
Moreover, itensuresthatallpixelsareusedequallyfrequently.
Typicallywepicksymmetric padding on both sides of the input height and width.
In this case we refer to â€ğ‘ ,ğ‘ â€ h w padding.
Mostcommonlyweset ğ‘ = ğ‘ , inwhichcasewesimplystatethatwechoose h w padding ğ‘.
A similar convention applies to strides.
When horizontal stride ğ‘  and vertical stride ğ‘  h w match, wesimplytalkaboutstrideğ‘ .
Thestridecanreducetheresolutionoftheoutput, for examplereducingtheheightandwidthoftheoutputtoonly1 ğ‘›oftheheightandwidthof theinputforğ‘› >1.
Bydefault, thepaddingis0andthestrideis1.
Sofarallpaddingthatwediscussedsimplyextendedimageswithzeros.
Thishassignif- icant computational benefit since it is trivial to accomplish.
Moreover, operators can be engineeredtotakeadvantageofthispaddingimplicitlywithouttheneedtoallocateaddi- tionalmemory.
Atthesametime, itallows CNNstoencodeimplicitpositioninformation withinanimage, simplybylearningwheretheâ€œwhitespaceâ€is.
Therearemanyalternatives to zero-padding.
Alsallakh et al.
(2020) provided an extensive overview of those (albeit withoutaclearcaseforwhentousenonzeropaddingsunlessartifactsoccur).
7.3.4 Exercises 1.
Giventhefinalcodeexampleinthissectionwithkernelsizeâ€3,5â€, paddingâ€0,1â€, and strideâ€3,4â€, calculatetheoutputshapetocheckifitisconsistentwiththeexperimental result.
252 Convolutional Neural Networks 2.
Foraudiosignals, whatdoesastrideof2correspondto? 3.
Implementmirrorpadding, i.
e., paddingwherethebordervaluesaresimplymirrored toextendtensors.
4.
Whatarethecomputationalbenefitsofastridelargerthan1? 5.
Whatmightbestatisticalbenefitsofastridelargerthan1? 6.
Howwouldyouimplementastrideof 1? Whatdoesitcorrespondto? Whenwouldthis 2 beuseful? Discussions121.
121 7.4 Multiple Input and Multiple Output Channels While we described the multiple channels that comprise each image (e.
g., color images havethestandard RGBchannelstoindicatetheamountofred, greenandblue)andcon- volutionallayersformultiplechannelsin Section7.1.4, untilnow, wesimplifiedallofour numericalexamplesbyworkingwithjustasingleinputandasingleoutputchannel.
This allowedustothinkofourinputs, convolutionkernels, andoutputseachastwo-dimensional tensors.
When we add channels into the mix, our inputs and hidden representations both become three-dimensionaltensors.
Forexample, each RGBinputimagehasshape3 â„ ğ‘¤.
We refer to this axis, with a size of 3, as the channel dimension.
The notion of channels is asoldas CNNsthemselves: forinstance Le Net-5(Le Cunetal.,1995)usesthem.
Inthis section, wewilltakeadeeperlookatconvolutionkernelswithmultipleinputandmultiple outputchannels.
import torch from d2l import torch as d2l 7.4.1 Multiple Input Channels Whentheinputdatacontainsmultiplechannels, weneedtoconstructaconvolutionkernel with the same number of input channels as the input data, so that it can perform cross- correlationwiththeinputdata.
Assumingthatthenumberofchannelsfortheinputdata is ğ‘, the number of input channels of the convolution kernel also needs to be ğ‘.
If our i i convolution kernelâ€™s window shape is ğ‘˜ ğ‘˜ , then, when ğ‘ = 1, we can think of our h w i convolutionkernelasjustatwo-dimensionaltensorofshapeğ‘˜ ğ‘˜ .
h w However, when ğ‘ > 1, we need a kernel that contains a tensor of shape ğ‘˜ ğ‘˜ for ev- i h w eryinputchannel.
Concatenatingthese ğ‘ tensorstogetheryieldsaconvolutionkernelof i shapeğ‘ ğ‘˜ ğ‘˜ .
Sincetheinputandconvolutionkerneleachhaveğ‘ channels, wecan i h w i 253 Multiple Inputand Multiple Output Channels performacross-correlationoperationonthetwo-dimensionaltensoroftheinputandthe two-dimensional tensor of the convolution kernel for each channel, adding the ğ‘ results i together(summingoverthechannels)toyieldatwo-dimensionaltensor.
Thisistheresult of a two-dimensional cross-correlation between a multi-channel input and a multi-input- channelconvolutionkernel.
.4.1providesanexampleofatwo-dimensionalcross-correlationwithtwoinputchan- nels.
Theshadedportionsarethefirstoutputelementaswellastheinputandkerneltensor elementsusedfortheoutputcomputation: â€1 1â€š2 2â€š4 3â€š5 4â€â€šâ€0 0â€š1 1â€š 3 2â€š4 3â€ =56.
t .4.1 Cross-correlationcomputationwithtwoinputchannels.
Tomakesurewereallyunderstandwhatisgoingonhere, wecanimplementcross-correlation operationswithmultipleinputchannelsourselves.
Noticethatallwearedoingisperform- ingacross-correlationoperationperchannelandthenaddinguptheresults.
def corr2d_multi_in(X, K): # Iterate through the 0th dimension (channel) of K first, then add them up return sum(d2l.
corr2d(x, k) for x, k in zip(X, K)) Wecanconstructtheinputtensor Xandthekerneltensor Kcorrespondingtothevaluesin .4.1tovalidatetheoutputofthecross-correlationoperation.
corr2d_multi_in(X, K) tensor([[ 56., 72.], [104., 120.]]) 7.4.2 Multiple Output Channels Regardless of the number of input channels, so far we always ended up with one output channel.
However, as we discussed in Section 7.1.4, it turns out to be essential to have multiplechannelsateachlayer.
Inthemostpopularneuralnetworkarchitectures, weactu- allyincreasethechanneldimensionaswegodeeperintheneuralnetwork, typicallydown- sampling to trade off spatial resolution for greater channel depth.
Intuitively, you could 254 Convolutional Neural Networks thinkofeachchannelasrespondingtoadifferentsetoffeatures.
Therealityisabitmore complicatedthanthis.
Anaiveinterpretationwouldsuggestthatrepresentationsarelearned independentlyperpixelorperchannel.
Instead, channelsareoptimizedtobejointlyuseful.
This means that rather than mapping a single channel to an edge detector, it may simply meanthatsomedirectioninchannelspacecorrespondstodetectingedges.
Denotebyğ‘ andğ‘ thenumberofinputandoutputchannels, respectively, andbyğ‘˜ andğ‘˜ i o h w theheightandwidthofthekernel.
Togetanoutputwithmultiplechannels, wecancreate akerneltensorofshapeğ‘ ğ‘˜ ğ‘˜ foreveryoutputchannel.
Weconcatenatethemonthe i h w outputchanneldimension, sothattheshapeoftheconvolutionkernelisğ‘ ğ‘ ğ‘˜ ğ‘˜ .
o i h w In cross-correlation operations, the result on each output channel is calculated from the convolutionkernelcorrespondingtothatoutputchannelandtakesinputfromallchannels intheinputtensor.
Weimplementacross-correlationfunctiontocalculatetheoutputofmultiplechannelsas shownbelow.
def corr2d_multi_in_out(X, K): # Iterate through the 0th dimension of K, and each time, perform # cross-correlation operations with input X.
All of the results are # stacked together return torch.
stack([corr2d_multi_in(X, k) for k in K], 0) Weconstructatrivialconvolutionkernelwiththreeoutputchannelsbyconcatenatingthe kerneltensorfor Kwith K+1and K+2.
K = torch.
stack((K, K + 1, K + 2), 0) K.
shape torch.
Size([3, 2, 2, 2]) Below, weperformcross-correlationoperationsontheinputtensor Xwiththekerneltensor K.
Nowtheoutputcontainsthreechannels.
Theresultofthefirstchannelisconsistentwith theresultofthepreviousinputtensor Xandthemulti-inputchannel, single-outputchannel kernel.
corr2d_multi_in_out(X, K) tensor([[[ 56., 72.], [104., 120.]], [[ 76., 100.], [148., 172.]], [[ 96., 128.], [192., 224.]]]) 255 Multiple Inputand Multiple Output Channels 7.4.3 1 1Convolutional Layer At first, a 1 1 convolution, i.
e., ğ‘˜ = ğ‘˜ = 1, does not seem to make much sense.
h w After all, a convolution correlates adjacent pixels.
A 1 1 convolution obviously does not.
Nonetheless, theyarepopularoperationsthataresometimesincludedinthedesigns ofcomplexdeepnetworks(Linetal.,2013, Szegedyetal.,2017).
Letâ€™sseeinsomedetail whatitactuallydoes.
Becausetheminimumwindowisused, the1 1convolutionlosestheabilityoflargercon- volutionallayerstorecognizepatternsconsistingofinteractionsamongadjacentelements intheheightandwidthdimensions.
Theonlycomputationofthe1 1convolutionoccurs onthechanneldimension.
.4.2showsthecross-correlationcomputationusingthe1 1convolutionkernelwith3 inputchannelsand2outputchannels.
Notethattheinputsandoutputshavethesameheight andwidth.
Eachelementintheoutputisderivedfromalinearcombinationofelementsat thesamepositionintheinputimage.
Youcouldthinkofthe1 1convolutionallayeras constitutingafullyconnectedlayerappliedateverysinglepixellocationtotransformthe ğ‘ corresponding input values into ğ‘ output values.
Because this is still a convolutional i o layer, theweightsaretiedacrosspixellocation.
Thusthe1 1convolutionallayerrequires ğ‘ ğ‘ weights(plusthebias).
Alsonotethatconvolutionallayersaretypicallyfollowed o i bynonlinearities.
Thisensuresthat1 1convolutionscannotsimplybefoldedintoother convolutions.
t .4.2 Thecross-correlationcomputationusesthe1 1convolutionkernelwiththreeinput channelsandtwooutputchannels.
Theinputandoutputhavethesameheightandwidth.
Letâ€™scheckwhetherthisworksinpractice: weimplementa1 1convolutionusingafully connectedlayer.
Theonlythingisthatweneedtomakesomeadjustmentstothedatashape beforeandafterthematrixmultiplication.
def corr2d_multi_in_out_1x1(X, K): c_i, h, w = X.
shape c_o = K.
shape[0] X = X.
reshape((c_i, h * w)) K = K.
reshape((c_o, c_i)) # Matrix multiplication in the fully connected layer Y = torch.
matmul(K, X) return Y.
reshape((c_o, h, w)) Whenperforming1 1convolutions, theabovefunctionisequivalenttothepreviouslyim- plementedcross-correlationfunctioncorr2d_multi_in_out.
Letâ€™scheckthiswithsome sampledata.
256 Convolutional Neural Networks X = torch.
normal(0, 1, (3, 3, 3)) K = torch.
normal(0, 1, (2, 3, 1, 1)) Y1 = corr2d_multi_in_out_1x1(X, K) Y2 = corr2d_multi_in_out(X, K) assert float(torch.
abs(Y1 - Y2).
sum()) < 1e-6 7.4.4 Discussion Channels allow us to combine the best of both worlds: MLPs that allow for significant nonlinearitiesandconvolutionsthatallowforlocalized analysisoffeatures.
Inparticular, channels allow the CNN to reason with multiple features, such as edge and shape detec- torsatthesametime.
Theyalsoofferapracticaltrade-offbetweenthedrasticparameter reductionarisingfromtranslationinvarianceandlocality, andtheneedforexpressiveand diversemodelsincomputervision.
Note, though, thatthisflexibilitycomesataprice.
Givenanimageofsizeâ€â„ ğ‘¤â€, thecost forcomputingağ‘˜ ğ‘˜ convolutionis Oâ€â„ ğ‘¤ ğ‘˜2â€.
Forğ‘ andğ‘ inputandoutputchannels i o respectively this increases to Oâ€â„ ğ‘¤ ğ‘˜2 ğ‘ ğ‘ â€.
For a 256 256 pixel image with a i o 5 5kerneland128inputandoutputchannelsrespectivelythisamountstoover53billion operations(wecountmultiplicationsandadditionsseparately).
Lateronwewillencounter effectivestrategiestocutdownonthecost, e.
g., byrequiringthechannel-wiseoperations tobeblock-diagonal, leadingtoarchitecturessuchas Res Ne Xt(Xieetal.,2017).
7.4.5 Exercises 1.
Assumethatwehavetwoconvolutionkernelsofsize ğ‘˜ and ğ‘˜ , respectively(withno 1 2 nonlinearityinbetween).
1.
Provethattheresultoftheoperationcanbeexpressedbyasingleconvolution.
2.
Whatisthedimensionalityoftheequivalentsingleconvolution? 3.
Istheconversetrue, i.
e., canyoualwaysdecomposeaconvolutionintotwosmaller ones? 2.
Assumeaninputofshapeğ‘ â„ ğ‘¤andaconvolutionkernelofshapeğ‘ ğ‘ ğ‘˜ ğ‘˜ , i o i h w paddingofâ€ğ‘ ,ğ‘ â€, andstrideofâ€ğ‘  ,ğ‘  â€.
h w h w 1.
Whatisthecomputationalcost(multiplicationsandadditions)fortheforwardprop- agation? 2.
Whatisthememoryfootprint? 3.
Whatisthememoryfootprintforthebackwardcomputation? 4.
Whatisthecomputationalcostforthebackpropagation? 3.
Bywhatfactordoesthenumberofcalculationsincreaseifwedoubleboththenumber ofinputchannelsğ‘ andthenumberofoutputchannelsğ‘ ? Whathappensifwedouble i o thepadding? 257 Pooling 4.
Arethevariables Y1and Y2inthefinalexampleofthissectionexactlythesame? Why? 5.
Expressconvolutionsasamatrixmultiplication, evenwhentheconvolutionwindowis not1 1.
6.
Yourtaskistoimplementfastconvolutionswitha ğ‘˜ ğ‘˜ kernel.
Oneofthealgorithm candidatesistoscanhorizontallyacrossthesource, readingağ‘˜-widestripandcomput- ingthe1-wideoutputstriponevalueatatime.
Thealternativeistoreada ğ‘˜ â€šÎ”wide stripandcomputeaÎ”-wideoutputstrip.
Whyisthelatterpreferable? Istherealimitto howlargeyoushouldchooseÎ”? 7.
Assumethatwehaveağ‘ ğ‘matrix.
1.
Howmuchfasterisittomultiplywithablock-diagonalmatrixifthematrixisbroken upintoğ‘blocks? 2.
Whatisthedownsideofhavingğ‘blocks? Howcouldyoufixit, atleastpartly? 122 Discussions122.
7.5 Pooling In many cases our ultimate task asks some global question about the image, e.
g., does it containacat? Consequently, theunitsofourfinallayershouldbesensitivetotheentire input.
By gradually aggregating information, yielding coarser and coarser maps, we ac- complishthisgoalofultimatelylearningaglobalrepresentation, whilekeepingallofthe advantages of convolutional layers at the intermediate layers of processing.
The deeper we go in the network, the larger the receptive field (relative to the input) to which each hidden node is sensitive.
Reducing spatial resolution accelerates this process, since the convolutionkernelscoveralargereffectivearea.
Moreover, whendetectinglower-levelfeatures, suchasedges(asdiscussedin Section7.2), we often want our representations to be somewhat invariant to translation.
For instance, if we take the image X with a sharp delineation between black and white and shift the whole image by one pixel to the right, i.
e., Z[i, j] = X[i, j + 1], then the output forthenewimage Zmightbevastlydifferent.
Theedgewillhaveshiftedbyonepixel.
In reality, objectshardlyeveroccurexactlyatthesameplace.
Infact, evenwithatripodand astationaryobject, vibrationofthecameraduetothemovementoftheshuttermightshift everythingbyapixelorso(high-endcamerasareloadedwithspecialfeaturestoaddress thisproblem).
This section introduces pooling layers, which serve the dual purposes of mitigating the sensitivity of convolutional layers to location and of spatially downsampling representa- tions.
258 Convolutional Neural Networks import torch from torch import nn from d2l import torch as d2l 7.5.1 Maximum Poolingand Average Pooling Like convolutional layers, pooling operators consist of a fixed-shape window that is slid overallregionsintheinputaccordingtoitsstride, computingasingleoutputforeachlo- cation traversed by the fixed-shape window (sometimes known as the pooling window).
However, unlike the cross-correlation computation of the inputs and kernels in the con- volutional layer, the pooling layer contains no parameters (there is no kernel).
Instead, poolingoperatorsaredeterministic, typicallycalculatingeitherthemaximumortheaver- age value of the elements in the pooling window.
These operations are called maximum pooling(max-poolingforshort)andaveragepooling, respectively.
Averagepoolingisessentiallyasoldas CNNs.
Theideaisakintodownsamplinganimage.
Ratherthanjusttakingthevalueofeverysecond(orthird)pixelforthelowerresolution image, wecanaverageoveradjacentpixelstoobtainanimagewithbettersignal-to-noise ratiosincewearecombiningtheinformationfrommultipleadjacentpixels.
Max-pooling wasintroducedin Riesenhuberand Poggio(1999)inthecontextofcognitiveneuroscience todescribehowinformationaggregationmightbeaggregatedhierarchicallyforthepurpose ofobjectrecognition; therealreadywasanearlierversioninspeechrecognition(Yamaguchi et al., 1990).
In almost all cases, max-pooling, as it is also referred to, is preferable to averagepooling.
Inbothcases, aswiththecross-correlationoperator, wecanthinkofthepoolingwindow asstartingfromtheupper-leftoftheinputtensorandslidingacrossitfromlefttorightand toptobottom.
Ateachlocationthatthepoolingwindowhits, itcomputesthemaximumor averagevalueoftheinputsubtensorinthewindow, dependingonwhethermaxoraverage poolingisemployed.
t .5.1 Max-poolingwithapoolingwindowshapeof2 2.
Theshadedportionsarethefirst outputelementaswellastheinputtensorelementsusedfortheoutputcomputation: maxâ€0,1,3,4â€ =4.
Theoutputtensorin.5.1hasaheightof2andawidthof2.
Thefourelementsare 259 Pooling derivedfromthemaximumvalueineachpoolingwindow: maxâ€0,1,3,4â€ =4, maxâ€1,2,4,5â€ =5, (7.5.1) maxâ€3,4,6,7â€ =7, maxâ€4,5,7,8â€ =8.
Moregenerally, wecandefinea ğ‘ ğ‘ poolinglayerbyaggregatingoveraregionofsaid size.
Returning tothe problemof edgedetection, weusethe outputof theconvolutional layerasinputfor2 2max-pooling.
Denoteby Xtheinputoftheconvolutionallayerinput and Ythepoolinglayeroutput.
Regardlessofwhetherornotthevaluesof X[i, j], X[i, j + 1], X[i+1, j]and X[i+1, j + 1]aredifferent, thepoolinglayeralwaysoutputs Y[i, j] = 1.
Thatistosay, usingthe2 2max-poolinglayer, wecanstilldetectifthe patternrecognizedbytheconvolutionallayermovesnomorethanoneelementinheightor width.
Inthecodebelow, weimplementtheforwardpropagationofthepoolinglayerinthepool2d function.
Thisfunctionissimilartothecorr2dfunctionin Section7.2.
However, nokernel isneeded, computingtheoutputaseitherthemaximumortheaverageofeachregioninthe input.
def pool2d(X, pool_size, mode='max'): p_h, p_w = pool_size Y = torch.
zeros((X.
shape[0] - p_h + 1, X.
shape[1] - p_w + 1)) for i in range(Y.
shape[0]): for j in range(Y.
shape[1]): if mode == 'max': Y[i, j] = X[i: i + p_h, j: j + p_w].
max() elif mode == 'avg': Y[i, j] = X[i: i + p_h, j: j + p_w].
mean() return Y Wecanconstructtheinputtensor Xin.5.1tovalidatetheoutputofthetwo-dimensional max-poolinglayer.
pool2d(X, (2, 2)) tensor([[4., 5.], [7., 8.]]) Also, wecanexperimentwiththeaveragepoolinglayer.
pool2d(X, (2, 2), 'avg') tensor([[2., 3.], [5., 6.]]) 260 Convolutional Neural Networks 7.5.2 Paddingand Stride Aswithconvolutionallayers, poolinglayerschangetheoutputshape.
Andasbefore, wecan adjusttheoperationtoachieveadesiredoutputshapebypaddingtheinputandadjustingthe stride.
Wecandemonstratetheuseofpaddingandstridesinpoolinglayersviathebuilt-in two-dimensionalmax-poolinglayerfromthedeeplearningframework.
Wefirstconstruct aninputtensor Xwhoseshapehasfourdimensions, wherethenumberofexamples(batch size)andnumberofchannelsareboth1.
X = torch.
arange(16, dtype=torch.
float32).
reshape((1, 1, 4, 4)) X tensor([[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]]]) Since pooling aggregates information from an area, deep learning frameworks default to matching pooling window sizes and stride.
For instance, if we use a pooling window of shape(3, 3)wegetastrideshapeof(3, 3)bydefault.
pool2d = nn.
Max Pool2d(3) # Pooling has no model parameters, hence it needs no initialization pool2d(X) tensor([[[[10.]]]]) Needlessto say, the stride andpadding can be manuallyspecified to overrideframework defaultsifrequired.
pool2d = nn.
Max Pool2d(3, padding=1, stride=2) pool2d(X) tensor([[[[ 5., 7.], [13., 15.]]]]) Of course, we can specify an arbitrary rectangular pooling window with arbitrary height andwidthrespectively, astheexamplebelowshows.
pool2d = nn.
Max Pool2d((2, 3), stride=(2, 3), padding=(0, 1)) pool2d(X) tensor([[[[ 5., 7.], [13., 15.]]]]) 261 Pooling 7.5.3 Multiple Channels Whenprocessingmulti-channelinputdata, thepoolinglayerpoolseachinputchannelsep- arately, ratherthansummingtheinputsupoverchannelsasinaconvolutionallayer.
This meansthatthenumberofoutputchannelsforthepoolinglayeristhesameasthenumberof inputchannels.
Below, wewillconcatenatetensors Xand X + 1onthechanneldimension toconstructaninputwithtwochannels.
X = torch.
cat((X, X + 1), 1) X tensor([[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]], [[ 1., 2., 3., 4.], [ 5., 6., 7., 8.], [ 9., 10., 11., 12.], [13., 14., 15., 16.]]]]) Aswecansee, thenumberofoutputchannelsisstilltwoafterpooling.
pool2d = nn.
Max Pool2d(3, padding=1, stride=2) pool2d(X) tensor([[[[ 5., 7.], [13., 15.]], [[ 6., 8.], [14., 16.]]]]) 7.5.4 Summary Pooling is an exceedingly simple operation.
It does exactly what its name indicates, ag- gregate results over a window of values.
All convolution semantics, such as strides and paddingapplyinthesamewayastheydidpreviously.
Notethatpoolingisindifferentto channels, i.
e., it leaves the number of channels unchanged and it applies to each channel separately.
Lastly, ofthetwopopularpoolingchoices, max-poolingispreferabletoaverage pooling, asitconferssomedegreeofinvariancetooutput.
Apopularchoiceistopicka poolingwindowsizeof2 2toquarterthespatialresolutionofoutput.
Notethattherearemanymorewaysofreducingresolutionbeyondpooling.
Forinstance, in stochasticpooling(Zeilerand Fergus, 2013)andfractionalmax-pooling(Graham, 2014) aggregation is combined with randomization.
This can slightly improve the accuracy in some cases.
Lastly, as we will see later with the attention mechanism, there are more refinedwaysofaggregatingoveroutputs, e.
g., byusingthealignmentbetweenaqueryand representationvectors.
262 Convolutional Neural Networks 7.5.5 Exercises 1.
Implementaveragepoolingthroughaconvolution.
2.
Provethatmax-poolingcannotbeimplementedthroughaconvolutionalone.
3.
Max-poolingcanbeaccomplishedusing Re LUoperations, i.
e., Re LUâ€ğ‘¥â€ =maxâ€0,ğ‘¥â€.
1.
Expressmaxâ€ğ‘,ğ‘â€byusingonly Re LUoperations.
2.
Usethistoimplementmax-poolingbymeansofconvolutionsand Re LUlayers.
3.
Howmanychannelsandlayersdoyouneedfora2 2convolution? Howmanyfor a3 3convolution? 4.
Whatisthecomputationalcostofthepoolinglayer? Assumethattheinputtothepooling layerisofsizeğ‘ â„ ğ‘¤, thepoolingwindowhasashapeof ğ‘ ğ‘ withapaddingof h w â€ğ‘ ,ğ‘ â€andastrideofâ€ğ‘  ,ğ‘  â€.
h w h w 5.
Whydoyouexpectmax-poolingandaveragepoolingtoworkdifferently? 6.
Doweneedaseparateminimumpoolinglayer? Canyoureplaceitwithanotheropera- tion? 7.
Wecouldusethesoftmaxoperationforpooling.
Whymightitnotbesopopular? 123 Discussions123.
7.6 Convolutional Neural Networks (Le Net) Wenowhavealltheingredientsrequiredtoassembleafully-functional CNN.
Inourearlier encounterwithimagedata, weappliedalinearmodelwithsoftmaxregression(Section4.4) andan MLP(Section5.2)topicturesofclothinginthe Fashion-MNISTdataset.
Tomake suchdataamenablewefirstflattenedeachimagefroma28 28matrixintoafixed-length 784-dimensionalvector, andthereafterprocessedtheminfullyconnectedlayers.
Nowthat wehaveahandleonconvolutionallayers, wecanretainthespatialstructureinourimages.
Asanadditionalbenefitofreplacingfullyconnectedlayerswithconvolutionallayers, we willenjoymoreparsimoniousmodelsthatrequirefarfewerparameters.
Inthissection, wewillintroduce Le Net, amongthefirstpublished CNNstocapturewide attentionforitsperformanceoncomputervisiontasks.
Themodelwasintroducedby(and named for) Yann Le Cun, then a researcher at AT&T Bell Labs, for the purpose of rec- ognizing handwritten digits in images (Le Cun et al., 1998).
This work represented the culmination of a decade of research developing the technology; Le Cunâ€™s team published thefirststudytosuccessfullytrain CNNsviabackpropagation(Le Cunetal.,1989).
Atthetime Le Netachievedoutstandingresultsmatchingtheperformanceofsupportvector machines, thenadominantapproachinsupervisedlearning, achievinganerrorrateofless 263 Convolutional Neural Networks(Le Net) than1%perdigit.
Le Netwaseventuallyadaptedtorecognizedigitsforprocessingdeposits in ATM machines.
To this day, some ATMs still run the code that Yann Le Cun and his colleague Leon Bottouwroteinthe1990s! import torch from torch import nn from d2l import torch as d2l 7.6.1 Le Net Atahighlevel, Le Net(Le Net-5)consistsoftwoparts: (i)aconvolutionalencoderconsist- ingoftwoconvolutionallayers; and(ii)adenseblockconsistingofthreefullyconnected t .6.1 Dataflowin Le Net.
Theinputisahandwrittendigit, theoutputisaprobabilityover10 possibleoutcomes.
Thebasicunitsineachconvolutionalblockareaconvolutionallayer, asigmoidactivation function, and a subsequent average pooling operation.
Note that while Re LUs and max- poolingworkbetter, theyhadnotyetbeendiscovered.
Eachconvolutionallayerusesa5 5 kernelandasigmoidactivationfunction.
Theselayersmapspatiallyarrangedinputstoa numberoftwo-dimensionalfeaturemaps, typicallyincreasingthenumberofchannels.
The firstconvolutionallayerhas6outputchannels, whilethesecondhas16.
Each2 2pooling operation(stride2)reducesdimensionalitybyafactorof4viaspatialdownsampling.
The convolutionalblockemitsanoutputwithshapegivenby(batchsize, numberofchannel, height, width).
Inordertopassoutputfromtheconvolutionalblocktothedenseblock, wemustflatteneach exampleintheminibatch.
Inotherwords, wetakethisfour-dimensionalinputandtransform itintothetwo-dimensionalinputexpectedbyfullyconnectedlayers: asareminder, thetwo- dimensionalrepresentationthatwedesireusesthefirstdimensiontoindexexamplesinthe minibatchandthesecondtogivetheflatvectorrepresentationofeachexample.
Le Netâ€™s dense block has three fully connected layers, with 120, 84, and 10 outputs, respectively.
Becausewearestillperformingclassification, the10-dimensionaloutputlayercorresponds tothenumberofpossibleoutputclasses.
264 Convolutional Neural Networks Whilegettingtothepointwhereyoutrulyunderstandwhatisgoingoninside Le Netmay havetakena bitof work, wehopethat the followingcodesnippet will convinceyouthat implementingsuchmodelswithmoderndeeplearningframeworksisremarkablysimple.
Weneedonlytoinstantiatea Sequentialblockandchaintogethertheappropriatelayers, using Xavierinitializationasintroducedin Section5.4.2.
def init_cnn(module): #@save """Initialize weights for CNNs.""" if type(module) == nn.
Linear or type(module) == nn.
Conv2d: nn.
init.
xavier_uniform_(module.
weight) class Le Net(d2l.
Classifier): #@save """The Le Net-5 model.""" def __init__(self, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nn.
Lazy Conv2d(6, kernel_size=5, padding=2), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Lazy Conv2d(16, kernel_size=5), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Flatten(), nn.
Lazy Linear(120), nn.
Sigmoid(), nn.
Lazy Linear(84), nn.
Sigmoid(), nn.
Lazy Linear(num_classes)) Wehavetakensomelibertyinthereproductionof Le Netinsofaraswehavereplacedthe Gaussianactivationlayerbyasoftmaxlayer.
Thisgreatlysimplifiestheimplementation, notleastduetothefactthatthe Gaussiandecoderisrarelyusednowadays.
Otherthanthat, thisnetworkmatchestheoriginal Le Net-5architecture.
Letâ€™sseewhathappensinsidethenetwork.
Bypassingasingle-channel(blackandwhite) 28 28imagethroughthenetworkandprintingtheoutputshapeateachlayer, wecaninspect themodeltoensurethatitsoperationslineupwithwhatweexpectfrom.6.2.
t .6.2 Compressednotationfor Le Net-5.
265 Convolutional Neural Networks(Le Net) @d2l.
add_to_class(d2l.
Classifier) #@save def layer_summary(self, X_shape): X = torch.
randn(*X_shape) for layer in self.
net: X = layer(X) print(layer.__class__.__name__, 'output shape:\t', X.
shape) model = Le Net() model.
layer_summary((1, 1, 28, 28)) Conv2d output shape: torch.
Size([1, 6, 28, 28]) Sigmoid output shape: torch.
Size([1, 6, 28, 28]) Avg Pool2d output shape: torch.
Size([1, 6, 14, 14]) Conv2d output shape: torch.
Size([1, 16, 10, 10]) Sigmoid output shape: torch.
Size([1, 16, 10, 10]) Avg Pool2d output shape: torch.
Size([1, 16, 5, 5]) Flatten output shape: torch.
Size([1, 400]) Linear output shape: torch.
Size([1, 120]) Sigmoid output shape: torch.
Size([1, 120]) Linear output shape: torch.
Size([1, 84]) Sigmoid output shape: torch.
Size([1, 84]) Linear output shape: torch.
Size([1, 10]) Notethattheheightandwidthoftherepresentationateachlayerthroughouttheconvolu- tional block is reduced (compared with the previous layer).
The first convolutional layer usestwopixelsofpaddingtocompensateforthereductioninheightandwidththatwould otherwiseresultfromusinga5 5kernel.
Asanaside, theimagesizeof28 28pixelsin theoriginal MNISTOCRdatasetisaresultoftrimmingtwopixelrows(andcolumns)from theoriginalscansthatmeasured32 32pixels.
Thiswasdoneprimarilytosavespace(a 30%reduction)atatimewhenmegabytesmattered.
Incontrast, thesecondconvolutionallayerforgoespadding, andthustheheightandwidth arebothreducedbyfourpixels.
Aswegoupthestackoflayers, thenumberofchannels increases layer-over-layer from 1 in the input to 6 after the first convolutional layer and 16afterthesecondconvolutionallayer.
However, eachpoolinglayerhalvestheheightand width.
Finally, eachfullyconnectedlayerreducesdimensionality, finallyemittinganoutput whosedimensionmatchesthenumberofclasses.
7.6.2 Training Nowthatwehaveimplementedthemodel, letâ€™srunanexperimenttoseehowthe Le Net-5 modelfareson Fashion-MNIST.
While CNNs have fewer parameters, they can still be more expensive to compute than similarly deep MLPs because each parameter participates in many more multiplications.
If you have access to a GPU, this might be a good time to put it into action to speed up training.
Notethatthed2l.
Trainerclasstakescareofalldetails.
Bydefault, itinitializes the model parameters on the available devices.
Just as with MLPs, our loss function is cross-entropy, andweminimizeitviaminibatchstochasticgradientdescent.
266 Convolutional Neural Networks trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128) model = Le Net(lr=0.1) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], init_cnn) trainer.
fit(model, data) 7.6.3 Summary Wehavemadesignificantprogressinthischapter.
Wemovedfromthe MLPsofthe1980s tothe CNNs ofthe 1990s andearly2000s.
The architecturesproposed, e.
g., in theform of Le Net-5remainmeaningful, eventothisday.
Itisworthcomparingtheerrorrateson Fashion-MNISTachievablewith Le Net-5bothtotheverybestpossiblewith MLPs(Section 5.2)andthosewithsignificantlymoreadvancedarchitecturessuchas Res Net(Section8.6).
Le Netismuchmoresimilartothelatterthantotheformer.
Oneoftheprimarydifferences, asweshallsee, isthatgreateramountsofcomputationenabledsignificantlymorecomplex architectures.
Aseconddifferenceistherelativeeasewithwhichwewereabletoimplement Le Net.
What usedtobeanengineeringchallengeworthmonthsof C++andassemblycode, engineering toimprove SN, anearly Lisp-baseddeeplearningtool(Bottouand Le Cun,1988), andfi- nallyexperimentationwithmodelscannowbeaccomplishedinminutes.
Itisthisincredible productivityboostthathasdemocratizeddeeplearningmodeldevelopmenttremendously.
Inthenextchapterwewilljourneydownthisrabbittoholetoseewhereittakesus.
7.6.4 Exercises 1.
Letâ€™smodernize Le Net.
Implementandtestthefollowingchanges: 1.
Replaceaveragepoolingwithmax-pooling.
2.
Replacethesoftmaxlayerwith Re LU.
2.
Trytochangethesizeofthe Le Netstylenetworktoimproveitsaccuracyinadditionto max-poolingand Re LU.
1.
Adjusttheconvolutionwindowsize.
2.
Adjustthenumberofoutputchannels.
267 Convolutional Neural Networks(Le Net) 3.
Adjustthenumberofconvolutionlayers.
4.
Adjustthenumberoffullyconnectedlayers.
5.
Adjustthelearningratesandothertrainingdetails(e.
g., initializationandnumberof epochs).
3.
Tryouttheimprovednetworkontheoriginal MNISTdataset.
4.
Displaytheactivationsofthefirstandsecondlayerof Le Netfordifferentinputs(e.
g., sweatersandcoats).
5.
What happens to the activations when you feed significantly different images into the network(e.
g., cats, cars, orevenrandomnoise)? Discussions124.
124 8 Modern Convolutional Neural Networks Now that we understand the basics of wiring together CNNs, letâ€™s take a tour of modern CNNarchitectures.
Thistouris, bynecessity, incomplete, thankstotheplethoraofexcit- ingnewdesignsbeingadded.
Theirimportancederivesfromthefactthatnotonlycanthey be used directly for vision tasks, but they also serve as basic feature generators for more advancedtaskssuchastracking(Zhangetal.,2021), segmentation(Longetal.,2015), ob- jectdetection(Redmonand Farhadi,2018), orstyletransformation(Gatysetal.,2016).
In thischapter, mostsectionscorrespondtoasignificant CNNarchitecturethatwasatsome point(orcurrently)thebasemodeluponwhichmanyresearchprojectsanddeployedsys- temswerebuilt.
Eachofthesenetworkswasbrieflyadominantarchitectureandmanywere winners or runners-up in the Image Net competition125 which has served as a barometer 125 ofprogressonsupervisedlearningincomputervisionsince2010.
Itisonlyrecentlythat Transformers have begun to displace CNNs, starting with Dosovitskiy et al.
(2021) and followedbythe Swin Transformer(Liuetal.,2021).
Wewillcoverthisdevelopmentlater in Chapter11.
Whiletheideaofdeepneuralnetworksisquitesimple(stacktogetherabunchoflayers), performancecanvarywildlyacrossarchitecturesandhyperparameterchoices.
Theneural networksdescribedinthischapteraretheproductofintuition, afewmathematicalinsights, andalotoftrialanderror.
Wepresentthesemodelsinchronologicalorder, partlytoconvey a sense of the history so that you can form your own intuitions about where the field is headingandperhapsdevelopyourownarchitectures.
Forinstance, batchnormalizationand residualconnectionsdescribedinthischapterhaveofferedtwopopularideasfortraining and designing deep models, both of which have since also been applied to architectures beyondcomputervision.
Webeginourtourofmodern CNNswith Alex Net(Krizhevskyetal.,2012), thefirstlarge- scalenetworkdeployedtobeatconventionalcomputervisionmethodsonalarge-scalevi- sionchallenge; the VGGnetwork(Simonyanand Zisserman,2014), whichmakesuseofa numberofrepeatingblocksofelements; thenetworkinnetwork(Ni N)thatconvolveswhole neuralnetworkspatch-wiseoverinputs(Linetal.,2013); Goog Le Netthatusesnetworks withmulti-branchconvolutions(Szegedyetal.,2015); theresidualnetwork(Res Net)(He etal.,2016), whichremainsoneofthemostpopularoff-the-shelfarchitecturesincomputer vision; Res Ne Xtblocks(Xieetal.,2017)forsparserconnections; and Dense Net(Huang etal.,2017)forageneralizationoftheresidualarchitecture.
Overtimemanyspecialopti- mizationsforefficientnetworkshavebeendeveloped, suchascoordinateshifts(Shift Net) (Wuetal.,2018).
Thisculminatedintheautomaticsearchforefficientarchitecturessuch 268 269 Deep Convolutional Neural Networks(Alex Net) as Mobile Netv3(Howardetal.,2019).
Italsoincludesthesemi-automaticdesignexplo- rationof Radosavovicetal.
(2020)thatledtothe Reg Net X/Ywhichwewilldiscusslater inthischapter.
Theworkisinstructiveinsofarasitoffersapathformarryingbruteforce computationwiththeingenuityofanexperimenterinthesearchforefficientdesignspaces.
Ofnoteisalsotheworkof Liuetal.
(2022)asitshowsthattrainingtechniques(e.
g., op- timizers, dataaugmentation, andregularization)playapivotalroleinimprovingaccuracy.
Italsoshowsthatlong-heldassumptions, suchasthesizeofaconvolutionwindow, may need to be revisited, given the increase in computation and data.
We will cover this and manymorequestionsinduecoursethroughoutthischapter.
8.1 Deep Convolutional Neural Networks (Alex Net) Although CNNs were well known in the computer vision and machine learning commu- nitiesfollowingtheintroductionof Le Net(Le Cunetal.,1995), theydidnotimmediately dominatethefield.
Although Le Netachievedgoodresultsonearlysmalldatasets, theper- formanceandfeasibilityoftraining CNNsonlarger, morerealisticdatasetshadyettobe established.
Infact, formuchoftheinterveningtimebetweentheearly1990sandthewa- tershed results of 2012 (Krizhevsky et al., 2012), neural networks were often surpassed byothermachinelearningmethods, suchaskernelmethods(SchÃ¶lkopfand Smola,2002), ensemblemethods(Freundand Schapire, 1996), andstructuredestimation(Taskaretal., 2004).
For computer vision, this comparison is perhaps not entirely accurate.
That is, although the inputs to convolutional networks consist of raw or lightly-processed (e.
g., by center- ing) pixel values, practitioners would never feed raw pixels into traditional models.
In- stead, typicalcomputervisionpipelinesconsistedofmanuallyengineeringfeatureextrac- tion pipelines, such as SIFT (Lowe, 2004), SURF (Bay et al., 2006), and bags of visual words (Sivic and Zisserman, 2003).
Rather than learning the features, the features were crafted.
Mostoftheprogresscamefromhavingmorecleverideasforfeatureextractionon theonehandanddeepinsightintogeometry(Hartleyand Zisserman,2000)ontheother.
Thelearningalgorithmwasoftenconsideredanafterthought.
Althoughsomeneuralnetworkacceleratorswereavailableinthe1990s, theywerenotyet sufficiently powerful to make deep multichannel, multilayer CNNs with a large number of parameters.
For instance, NVIDIAâ€™s Ge Force 256 from 1999 was able to process at most480millionfloating-pointoperations, suchasadditionsandmultiplications, persec- ond(MFLOPS), withoutanymeaningfulprogrammingframeworkforoperationsbeyond games.
Todayâ€™s accelerators are able to perform in excess of 1000 TFLOPs per device.
Moreover, datasetswerestillrelativelysmall: OCRon60,000low-resolution28 28pixel imageswasconsideredahighlychallengingtask.
Addedtotheseobstacles, keytricksfor trainingneuralnetworksincludingparameterinitializationheuristics(Glorotand Bengio, 2010), clevervariantsofstochasticgradientdescent(Kingmaand Ba,2014), non-squashing 270 Modern Convolutional Neural Networks activationfunctions(Nairand Hinton,2010), andeffectiveregularizationtechniques(Sri- vastavaetal.,2014)werestillmissing.
Thus, rather than training end-to-end (pixel to classification) systems, classical pipelines lookedmorelikethis: 1.
Obtainaninterestingdataset.
Intheearlydays, thesedatasetsrequiredexpensivesen- sors.
For instance, the Apple Quick Take 100126 of 1994 sported a whopping 0.3 126 megapixel(VGA)resolution, capableofstoringupto8images, allforthepriceof$1000.
2.
Preprocessthedatasetwithhand-craftedfeaturesbasedonsomeknowledgeofoptics, geometry, other analytic tools, and occasionally on the serendipitous discoveries by luckygraduatestudents.
3.
Feed the data through a standard set of feature extractors such as the SIFT (scale- invariantfeaturetransform)(Lowe,2004), the SURF(speededuprobustfeatures)(Bay etal.,2006), oranynumberofotherhand-tunedpipelines.
Open CVstillprovides SIFT extractorstothisday! 4.
Dumptheresultingrepresentationsintoyourfavoriteclassifier, likelyalinearmodelor kernelmethod, totrainaclassifier.
Ifyouspoketomachinelearningresearchers, theywouldreplythatmachinelearningwas bothimportantandbeautiful.
Eleganttheoriesprovedthepropertiesofvariousclassifiers (Boucheron et al., 2005) and convex optimization (Boyd and Vandenberghe, 2004) had becomethemainstayforobtainingthem.
Thefieldofmachinelearningwasthriving, rig- orous, andeminentlyuseful.
However, ifyouspoketoacomputervisionresearcher, you would hear a very different story.
The dirty truth of image recognition, they would tell you, is that features, geometry (Hartley and Zisserman, 2000, Hartley and Kahl, 2009), andengineering, ratherthannovellearningalgorithms, droveprogress.
Computervision researchers justifiably believed that a slightly bigger or cleaner dataset or a slightly im- provedfeature-extractionpipelinematteredfarmoretothefinalaccuracythananylearning algorithm.
import torch from torch import nn from d2l import torch as d2l 8.1.1 Representation Learning Anotherwaytocastthestateofaffairsisthatthemostimportantpartofthepipelinewasthe representation.
Andupuntil2012therepresentationwascalculatedmostlymechanically.
In fact, engineering a new set of feature functions, improving results, and writing up the methodallfeaturedprominentlyinpapers.
SIFT(Lowe,2004), SURF(Bayetal.,2006), HOG (histograms of oriented gradient) (Dalal and Triggs, 2005), bags of visual words (Sivicand Zisserman,2003), andsimilarfeatureextractorsruledtheroost.
Anothergroupofresearchers, including Yann Le Cun, Geoff Hinton, Yoshua Bengio, An- drew Ng, Shun-ichi Amari, and Juergen Schmidhuber, haddifferentplans.
Theybelieved 271 Deep Convolutional Neural Networks(Alex Net) thatfeaturesthemselvesoughttobelearned.
Moreover, theybelievedthattobereasonably complex, the features ought to be hierarchically composed with multiple jointly learned layers, each with learnable parameters.
In the case of an image, the lowest layers might cometodetectedges, colors, andtextures, byanalogywithhowthevisualsysteminani- malsprocessesitsinput.
Inparticular, theautomaticdesignofvisualfeaturessuchasthose obtainedbysparsecoding(Olshausenand Field,1996)remainedanopenchallengeuntil theadventofmodern CNNs.
Itwasnotuntil Deanetal.
(2012), Le(2013)thattheideaof generatingfeaturesfromimagedataautomaticallygainedsignificanttraction.
Thefirstmodern CNN(Krizhevskyetal.,2012), named Alex Netafteroneofitsinventors, Alex Krizhevsky, islargelyanevolutionaryimprovementover Le Net.
Itachievedexcellent performanceinthe2012Image Netchallenge.
t .1.1 Imagefilterslearnedbythefirstlayerof Alex Net.
Reproductioncourtesyof Krizhevsky etal.
(2012).
Interestingly, inthelowestlayersofthenetwork, themodellearnedfeatureextractorsthat layersinthenetworkmightbuildupontheserepresentationstorepresentlargerstructures, like eyes, noses, blades of grass, and so on.
Even higher layers might represent whole objectslikepeople, airplanes, dogs, orfrisbees.
Ultimately, thefinalhiddenstatelearnsa compactrepresentationoftheimagethatsummarizesitscontentssuchthatdatabelonging todifferentcategoriescanbeeasilyseparated.
Alex Net (2012) and its precursor Le Net (1995) share many architectural elements.
This begsthequestion: whydidittakesolong? Akeydifferencewasthat, overtheprevioustwo decades, theamountofdataandthecomputingpoweravailablehadincreasedsignificantly.
Assuch Alex Netwasmuchlarger: itwastrainedonmuchmoredata, andonmuchfaster GPUscomparedtothe CPUsavailablein1995.
272 Modern Convolutional Neural Networks Missing Ingredient: Data Deepmodelswithmanylayersrequirelargeamountsofdatainordertoentertheregime where they significantly outperform traditional methods based on convex optimizations (e.
g., linearandkernelmethods).
However, giventhelimitedstoragecapacityofcomputers, therelativeexpenseof(imaging)sensors, andthecomparativelytighterresearchbudgets in the 1990s, most research relied on tiny datasets.
Numerous papers relied on the UCI collection of datasets, many of which contained only hundreds or (a few) thousands of imagescapturedinlowresolutionandoftenwithanartificiallycleanbackground.
In 2009, the Image Net dataset was released (Deng et al., 2009), challenging researchers tolearnmodelsfrom1millionexamples,1000eachfrom1000distinctcategoriesofob- jects.
Thecategoriesthemselveswerebasedonthemostpopularnounnodesin Word Net (Miller,1995).
The Image Netteamused Google Image Searchtoprefilterlargecandidate setsforeachcategoryandemployedthe Amazon Mechanical Turkcrowdsourcingpipeline toconfirmforeachimagewhetheritbelongedtotheassociatedcategory.
Thisscalewasun- precedented, exceedingothersbyoveranorderofmagnitude(e.
g., CIFAR-100has60,000 images).
Anotheraspectwasthattheimageswereatrelativelyhighresolutionof224 224 pixels, unlike the 80 million-sized Tiny Images dataset (Torralba et al., 2008), consisting of32 32pixelthumbnails.
Thisallowedfortheformationofhigher-levelfeatures.
The associated competition, dubbed the Image Net Large Scale Visual Recognition Challenge (Russakovsky et al., 2015), pushed computer vision and machine learning research for- ward, challengingresearchersto identifywhichmodelsperformedbestatagreaterscale thanacademicshadpreviouslyconsidered.
Thelargestvisiondatasets, suchas LAION-5B (Schuhmannetal.,2022)containbillionsofimageswithadditionalmetadata.
Missing Ingredient: Hardware Deeplearningmodelsarevoraciousconsumersofcomputecycles.
Trainingcantakehun- dredsofepochs, andeachiterationrequirespassingdatathroughmanylayersofcompu- tationallyexpensivelinearalgebraoperations.
Thisisoneofthemainreasonswhyinthe 1990sandearly2000s, simplealgorithmsbasedonthemore-efficientlyoptimizedconvex objectiveswerepreferred.
Graphical processing units (GPUs) proved to be a game changer in making deep learn- ingfeasible.
Thesechipshadearlierbeendevelopedforacceleratinggraphicsprocessing to benefit computer games.
In particular, they were optimized for high throughput 4 4 matrixâ€“vectorproducts, whichareneededformanycomputergraphicstasks.
Fortunately, themathisstrikinglysimilartothatrequiredforcalculatingconvolutionallayers.
Around that time, NVIDIA and ATI had begun optimizing GPUs for general computing opera- tions(Fernando, 2004), going as faras to marketthem as general-purpose GPUs (GPG- PUs).
To provide some intuition, consider the cores of a modern microprocessor (CPU).
Each ofthecoresisfairlypowerfulrunningatahighclockfrequencyandsportinglargecaches (uptoseveralmegabytesof L3).
Eachcoreiswell-suitedtoexecutingawiderangeofin- structions, withbranchpredictors, adeeppipeline, specializedexecutionunits, speculative 273 Deep Convolutional Neural Networks(Alex Net) execution, and many other bells and whistles that enable it to run a large variety of pro- gramswithsophisticatedcontrolflow.
Thisapparentstrength, however, isalsoits Achilles heel: general-purpose cores are very expensive to build.
They excel at general-purpose codewithlotsofcontrolflow.
Thisrequireslotsofchiparea, notjustfortheactual ALU (arithmetic logical unit) where computation happens, but also for all the aforementioned bells and whistles, plus memory interfaces, caching logic between cores, high-speed in- terconnects, and so on.
CPUs are comparatively bad at any single task when compared withdedicatedhardware.
Modernlaptopshave4â€“8cores, andevenhigh-endserversrarely exceed64corespersocket, simplybecauseitisnotcost-effective.
Bycomparison, GPUscanconsistofthousandsofsmallprocessingelements(NIVIDAâ€™s latest Amperechipshaveupto6912CUDAcores), oftengroupedintolargergroups(NVIDIA callsthemwarps).
Thedetailsdiffersomewhatbetween NVIDIA, AMD, ARMandother chipvendors.
Whileeachcoreisrelativelyweak, runningatabout1GHzclockfrequency, it is the total number of such cores that makes GPUs orders of magnitude faster than CPUs.
For instance, NVIDIAâ€™s recent Ampere A100 GPU offers over 300 TFLOPs per chip for specialized 16-bit precision (BFLOAT16) matrix-matrix multiplications, and up to 20 TFLOPs for more general-purpose floating point operations (FP32).
At the same time, floatingpointperformanceof CPUsrarelyexceeds1TFLOPs.
Forinstance, Ama- zonâ€™s Graviton 3 reaches 2 TFLOPs peak performance for 16-bit precision operations, a numbersimilartothe GPUperformanceof Appleâ€™s M1processor.
Therearemanyreasonswhy GPUsaremuchfasterthan CPUsintermsof FLOPs.
First, powerconsumptiontendstogrowquadraticallywithclockfrequency.
Hence, forthepower budgetofa CPUcorethatrunsfourtimesfaster(atypicalnumber), youcanuse16GPU coresat 1 thespeed, whichyields16 1 =4timestheperformance.
Second, GPUcoresare 4 4 muchsimpler(infact, foralongtimetheywerenotevenabletoexecutegeneral-purpose code), whichmakesthemmoreenergyefficient.
Forinstance,(i)theytendnottosupport speculativeevaluation,(ii)ittypicallyisnotpossibletoprogrameachprocessingelement individually, and(iii)thecachespercoretendtobemuchsmaller.
Last, manyoperations indeeplearningrequirehighmemorybandwidth.
Again, GPUsshineherewithbusesthat areatleast10timesaswideasmany CPUs.
Backto2012.
Amajorbreakthroughcamewhen Alex Krizhevskyand Ilya Sutskeverim- plementedadeep CNNthatcouldrunon GPUs.
Theyrealizedthatthecomputationalbot- tlenecksin CNNs, convolutionsandmatrixmultiplications, arealloperationsthatcouldbe parallelizedinhardware.
Usingtwo NVIDIAGTX580swith3GBofmemory, eitherof whichwascapableof1.5TFLOPs(stillachallengeformost CPUsadecadelater), theyim- 127 plementedfastconvolutions.
Thecuda-convnet127 codewasgoodenoughthatforseveral yearsitwastheindustrystandardandpoweredthefirstcoupleofyearsofthedeeplearning boom.
8.1.2 Alex Net Alex Net, whichemployedan8-layer CNN, wonthe Image Net Large Scale Visual Recog- nition Challenge2012byalargemargin(Russakovskyetal.,2013).
Thisnetworkshowed, 274 Modern Convolutional Neural Networks for the first time, that the featuresobtained bylearning can transcend manually-designed features, breakingthepreviousparadigmincomputervision.
Thearchitecturesof Alex Netand Le Netarestrikinglysimilar, as.1.2illustrates.
Note that we provide a slightly streamlined version of Alex Net removing some of the design quirksthatwereneededin2012tomakethemodelfitontwosmall GPUs.
t .1.2 From Le Net(left)to Alex Net(right).
Therearealsosignificantdifferencesbetween Alex Netand Le Net.
First, Alex Netismuch deeperthanthecomparativelysmall Le Net-5.
Alex Netconsistsofeightlayers: fivecon- volutionallayers, twofullyconnectedhiddenlayers, andonefullyconnectedoutputlayer.
Second, Alex Net used the Re LU instead of the sigmoid as its activation function.
Letâ€™s delveintothedetailsbelow.
Architecture In Alex Netâ€™s first layer, the convolution window shape is 11 11.
Since the images in Image Net are eight times taller and wider than the MNIST images, objects in Image Net datatendtooccupymorepixelswithmorevisualdetail.
Consequently, alargerconvolution window is needed to capture the object.
The convolution window shape in the second layerisreducedto 5 5, followedby3 3.
Inaddition, afterthefirst, second, andfifth convolutional layers, the network adds max-pooling layers with a window shape of 3 3 and a stride of 2.
Moreover, Alex Net has ten times more convolution channels than Le Net.
Afterthefinalconvolutionallayer, therearetwohugefullyconnectedlayerswith4096out- puts.
Theselayersrequirenearly1GBmodelparameters.
Becauseofthelimitedmemory 275 Deep Convolutional Neural Networks(Alex Net) inearly GPUs, theoriginal Alex Netusedadualdatastreamdesign, sothateachoftheir two GPUscouldberesponsibleforstoringandcomputingonlyitshalfofthemodel.
Fortu- nately, GPUmemoryiscomparativelyabundantnow, sowerarelyneedtobreakupmodels across GPUsthesedays(ourversionofthe Alex Netmodeldeviatesfromtheoriginalpaper inthisaspect).
Activation Functions Furthermore, Alex Netchangedthesigmoidactivationfunctiontoasimpler Re LUactiva- tionfunction.
Ontheonehand, thecomputationofthe Re LUactivationfunctionissimpler.
Forexample, itdoesnothavetheexponentiationoperationfoundinthesigmoidactivation function.
On the other hand, the Re LU activation function makes model training easier when using different parameter initialization methods.
This is because, when the output ofthesigmoidactivationfunctionisverycloseto0or1, thegradientoftheseregionsis almost0, sothatbackpropagationcannotcontinuetoupdatesomeofthemodelparameters.
Bycontrast, thegradientofthe Re LUactivationfunctioninthepositiveintervalisalways1 (Section5.1.2).
Therefore, ifthemodelparametersarenotproperlyinitialized, thesigmoid functionmayobtainagradientofalmost0inthepositiveinterval, meaningthatthemodel cannotbeeffectivelytrained.
Capacity Controland Preprocessing Alex Net controls the model complexity of the fully connected layer by dropout (Section 5.6), while Le Netonlyusesweightdecay.
Toaugmentthedataevenfurther, thetraining loopof Alex Netaddedagreatdealofimageaugmentation, suchasflipping, clipping, and color changes.
This makes the model more robust and the larger sample size effectively reducesoverfitting.
See Buslaevetal.
(2020)foranin-depthreviewofsuchpreprocessing steps.
class Alex Net(d2l.
Classifier): def __init__(self, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nn.
Lazy Conv2d(96, kernel_size=11, stride=4, padding=1), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2), nn.
Lazy Conv2d(256, kernel_size=5, padding=2), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2), nn.
Lazy Conv2d(384, kernel_size=3, padding=1), nn.
Re LU(), nn.
Lazy Conv2d(384, kernel_size=3, padding=1), nn.
Re LU(), nn.
Lazy Conv2d(256, kernel_size=3, padding=1), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2), nn.
Flatten(), nn.
Lazy Linear(4096), nn.
Re LU(), nn.
Dropout(p=0.5), nn.
Lazy Linear(4096), nn.
Re LU(), nn.
Dropout(p=0.5), nn.
Lazy Linear(num_classes)) self.
net.
apply(d2l.
init_cnn) Weconstructasingle-channeldataexamplewithbothheightandwidthof224toobserve 276 Modern Convolutional Neural Networks Alex Net().
layer_summary((1, 1, 224, 224)) Conv2d output shape: torch.
Size([1, 96, 54, 54]) Re LU output shape: torch.
Size([1, 96, 54, 54]) Max Pool2d output shape: torch.
Size([1, 96, 26, 26]) Conv2d output shape: torch.
Size([1, 256, 26, 26]) Re LU output shape: torch.
Size([1, 256, 26, 26]) Max Pool2d output shape: torch.
Size([1, 256, 12, 12]) Conv2d output shape: torch.
Size([1, 384, 12, 12]) Re LU output shape: torch.
Size([1, 384, 12, 12]) Conv2d output shape: torch.
Size([1, 384, 12, 12]) Re LU output shape: torch.
Size([1, 384, 12, 12]) Conv2d output shape: torch.
Size([1, 256, 12, 12]) Re LU output shape: torch.
Size([1, 256, 12, 12]) Max Pool2d output shape: torch.
Size([1, 256, 5, 5]) Flatten output shape: torch.
Size([1, 6400]) Linear output shape: torch.
Size([1, 4096]) Re LU output shape: torch.
Size([1, 4096]) Dropout output shape: torch.
Size([1, 4096]) Linear output shape: torch.
Size([1, 4096]) Re LU output shape: torch.
Size([1, 4096]) Dropout output shape: torch.
Size([1, 4096]) Linear output shape: torch.
Size([1, 10]) 8.1.3 Training Although Alex Netwastrainedon Image Netin Krizhevskyetal.
(2012), weuse Fashion- MNIST here since training an Image Net model to convergence could take hours or days evenonamodern GPU.
Oneoftheproblemswithapplying Alex Netdirectlyon Fashion- MNISTisthatitsimageshavelowerresolution(28 28pixels)than Image Netimages.
To makethingswork, weupsamplethemto224 224.
Thisisgenerallynotasmartpractice, as itsimplyincreasesthecomputationalcomplexitywithoutaddinginformation.
Nonetheless, wedoitheretobefaithfultothe Alex Netarchitecture.
Weperformthisresizingwiththe resizeargumentinthed2l.
Fashion MNISTconstructor.
Now, wecanstarttraining Alex Net.
Comparedto Le Netin Section7.6, themainchange hereistheuseofasmallerlearningrateandmuchslowertrainingduetothedeeperand widernetwork, thehigherimageresolution, andthemorecostlyconvolutions.
model = Alex Net(lr=0.01) data = d2l.
Fashion MNIST(batch_size=128, resize=(224, 224)) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) trainer.
fit(model, data) 8.1.4 Discussion Alex Netâ€™s structure bears a striking resemblance to Le Net, with a number of critical im- provements, bothforaccuracy(dropout)andforeaseoftraining(Re LU).
Whatisequally striking is the amount of progress that has been made in terms of deep learning tooling.
277 Deep Convolutional Neural Networks(Alex Net) What was several months of work in 2012 can now be accomplished in a dozen lines of codeusinganymodernframework.
Reviewingthearchitecture, weseethat Alex Nethasan Achillesheelwhenitcomestoeffi- ciency: thelasttwohiddenlayersrequirematricesofsize6400 4096and4096 4096, re- spectively.
Thiscorrespondsto164MBofmemoryand81MFLOPsofcomputation, both ofwhichareanontrivialoutlay, especiallyonsmallerdevices, suchasmobilephones.
This isoneofthereasonswhy Alex Nethasbeensurpassedbymuchmoreeffectivearchitectures thatwewillcoverinthefollowingsections.
Nonetheless, itisakeystepfromshallowto deep networks that are used nowadays.
Note that even though the number of parameters exceedsbyfartheamountoftrainingdatainourexperiments(thelasttwolayershavemore than40millionparameters, trainedonadatasetsof60thousandimages), thereishardly anyoverfitting: trainingandvalidationlossarevirtuallyidenticalthroughouttraining.
This isduetotheimprovedregularization, suchasdropout, inherentinmoderndeepnetwork designs.
Althoughitseemsthatthereareonlyafewmorelinesin Alex Netâ€™simplementationthan in Le Netâ€™s, ittooktheacademiccommunitymanyyearstoembracethisconceptualchange andtakeadvantageofitsexcellentexperimentalresults.
Thiswasalsoduetothelackof efficientcomputationaltools.
Atthetimeneither Dist Belief(Deanetal.,2012)nor Caffe (Jiaetal.,2014)existed, and Theano(Bergstraetal.,2010)stilllackedmanydistinguishing features.
Itwastheavailabilityof Tensor Flow(Abadietal.,2016)thatdramaticallychanged thesituation.
8.1.5 Exercises 1.
Followinguponthediscussionabove, analyzethecomputationalpropertiesof Alex Net.
1.
Computethememoryfootprintforconvolutionsandfullyconnectedlayers, respec- tively.
Whichonedominates? 2.
Calculatethecomputationalcostfortheconvolutionsandthefullyconnectedlayers.
3.
Howdoesthememory(readandwritebandwidth, latency, size)affectcomputation? Isthereanydifferenceinitseffectsfortrainingandinference? 2.
You are a chip designer and need to trade off computation and memory bandwidth.
Forexample, afasterchiprequiresmorepowerandpossiblyalargerchiparea.
More 278 Modern Convolutional Neural Networks memorybandwidthrequiresmorepinsandcontrollogic, thusalsomorearea.
Howdo youoptimize? 3.
Whydoengineersnolongerreportperformancebenchmarkson Alex Net? 4.
Try increasing the number of epochs when training Alex Net.
Compared with Le Net, howdotheresultsdiffer? Why? 5.
Alex Net may be too complex for the Fashion-MNIST dataset, in particular due to the lowresolutionoftheinitialimages.
1.
Trysimplifyingthemodeltomakethetrainingfaster, whileensuringthattheaccu- racydoesnotdropsignificantly.
2.
Designabettermodelthatworksdirectlyon28 28images.
6.
Modifythebatchsize, andobservethechangesinthroughput(images/s), accuracy, and GPUmemory.
7.
Applydropoutand Re LUto Le Net-5.
Doesitimprove? Canyouimprovethingsfurther bypreprocessingtotakeadvantageoftheinvariancesinherentintheimages? 8.
Canyoumake Alex Netoverfit? Whichfeaturedoyouneedtoremoveorchangetobreak training? 128 Discussions128.
8.2 Networks Using Blocks (VGG) While Alex Netofferedempiricalevidencethatdeep CNNscanachievegoodresults, itdid notprovideageneraltemplatetoguidesubsequentresearchersindesigningnewnetworks.
Inthefollowingsections, wewillintroduceseveralheuristicconceptscommonlyusedto designdeepnetworks.
Progressinthisfieldmirrorsthatof VLSI(verylargescaleintegration)inchipdesignwhere engineersmovedfromplacingtransistorstologicalelementstologicblocks(Mead,1980).
Similarly, thedesignofneuralnetworkarchitectureshasgrownprogressivelymoreabstract, with researchers moving from thinking in terms of individual neurons to whole layers, and now to blocks, repeating patterns of layers.
A decade later, this has now progressed to researchers using entire trained models to repurpose them for different, albeit related, tasks.
Suchlargepretrainedmodelsaretypicallycalledfoundationmodels(Bommasaniet al.,2021).
Backtonetworkdesign.
Theideaofusingblocksfirstemergedfromthe Visual Geometry Group(VGG)at Oxford University, intheireponymously-named VGGnetwork(Simonyan and Zisserman,2014).
Itiseasytoimplementtheserepeatedstructuresincodewithany moderndeeplearningframeworkbyusingloopsandsubroutines.
279 Networks Using Blocks(VGG) import torch from torch import nn from d2l import torch as d2l 8.2.1 VGGBlocks Thebasicbuildingblockof CNNsisasequenceofthefollowing: (i)aconvolutionallayer withpaddingtomaintaintheresolution,(ii)anonlinearitysuchasa Re LU,(iii)apooling layersuchasmax-poolingtoreducetheresolution.
Oneoftheproblemswiththisapproach isthatthespatialresolutiondecreasesquiterapidly.
Inparticular, thisimposesahardlimit of log ğ‘‘ convolutionallayers on the networkbefore all dimensions (ğ‘‘) are used up.
For 2 instance, inthecaseof Image Net, itwouldbeimpossibletohavemorethan8convolutional layersinthisway.
Thekeyideaof Simonyanand Zisserman(2014)wastousemultipleconvolutionsinbe- tween downsampling via max-pooling in the form of a block.
They were primarily in- terested in whether deep or wide networks perform better.
For instance, the successive applicationoftwo3 3convolutionstouchesthesamepixelsasasingle5 5convolution does.
Atthesametime, thelatterusesapproximatelyasmanyparameters(25 ğ‘2)asthree 3 3convolutionsdo(3 9 ğ‘2).
Inaratherdetailedanalysistheyshowedthatdeepandnar- rownetworkssignificantlyoutperformtheirshallowcounterparts.
Thissetdeeplearning onaquestforeverdeepernetworkswithover100layersfortypicalapplications.
Stacking 3 3convolutionshasbecomeagoldstandardinlaterdeepnetworks(adesigndecision onlytoberevisitedrecentlyby Liuetal.
(2022)).
Consequently, fastimplementationsfor smallconvolutionshavebecomeastapleon GPUs(Lavinand Gray,2016).
Backto VGG: a VGGblockconsistsofasequenceofconvolutionswith3 3kernelswith paddingof1(keepingheightandwidth)followedbya2 2max-poolinglayerwithstride of2(halvingheightandwidthaftereachblock).
Inthecodebelow, wedefineafunction calledvgg_blocktoimplementone VGGblock.
The function below takes two arguments, corresponding to the number of convolutional layersnum_convsandthenumberofoutputchannelsnum_channels.
def vgg_block(num_convs, out_channels): layers = [] for _ in range(num_convs): layers.
append(nn.
Lazy Conv2d(out_channels, kernel_size=3, padding=1)) layers.
append(nn.
Re LU()) layers.
append(nn.
Max Pool2d(kernel_size=2, stride=2)) return nn.
Sequential(*layers) 8.2.2 VGGNetwork Like Alex Net and Le Net, the VGG Network can be partitioned into two parts: the first consisting mostly of convolutional and pooling layers and the second consisting of fully 280 Modern Convolutional Neural Networks connectedlayersthatareidenticaltothosein Alex Net.
Thekeydifferenceisthatthecon- volutionallayersaregroupedinnonlineartransformationsthatleavethedimensonalityun- changed, followedbyaresolution-reductionstep, asdepictedin.2.1.
t .2.1 From Alex Netto VGG.
Thekeydifferenceisthat VGGconsistsofblocksoflayers, whereas Alex Netâ€™slayersarealldesignedindividually.
Theconvolutionalpartofthenetworkconnectsseveral VGGblocksfrom.2.1(also definedinthevgg_blockfunction)insuccession.
Thisgroupingofconvolutionsisapat- ternthathasremainedalmostunchangedoverthepastdecade, althoughthespecificchoice ofoperationshasundergoneconsiderablemodifications.
Thevariablearchconsistsofa listoftuples(oneperblock), whereeachcontainstwovalues: thenumberofconvolutional layers and the number of output channels, which are precisely the arguments required to callthevgg_blockfunction.
Assuch, VGGdefinesafamilyofnetworksratherthanjusta specificmanifestation.
Tobuildaspecificnetworkwesimplyiterateoverarchtocompose theblocks.
class VGG(d2l.
Classifier): def __init__(self, arch, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() conv_blks = [] for (num_convs, out_channels) in arch: conv_blks.
append(vgg_block(num_convs, out_channels)) self.
net = nn.
Sequential( *conv_blks, nn.
Flatten(), (continuesonnextpage) 281 Networks Using Blocks(VGG) (continuedfrompreviouspage) nn.
Lazy Linear(4096), nn.
Re LU(), nn.
Dropout(0.5), nn.
Lazy Linear(4096), nn.
Re LU(), nn.
Dropout(0.5), nn.
Lazy Linear(num_classes)) self.
net.
apply(d2l.
init_cnn) Theoriginal VGGnetworkhadfiveconvolutionalblocks, amongwhichthefirsttwohave oneconvolutionallayereachandthelatterthreecontaintwoconvolutionallayerseach.
The firstblockhas64outputchannelsandeachsubsequentblockdoublesthenumberofoutput channels, untilthatnumberreaches512.
Sincethisnetworkuseseightconvolutionallayers andthreefullyconnectedlayers, itisoftencalled VGG-11.
VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).
layer_summary( (1, 1, 224, 224)) Sequential output shape: torch.
Size([1, 64, 112, 112]) Sequential output shape: torch.
Size([1, 128, 56, 56]) Sequential output shape: torch.
Size([1, 256, 28, 28]) Sequential output shape: torch.
Size([1, 512, 14, 14]) Sequential output shape: torch.
Size([1, 512, 7, 7]) Flatten output shape: torch.
Size([1, 25088]) Linear output shape: torch.
Size([1, 4096]) Re LU output shape: torch.
Size([1, 4096]) Dropout output shape: torch.
Size([1, 4096]) Linear output shape: torch.
Size([1, 4096]) Re LU output shape: torch.
Size([1, 4096]) Dropout output shape: torch.
Size([1, 4096]) Linear output shape: torch.
Size([1, 10]) Asyoucansee, wehalveheightandwidthateachblock, finallyreachingaheightandwidth of7beforeflatteningtherepresentationsforprocessingbythefullyconnectedpartofthe network.
Simonyan and Zisserman (2014) described several other variants of VGG.
In fact, ithasbecomethenormtoproposefamiliesofnetworkswithdifferentspeedâ€“accuracy trade-offwhenintroducinganewarchitecture.
8.2.3 Training Since VGG-11iscomputationallymoredemandingthan Alex Netweconstructanetwork with a smaller number of channels.
This is more than sufficient for training on Fashion- MNIST.
Themodeltrainingprocessissimilartothatof Alex Netin Section8.1.
Againob- servetheclosematchbetweenvalidationandtrainingloss, suggestingonlyasmallamount ofoverfitting.
model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(224, 224)) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) 282 Modern Convolutional Neural Networks 8.2.4 Summary Onemightarguethat VGGisthefirsttrulymodernconvolutionalneuralnetwork.
While Alex Netintroducedmanyofthecomponentsofwhatmakedeeplearningeffectiveatscale, itis VGGthatarguablyintroducedkeypropertiessuchasblocksofmultipleconvolutions andapreferencefordeepandnarrownetworks.
Itisalsothefirstnetworkthatisactually anentirefamilyofsimilarlyparametrizedmodels, givingthepractitionerampletrade-off betweencomplexityandspeed.
Thisisalsotheplacewheremoderndeeplearningframe- works shine.
It is no longer necessary to generate XML configuration files to specify a networkbutrather, toassemblesaidnetworksthroughsimple Pythoncode.
Morerecently Par Net(Goyaletal.,2021)demonstratedthatitispossibletoachievecom- petitive performance using a much more shallow architecture through a large number of parallelcomputations.
Thisisanexcitingdevelopmentandthereishopethatitwillinflu- encearchitecturedesignsinthefuture.
Fortheremainderofthechapter, though, wewill followthepathofscientificprogressoverthepastdecade.
8.2.5 Exercises 1.
Comparedwith Alex Net, VGGismuchslowerintermsofcomputation, anditalsoneeds more GPUmemory.
1.
Comparethenumberofparametersneededfor Alex Netand VGG.
2.
Compare the number of floating point operations used in the convolutional layers andinthefullyconnectedlayers.
3.
Howcouldyoureducethecomputationalcostcreatedbythefullyconnectedlayers? 2.
Whendisplayingthedimensionsassociatedwiththevariouslayersofthenetwork, we onlyseetheinformationassociatedwitheightblocks(plussomeauxiliarytransforms), eventhoughthenetworkhas11layers.
Wheredidtheremainingthreelayersgo? 3.
Use Table1inthe VGGpaper(Simonyanand Zisserman,2014)toconstructothercom- monmodels, suchas VGG-16or VGG-19.
4.
Upsampling the resolution in Fashion-MNIST eight-fold from 28 28 to 224 224 dimensions is very wasteful.
Try modifying the network architecture and resolution conversion, e.
g., to56orto84dimensionsforitsinputinstead.
Canyoudosowithout 283 Networkin Network(Ni N) reducingtheaccuracyofthenetwork? Consultthe VGGpaper(Simonyanand Zisser- man,2014)forideasonaddingmorenonlinearitiespriortodownsampling.
Discussions129.
129 8.3 Network in Network (Ni N) Le Net, Alex Net, and VGGallshareacommondesignpattern: extractfeaturesexploiting spatial structure via a sequence of convolutions and pooling layers and post-process the representationsviafullyconnectedlayers.
Theimprovementsupon Le Netby Alex Netand VGGmainlylieinhowtheselaternetworkswidenanddeepenthesetwomodules.
This design poses two major challenges.
First, the fully connected layers at the end of thearchitectureconsumetremendousnumbersofparameters.
Forinstance, evenasimple model such as VGG-11 requires a monstrous matrix, occupying almost 400MB of RAM insingleprecision(FP32).
Thisisasignificantimpedimenttocomputation, inparticular onmobileandembeddeddevices.
Afterall, evenhigh-endmobilephonessportnomore than 8GB of RAM.
At the time VGG was invented, this was an order of magnitude less (thei Phone4Shad512MB).
Assuch, itwouldhavebeendifficulttojustifyspendingthe majorityofmemoryonanimageclassifier.
Second, it is equally impossible to add fully connected layers earlier in the network to increasethedegreeofnonlinearity: doingsowoulddestroythespatialstructureandrequire potentiallyevenmorememory.
The network in network (Ni N) blocks (Lin et al., 2013) offer an alternative, capable of solvingbothproblemsinonesimplestrategy.
Theywereproposedbasedonaverysimple insight: (i)use1 1convolutionstoaddlocalnonlinearitiesacrossthechannelactivations and(ii)useglobalaveragepoolingtointegrateacrossalllocationsinthelastrepresentation layer.
Note that global average pooling would not be effective, were it not for the added nonlinearities.
Letâ€™sdiveintothisindetail.
import torch from torch import nn from d2l import torch as d2l 8.3.1 Ni NBlocks Recall Section7.4.3.
Initwesaidthattheinputsandoutputsofconvolutionallayersconsist offour-dimensionaltensorswithaxescorrespondingtotheexample, channel, height, and width.
Alsorecallthattheinputsandoutputsoffullyconnectedlayersaretypicallytwo- dimensional tensors corresponding to the example and feature.
The idea behind Ni N is to apply a fully connected layer at each pixel location (for each height and width).
The 284 Modern Convolutional Neural Networks resulting1 1convolutioncanbethoughtofasafullyconnectedlayeractingindependently oneachpixellocation.
.3.1illustratesthemainstructuraldifferencesbetween VGGand Ni N, andtheirblocks.
Noteboththedifferenceinthe Ni Nblocks(theinitialconvolutionisfollowedby1 1con- volutions, whereas VGG retains 3 3 convolutions) and at the end where we no longer requireagiantfullyconnectedlayer.
t .3.1 Comparingthearchitecturesof VGGand Ni N, andoftheirblocks.
def nin_block(out_channels, kernel_size, strides, padding): return nn.
Sequential( nn.
Lazy Conv2d(out_channels, kernel_size, strides, padding), nn.
Re LU(), nn.
Lazy Conv2d(out_channels, kernel_size=1), nn.
Re LU(), nn.
Lazy Conv2d(out_channels, kernel_size=1), nn.
Re LU()) 8.3.2 Ni NModel Ni Nusesthesameinitialconvolutionsizesas Alex Net(itwasproposedshortlythereafter).
The kernel sizes are 11 11, 5 5, and 3 3, respectively, and the numbers of output 285 Networkin Network(Ni N) channelsmatchthoseof Alex Net.
Each Ni Nblockisfollowedbyamax-poolinglayerwith astrideof2andawindowshapeof3 3.
The second significant difference between Ni N and both Alex Net and VGG is that Ni N avoidsfullyconnectedlayersaltogether.
Instead, Ni Nusesa Ni Nblockwithanumberof outputchannelsequaltothenumberoflabelclasses, followedbyaglobalaveragepooling layer, yieldingavectoroflogits.
Thisdesignsignificantlyreducesthenumberofrequired modelparameters, albeitattheexpenseofapotentialincreaseintrainingtime.
class Ni N(d2l.
Classifier): def __init__(self, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nin_block(96, kernel_size=11, strides=4, padding=0), nn.
Max Pool2d(3, stride=2), nin_block(256, kernel_size=5, strides=1, padding=2), nn.
Max Pool2d(3, stride=2), nin_block(384, kernel_size=3, strides=1, padding=1), nn.
Max Pool2d(3, stride=2), nn.
Dropout(0.5), nin_block(num_classes, kernel_size=3, strides=1, padding=1), nn.
Adaptive Avg Pool2d((1, 1)), nn.
Flatten()) self.
net.
apply(d2l.
init_cnn) Wecreateadataexampletoseetheoutputshapeofeachblock.
Ni N().
layer_summary((1, 1, 224, 224)) Sequential output shape: torch.
Size([1, 96, 54, 54]) Max Pool2d output shape: torch.
Size([1, 96, 26, 26]) Sequential output shape: torch.
Size([1, 256, 26, 26]) Max Pool2d output shape: torch.
Size([1, 256, 12, 12]) Sequential output shape: torch.
Size([1, 384, 12, 12]) Max Pool2d output shape: torch.
Size([1, 384, 5, 5]) Dropout output shape: torch.
Size([1, 384, 5, 5]) Sequential output shape: torch.
Size([1, 10, 5, 5]) Adaptive Avg Pool2d output shape: torch.
Size([1, 10, 1, 1]) Flatten output shape: torch.
Size([1, 10]) 8.3.3 Training Asbeforeweuse Fashion-MNISTtotrainthemodelusingthesameoptimizerthatweused for Alex Netand VGG.
model = Ni N(lr=0.05) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(224, 224)) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) 286 Modern Convolutional Neural Networks 8.3.4 Summary Ni Nhasdramaticallyfewerparametersthan Alex Netand VGG.
Thisstemsprimarilyfrom thefactthatitneedsnogiantfullyconnectedlayers.
Instead, itusesglobalaveragepooling toaggregateacrossallimagelocationsafterthelaststageofthenetworkbody.
Thisobvi- atestheneedforexpensive(learned)reductionoperationsandreplacesthembyasimple average.
Whatsurprisedresearchersatthetimewasthefactthatthisaveragingoperation did not harm accuracy.
Note that averaging across a low-resolution representation (with manychannels)alsoaddstotheamountoftranslationinvariancethatthenetworkcanhan- dle.
Choosingfewerconvolutionswithwidekernelsandreplacingthemby1 1convolutions aids the quest for fewer parameters further.
It can cater for a significant amount of non- linearity across channels within any given location.
Both 1 1 convolutions and global averagepoolingsignificantlyinfluencedsubsequent CNNdesigns.
8.3.5 Exercises 1.
Whyaretheretwo1 1convolutionallayersper Ni Nblock? Increasetheirnumberto three.
Reducetheirnumbertoone.
Whatchanges? 2.
Whatchangesifyoureplacethe1 1convolutionsby3 3convolutions? 3.
What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, numberofparameters)? 4.
Calculatetheresourceusagefor Ni N.
1.
Whatisthenumberofparameters? 2.
Whatistheamountofcomputation? 3.
Whatistheamountofmemoryneededduringtraining? 4.
Whatistheamountofmemoryneededduringprediction? 5.
Whatarepossibleproblemswithreducingthe384 5 5representationtoa10 5 5 representationinonestep? 6.
Usethestructuraldesigndecisionsin VGGthatledto VGG-11, VGG-16, and VGG-19 todesignafamilyof Ni N-likenetworks.
287 Multi-Branch Networks(Goog Le Net) Discussions130.
130 8.4 Multi-Branch Networks (Goog Le Net) In2014, Goog Le Netwonthe Image Net Challenge(Szegedyetal.,2015), usingastructure thatcombinedthestrengthsof Ni N(Linetal.,2013), repeatedblocks(Simonyanand Zis- serman,2014), andacocktailofconvolutionkernels.
Itwasarguablyalsothefirstnetwork thatexhibitedacleardistinctionamongthestem(dataingest), body(dataprocessing), and head(prediction)ina CNN.
Thisdesignpatternhaspersistedeversinceinthedesignof deepnetworks: thestemisgivenbythefirsttwoorthreeconvolutionsthatoperateonthe image.
Theyextractlow-levelfeaturesfromtheunderlyingimages.
Thisisfollowedbya body of convolutional blocks.
Finally, the head maps the features obtained so far to the requiredclassification, segmentation, detection, ortrackingproblemathand.
Thekeycontributionin Goog Le Netwasthedesignofthenetworkbody.
Itsolvedtheprob- lemofselectingconvolutionkernelsinaningeniousway.
Whileotherworkstriedtoiden- tifywhichconvolution, rangingfrom1 1to11 11wouldbebest, itsimplyconcatenated multi-branch convolutions.
In what follows we introduce a slightly simplified version of Goog Le Net: theoriginaldesignincludedanumberoftricksforstabilizingtrainingthrough intermediatelossfunctions, appliedtomultiplelayersofthenetwork.
Theyarenolonger necessaryduetotheavailabilityofimprovedtrainingalgorithms.
import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 8.4.1 Inception Blocks Thebasicconvolutionalblockin Goog Le Netiscalledan Inceptionblock, stemmingfrom thememeâ€œweneedtogodeeperâ€fromthemovie Inception.
t .4.1 Structureofthe Inceptionblock.
Asdepictedin.4.1, theinceptionblockconsistsoffourparallelbranches.
Thefirst three branches use convolutional layers with window sizes of 1 1, 3 3, and 5 5 to extractinformationfromdifferentspatialsizes.
Themiddletwobranchesalsoadda1 1 288 Modern Convolutional Neural Networks convolutionoftheinputtoreducethenumberofchannels, reducingthemodelâ€™scomplex- ity.
Thefourthbranchusesa3 3max-poolinglayer, followedbya1 1convolutional layer to change the number of channels.
The four branches all use appropriate padding to give the input and output the same height and width.
Finally, the outputs along each branchareconcatenatedalongthechanneldimensionandcomprisetheblockâ€™soutput.
The commonly-tunedhyperparametersofthe Inceptionblockarethenumberofoutputchannels perlayer, i.
e., howtoallocatecapacityamongconvolutionsofdifferentsize.
class Inception(nn.
Module): # c1--c4 are the number of output channels for each branch def __init__(self, c1, c2, c3, c4, **kwargs): super(Inception, self).__init__(**kwargs) # Branch 1 self.
b1_1 = nn.
Lazy Conv2d(c1, kernel_size=1) # Branch 2 self.
b2_1 = nn.
Lazy Conv2d(c2[0], kernel_size=1) self.
b2_2 = nn.
Lazy Conv2d(c2[1], kernel_size=3, padding=1) # Branch 3 self.
b3_1 = nn.
Lazy Conv2d(c3[0], kernel_size=1) self.
b3_2 = nn.
Lazy Conv2d(c3[1], kernel_size=5, padding=2) # Branch 4 self.
b4_1 = nn.
Max Pool2d(kernel_size=3, stride=1, padding=1) self.
b4_2 = nn.
Lazy Conv2d(c4, kernel_size=1) def forward(self, x): b1 = F.
relu(self.
b1_1(x)) b2 = F.
relu(self.
b2_2(F.
relu(self.
b2_1(x)))) b3 = F.
relu(self.
b3_2(F.
relu(self.
b3_1(x)))) b4 = F.
relu(self.
b4_2(self.
b4_1(x))) return torch.
cat((b1, b2, b3, b4), dim=1) To gain some intuition for why this network works so well, consider the combination of the filters.
They explore the image in a variety of filter sizes.
This means that details at differentextentscanberecognizedefficientlybyfiltersofdifferentsizes.
Atthesametime, wecanallocatedifferentamountsofparametersfordifferentfilters.
8.4.2 Goog Le Net Model Asshownin.4.2, Goog Le Netusesastackofatotalof9inceptionblocks, arranged intothreegroupswithmax-poolinginbetween, andglobalaveragepoolinginitsheadto generateitsestimates.
Max-poolingbetweeninceptionblocksreducesthedimensionality.
Atitsstem, thefirstmoduleissimilarto Alex Netand Le Net.
t .4.2 The Goog Le Netarchitecture.
289 Multi-Branch Networks(Goog Le Net) We can now implement Goog Le Net piece by piece.
Letâ€™s begin with the stem.
The first moduleusesa64-channel7 7convolutionallayer.
class Google Net(d2l.
Classifier): def b1(self): return nn.
Sequential( nn.
Lazy Conv2d(64, kernel_size=7, stride=2, padding=3), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) Thesecondmoduleusestwoconvolutionallayers: first, a64-channel1 1convolutional layer, followed by a 3 3 convolutional layer that triples the number of channels.
This corresponds to the second branch in the Inception block and concludes the design of the body.
Atthispointwehave192channels.
@d2l.
add_to_class(Google Net) def b2(self): return nn.
Sequential( nn.
Lazy Conv2d(64, kernel_size=1), nn.
Re LU(), nn.
Lazy Conv2d(192, kernel_size=3, padding=1), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) Thethirdmoduleconnectstwocomplete Inceptionblocksinseries.
Thenumberofoutput channelsofthefirst Inceptionblockis64â€š128â€š32â€š32=256.
Thisamountstoaratioof thenumberofoutputchannelsamongthefourbranchesof2:4:1:1.
Toachievethis, we firstreducetheinputdimensionsby 1 andby 1 inthesecondandthirdbranchrespectively 2 12 toarriveat96=192 2and16=192 12channelsrespectively.
Thenumberofoutputchannelsofthesecond Inceptionblockisincreasedto128â€š192â€š 96â€š64=480, yieldingaratioof128:192:96:64=4:6:3:2.
Asbefore, weneedto reducethenumberofintermediatedimensionsinthesecondandthirdchannel.
Ascaleof 1 and 1 respectivelysuffices, yielding128and32channelsrespectively.
Thisiscaptured 2 8 bytheargumentsofthefollowing Inceptionblockconstructors.
@d2l.
add_to_class(Google Net) def b3(self): return nn.
Sequential(Inception(64, (96, 128), (16, 32), 32), Inception(128, (128, 192), (32, 96), 64), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) The fourth module is more complicated.
It connects five Inception blocks in series, and theyhave192â€š208â€š48â€š64=512,160â€š224â€š64â€š64=512,128â€š256â€š64â€š64=512, 112â€š288â€š64â€š64=528, and256â€š320â€š128â€š128=832outputchannels, respectively.
Thenumberofchannelsassignedtothesebranchesissimilartothatinthethirdmodule: thesecondbranchwiththe3 3convolutionallayeroutputsthelargestnumberofchannels, followedbythefirstbranchwithonlythe1 1convolutionallayer, thethirdbranchwith the5 5convolutionallayer, andthefourthbranchwiththe3 3max-poolinglayer.
The secondandthirdbrancheswillfirstreducethenumberofchannelsaccordingtotheratio.
Theseratiosareslightlydifferentindifferent Inceptionblocks.
290 Modern Convolutional Neural Networks @d2l.
add_to_class(Google Net) def b4(self): return nn.
Sequential(Inception(192, (96, 208), (16, 48), 64), Inception(160, (112, 224), (24, 64), 64), Inception(128, (128, 256), (24, 64), 64), Inception(112, (144, 288), (32, 64), 64), Inception(256, (160, 320), (32, 128), 128), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) Thefifthmodulehastwo Inceptionblockswith256â€š320â€š128â€š128=832and384â€š384â€š 128â€š128=1024outputchannels.
Thenumberofchannelsassignedtoeachbranchisthe same as that in the third and fourth modules, but differs in specific values.
It should be notedthatthefifthblockisfollowedbytheoutputlayer.
Thisblockusestheglobalaverage poolinglayertochangetheheightandwidthofeachchannelto1, justasin Ni N.
Finally, weturntheoutputintoatwo-dimensionalarrayfollowedbyafullyconnectedlayerwhose numberofoutputsisthenumberoflabelclasses.
@d2l.
add_to_class(Google Net) def b5(self): return nn.
Sequential(Inception(256, (160, 320), (32, 128), 128), Inception(384, (192, 384), (48, 128), 128), nn.
Adaptive Avg Pool2d((1,1)), nn.
Flatten()) Nowthatwedefinedallblocksb1throughb5, itisjustamatterofassemblingthemallinto afullnetwork.
@d2l.
add_to_class(Google Net) def __init__(self, lr=0.1, num_classes=10): super(Google Net, self).__init__() self.
save_hyperparameters() self.
b5(), nn.
Lazy Linear(num_classes)) self.
net.
apply(d2l.
init_cnn) The Goog Le Net model is computationally complex.
Note the large number of relatively arbitraryhyperparametersintermsofthenumberofchannelschosen, thenumberofblocks priortodimensionalityreduction, therelativepartitioningofcapacityacrosschannels, etc.
Muchofitisduetothefactthatatthetimewhen Goog Le Netwasintroduced, automatic toolsfornetworkdefinitionordesignexplorationwerenotyetavailable.
Forinstance, by nowwetakeitforgrantedthatacompetentdeeplearningframeworkiscapableofinferring dimensionalitiesofinputtensorsautomatically.
Atthetime, manysuchconfigurationshad tobespecifiedexplicitlybytheexperimenter, thusoftenslowingdownactiveexperimen- tation.
Moreover, the tools needed for automatic exploration were still in flux and initial experiments largely amounted to costly brute-force exploration, genetic algorithms, and similarstrategies.
For now the only modification we will carry out is to reduce the input height and width from224to96tohaveareasonabletrainingtimeon Fashion-MNIST.
Thissimplifiesthe 291 Multi-Branch Networks(Goog Le Net) computation.
Letâ€™shavealookatthechangesintheshapeoftheoutputbetweenthevarious modules.
model = Google Net().
layer_summary((1, 1, 96, 96)) Sequential output shape: torch.
Size([1, 64, 24, 24]) Sequential output shape: torch.
Size([1, 192, 12, 12]) Sequential output shape: torch.
Size([1, 480, 6, 6]) Sequential output shape: torch.
Size([1, 832, 3, 3]) Sequential output shape: torch.
Size([1, 1024]) Linear output shape: torch.
Size([1, 10]) 8.4.3 Training Asbefore, wetrainourmodelusingthe Fashion-MNISTdataset.
Wetransformitto96 96 pixelresolutionbeforeinvokingthetrainingprocedure.
model = Google Net(lr=0.01) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(96, 96)) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) 8.4.4 Discussion Akeyfeatureof Goog Le Netisthatitisactuallycheapertocomputethanitspredecessors whilesimultaneouslyprovidingimprovedaccuracy.
Thismarksthebeginningofamuch moredeliberatenetworkdesignthattradesoffthecostofevaluatinganetworkwithareduc- tioninerrors.
Italsomarksthebeginningofexperimentationatablocklevelwithnetwork designhyperparameters, eventhoughitwasentirelymanualatthetime.
Wewillrevisitthis topicin Section8.8whendiscussingstrategiesfornetworkstructureexploration.
Overthefollowingsectionswewillencounteranumberofdesignchoices(e.
g., batchnor- malization, residualconnections, andchannelgrouping)thatallowustoimprovenetworks significantly.
For now, you can be proud to have implemented what is arguably the first trulymodern CNN.
292 Modern Convolutional Neural Networks 8.4.5 Exercises 1.
Goog Le Netwassosuccessfulthatitwentthroughanumberofiterations, progressively improvingspeedandaccuracy.
Trytoimplementandrunsomeofthem.
Theyinclude thefollowing: 1.
Add a batch normalization layer (Ioffe and Szegedy, 2015), as described later in Section8.5.
2.
Makeadjustmentstothe Inceptionblock(width, choiceandorderofconvolutions), asdescribedin Szegedyetal.
(2016).
3.
Uselabelsmoothingformodelregularization, asdescribedin Szegedyetal.
(2016).
4.
Makefurtheradjustmentstothe Inceptionblockbyaddingresidualconnection(Szegedy etal.,2017), asdescribedlaterin Section8.6.
2.
Whatistheminimumimagesizeneededfor Goog Le Nettowork? 3.
Canyoudesignavariantof Goog Le Netthatworkson Fashion-MNISTâ€™snativeresolu- tionof28 28pixels? Howwouldyouneedtochangethestem, thebody, andthehead ofthenetwork, ifanythingatall? 4.
Comparethemodelparametersizesof Alex Net, VGG, Ni N, and Goog Le Net.
Howdo thelattertwonetworkarchitecturessignificantlyreducethemodelparametersize? 5.
Comparetheamountofcomputationneededin Goog Le Netand Alex Net.
Howdoesthis affectthedesignofanacceleratorchip, e.
g., intermsofmemorysize, memoryband- width, cachesize, theamountofcomputation, andthebenefitofspecializedoperations? 131 Discussions131.
8.5 Batch Normalization Trainingdeepneuralnetworksisdifficult.
Gettingthemtoconvergeinareasonableamount of time can be tricky.
In this section, we describe batch normalization, a popular and effective technique that consistently accelerates the convergence of deep networks (Ioffe and Szegedy, 2015).
Together with residual blocksâ€”covered later in Section 8.6â€”batch normalizationhasmadeitpossibleforpractitionerstoroutinelytrainnetworkswithover 100layers.
Asecondary(serendipitous)benefitofbatchnormalizationliesinitsinherent regularization.
import torch from torch import nn from d2l import torch as d2l 293 Batch Normalization 8.5.1 Training Deep Networks Whenworkingwithdata, weoftenpreprocessbeforetraining.
Choicesregardingdatapre- processingoftenmakeanenormousdifferenceinthefinalresults.
Recallourapplicationof MLPstopredictinghouseprices(Section5.7).
Ourfirststepwhenworkingwithrealdata wastostandardizeourinputfeaturestohavezeromeanğ =0andunitvarianceğšº =1across multipleobservations(Friedman,1987), frequentlyrescalingthelattersothatthediagonal is unity, i.
e., Î£ğ‘–ğ‘– = 1.
Yet another strategy is to rescale vectors to unit length, possibly zero mean per observation.
This can work well, e.
g., for spatial sensor data.
These pre- processingtechniquesandmanyothers, arebeneficialforkeepingtheestimationproblem wellcontrolled.
Forareviewoffeatureselectionandextractionseethearticleof Guyonet al.
(2008), forexample.
Standardizingvectorsalsohastheniceside-effectofconstraining thefunctioncomplexityoffunctionsthatactuponit.
Forinstance, thecelebratedradius- marginbound(Vapnik,1995)insupportvectormachinesandthe Perceptron Convergence Theorem(Novikoff,1962)relyoninputsofboundednorm.
Intuitively, thisstandardizationplaysnicelywithouroptimizerssinceitputstheparameters a priori on a similar scale.
As such, it is only natural to ask whether a corresponding normalizationstepinsideadeepnetworkmightnotbebeneficial.
Whilethisisnotquite the reasoning that led to the invention of batch normalization (Ioffe and Szegedy, 2015), itisausefulwayofunderstandingitanditscousin, layernormalization(Baetal.,2016), withinaunifiedframework.
Second, foratypical MLPor CNN, aswetrain, thevariablesinintermediatelayers(e.
g., affine transformation outputs in MLP) may take values with widely varying magnitudes: whether along the layers from input to output, across units in the same layer, and over time due to our updates to the model parameters.
The inventors of batch normalization postulatedinformallythatthisdriftinthedistributionofsuchvariablescouldhamperthe convergenceofthenetwork.
Intuitively, wemightconjecturethatifonelayerhasvariable activations that are 100 times that of another layer, this might necessitate compensatory adjustmentsinthelearningrates.
Adaptivesolverssuchas Ada Grad(Duchietal.,2011), Adam(Kingmaand Ba,2014), Yogi(Zaheeretal.,2018), or Distributed Shampoo(Anil etal.,2020)aimtoaddressthisfromtheviewpointofoptimization, e.
g., byaddingaspects ofsecond-ordermethods.
Thealternativeistopreventtheproblemfromoccurring, simply byadaptivenormalization.
Third, deepernetworksarecomplexandtendtobemoreliabletooverfitting.
Thismeans thatregularizationbecomesmorecritical.
Acommontechniqueforregularizationisnoise injection.
This has been known for a long time, e.
g., with regard to noise injection for the inputs (Bishop, 1995).
It also forms the basis of dropout in Section 5.6.
As it turns out, quite serendipitously, batch normalization conveys all three benefits: preprocessing, numericalstability, andregularization.
Batch normalization is applied to individual layers, or optionally, to all of them: In each trainingiteration, wefirstnormalizetheinputs(ofbatchnormalization)bysubtractingtheir meananddividingbytheirstandarddeviation, wherebothareestimatedbasedonthestatis- ticsofthecurrentminibatch.
Next, weapplyascalecoefficientandanoffsettorecoverthe 294 Modern Convolutional Neural Networks lostdegreesoffreedom.
Itispreciselyduetothisnormalizationbasedonbatchstatistics thatbatchnormalizationderivesitsname.
Notethatifwetriedtoapplybatchnormalizationwithminibatchesofsize1, wewouldnot be able to learn anything.
That is because after subtracting the means, each hidden unit wouldtakevalue0.
Asyoumightguess, since wearedevotingawhole sectiontobatch normalization, with large enough minibatches the approach proves effective and stable.
Onetakeawayhereisthatwhenapplyingbatchnormalization, thechoiceofbatchsizeis evenmoresignificantthanwithoutbatchnormalization, oratleast, suitablecalibrationis neededaswemightadjustbatchsize.
Denoteby B aminibatchandletx 2 B beaninputtobatchnormalization(BN).
Inthis casethebatchnormalizationisdefinedasfollows: BNâ€xâ€ =ğœ¸ x ğË†B â€šğœ·.
(8.5.1) ğˆË†B In(8.5.1),ğË†BisthesamplemeanandğˆË†Bisthesamplestandarddeviationoftheminibatch B.
Afterapplyingstandardization, theresultingminibatchhaszeromeanandunitvariance.
Thechoiceofunitvariance(ratherthansomeothermagicnumber)isarbitrary.
Werecover thisdegreeoffreedombyincludinganelementwisescaleparameterğœ¸andshiftparameter ğœ· that have the same shape as x.
Both are parameters that need to be learned as part of modeltraining.
Thevariablemagnitudesforintermediatelayerscannotdivergeduringtrainingsincebatch normalizationactivelycentersandrescalesthembacktoagivenmeanandsize(viağË†Band ğˆË†B).
Practicalexperienceconfirmsthat, asalludedtowhendiscussingfeaturerescaling, batchnormalizationseemstoallowformoreaggressivelearningrates.
Wecalculate ğË†B andğˆË†B in(8.5.1)asfollows: 1 1 ğË†B = j Bj xandğˆË†2 B = j Bj â€x ğË†B â€2â€šğœ–.
(8.5.2) x2B x2B Notethatweaddasmallconstantğœ– > 0tothevarianceestimatetoensurethatwenever attempt division by zero, even in cases where the empirical variance estimate might be verysmallorvanish.
TheestimatesğË†B andğˆË†B counteractthescalingissuebyusingnoisy estimatesofmeanandvariance.
Youmightthinkthatthisnoisinessshouldbeaproblem.
Onthecontrary, itisactuallybeneficial.
Thisturnsouttobearecurringthemeindeeplearning.
Forreasonsthatarenotyetwell- characterized theoretically, various sources of noise in optimization often lead to faster trainingandlessoverfitting: thisvariationappearstoactasaformofregularization.
Teye etal.
(2018)and Luoetal.
(2018)relatedthepropertiesofbatchnormalizationto Bayesian priorsandpenalties, respectively.
Inparticular, thisshedssomelightonthepuzzleofwhy batch normalization works best for moderate minibatch sizes in the 50â€“100 range.
This particularsizeofminibatchseemstoinjectjusttheâ€œrightamountâ€ofnoiseperlayer, both intermsofscaleviağˆË†, andintermsofoffsetviağË†: alargerminibatchregularizeslessdue to the more stable estimates, whereas tiny minibatches destroy useful signal due to high variance.
Exploringthisdirectionfurther, consideringalternativetypesofpreprocessing andfilteringmayyetleadtoothereffectivetypesofregularization.
295 Batch Normalization Fixing a trained model, you might think that we would prefer using the entire dataset to estimatethemeanandvariance.
Oncetrainingiscomplete, whywouldwewantthesame image to be classified differently, depending on the batch in which it happens to reside? Duringtraining, suchexactcalculationisinfeasiblebecausetheintermediatevariablesfor all data examples change every time we update our model.
However, once the model is trained, we can calculate the means and variances of each layerâ€™s variables based on the entiredataset.
Indeedthisisstandardpracticeformodelsemployingbatchnormalization; thusbatchnormalizationlayersfunctiondifferentlyintrainingmode(normalizingbymini- batchstatistics)thaninpredictionmode(normalizingbydatasetstatistics).
Inthisformthey closelyresemblethebehaviorofdropoutregularizationof Section5.6, wherenoiseisonly injectedduringtraining.
8.5.2 Batch Normalization Layers Batch normalization implementations for fully connected layers and convolutional layers areslightlydifferent.
Onekeydifferencebetweenbatchnormalizationandotherlayersis that because the former operates on a full minibatch at a time, we cannot just ignore the batchdimensionaswedidbeforewhenintroducingotherlayers.
Fully Connected Layers Whenapplyingbatchnormalizationtofullyconnectedlayers, Ioffeand Szegedy(2015), in theiroriginalpaperinsertedbatchnormalizationaftertheaffinetransformationandbefore the nonlinear activation function.
Later applications experimented with inserting batch normalization right after activation functions.
Denoting the input to the fully connected layer by x, the affine transformation by Wxâ€šb (with the weight parameter W and the biasparameterb), andtheactivationfunctionby ğœ™, wecanexpressthecomputationofa batch-normalization-enabled, fullyconnectedlayeroutputhasfollows: h= ğœ™â€BNâ€Wxâ€šbâ€â€.
(8.5.3) Recallthatmeanandvariancearecomputedonthesameminibatchonwhichthetransfor- mationisapplied.
Convolutional Layers Similarly, withconvolutionallayers, wecanapplybatchnormalizationaftertheconvolution butbeforethenonlinearactivationfunction.
Thekeydifferencefrombatchnormalization in fully connected layers is that we apply the operation on a per-channel basis across all locations.
This is compatible with our assumption of translation invariance that led to convolutions: weassumedthatthespecificlocationofapatternwithinanimagewasnot criticalforthepurposeofunderstanding.
Assume that our minibatches contain ğ‘š examples and that for each channel, the output oftheconvolutionhasheight ğ‘ andwidth ğ‘.
Forconvolutionallayers, wecarryouteach batchnormalizationovertheğ‘š ğ‘ ğ‘ elementsperoutputchannelsimultaneously.
Thus, 296 Modern Convolutional Neural Networks wecollectthevaluesoverallspatiallocationswhencomputingthemeanandvarianceand consequentlyapplythesamemeanandvariancewithinagivenchanneltonormalizethe valueateachspatiallocation.
Eachchannelhasitsownscaleandshiftparameters, bothof whicharescalars.
Layer Normalization Note that in the context of convolutions the batch normalization is well defined even for minibatchesofsize1: afterall, wehaveallthelocationsacrossanimagetoaverage.
Con- sequently, meanandvariancearewelldefined, evenifitisjustwithinasingleobservation.
Thisconsiderationled Baetal.
(2016)tointroducethenotionoflayernormalization.
It worksjustlikeabatchnorm, onlythatitisappliedtooneobservationatatime.
Conse- quentlyboththeoffsetandthescalingfactorarescalars.
Foran ğ‘›-dimensionalvectorx, layernormsaregivenby x ğœ‡Ë† x! LNâ€xâ€ = , (8.5.4) ğœË† wherescalingandoffsetareappliedcoefficient-wiseandgivenby ğ‘› ğ‘› 1 1 ğœ‡Ë† d = ef ğ‘› ğ‘¥ ğ‘– andğœË†2 d = ef ğ‘› â€ğ‘¥ ğ‘– ğœ‡Ë†â€2â€šğœ–.
(8.5.5) ğ‘–=1 ğ‘–=1 Asbeforeweaddasmalloffsetğœ– >0topreventdivisionbyzero.
Oneofthemajorbenefits ofusinglayernormalizationisthatitpreventsdivergence.
Afterall, ignoringğœ–, theoutput ofthelayernormalizationisscaleindependent.
Thatis, wehave LNâ€xâ€ LNâ€ğ›¼xâ€forany choiceofğ›¼ â‰  0.
Thisbecomesanequalityfor jğ›¼j ! 1(theapproximateequalityisdue totheoffsetğœ– forthevariance).
Anotheradvantageofthelayernormalizationisthatitdoesnotdependontheminibatch size.
Itisalsoindependentofwhetherweareintrainingortestregime.
Inotherwords, itis simplyadeterministictransformationthatstandardizestheactivationstoagivenscale.
This canbeverybeneficialinpreventingdivergenceinoptimization.
Weskipfurtherdetailsand recommendthatinterestedreadersconsulttheoriginalpaper.
Batch Normalization During Prediction Aswementionedearlier, batchnormalizationtypicallybehavesdifferentlyintrainingmode thaninpredictionmode.
First, thenoiseinthesamplemeanandthesamplevariancearising fromestimatingeachonminibatchesisnolongerdesirableoncewehavetrainedthemodel.
Second, wemightnothavetheluxuryofcomputingper-batchnormalizationstatistics.
For example, wemightneedtoapplyourmodeltomakeonepredictionatatime.
Typically, aftertraining, weusetheentiredatasettocomputestableestimatesofthevari- able statistics and then fix them at prediction time.
Hence, batch normalization behaves differentlyduringtrainingthanattesttime.
Recallthatdropoutalsoexhibitsthischarac- teristic.
297 Batch Normalization 8.5.3 Implementationfrom Scratch To see how batch normalization works in practice, we implement one from scratch be- low.
def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum): # Use is_grad_enabled to determine whether we are in training mode if not torch.
is_grad_enabled(): # In prediction mode, use mean and variance obtained by moving average X_hat = (X - moving_mean) / torch.
sqrt(moving_var + eps) else: assert len(X.
shape) in (2, 4) if len(X.
shape) == 2: # When using a fully connected layer, calculate the mean and # variance on the feature dimension mean = X.
mean(dim=0) var = ((X - mean) ** 2).
mean(dim=0) else: # When using a two-dimensional convolutional layer, calculate the # mean and variance on the channel dimension (axis=1).
Here we # need to maintain the shape of X, so that the broadcasting # operation can be carried out later mean = X.
mean(dim=(0, 2, 3), keepdim=True) var = ((X - mean) ** 2).
mean(dim=(0, 2, 3), keepdim=True) # In training mode, the current mean and variance are used X_hat = (X - mean) / torch.
sqrt(var + eps) # Update the mean and variance using moving average moving_mean = (1.0 - momentum) * moving_mean + momentum * mean moving_var = (1.0 - momentum) * moving_var + momentum * var Y = gamma * X_hat + beta # Scale and shift return Y, moving_mean.
data, moving_var.
data Wecannowcreateaproper Batch Normlayer.
Ourlayerwillmaintainproperparametersfor scalegammaandshiftbeta, bothofwhichwillbeupdatedinthecourseoftraining.
Addi- tionally, ourlayerwillmaintainmovingaveragesofthemeansandvariancesforsubsequent useduringmodelprediction.
Puttingasidethealgorithmicdetails, notethedesignpatternunderlyingourimplementation ofthelayer.
Typically, wedefinethemathematicsinaseparatefunction, saybatch_norm.
Wethenintegratethisfunctionalityintoacustomlayer, whosecodemostlyaddressesbook- keepingmatters, suchasmovingdatatotherightdevicecontext, allocatingandinitializing any required variables, keeping track of moving averages (here for mean and variance), andsoon.
Thispatternenablesacleanseparationofmathematicsfromboilerplatecode.
Alsonotethatforthesakeofconveniencewedidnotworryaboutautomaticallyinferring theinputshapehere; thusweneedtospecifythenumberoffeaturesthroughout.
Bynow all modern deep learning frameworks offer automatic detection of size and shape in the high-levelbatchnormalization APIs(inpracticewewillusethisinstead).
class Batch Norm(nn.
Module): # num_features: the number of outputs for a fully connected layer or the # number of output channels for a convolutional layer.
num_dims: 2 for a (continuesonnextpage) 298 Modern Convolutional Neural Networks (continuedfrompreviouspage) # fully connected layer and 4 for a convolutional layer def __init__(self, num_features, num_dims): super().__init__() if num_dims == 2: shape = (1, num_features) else: shape = (1, num_features, 1, 1) # The scale parameter and the shift parameter (model parameters) are # initialized to 1 and 0, respectively self.
gamma = nn.
Parameter(torch.
ones(shape)) self.
beta = nn.
Parameter(torch.
zeros(shape)) # The variables that are not model parameters are initialized to 0 and # 1 self.
moving_mean = torch.
zeros(shape) self.
moving_var = torch.
ones(shape) def forward(self, X): # If X is not on the main memory, copy moving_mean and moving_var to # the device where X is located if self.
moving_mean.
device != X.
device: self.
moving_mean = self.
moving_mean.
to(X.
device) self.
moving_var = self.
moving_var.
to(X.
device) # Save the updated moving_mean and moving_var Y, self.
moving_mean, self.
moving_var = batch_norm( X, self.
gamma, self.
beta, self.
moving_mean, self.
moving_var, eps=1e-5, momentum=0.1) return Y Weusedmomentumtogoverntheaggregationoverpastmeanandvarianceestimates.
This issomewhatofamisnomerasithasnothingwhatsoevertodowiththemomentumtermof optimization.
Nonetheless, itisthecommonlyadoptednameforthistermandindeference to APInamingconventionweusethesamevariablenameinourcode.
8.5.4 Le Netwith Batch Normalization Toseehowtoapply Batch Normincontext, belowweapplyittoatraditional Le Netmodel (Section7.6).
Recallthatbatchnormalizationisappliedaftertheconvolutionallayersor fullyconnectedlayersbutbeforethecorrespondingactivationfunctions.
class BNLe Net Scratch(d2l.
Classifier): def __init__(self, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nn.
Lazy Conv2d(6, kernel_size=5), Batch Norm(6, num_dims=4), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Lazy Conv2d(16, kernel_size=5), Batch Norm(16, num_dims=4), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Flatten(), nn.
Lazy Linear(120), Batch Norm(120, num_dims=2), nn.
Sigmoid(), nn.
Lazy Linear(84), Batch Norm(84, num_dims=2), nn.
Sigmoid(), nn.
Lazy Linear(num_classes)) 299 Batch Normalization Asbefore, wewilltrainournetworkonthe Fashion-MNISTdataset.
Thiscodeisvirtually identicaltothatwhenwefirsttrained Le Net.
trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128) model = BNLe Net Scratch(lr=0.1) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) Letâ€™shavealookatthescaleparametergammaandtheshiftparameterbetalearnedfrom thefirstbatchnormalizationlayer.
grad_fn=<View Backward0>), â†©!', grad_fn=<View Backward0>)) 8.5.5 Concise Implementation Compared with the Batch Norm class, which we just defined ourselves, we can use the Batch Norm class defined in high-level APIs from the deep learning framework directly.
Thecodelooksvirtuallyidenticaltoourimplementationabove, exceptthatwenolonger needtoprovideadditionalargumentsforittogetthedimensionsright.
class BNLe Net(d2l.
Classifier): def __init__(self, lr=0.1, num_classes=10): super().__init__() self.
save_hyperparameters() self.
net = nn.
Sequential( nn.
Lazy Conv2d(6, kernel_size=5), nn.
Lazy Batch Norm2d(), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Lazy Conv2d(16, kernel_size=5), nn.
Lazy Batch Norm2d(), nn.
Sigmoid(), nn.
Avg Pool2d(kernel_size=2, stride=2), nn.
Flatten(), nn.
Lazy Linear(120), nn.
Lazy Batch Norm1d(), (continuesonnextpage) 300 Modern Convolutional Neural Networks (continuedfrompreviouspage) nn.
Sigmoid(), nn.
Lazy Linear(84), nn.
Lazy Batch Norm1d(), nn.
Sigmoid(), nn.
Lazy Linear(num_classes)) Below, weusethesamehyperparameterstotrainourmodel.
Notethatasusual, thehigh- level APIvariantrunsmuchfasterbecauseitscodehasbeencompiledto C++or CUDA whileourcustomimplementationmustbeinterpretedby Python.
trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128) model = BNLe Net(lr=0.1) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) 8.5.6 Discussion Intuitively, batch normalization is thought to make the optimization landscape smoother.
However, wemustbecarefultodistinguishbetweenspeculativeintuitionsandtrueexpla- nationsforthephenomenathatweobservewhentrainingdeepmodels.
Recallthatwedo notevenknowwhysimplerdeepneuralnetworks(MLPsandconventional CNNs)general- izewellinthefirstplace.
Evenwithdropoutandweightdecay, theyremainsoflexiblethat theirabilitytogeneralizetounseendatalikelyneedssignificantlymorerefinedlearning- theoreticgeneralizationguarantees.
Theoriginalpaperproposingbatchnormalization(Ioffeand Szegedy,2015), inadditionto introducingapowerfulandusefultool, offeredanexplanationforwhyitworks: byreducing internalcovariateshift.
Presumablybyinternalcovariateshifttheymeantsomethinglike theintuitionexpressedaboveâ€”thenotionthatthedistributionofvariablevalueschanges overthecourseoftraining.
However, thereweretwoproblemswiththisexplanation: i)This driftisverydifferentfromcovariateshift, renderingthenameamisnomer.
Ifanything, it isclosertoconceptdrift.
ii)Theexplanationoffersanunder-specifiedintuitionbutleaves thequestionofwhypreciselythistechniqueworksanopenquestionwantingforarigorous explanation.
Throughoutthisbook, weaimtoconveytheintuitionsthatpractitionersuseto guidetheirdevelopmentofdeepneuralnetworks.
However, webelievethatitisimportant toseparatetheseguidingintuitionsfromestablishedscientificfact.
Eventually, whenyou 301 Batch Normalization masterthismaterialandstartwritingyourownresearchpapersyouwillwanttobeclearto delineatebetweentechnicalclaimsandhunches.
Followingthesuccessofbatchnormalization, itsexplanationintermsofinternalcovariate shift has repeatedly surfaced in debates in the technical literature and broader discourse abouthowtopresentmachinelearningresearch.
Inamemorablespeechgivenwhileac- ceptinga Testof Time Awardatthe2017Neur IPSconference, Ali Rahimiusedinternal covariateshiftasafocalpointinanargumentlikeningthemodernpracticeofdeeplearning toalchemy.
Subsequently, theexamplewasrevisitedindetailinapositionpaperoutlining troubling trends in machine learning (Lipton and Steinhardt, 2018).
Other authors have proposedalternativeexplanationsforthesuccessofbatchnormalization, some(Santurkar etal.,2018)claimingthatbatchnormalizationâ€™ssuccesscomesdespiteexhibitingbehavior thatisinsomewaysoppositetothoseclaimedintheoriginalpaper.
Wenotethattheinternalcovariateshift isnomoreworthyofcriticismthananyofthou- sandsofsimilarlyvagueclaimsmadeeveryyearinthetechnicalmachinelearningliterature.
Likely, itsresonanceasafocalpointofthesedebatesowestoitsbroadrecognizabilityfor thetargetaudience.
Batchnormalizationhasprovenanindispensablemethod, appliedin nearlyalldeployedimageclassifiers, earningthepaperthatintroducedthetechniquetensof thousandsofcitations.
Weconjecture, though, thattheguidingprinciplesofregularization throughnoiseinjection, accelerationthroughrescalingandlastlypreprocessingmaywell leadtofurtherinventionsoflayersandtechniquesinthefuture.
On a more practical note, there are a number of aspects worth remembering about batch normalization: Duringmodeltraining, batchnormalizationcontinuouslyadjuststheintermediateoutput ofthenetworkbyutilizingthemeanandstandarddeviationoftheminibatch, sothat thevaluesoftheintermediateoutputineachlayerthroughouttheneuralnetworkare morestable.
Batchnormalizationisslightlydifferentforfullyconnectedlayersthanforconvolutional layers.
Infact, forconvolutionallayers, layernormalizationcansometimesbeusedas analternative.
Likeadropoutlayer, batchnormalizationlayershavedifferentbehaviorsintrainingmode thaninpredictionmode.
Batchnormalizationisusefulforregularizationandimprovingconvergenceinoptimiza- tion.
By contrast, the original motivation of reducing internal covariate shift seems nottobeavalidexplanation.
Formorerobustmodelsthatarelesssensitivetoinputperturbations, considerremoving batchnormalization(Wangetal.,2022).
8.5.7 Exercises 1.
Shouldweremovethebiasparameterfromthefullyconnectedlayerortheconvolutional layerbeforethebatchnormalization? Why? 302 Modern Convolutional Neural Networks 2.
Comparethelearningratesfor Le Netwithandwithoutbatchnormalization.
1.
Plottheincreaseinvalidationaccuracy.
2.
Howlargecanyoumakethelearningratebeforetheoptimizationfailsinbothcases? 3.
Doweneedbatchnormalizationineverylayer? Experimentwithit.
4.
Implementaâ€œliteâ€versionofbatchnormalizationthatonlyremovesthemean, oralter- nativelyonethatonlyremovesthevariance.
Howdoesitbehave? 5.
Fixtheparametersbetaandgamma.
Observeandanalyzetheresults.
6.
Canyoureplacedropoutbybatchnormalization? Howdoesthebehaviorchange? 7.
Researchideas: thinkofothernormalizationtransformsthatyoucanapply: 1.
Canyouapplytheprobabilityintegraltransform? 2.
Canyouuseafull-rankcovarianceestimate? Whyshouldyouprobablynotdothat? 3.
Canyouuseothercompactmatrixvariants(block-diagonal, low-displacementrank, Monarch, etc.)? 4.
Doesasparsificationcompressionactasaregularizer? 5.
Arethereotherprojections(e.
g., convexcone, symmetrygroup-specifictransforms) thatyoucanuse? Discussions132.
132 8.6 Residual Networks (Res Net) and Res Ne Xt Aswedesigneverdeepernetworksitbecomesimperativetounderstandhowaddinglayers can increase the complexity and expressiveness of the network.
Even more important is theabilitytodesignnetworkswhereaddinglayersmakesnetworksstrictlymoreexpressive ratherthanjustdifferent.
Tomakesomeprogressweneedabitofmathematics.
import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 8.6.1 Function Classes Consider F, theclassoffunctionsthataspecificnetworkarchitecture(togetherwithlearn- ingratesandotherhyperparametersettings)canreach.
Thatis, forall ğ‘“ 2 F thereexists somesetofparameters(e.
g., weightsandbiases)thatcanbeobtainedthroughtrainingon asuitabledataset.
Letâ€™sassumethat ğ‘“ istheâ€œtruthâ€functionthatwereallywouldliketo 303 Residual Networks(Res Net)and Res Ne Xt find.
Ifitisin F, weareingoodshapebuttypicallywewillnotbequitesolucky.
Instead, wewilltrytofindsome ğ‘“ whichisourbestbetwithin F.
Forinstance, givenadataset F withfeatures Xandlabelsy, wemighttryfindingitbysolvingthefollowingoptimization problem: ğ‘“ F d = ef argminğ¿â€X, y, ğ‘“â€subjectto ğ‘“ 2 F.
(8.6.1) ğ‘“ We know that regularization (Morozov, 1984, Tikhonov and Arsenin, 1977) may control complexityof F andachieveconsistency, soalargersizeoftrainingdatagenerallyleadsto better ğ‘“ .
Itisonlyreasonabletoassumethatifwedesignadifferentandmorepowerful F architecture F0 we should arrive at a better outcome.
In other words, we would expect that ğ‘“ is â€œbetterâ€ than ğ‘“ .
However, if F âŠˆ F0 there is no guarantee that this should F0 F evenhappen.
Infact, ğ‘“ mightwellbeworse.
Asillustratedby.6.1, fornon-nested F0 functionclasses, alargerfunctionclassdoesnotalwaysmoveclosertotheâ€œtruthâ€function ğ‘“ .
Forinstance, ontheleftof.6.1, though F iscloserto ğ‘“ than F , F movesaway 3 1 6 and there is no guarantee that further increasing the complexity can reduce the distance from ğ‘“ .
Withnestedfunctionclasseswhere F F ontherightof.6.1, we 1 6 canavoidtheaforementionedissuefromthenon-nestedfunctionclasses.
t .6.1 Fornon-nestedfunctionclasses, alarger(indicatedbyarea)functionclassdoesnot guaranteewewillgetclosertotheâ€œtruthâ€function(f ).
Thisdoesnothappeninnested functionclasses.
Thus, onlyiflargerfunctionclassescontainthesmalleronesareweguaranteedthatincreas- ingthemstrictlyincreasestheexpressivepowerofthenetwork.
Fordeepneuralnetworks, ifwecantrainthenewly-addedlayerintoanidentityfunction ğ‘“â€xâ€ = x, thenewmodel willbeaseffectiveastheoriginalmodel.
Asthenewmodelmaygetabettersolutiontofit thetrainingdataset, theaddedlayermightmakeiteasiertoreducetrainingerrors.
This is the question that He et al.
(2016) considered when working on very deep com- putervisionmodels.
Attheheartoftheirproposedresidualnetwork (Res Net)istheidea that every additional layer should more easily contain the identity function as one of its elements.
These considerations are rather profound but they led to a surprisingly simple solution, aresidualblock.
Withit, Res Netwonthe Image Net Large Scale Visual Recogni- tion Challengein2015.
Thedesignhadaprofoundinfluenceonhowtobuilddeepneural networks.
Forinstance, residualblockshavebeenaddedtorecurrentnetworks(Kimetal., 2017, Prakash et al., 2016).
Likewise, Transformers (Vaswani et al., 2017) use them to 304 Modern Convolutional Neural Networks stack many layers of networks efficiently.
It is also used in graph neural networks (Kipf and Welling,2016)and, asabasicconcept, ithasbeenusedextensivelyincomputervision (Redmonand Farhadi,2018, Renetal.,2015).
Notethatresidualnetworksarepredatedby highwaynetworks(Srivastavaetal.,2015)thatsharesomeofthemotivation, albeitwithout theelegantparametrizationaroundtheidentityfunction.
8.6.2 Residual Blocks Letâ€™sfocusonalocalpartofaneuralnetwork, asdepictedin.6.2.
Denotetheinput byx.
Weassumethat ğ‘“â€xâ€, thedesiredunderlyingmappingwewanttoobtainbylearning, istobeusedasinputtotheactivationfunctiononthetop.
Ontheleft, theportionwithinthe dotted-lineboxmustdirectlylearn ğ‘“â€xâ€.
Ontheright, theportionwithinthedotted-line boxneedstolearntheresidualmappingğ‘”â€xâ€ = ğ‘“â€xâ€ x, whichishowtheresidualblock derivesitsname.
Iftheidentitymapping ğ‘“â€xâ€ =xisthedesiredunderlyingmapping, the residualmappingamountstoğ‘”â€xâ€ =0anditisthuseasiertolearn: weonlyneedtopushthe weightsandbiasesoftheupperweightlayer(e.
g., fullyconnectedlayerandconvolutional layer)withinthedotted-lineboxtozero.
Therightfigureillustratestheresidualblock of Res Net, where the solid line carrying the layer input x to the addition operator is called aresidualconnection(orshortcutconnection).
Withresidualblocks, inputscanforward propagatefasterthroughtheresidualconnectionsacrosslayers.
Infact, theresidualblock canbethoughtofasaspecialcaseofthemulti-branch Inceptionblock: ithastwobranches oneofwhichistheidentitymapping.
t .6.2 Inaregularblock(left), theportionwithinthedotted-lineboxmustdirectlylearnthe mappingfâ€xâ€.
Inaresidualblock(right), theportionwithinthedotted-lineboxneedsto learntheresidualmappinggâ€xâ€ =fâ€xâ€ x, makingtheidentitymappingfâ€xâ€ =xeasier tolearn.
Res Nethas VGGâ€™sfull3 3convolutionallayerdesign.
Theresidualblockhastwo3 3 convolutional layers with the same number of output channels.
Each convolutional layer isfollowedbyabatchnormalizationlayeranda Re LUactivationfunction.
Then, weskip thesetwoconvolutionoperationsandaddtheinputdirectlybeforethefinal Re LUactivation function.
Thiskindofdesignrequiresthattheoutputofthetwoconvolutionallayershasto beofthesameshapeastheinput, sothattheycanbeaddedtogether.
Ifwewanttochange the number of channels, we need to introduce an additional 1 1 convolutional layer to 305 Residual Networks(Res Net)and Res Ne Xt transformtheinputintothedesiredshapefortheadditionoperation.
Letâ€™shavealookat thecodebelow.
class Residual(nn.
Module): #@save """The Residual block of Res Net models.""" def __init__(self, num_channels, use_1x1conv=False, strides=1): super().__init__() self.
conv1 = nn.
Lazy Conv2d(num_channels, kernel_size=3, padding=1, stride=strides) self.
conv2 = nn.
Lazy Conv2d(num_channels, kernel_size=3, padding=1) if use_1x1conv: self.
conv3 = nn.
Lazy Conv2d(num_channels, kernel_size=1, stride=strides) else: self.
conv3 = None self.
bn1 = nn.
Lazy Batch Norm2d() self.
bn2 = nn.
Lazy Batch Norm2d() def forward(self, X): Y = F.
relu(self.
bn1(self.
conv1(X))) Y = self.
bn2(self.
conv2(Y)) if self.
conv3: X = self.
conv3(X) Y += X return F.
relu(Y) Thiscodegeneratestwotypesofnetworks: onewhereweaddtheinputtotheoutputbefore applyingthe Re LUnonlinearitywheneveruse_1x1conv=False; andonewhereweadjust channelsandresolutionbymeansofa1 1convolutionbeforeadding.
.6.3illustrates this.
t .6.3 Res Netblockwithandwithout1 1convolution, whichtransformstheinputintothe desiredshapefortheadditionoperation.
Nowletâ€™slookatasituationwheretheinputandoutputareofthesameshape, where1 1 convolutionisnotneeded.
306 Modern Convolutional Neural Networks blk = Residual(3) X = torch.
randn(4, 3, 6, 6) blk(X).
shape torch.
Size([4, 3, 6, 6]) Wealsohavetheoptiontohalvetheoutputheightandwidthwhileincreasingthenumber ofoutputchannels.
Inthiscaseweuse1 1convolutionsviause_1x1conv=True.
This comesinhandyatthebeginningofeach Res Netblocktoreducethespatialdimensionality viastrides=2.
blk = Residual(6, use_1x1conv=True, strides=2) blk(X).
shape torch.
Size([4, 6, 3, 3]) 8.6.3 Res Net Model Thefirsttwolayersof Res Netarethesameasthoseofthe Goog Le Netwedescribedbefore: the7 7convolutionallayerwith64outputchannelsandastrideof2isfollowedbythe 3 3max-poolinglayerwithastrideof2.
Thedifferenceisthebatchnormalizationlayer addedaftereachconvolutionallayerin Res Net.
class Res Net(d2l.
Classifier): def b1(self): return nn.
Sequential( nn.
Lazy Conv2d(64, kernel_size=7, stride=2, padding=3), nn.
Lazy Batch Norm2d(), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) Goog Le Net uses four modules made up of Inception blocks.
However, Res Net uses four modulesmadeupofresidualblocks, eachofwhichusesseveralresidualblockswiththe samenumberofoutputchannels.
Thenumberofchannelsinthefirstmoduleisthesame asthenumberofinputchannels.
Sinceamax-poolinglayerwithastrideof2hasalready beenused, itisnotnecessarytoreducetheheightandwidth.
Inthefirstresidualblockfor eachofthesubsequentmodules, thenumberofchannelsisdoubledcomparedwiththatof thepreviousmodule, andtheheightandwidtharehalved.
@d2l.
add_to_class(Res Net) def block(self, num_residuals, num_channels, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.
append(Residual(num_channels, use_1x1conv=True, strides=2)) else: (continuesonnextpage) 307 Residual Networks(Res Net)and Res Ne Xt (continuedfrompreviouspage) blk.
append(Residual(num_channels)) return nn.
Sequential(*blk) Then, weaddallthemodulesto Res Net.
Here, tworesidualblocksareusedforeachmod- ule.
Lastly, just like Goog Le Net, we add a global average pooling layer, followed by the fullyconnectedlayeroutput.
@d2l.
add_to_class(Res Net) def __init__(self, arch, lr=0.1, num_classes=10): super(Res Net, self).__init__() self.
save_hyperparameters() self.
net = nn.
Sequential(self.
b1()) for i, b in enumerate(arch): self.
net.
add_module(f'b{i+2}', self.
block(*b, first_block=(i==0))) self.
net.
add_module('last', nn.
Sequential( nn.
Adaptive Avg Pool2d((1, 1)), nn.
Flatten(), nn.
Lazy Linear(num_classes))) self.
net.
apply(d2l.
init_cnn) Therearefourconvolutionallayersineachmodule(excludingthe1 1convolutionallayer).
Togetherwiththefirst7 7convolutionallayerandthefinalfullyconnectedlayer, thereare 18layersintotal.
Therefore, thismodeliscommonlyknownas Res Net-18.
Byconfiguring different numbers of channels and residual blocks in the module, we can create different Res Netmodels, suchasthedeeper152-layer Res Net-152.
Althoughthemainarchitecture of Res Netissimilartothatof Goog Le Net, Res Netâ€™sstructureissimplerandeasiertomod- depictsthefull Res Net-18.
t .6.4 The Res Net-18architecture.
Beforetraining Res Net, letâ€™sobservehowtheinputshapechangesacrossdifferentmodules in Res Net.
Asinallthepreviousarchitectures, theresolutiondecreaseswhilethenumber ofchannelsincreasesupuntilthepointwhereaglobalaveragepoolinglayeraggregatesall features.
class Res Net18(Res Net): def __init__(self, lr=0.1, num_classes=10): super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)), lr, num_classes) 308 Modern Convolutional Neural Networks Res Net18().
layer_summary((1, 1, 96, 96)) Sequential output shape: torch.
Size([1, 64, 24, 24]) Sequential output shape: torch.
Size([1, 64, 24, 24]) Sequential output shape: torch.
Size([1, 128, 12, 12]) Sequential output shape: torch.
Size([1, 256, 6, 6]) Sequential output shape: torch.
Size([1, 512, 3, 3]) Sequential output shape: torch.
Size([1, 10]) 8.6.4 Training Wetrain Res Netonthe Fashion-MNISTdataset, justlikebefore.
Res Netisquiteapow- erfulandflexiblearchitecture.
Theplotcapturingtrainingandvalidationlossillustratesa significantgapbetweenbothgraphs, withthetraininglossbeingconsiderablylower.
For anetworkofthisflexibility, moretrainingdatawouldofferdistinctbenefitinclosingthe gapandimprovingaccuracy.
model = Res Net18(lr=0.01) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(96, 96)) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model, data) 8.6.5 Res Ne Xt Oneofthechallengesoneencountersinthedesignof Res Netisthetrade-offbetweennon- linearityanddimensionalitywithinagivenblock.
Thatis, wecouldaddmorenonlinearity byincreasingthenumberoflayers, orbyincreasingthewidthoftheconvolutions.
Anal- ternativestrategyistoincreasethenumberofchannelsthatcancarryinformationbetween blocks.
Unfortunately, the latter comes with a quadratic penalty since the computational costofingestingğ‘ channelsandemittingğ‘ channelsisproportionalto Oâ€ğ‘ ğ‘ â€(seeour i o i o discussionin Section7.4).
We can take some inspiration from the Inception block of .4.1 which has informa- tionflowingthroughtheblockinseparategroups.
Applyingtheideaofmultipleindepen- dent groups to the Res Net block of .6.3 led to the design of Res Ne Xt (Xie et al., 309 Residual Networks(Res Net)and Res Ne Xt 2017).
Different from the smorgasbord of transformations in Inception, Res Ne Xt adopts the same transformation in all branches, thus minimizing the need for manual tuning of eachbranch.
t .6.5 The Res Ne Xtblock.
Theuseofgroupedconvolutionwithg groupsisg timesfasterthan adenseconvolution.
Itisabottleneckresidualblockwhenthenumberofintermediate channelsb islessthanc.
Breakingupaconvolutionfromğ‘ toğ‘ channelsintooneofğ‘”groupsofsizeğ‘ ğ‘”gener- i o i atingğ‘”outputsofsizeğ‘ ğ‘”iscalled, quitefittingly, agroupedconvolution.
Thecomputa- o tionalcost(proportionally)isreducedfrom Oâ€ğ‘ ğ‘ â€to Oâ€ğ‘” â€ğ‘ ğ‘”â€ â€ğ‘ ğ‘”â€â€ = Oâ€ğ‘ ğ‘ ğ‘”â€, i o i o i o i.
e., itisğ‘”timesfaster.
Evenbetter, thenumberofparametersneededtogeneratetheoutput isalsoreducedfromağ‘ ğ‘ matrixtoğ‘”smallermatricesofsizeâ€ğ‘ ğ‘”â€ â€ğ‘ ğ‘”â€, againa i o i o ğ‘”timesreduction.
Inwhatfollowsweassumethatbothğ‘ andğ‘ aredivisiblebyğ‘”.
i o Theonlychallengeinthisdesignisthatnoinformationisexchangedbetweentheğ‘”groups.
The Res Ne Xtblockof.6.5amendsthisintwoways: thegroupedconvolutionwith a3 3kernelissandwichedinbetweentwo1 1convolutions.
Thesecondoneserves doubledutyinchangingthenumberofchannelsback.
Thebenefitisthatweonlypaythe Oâ€ğ‘ ğ‘â€ costfor1 1kernelsandcanmakedowithan Oâ€ğ‘2 ğ‘”â€ costfor3 3kernels.
Similar to the residual block implementation in Section 8.6.2, the residual connection is replaced(thusgeneralized)bya1 1convolution.
Theright-handfigurein.6.5providesamuchmoreconcisesummaryoftheresulting network block.
It will also play a major role in the design of generic modern CNNs in Section8.8.
Notethattheideaofgroupedconvolutionsdatesbacktotheimplementation of Alex Net (Krizhevsky et al., 2012).
When distributing the network across two GPUs withlimitedmemory, theimplementationtreatedeach GPUasitsownchannelwithnoill effects.
Thefollowingimplementationofthe Res Ne Xt Blockclasstakesasargumentgroups(ğ‘”), withbot_channels(ğ‘)intermediate(bottleneck)channels.
Lastly, whenweneedtoreduce 310 Modern Convolutional Neural Networks theheightandwidthoftherepresentation, weaddastrideof2bysettinguse_1x1conv=True, strides=2.
class Res Ne Xt Block(nn.
Module): #@save """The Res Ne Xt block.""" def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False, strides=1): super().__init__() bot_channels = int(round(num_channels * bot_mul)) self.
conv1 = nn.
Lazy Conv2d(bot_channels, kernel_size=1, stride=1) self.
conv2 = nn.
Lazy Conv2d(bot_channels, kernel_size=3, stride=strides, padding=1, groups=bot_channels//groups) self.
conv3 = nn.
Lazy Conv2d(num_channels, kernel_size=1, stride=1) self.
bn1 = nn.
Lazy Batch Norm2d() self.
bn2 = nn.
Lazy Batch Norm2d() self.
bn3 = nn.
Lazy Batch Norm2d() if use_1x1conv: self.
conv4 = nn.
Lazy Conv2d(num_channels, kernel_size=1, stride=strides) self.
bn4 = nn.
Lazy Batch Norm2d() else: self.
conv4 = None def forward(self, X): Y = F.
relu(self.
bn1(self.
conv1(X))) Y = F.
relu(self.
bn2(self.
conv2(Y))) Y = self.
bn3(self.
conv3(Y)) if self.
conv4: X = self.
bn4(self.
conv4(X)) return F.
relu(Y + X) Itsuseisentirelyanalogoustothatofthe Res Net Blockdiscussedpreviously.
Forinstance, when using (use_1x1conv=False, strides=1), the input and output are of the same shape.
Alternatively, setting use_1x1conv=True, strides=2 halves the output height andwidth.
blk = Res Ne Xt Block(32, 16, 1) X = torch.
randn(4, 32, 96, 96) blk(X).
shape torch.
Size([4, 32, 96, 96]) 8.6.6 Summaryand Discussion Nested function classes are desirable since they allow us to obtain strictly more power- ful rather than also subtly different function classes when adding capacity.
One way of accomplishing this is by letting additional layers to simply pass through the input to the output.
Residualconnectionsallowforthis.
Asaconsequence, thischangestheinductive bias from simple functions being of the form ğ‘“â€xâ€ = 0 to simple functions looking like ğ‘“â€xâ€ =x.
311 Residual Networks(Res Net)and Res Ne Xt Theresidualmappingcanlearntheidentityfunctionmoreeasily, suchaspushingparam- etersintheweightlayertozero.
Wecantrainaneffectivedeepneuralnetworkbyhaving residualblocks.
Inputscanforwardpropagatefasterthroughtheresidualconnectionsacross layers.
Asaconsequence, wecanthustrainmuchdeepernetworks.
Forinstance, theorigi- nal Res Netpaper(Heetal.,2016)allowedforupto152layers.
Anotherbenefitofresidual networks is that it allows us to add layers, initialized as the identity function, during the training process.
After all, the default behavior of a layer is to let the data pass through unchanged.
Thiscanacceleratethetrainingofverylargenetworksinsomecases.
Priortoresidualconnections, bypassingpathswithgatingunitswereintroducedtoeffec- tivelytrainhighwaynetworkswithover100layers(Srivastavaetal.,2015).
Usingidentity functionsasbypassingpaths, Res Netperformedremarkablywellonmultiplecomputervi- siontasks.
Residualconnectionshadamajorinfluenceonthedesignofsubsequentdeep neuralnetworks, ofeitherconvolutionalorsequentialnature.
Aswewillintroducelater, the Transformerarchitecture(Vaswanietal.,2017)adoptsresidualconnections(together withotherdesignchoices)andispervasiveinareasasdiverseaslanguage, vision, speech, andreinforcementlearning.
Res Ne Xtisanexampleforhowthedesignofconvolutionalneuralnetworkshasevolved overtime: bybeingmorefrugalwithcomputationandtradingitoffagainstthesizeofthe activations(numberofchannels), itallowsforfasterandmoreaccuratenetworksatlower cost.
Analternativewayofviewinggroupedconvolutionsistothinkofablock-diagonal matrixfortheconvolutionalweights.
Notethattherearequiteafewsuchâ€œtricksâ€thatlead tomoreefficientnetworks.
Forinstance, Shift Net(Wuetal.,2018)mimickstheeffectsof a3 3convolution, simplybyaddingshiftedactivationstothechannels, offeringincreased functioncomplexity, thistimewithoutanycomputationalcost.
A common feature of the designs we have discussed so far is that the network design is fairlymanual, primarilyrelyingontheingenuityofthedesignertofindtheâ€œrightâ€network hyperparameters.
Whileclearlyfeasible, itisalsoverycostlyintermsofhumantimeand thereisnoguaranteethattheoutcomeisoptimalinanysense.
In Section8.8wewilldiscuss anumberofstrategiesforobtaininghighqualitynetworksinamoreautomatedfashion.
In particular, wewillreviewthenotionofnetworkdesignspacesthatledtothe Reg Net X/Y models(Radosavovicetal.,2020).
8.6.7 Exercises 1.
Whatarethemajordifferencesbetweenthe Inceptionblockin.4.1andtheresidual block? How do they compare in terms of computation, accuracy, and the classes of functionstheycandescribe? 2.
Referto Table1inthe Res Netpaper(Heetal.,2016)toimplementdifferentvariantsof thenetwork.
3.
For deeper networks, Res Net introduces a â€œbottleneckâ€ architecture to reduce model complexity.
Trytoimplementit.
4.
Insubsequentversionsof Res Net, theauthorschangedtheâ€œconvolution, batchnormal- 312 Modern Convolutional Neural Networks ization, andactivationâ€structuretotheâ€œbatchnormalization, activation, andconvolu- tionâ€structure.
Makethisimprovementyourself.
See Figure1in Heetal.
(2016)for details.
5.
Whycanâ€™twejustincreasethecomplexityoffunctionswithoutbound, evenifthefunc- tionclassesarenested? Discussions133.
133 8.7 Densely Connected Networks (Dense Net) Res Net significantly changed the view of how to parametrize the functions in deep net- works.
Dense Net(denseconvolutionalnetwork)istosomeextentthelogicalextensionof this(Huangetal.,2017).
Dense Netischaracterizedbyboththeconnectivitypatternwhere eachlayerconnectstoalltheprecedinglayersandtheconcatenationoperation(ratherthan theadditionoperatorin Res Net)topreserveandreusefeaturesfromearlierlayers.
Toun- derstandhowtoarriveatit, letâ€™stakeasmalldetourtomathematics.
import torch from torch import nn from d2l import torch as d2l 8.7.1 From Res Netto Dense Net Recallthe Taylorexpansionforfunctions.
Atthepointğ‘¥ =0itcanbewrittenas ğ‘“00â€0â€ ğ‘“000â€0â€ ğ‘“â€ğ‘¥â€ = ğ‘“â€0â€â€šğ‘¥ ğ‘“0â€0â€â€šğ‘¥ â€šğ‘¥ â€š .
(8.7.1) 2! 3! Thekeypointisthatitdecomposesafunctionintotermsofincreasinglyhigherorder.
Ina similarvein, Res Netdecomposesfunctionsinto ğ‘“â€xâ€ =xâ€šğ‘”â€xâ€.
(8.7.2) Thatis, Res Netdecomposes ğ‘“ intoasimplelineartermandamorecomplexnonlinearone.
What if we wanted to capture (not necessarily add) information beyond two terms? One suchsolutionis Dense Net(Huangetal.,2017).
t .7.1 Themaindifferencebetween Res Net(left)and Dense Net(right)incross-layer connections: useofadditionanduseofconcatenation.
313 Densely Connected Networks(Dense Net) As shown in .7.1, the key difference between Res Net and Dense Net is that in the latter case outputs are concatenated (denoted by Â»,â€¦) rather than added.
As a result, we performamappingfromxtoitsvaluesafterapplyinganincreasinglycomplexsequence offunctions: 1 2 1 3 1 2 1 Intheend, allthesefunctionsarecombinedin MLPtoreducethenumberoffeaturesagain.
Intermsofimplementationthisisquitesimple: ratherthanaddingterms, weconcatenate them.
Thename Dense Netarisesfromthefactthatthedependencygraphbetweenvariables becomesquitedense.
Thefinallayerofsuchachainisdenselyconnectedtoallprevious t Themaincomponentsthatcomprisea Dense Netaredenseblocksandtransitionlayers.
The formerdefinehowtheinputsandoutputsareconcatenated, whilethelattercontrolthenum- berofchannelssothatitisnottoolarge, sincetheexpansionx! Â»x, ğ‘“ â€xâ€, ğ‘“ â€Â»x, ğ‘“ â€xâ€â€¦â€,...â€¦ 1 2 1 canbequitehigh-dimensional.
8.7.2 Dense Blocks Dense Net uses the modified â€œbatch normalization, activation, and convolutionâ€ structure of Res Net (see the exercise in Section 8.6).
First, we implement this convolution block structure.
def conv_block(num_channels): return nn.
Sequential( nn.
Lazy Batch Norm2d(), nn.
Re LU(), nn.
Lazy Conv2d(num_channels, kernel_size=3, padding=1)) A dense block consists of multiple convolution blocks, each using the same number of outputchannels.
Intheforwardpropagation, however, weconcatenatetheinputandoutput ofeachconvolutionblockonthechanneldimension.
Lazyevaluationallowsustoadjust thedimensionalityautomatically.
class Dense Block(nn.
Module): def __init__(self, num_convs, num_channels): super(Dense Block, self).__init__() layer = [] for i in range(num_convs): layer.
append(conv_block(num_channels)) self.
net = nn.
Sequential(*layer) (continuesonnextpage) 314 Modern Convolutional Neural Networks (continuedfrompreviouspage) def forward(self, X): for blk in self.
net: Y = blk(X) # Concatenate input and output of each block along the channels X = torch.
cat((X, Y), dim=1) return X Inthefollowingexample, wedefinea Dense Blockinstancewithtwoconvolutionblocksof 10outputchannels.
Whenusinganinputwiththreechannels, wewillgetanoutputwith 3â€š10â€š10=23channels.
Thenumberofconvolutionblockchannelscontrolsthegrowth in the number of output channels relative to the number of input channels.
This is also referredtoasthegrowthrate.
blk = Dense Block(2, 10) X = torch.
randn(4, 3, 8, 8) Y = blk(X) Y.
shape torch.
Size([4, 23, 8, 8]) 8.7.3 Transition Layers Sinceeachdenseblockwillincreasethenumberofchannels, addingtoomanyofthemwill leadtoanexcessivelycomplexmodel.
Atransitionlayerisusedtocontrolthecomplexity ofthemodel.
Itreducesthenumberofchannelsbyusinga1 1convolution.
Moreover, it halvestheheightandwidthviaaveragepoolingwithastrideof2.
def transition_block(num_channels): return nn.
Sequential( nn.
Lazy Batch Norm2d(), nn.
Re LU(), nn.
Lazy Conv2d(num_channels, kernel_size=1), nn.
Avg Pool2d(kernel_size=2, stride=2)) Applyatransitionlayerwith10channelstotheoutputofthedenseblockintheprevious example.
This reduces the number of output channels to 10, and halves the height and width.
blk = transition_block(10) blk(Y).
shape torch.
Size([4, 10, 4, 4]) 8.7.4 Dense Net Model 315 Densely Connected Networks(Dense Net) Next, wewillconstructa Dense Netmodel.
Dense Netfirstusesthesamesingleconvolu- tionallayerandmax-poolinglayerasin Res Net.
class Dense Net(d2l.
Classifier): def b1(self): return nn.
Sequential( nn.
Lazy Conv2d(64, kernel_size=7, stride=2, padding=3), nn.
Lazy Batch Norm2d(), nn.
Re LU(), nn.
Max Pool2d(kernel_size=3, stride=2, padding=1)) Then, similartothefourmodulesmadeupofresidualblocksthat Res Netuses, Dense Net usesfourdenseblocks.
Aswith Res Net, wecansetthenumberofconvolutionallayersused ineachdenseblock.
Here, wesetitto4, consistentwiththe Res Net-18modelin Section 8.6.
Furthermore, wesetthenumberofchannels(i.
e., growthrate)fortheconvolutional layersinthedenseblockto32, so128channelswillbeaddedtoeachdenseblock.
In Res Net, theheightandwidtharereducedbetweeneachmodulebyaresidualblockwith astrideof2.
Here, weusethetransitionlayertohalvetheheightandwidthandhalvethe numberofchannels.
Similarto Res Net, aglobalpoolinglayerandafullyconnectedlayer areconnectedattheendtoproducetheoutput.
@d2l.
add_to_class(Dense Net) def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4), lr=0.1, num_classes=10): super(Dense Net, self).__init__() self.
save_hyperparameters() self.
net = nn.
Sequential(self.
b1()) for i, num_convs in enumerate(arch): self.
net.
add_module(f'dense_blk{i+1}', Dense Block(num_convs, growth_rate)) # The number of output channels in the previous dense block num_channels += num_convs * growth_rate # A transition layer that halves the number of channels is added # between the dense blocks if i != len(arch) - 1: num_channels //= 2 self.
net.
add_module(f'tran_blk{i+1}', transition_block( num_channels)) self.
net.
add_module('last', nn.
Sequential( nn.
Lazy Batch Norm2d(), nn.
Re LU(), nn.
Adaptive Avg Pool2d((1, 1)), nn.
Flatten(), nn.
Lazy Linear(num_classes))) self.
net.
apply(d2l.
init_cnn) 8.7.5 Training Sinceweareusingadeepernetworkhere, inthissection, wewillreducetheinputheight andwidthfrom224to96tosimplifythecomputation.
316 Modern Convolutional Neural Networks model = Dense Net(lr=0.01) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(96, 96)) trainer.
fit(model, data) 8.7.6 Summaryand Discussion Themaincomponentsthatcomprise Dense Netaredenseblocksandtransitionlayers.
For the latter, we need to keep the dimensionality under control when composing the net- work by adding transition layers that shrink the number of channels again.
In terms of cross-layer connections, in contrast to Res Net, where inputs and outputs are added to- gether, Dense Net concatenates inputs and outputs on the channel dimension.
Although theseconcatenationoperationsreusefeaturestoachievecomputationalefficiency, unfortu- natelytheyleadtoheavy GPUmemoryconsumption.
Asaresult, applying Dense Netmay requiremorememory-efficientimplementationsthatmayincreasetrainingtime(Pleisset al.,2017).
8.7.7 Exercises 1.
Whydoweuseaveragepoolingratherthanmax-poolinginthetransitionlayer? 2.
Oneoftheadvantagesmentionedinthe Dense Netpaperisthatitsmodelparametersare smallerthanthoseof Res Net.
Whyisthisthecase? 3.
Oneproblemforwhich Dense Nethasbeencriticizedisitshighmemoryconsumption.
1.
Isthisreallythecase? Trytochangetheinputshapeto224 224tocomparethe actual GPUmemoryconsumptionempirically.
2.
Canyouthinkofanalternativemeansofreducingthememoryconsumption? How wouldyouneedtochangetheframework? 4.
Implementthevarious Dense Netversionspresentedin Table1ofthe Dense Netpaper (Huangetal.,2017).
5.
Designan MLP-basedmodelbyapplyingthe Dense Netidea.
Applyittothehousing 134 pricepredictiontaskin Section5.7.
Discussions134.
317 Designing Convolution Network Architectures 8.8 Designing Convolution Network Architectures The previous sections have taken us on a tour of modern network design for computer vision.
Common to all the work we covered was that it greatly relied on the intuition of scientists.
Many of the architectures are heavily informed by human creativity and to a muchlesserextentbysystematicexplorationofthedesignspacethatdeepnetworksoffer.
Nonetheless, thisnetworkengineeringapproachhasbeentremendouslysuccessful.
Eversince Alex Net(Section8.1)beatconventionalcomputervisionmodelson Image Net, ithasbecomepopulartoconstructverydeepnetworksbystackingblocksofconvolutions, alldesignedaccordingtothesamepattern.
Inparticular,3 3convolutionswerepopular- izedby VGGnetworks(Section8.2).
Ni N(Section8.3)showedthateven1 1convolu- tionscouldbebeneficialbyaddinglocalnonlinearities.
Moreover, Ni Nsolvedtheproblem of aggregating information at the head of a network by aggregating across all locations.
Goog Le Net(Section8.4)addedmultiplebranchesofdifferentconvolutionwidth, combin- ingtheadvantagesof VGGand Ni Ninits Inceptionblock.
Res Nets(Section8.6)changed the inductive bias towards the identity mapping (from ğ‘“â€ğ‘¥â€ = 0).
This allowed for very deep networks.
Almost a decade later, the Res Net design is still popular, a testament to itsdesign.
Lastly, Res Ne Xt(Section8.6.5)addedgroupedconvolutions, offeringabetter trade-off between parameters and computation.
A precursor to Transformers for vision, the Squeeze-and-Excitation Networks(SENets)allowforefficientinformationtransferbe- tween locations (Hu et al., 2018).
This was accomplished by computing a per-channel globalattentionfunction.
Uptonowwehaveomittednetworksobtainedvianeuralarchitecturesearch(NAS)(Liu etal.,2018, Zophand Le,2016).
Wechosetodososincetheircostisusuallyenormous, relying on brute-force search, genetic algorithms, reinforcement learning, or some other formofhyperparameteroptimization.
Givenafixedsearchspace, NASusesasearchstrat- egytoautomaticallyselectanarchitecturebasedonthereturnedperformanceestimation.
Theoutcomeof NASisasinglenetworkinstance.
Efficient Netsareanotableoutcomeof thissearch(Tanand Le,2019).
In the following we discuss an idea that is quite different to the quest for the single best network.
Itiscomputationallyrelativelyinexpensive, itleadstoscientificinsightsonthe way, anditisquiteeffectiveintermsofthequalityofoutcomes.
Letâ€™sreviewthestrategy by Radosavovicetal.
(2020)todesignnetworkdesignspaces.
Thestrategycombinesthe strengthofmanualdesignand NAS.
Itaccomplishesthisbyoperatingondistributionsof networksandoptimizingthedistributionsinawaytoobtaingoodperformanceforentire familiesofnetworks.
Theoutcomeofitare Reg Nets, specifically Reg Net Xand Reg Net Y, plusarangeofguidingprinciplesforthedesignofperformant CNNs.
import torch from torch import nn (continuesonnextpage) 318 Modern Convolutional Neural Networks (continuedfrompreviouspage) from torch.
nn import functional as F from d2l import torch as d2l 8.8.1 The Any Net Design Space Thedescriptionbelowcloselyfollowsthereasoningin Radosavovicetal.
(2020)withsome abbreviationstomakeitfitinthescopeofthebook.
Tobegin, weneedatemplateforthe familyofnetworkstoexplore.
Oneofthecommonalitiesofthedesignsinthischapteris that the networks consist of a stem, a body and a head.
The stem performs initial image processing, often through convolutions with a larger window size.
The body consists of multipleblocks, carryingoutthebulkofthetransformationsneededtogofromrawimages to object representations.
Lastly, the head converts this into the desired outputs, such as viaasoftmaxregressorformulticlassclassification.
Thebody, inturn, consistsofmultiple stages, operating on the image at decreasing resolutions.
In fact, both the stem and each subsequentstagequarterthespatialresolution.
Lastly, eachstageconsistsofoneormore blocks.
This pattern is common to all networks, from VGGto Res Ne Xt.
Indeed, forthe designofgeneric Any Netnetworks, Radosavovicetal.
(2020)usedthe Res Ne Xtblockof .6.5.
t .8.1 The Any Netdesignspace.
Thenumbersâ€c, râ€alongeacharrowindicatethenumberof channelscandtheresolutionr r oftheimagesatthatpoint.
Fromlefttoright: generic networkstructurecomposedofstem, body, andhead; bodycomposedoffourstages; detailedstructureofastage; twoalternativestructuresforblocks, onewithout downsamplingandonethathalvestheresolutionineachdimension.
Designchoices includedepthd , thenumberofoutputchannelsc , thenumberofgroupsg , and i i i bottleneckratiok foranystagei.
i Letâ€™sreviewthestructureoutlinedin.8.1indetail.
Asmentioned, an Any Netconsists ofastem, body, andhead.
Thestemtakesasitsinput RGBimages(3channels), usinga 3 3convolutionwithastrideof2, followedbyabatchnorm, tohalvetheresolutionfrom ğ‘Ÿ ğ‘Ÿtoğ‘Ÿ 2 ğ‘Ÿ 2.
Moreover, itgeneratesğ‘ channelsthatserveasinputtothebody.
0 319 Designing Convolution Network Architectures Sincethenetworkisdesignedtoworkwellwith Image Netimagesofshape224 224 3, the body serves to reduce this to 7 7 ğ‘ through 4 stages (recall that 224 21â€š4 = 7), 4 eachwithaneventualstrideof2.
Lastly, theheademploysanentirelystandarddesignvia globalaveragepooling, similarto Ni N(Section8.3), followedbyafullyconnectedlayerto emitanğ‘›-dimensionalvectorforğ‘›-classclassification.
Mostoftherelevantdesigndecisionsareinherenttothebodyofthenetwork.
Itproceedsin stages, whereeachstageiscomposedofthesametypeof Res Ne Xtblocksaswediscussed in Section 8.6.5.
The design there is again entirely generic: we begin with a block that halvestheresolutionbyusingastrideof2(therightmostin.8.1).
Tomatchthis, the residualbranchofthe Res Ne Xtblockneedstopassthrougha1 1convolution.
Thisblock isfollowedbyavariablenumberofadditional Res Ne Xtblocksthatleavebothresolution and the number of channels unchanged.
Note that a common design practice is to add a slight bottleneck in the design of convolutional blocks.
As such, with bottleneck ratio ğ‘˜ ğ‘– 1 we afford some number of channels, ğ‘ ğ‘– ğ‘˜ ğ‘–, within each block for stage ğ‘– (as the experimentsshow, thisisnotreallyeffectiveandshouldbeskipped).
Lastly, sinceweare dealingwith Res Ne Xtblocks, wealsoneedtopickthenumberofgroups ğ‘” ğ‘– forgrouped convolutionsatstageğ‘–.
This seemingly generic design space provides us nonetheless with many parameters: we cansettheblockwidth(numberofchannels)ğ‘ ,...ğ‘ , thedepth(numberofblocks)per 0 4 1 4 1 4 ğ‘” ,...ğ‘” .
Intotalthisaddsupto17parameters, resultinginanunreasonablylargenumber 1 4 of configurations that would warrant exploring.
We need some tools to reduce this huge designspaceeffectively.
Thisiswheretheconceptualbeautyofdesignspacescomesin.
Beforewedoso, letâ€™simplementthegenericdesignfirst.
class Any Net(d2l.
Classifier): def stem(self, num_channels): return nn.
Sequential( nn.
Lazy Conv2d(num_channels, kernel_size=3, stride=2, padding=1), nn.
Lazy Batch Norm2d(), nn.
Re LU()) Each stage consists of depth Res Ne Xt blocks, where num_channels specifies the block width.
Notethatthefirstblockhalvestheheightandwidthofinputimages.
@d2l.
add_to_class(Any Net) def stage(self, depth, num_channels, groups, bot_mul): blk = [] for i in range(depth): if i == 0: blk.
append(d2l.
Res Ne Xt Block(num_channels, groups, bot_mul, use_1x1conv=True, strides=2)) else: blk.
append(d2l.
Res Ne Xt Block(num_channels, groups, bot_mul)) return nn.
Sequential(*blk) Putting the network stem, body, and head together, we complete the implementation of Any Net.
320 Modern Convolutional Neural Networks @d2l.
add_to_class(Any Net) def __init__(self, arch, stem_channels, lr=0.1, num_classes=10): super(Any Net, self).__init__() self.
save_hyperparameters() self.
net = nn.
Sequential(self.
stem(stem_channels)) for i, s in enumerate(arch): self.
net.
add_module(f'stage{i+1}', self.
stage(*s)) self.
net.
add_module('head', nn.
Sequential( nn.
Adaptive Avg Pool2d((1, 1)), nn.
Flatten(), nn.
Lazy Linear(num_classes))) self.
net.
apply(d2l.
init_cnn) 8.8.2 Distributionsand Parametersof Design Spaces As just discussed in Section 8.8.1, parameters of a design space are hyperparameters of networksinthatdesignspace.
Considertheproblemofidentifyinggoodparametersinthe Any Net design space.
We could try finding the single best parameter choice for a given amountofcomputation(e.
g., FLOPsandcomputetime).
Ifweallowedforevenonlytwo possiblechoicesforeachparameter, wewouldhavetoexplore217 =131072combinations to find the best solution.
This is clearly infeasible because of its exorbitant cost.
Even worse, wedonotreallylearnanythingfromthisexerciseintermsofhowoneshoulddesign anetwork.
Nexttimeweadd, say, an X-stage, orashiftoperation, orsimilar, wewouldneed tostartfromscratch.
Evenworse, duetothestochasticityintraining(rounding, shuffling, bit errors), no two runs are likely to produce exactly the same results.
A better strategy wouldbetotrytodeterminegeneralguidelinesofhowthechoicesofparametersshould berelated.
Forinstance, thebottleneckratio, thenumberofchannels, blocks, groups, or theirchangebetweenlayersshouldideallybegovernedbyacollectionofsimplerules.
The approachin Radosavovicetal.
(2019)reliesonthefollowingfourassumptions: 1.
We assume that general design principles actually exist, so that many networks satis- fyingthese requirementsshould offer good performance.
Consequently, identifying a distribution over networks can be a sensible strategy.
In other words, we assume that therearemanygoodneedlesinthehaystack.
2.
Weneednottrainnetworkstoconvergencebeforewecanassesswhetheranetworkis good.
Instead, it is sufficient to use the intermediate results as reliable guidance for final accuracy.
Using (approximate) proxies to optimize an objective is referred to as multi-fidelityoptimization(Forresteretal.,2007).
Consequently, designoptimizationis carriedout, basedontheaccuracyachievedafteronlyafewpassesthroughthedataset, reducingthecostsignificantly.
3.
Resultsobtainedatasmallerscale(forsmallernetworks)generalizetolargerones.
Con- sequently, optimizationiscarriedoutfornetworksthatarestructurallysimilar, butwith asmallernumberofblocks, fewerchannels, etc.
Onlyintheendwillweneedtoverify thattheso-foundnetworksalsooffergoodperformanceatscale.
4.
Aspects of the design can be approximately factorized so that it is possible to infer 321 Designing Convolution Network Architectures theireffectonthequalityoftheoutcomesomewhatindependently.
Inotherwords, the optimizationproblemismoderatelyeasy.
Theseassumptionsallowustotestmanynetworkscheaply.
Inparticular, wecansample uniformlyfromthespaceofconfigurationsandevaluatetheirperformance.
Subsequently, we can evaluate the quality of the choice of parameters by reviewing the distribution of error/accuracy that can be achieved with said networks.
Denote by ğ¹â€ğ‘’â€ the cumulative distribution function (CDF) for errors committed by networks of a given design space, drawnusingprobabilitydisribution ğ‘.
Thatis, ğ¹â€ğ‘’,ğ‘â€ d = ef ğ‘ƒ net ğ‘ fğ‘’â€netâ€ ğ‘’g.
(8.8.1) Ourgoalisnowtofindadistribution ğ‘overnetworkssuchthatmostnetworkshaveavery low error rate and where the support of ğ‘ is concise.
Of course, this is computationally infeasibletoperformaccurately.
Weresorttoasampleofnetworks Z d = ef fnet 1 ,...
netğ‘› g (witherrorsğ‘’ 1 ,...,ğ‘’ ğ‘›, respectively)fromğ‘andusetheempirical CDFğ¹Ë†â€ğ‘’, Zâ€instead: ğ‘› 1 ğ¹Ë†â€ğ‘’, Zâ€ = ğ‘› 1â€ğ‘’ ğ‘– ğ‘’â€.
(8.8.2) ğ‘–=1 Wheneverthe CDFforonesetofchoicesmajorizes(ormatches)another CDFitfollows that its choice of parameters is superior (or indifferent).
Accordingly Radosavovic et al.
(2020)experimentedwithasharednetworkbottleneckratio ğ‘˜ ğ‘– = ğ‘˜ forallstagesğ‘– ofthe network.
Thisgetsridofthreeofthefourparametersgoverningthebottleneckratio.
To assesswhetherthis(negatively)affectstheperformanceonecandrawnetworksfromthe constrainedandfromtheunconstraineddistributionandcomparethecorresonding CDFs.
Itturnsoutthatthisconstraintdoesnotaffecttheaccuracyofthedistributionofnetworks at all, as can be seen in the first panel of .8.2.
Likewise, we could choose to pick the same group width ğ‘” ğ‘– = ğ‘” occurring at the various stages of the network.
Again, this doesnotaffectperformance, ascanbeseeninthesecondpanelof.8.2.
Bothsteps combinedreducethenumberoffreeparametersbysix.
t .8.2 Comparingerrorempiricaldistributionfunctionsofdesignspaces.
Any Net isthe A originaldesignspace; Any Net tiesthebottleneckratios, Any Net alsotiesgroup B C widths, Any Net increasesthenetworkdepthacrossstages.
Fromlefttoright: (i)tying D bottleneckratioshasnoeffectonperformance;(ii)tyinggroupwidthshasnoeffecton performance;(iii)increasingnetworkwidths(channels)acrossstagesimproves performance;(iv)increasingnetworkdepthsacrossstagesimprovesperformance.
Figure courtesyof Radosavovicetal.
(2020).
Nextwelookforwaystoreducethemultitudeofpotentialchoicesforwidthanddepthofthe 322 Modern Convolutional Neural Networks stages.
Itisareasonableassumptionthat, aswegodeeper, thenumberofchannelsshould Likewise, itisequallyreasonabletoassumethatasthestagesprogress, theyshouldbecome deeper, i.
e.,ğ‘‘ ğ‘– ğ‘‘ ğ‘– 1 , yielding Any Net X ğ¸ .
Thiscanbeexperimentallyverifiedinthethird andfourthpanelof.8.2, respectively.
8.8.3 Reg Net Theresulting Any Net X designspaceconsistsofsimplenetworksfollowingeasy-to-interpret ğ¸ designprinciples: Sharethebottleneckratioğ‘˜ ğ‘– = ğ‘˜ forallstagesğ‘–; Sharethegroupwidthğ‘” ğ‘– =ğ‘”forallstagesğ‘–; Increasenetworkwidthacrossstages: ğ‘ ğ‘– ğ‘ ğ‘–â€š1 ; Increasenetworkdepthacrossstages: ğ‘‘ ğ‘– ğ‘‘ ğ‘–â€š1 .
This leaves us with a final set of choices: how to pick the specific values for the above parameters of the eventual Any Net X design space.
By studying the best-performing ğ¸ networks from the distribution in Any Net X one can observe the following: the width ğ¸ of the network ideally increases linearly with the block index across the network, i.
e., ğ‘ ğ‘— ğ‘ 0 â€šğ‘ ğ‘ ğ‘—, where ğ‘— istheblockindexandslopeğ‘ ğ‘ > 0.
Giventhatwegettochoosea differentblockwidthonlyperstage, wearriveatapiecewiseconstantfunction, engineered tomatchthisdependence.
Furthermore, experimentsalsoshowthatabottleneckratioof ğ‘˜ =1performsbest, i.
e., weareadvisednottousebottlenecksatall.
Werecommendtheinterestedreaderreviewsfurtherdetailsinthedesignofspecificnet- works for different amounts of computation by perusing Radosavovic et al.
(2020).
For instance, aneffective32-layer Reg Net Xvariantisgivenby ğ‘˜ = 1(nobottleneck),ğ‘” = 16 (groupwidthis16), ğ‘ = 32andğ‘ = 80channelsforthefirstandsecondstage, respec- 1 2 tively, chosen to be ğ‘‘ = 4 and ğ‘‘ = 6 blocks deep.
The astonishing insight from the 1 2 designisthatitstillapplies, evenwheninvestigatingnetworksatalargerscale.
Evenbet- ter, itevenholdsfor Squeeze-and-Excitation(SE)networkdesigns(Reg Net Y)thathavea globalchannelactivation(Huetal.,2018).
class Reg Net X32(Any Net): def __init__(self, lr=0.1, num_classes=10): stem_channels, groups, bot_mul = 32, 16, 1 depths, channels = (4, 6), (32, 80) super().__init__( ((depths[0], channels[0], groups, bot_mul), (depths[1], channels[1], groups, bot_mul)), stem_channels, lr, num_classes) Wecanseethateach Reg Net Xstageprogressivelyreducesresolutionandincreasesoutput channels.
323 Designing Convolution Network Architectures Reg Net X32().
layer_summary((1, 1, 96, 96)) Sequential output shape: torch.
Size([1, 32, 48, 48]) Sequential output shape: torch.
Size([1, 32, 24, 24]) Sequential output shape: torch.
Size([1, 80, 12, 12]) Sequential output shape: torch.
Size([1, 10]) 8.8.4 Training Trainingthe32-layer Reg Net Xonthe Fashion-MNISTdatasetisjustlikebefore.
model = Reg Net X32(lr=0.05) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(96, 96)) trainer.
fit(model, data) 8.8.5 Discussion Withdesirableinductivebiases (assumptionsorpreferences)likelocalityandtranslation invariance(Section7.1)forvision, CNNshavebeenthedominantarchitecturesinthisarea.
This remained the case from Le Netup until Transformers (Section 11.7) (Dosovitskiy et al.,2021, Touvronetal.,2021)startedsurpassing CNNsintermsofaccuracy.
Whilemuch oftherecentprogressintermsofvision Transformerscanbebackportedinto CNNs(Liu etal.,2022), itisonlypossibleatahighercomputationalcost.
Justasimportantly, recent hardwareoptimizations(NVIDIAAmpereand Hopper)haveonlywidenedthegapinfavor of Transformers.
Itisworthnotingthat Transformershaveasignificantlylowerdegreeofinductivebiasto- wardslocalityandtranslationinvariancethan CNNs.
Thatlearnedstructuresprevailedis due, not least, to the availability of large image collections, such as LAION-400m and LAION-5B (Schuhmann et al., 2022) with up to 5 billion images.
Quite surprisingly, some of the more relevant work in this context even includes MLPs (Tolstikhin et al., 2021).
Insum, vision Transformers(Section11.8)bynowleadintermsofstate-of-the-artperfor- manceinlarge-scaleimageclassification, showingthatscalabilitytrumpsinductivebiases 324 Modern Convolutional Neural Networks (Dosovitskiy et al., 2021).
This includes pretraining large-scale Transformers (Section 11.9)withmulti-headself-attention(Section11.5).
Weinvitethereaderstodiveintothese chaptersforamuchmoredetaileddiscussion.
8.8.6 Exercises 1.
Increasethenumberofstagestofour.
Canyoudesignadeeper Reg Net Xthatperforms better? 2.
De-Res Ne Xt-ify Reg Netsbyreplacingthe Res Ne Xtblockwiththe Res Netblock.
How doesyournewmodelperform? 3.
Implementmultipleinstancesofaâ€œVio Netâ€familybyviolatingthedesignprinciplesof Reg Net X.
Howdotheyperform? Whichof(ğ‘‘ ğ‘–,ğ‘ ğ‘–,ğ‘” ğ‘–,ğ‘ ğ‘–)isthemostimportantfactor? 4.
Yourgoalistodesigntheâ€œperfectâ€MLP.
Canyouusethedesignprinciplesintroduced abovetofindgoodarchitectures? Isitpossibletoextrapolatefromsmalltolargenet- works? Discussions135.
135 9 Recurrent Neural Networks Upuntilnow, wehavefocusedprimarilyonfixed-lengthdata.
Whenintroducinglinearand logisticregressionin Chapter3and Chapter4andmultilayerperceptronsin Chapter5, we werehappytoassumethateachfeaturevectorxğ‘–consistedofafixednumberofcomponents ğ‘¥ 1 ,...,ğ‘¥ ğ‘‘, whereeachnumericalfeatureğ‘¥ ğ‘— correspondedtoaparticularattribute.
These datasetsaresometimescalledtabular, becausetheycanbearrangedintables, whereeach exampleğ‘–getsitsownrow, andeachattributegetsitsowncolumn.
Crucially, withtabular data, weseldomassumeanyparticularstructureoverthecolumns.
Subsequently, in Chapter 7, we moved on to image data, where inputs consist of the raw pixelvaluesateachcoordinateinanimage.
Imagedatahardlyfittedthebillofaprotypical tabulardataset.
There, weneeded tocall uponconvolutionalneuralnetworks(CNNs)to handle the hierarchical structure and invariances.
However, our data were still of fixed length.
Every Fashion-MNIST image is represented as a 28 28 grid of pixel values.
Moreover, ourgoalwastodevelopamodelthatlookedatjustoneimageandthenoutputted asingleprediction.
Butwhatshouldwedowhenfacedwithasequenceofimages, asina video, orwhentaskedwithproducingasequentiallystructuredprediction, asinthecaseof imagecaptioning? Agreatmanylearningtasksrequiredealingwithsequentialdata.
Imagecaptioning, speech synthesis, andmusicgenerationallrequirethatmodelsproduceoutputsconsistingofse- quences.
In other domains, such as time series prediction, video analysis, and musical informationretrieval, amodelmustlearnfrominputsthataresequences.
Thesedemands oftenarisesimultaneously: taskssuchastranslatingpassagesoftextfromonenaturallan- guage to another, engaging in dialogue, or controlling a robot, demand that models both ingestandoutputsequentiallystructureddata.
Recurrentneuralnetworks(RNNs)aredeeplearningmodelsthatcapturethedynamicsof sequencesviarecurrentconnections, whichcanbethoughtofascyclesinthenetworkof nodes.
Thismightseemcounterintuitiveatfirst.
Afterall, itisthefeedforwardnatureof neural networks that makes the order of computation unambiguous.
However, recurrent edgesaredefinedinaprecisewaythatensuresthatnosuchambiguitycanarise.
Recurrent neuralnetworksareunrolled acrosstimesteps(orsequencesteps), withthesameunder- lying parameters applied at each step.
While the standard connections are applied syn- chronously to propagate each layerâ€™s activations to the subsequent layer at the same time step, therecurrentconnectionsaredynamic, passinginformationacrossadjacenttimesteps.
As the unfolded view in .1 reveals, RNNs can be thought of as feedforward neural 325 326 Recurrent Neural Networks networkswhereeachlayerâ€™sparameters(bothconventionalandrecurrent)aresharedacross timesteps.
t .1 Ontheleftrecurrentconnectionsaredepictedviacyclicedges.
Ontheright, weunfold the RNNovertimesteps.
Here, recurrentedgesspanadjacenttimesteps, while conventionalconnectionsarecomputedsynchronously.
Likeneuralnetworksmorebroadly, RNNshavealongdiscipline-spanninghistory, origi- natingasmodelsofthebrainpopularizedbycognitivescientistsandsubsequentlyadopted aspracticalmodelingtoolsemployedbythemachinelearningcommunity.
Aswedofor deeplearningmorebroadly, inthisbookweadoptthemachinelearningperspective, focus- ingon RNNsaspracticaltoolsthatrosetopopularityinthe2010sowingtobreakthrough results on such diverse tasks as handwriting recognition (Graves et al., 2008), machine translation(Sutskeveretal.,2014), andrecognizingmedicaldiagnoses(Liptonetal.,2016).
Wepointthereaderinterestedinmorebackgroundmaterialtoapubliclyavailablecompre- hensivereview(Liptonetal.,2015).
Wealsonotethatsequentialityisnotuniqueto RNNs.
Forexample, the CNNsthatwealreadyintroducedcanbeadaptedtohandledataofvarying length, e.
g., imagesofvaryingresolution.
Moreover, RNNshaverecentlycededconsider- ablemarketshareto Transformermodels, whichwillbecoveredin Chapter11.
However, RNNsrosetoprominenceasthedefaultmodelsforhandlingcomplexsequentialstructure indeeplearning, andremainstaplemodelsforsequentialmodelingtothisday.
Thestories of RNNsandofsequencemodelingareinextricablylinked, andthisisasmuchachapter aboutthe ABCsofsequencemodelingproblemsasitisachapterabout RNNs.
One key insight paved the way for a revolution in sequence modeling.
While the inputs andtargetsformanyfundamentaltasksinmachinelearningcannoteasilyberepresented as fixed-length vectors, they can often nevertheless be represented as varying-length se- quencesoffixed-lengthvectors.
Forexample, documentscanberepresentedassequences of words; medical records can often be represented as sequences of events (encounters, medications, procedures, labtests, diagnoses); videoscanberepresentedasvarying-length sequencesofstillimages.
Whilesequencemodelshavepoppedupinnumerousapplicationareas, basicresearchinthe areahasbeendrivenpredominantlybyadvancesoncoretasksinnaturallanguageprocess- ing.
Thus, throughoutthischapter, wewillfocusourexpositionandexamplesontextdata.
If you get the hang of these examples, then applying the models to other data modalities shouldberelativelystraightforward.
Inthenextfewsections, weintroducebasicnotation forsequencesandsomeevaluationmeasuresforassessingthequalityofsequentiallystruc- turedmodeloutputs.
Afterthat, wediscussbasicconceptsofalanguagemodelandusethis 327 Workingwith Sequences discussiontomotivateourfirst RNNmodels.
Finally, wedescribethemethodforcalculat- inggradientswhenbackpropagatingthrough RNNsandexploresomechallengesthatare oftenencounteredwhentrainingsuchnetworks, motivatingthemodern RNNarchitectures thatwillfollowin Chapter10.
9.1 Working with Sequences Upuntilnow, wehavefocusedonmodelswhoseinputsconsistedofasinglefeaturevector x 2 Rğ‘‘ .
Themainchangeofperspectivewhendevelopingmodelscapableofprocessing sequences is that we now focus on inputs that consist of an ordered list of feature vec- tors x 1 ,..., xğ‘‡, where each feature vector xğ‘¡ is indexed by a time step ğ‘¡ 2 Zâ€š lying in Rğ‘‘ .
Somedatasetsconsistofasinglemassivesequence.
Consider, forexample, theextremely longstreamsofsensorreadingsthatmightbeavailabletoclimatescientists.
Insuchcases, we might create training datasets by randomly sampling subsequences of some predeter- mined length.
More often, our data arrives as a collection of sequences.
Consider the followingexamples: (i)acollectionofdocuments, eachrepresentedasitsownsequenceof words, andeachhavingitsownlengthğ‘‡ ğ‘–;(ii)sequencerepresentationofpatientstaysinthe hospital, whereeachstayconsistsofanumberofeventsandthesequencelengthdepends roughlyonthelengthofthestay.
Previously, whendealingwithindividualinputs, weassumedthattheyweresampledinde- pendentlyfromthesameunderlyingdistribution ğ‘ƒâ€ğ‘‹â€.
Whilewestillassumethatentire sequences (e.
g., entire documents or patient trajectories) are sampled independently, we cannotassumethatthedataarrivingateachtimestepareindependentofeachother.
For example, thewordsthatlikelytoappearlaterinadocumentdependheavilyonwordsoc- curringearlierinthedocument.
Themedicineapatientislikelytoreceiveonthe10thday ofahospitalvisitdependsheavilyonwhattranspiredinthepreviousninedays.
This should come as no surprise.
If we did not believe that the elements in a sequence wererelated, wewouldnothavebotheredtomodelthemasasequenceinthefirstplace.
Considertheusefulnessoftheauto-fillfeaturesthatarepopularonsearchtoolsandmodern emailclients.
Theyareusefulpreciselybecauseitisoftenpossibletopredict(imperfectly, but better than random guessing) what the likely continuations of a sequence might be, givensomeinitialprefix.
Formostsequencemodels, wedonotrequireindependence, or evenstationarity, ofoursequences.
Instead, werequireonlythatthesequencesthemselves aresampledfromsomefixedunderlyingdistributionoverentiresequences.
Thisflexibleapproachallowsforsuchphenomena as(i) documents lookingsignificantly differentatthebeginningthanattheend; or(ii)patientstatusevolvingeithertowardsrecov- eryortowardsdeathoverthecourseofahospitalstay; or(iii)customertasteevolvinginpre- dictablewaysoverthecourseofcontinuedinteractionwitharecommendersystem.
328 Recurrent Neural Networks Wesometimeswishtopredictafixedtargetğ‘¦givensequentiallystructuredinput(e.
g., sen- timentclassificationbasedonamoviereview).
Atothertimes, wewishtopredictasequen- tiallystructuredtarget(ğ‘¦ 1 times, ourgoalistopredictsequentiallystructuredtargetsbasedonsequentiallystructured inputs (e.
g., machine translation or video captioning).
Such sequence-to-sequence tasks take two forms: (i) aligned: where the input at each time step aligns with a correspond- ingtarget(e.
g., partofspeechtagging); (ii)unaligned: wheretheinputandtargetdonot necessarilyexhibitastep-for-stepcorrespondence(e.
g., machinetranslation).
Beforeweworryabouthandlingtargetsofanykind, wecantacklethemoststraightforward problem: unsuperviseddensitymodeling(alsocalledsequencemodeling).
Here, givena collectionofsequences, ourgoalistoestimatetheprobabilitymassfunctionthattellsus howlikelywearetoseeanygivensequence, i.
e., ğ‘â€x 1 ,..., xğ‘‡ â€.
%matplotlib inline import torch from torch import nn from d2l import torch as d2l 9.1.1 Autoregressive Models Beforeintroducingspecializedneuralnetworksdesignedtohandlesequentiallystructured data, letâ€™s take a look at some actual sequence data and build up some basic intuitions and statistical tools.
In particular, we will focus on stock price data from the FTSE 100 index(.1.1).
Ateachtimestepğ‘¡ 2 Zâ€š , weobservetheprice,ğ‘¥ ğ‘¡, oftheindexatthat time.
t .1.1 FTSE100indexoverabout30years.
Nowsupposethatatraderwouldliketomakeshort-termtrades, strategicallygettinginto or out of the index, depending on whether they believe that it will rise or decline in the subsequenttimestep.
Absentanyotherfeatures(news, financialreportingdata, etc.), the 329 Workingwith Sequences only available signal for predicting the subsequent value is the history of prices to date.
Thetraderisthusinterestedinknowingtheprobabilitydistribution overpricesthattheindexmighttakeinthesubsequenttimestep.
Whileestimatingtheentire distributionoveracontinuouslyvaluedrandomvariablecanbedifficult, thetraderwould behappytofocusonafewkeystatisticsofthedistribution, particularlytheexpectedvalue andthevariance.
Onesimplestrategyforestimatingtheconditionalexpectation wouldbetoapplyalinearregressionmodel(recall Section3.1).
Suchmodelsthatregress the value of a signal on the previous values of that same signal are naturally called au- toregressivemodels.
Thereisjustonemajorproblem: thenumberofinputs,ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 varies, dependingonğ‘¡.
Inotherwords, thenumberofinputsincreaseswiththeamountof data that we encounter.
Thus if we want to treat our historical data as a training set, we are left with the problem that each example has a different number of features.
Much of whatfollowsinthischapterwillrevolvearoundtechniquesforovercomingthesechallenges when engaging in such autoregressive modeling problems where the object of interest is ğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 â€orsomestatistic(s)ofthisdistribution.
Afewstrategiesrecurfrequently.
Firstofall, wemightbelievethatalthoughlongsequences ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 areavailable, itmaynotbenecessarytolookbacksofarinthehistorywhen predicting the near future.
In this case we might content ourselves to condition on some window of length ğœ and only use ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ ğ‘¡ ğœ observations.
The immediate benefit is thatnowthenumberofargumentsisalwaysthesame, atleastforğ‘¡ > ğœ.
Thisallowsusto trainanylinearmodelordeepnetworkthatrequiresfixed-lengthvectorsasinputs.
Second, we might develop models that maintain some summary â„ ğ‘¡ of the past observations (see .1.2) and at the same time update â„ ğ‘¡ in addition to the prediction ğ‘¥Ë†ğ‘¡.
This leads to models that estimate not only ğ‘¥ ğ‘¡ with ğ‘¥Ë†ğ‘¡ = ğ‘ƒâ€ğ‘¥ ğ‘¡ j â„ ğ‘¡ â€ but also updates of the form â„ ğ‘¡ = ğ‘”â€â„ ğ‘¡ 1 ,ğ‘¥ ğ‘¡ 1 â€.
Sinceâ„ ğ‘¡isneverobserved, thesemodelsarealsocalledlatentautoregressive models.
t .1.2 Alatentautoregressivemodel.
Toconstructtrainingdatafromhistoricaldata, onetypicallycreatesexamplesbysampling windows randomly.
In general, we do not expect time to stand still.
However, we often assumethatwhilethespecificvaluesofğ‘¥ ğ‘¡ mightchange, thedynamicsaccordingtowhich eachsubsequentobservationisgeneratedgiventhepreviousobservationsdonot.
Statisti- cianscalldynamicsthatdonotchangestationary.
330 Recurrent Neural Networks 9.1.2 Sequence Models Sometimes, especiallywhenworkingwithlanguage, wewishtoestimatethejointprobabil- ityofanentiresequence.
Thisisacommontaskwhenworkingwithsequencescomposed ofdiscretetokens, suchaswords.
Generally, theseestimatedfunctionsarecalledsequence models and for natural language data, they are called language models.
The field of se- quencemodelinghasbeendrivensomuchbynaturallanguageprocessing, thatweoften describe sequence models as â€œlanguage modelsâ€, even when dealing with non-language data.
Languagemodelsproveusefulforallsortsofreasons.
Sometimeswewanttoevalu- atethelikelihoodofsentences.
Forexample, wemightwishtocomparethenaturalnessof twocandidateoutputsgeneratedbyamachinetranslationsystemorbyaspeechrecognition system.
Butlanguagemodelinggivesusnotonlythecapacitytoevaluatelikelihood, but theabilitytosamplesequences, andeventooptimizeforthemostlikelysequences.
Whilelanguagemodelingmightnot, atfirstglance, looklikeanautoregressiveproblem, we can reduce language modeling to autoregressive prediction by decomposing the joint densityofasequence ğ‘â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘‡ â€ intotheproductofconditionaldensitiesinaleft-to- rightfashionbyapplyingthechainruleofprobability: ğ‘‡ ğ‘¡=2 Note that if we are working with discrete signals such as words, then the autoregressive modelmustbeaprobabilisticclassifier, outputtingafullprobabilitydistributionoverthe vocabularyforwhateverwordwillcomenext, giventheleftwardscontext.
Markov Models Now suppose that we wish to employ the strategy mentioned above, where we condition ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 .
Wheneverwecanthrowawaythehistorybeyondthepreviousğœstepswithout anylossinpredictivepower, wesaythatthesequencesatisfiesa Markovcondition, i.
e., that thefutureisconditionallyindependentofthepast, giventherecenthistory.
Whenğœ = 1, wesaythatthedataischaracterizedbyafirst-order Markovmodel, andwhen ğœ = ğ‘˜, we say that the data is characterized by a ğ‘˜th-order Markov model.
For when the first-order Markovconditionholds(ğœ =1)thefactorizationofourjointprobabilitybecomesaproduct ofprobabilitiesofeachwordgiventhepreviousword: ğ‘‡ ğ‘¡=2 Weoftenfinditusefultoworkwithmodelsthatproceedasthougha Markovconditionwere satisfied, evenwhenweknowthatthisisonlyapproximatelytrue.
Withrealtextdocuments wecontinuetogaininformationasweincludemoreandmoreleftwardscontext.
Butthese gains diminish rapidly.
Thus, sometimes we compromise, obviating computational and statistical difficulties by training models whose validity depends on a ğ‘˜th-order Markov condition.
Even todayâ€™s massive RNN- and Transformer-based language models seldom incorporatemorethanthousandsofwordsofcontext.
331 Workingwith Sequences Withdiscretedata, atrue Markovmodelsimplycountsthenumberoftimesthateachword has occurred in each context, producing the relative frequency estimate of ğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 â€.
Wheneverthedataassumesonlydiscretevalues(asinlanguage), themostlikelysequence ofwordscanbecomputedefficientlyusingdynamicprogramming.
The Orderof Decoding Youmaybewonderingwhywerepresentedthefactorizationofatextsequenceğ‘ƒâ€ğ‘¥ 1 ,...,ğ‘¥ ğ‘‡ â€ as a left-to-right chain of conditional probabilities.
Why not right-to-left or some other, seeminglyrandomorder? Inprinciple, thereisnothingwrongwithunfoldingğ‘ƒâ€ğ‘¥ 1 ,...,ğ‘¥ ğ‘‡ â€ inreverseorder.
Theresultisavalidfactorization: 1 ğ‘¡=ğ‘‡ 1 However, there are many reasons why factorizing text in the same direction in which we readit(left-to-rightformostlanguages, butright-to-leftfor Arabicand Hebrew)ispreferred forthetaskoflanguagemodeling.
First, thisisjustamorenaturaldirectionforustothink about.
After all we all read text every day, and this process is guided by our ability to anticipatewhichwordsandphrasesarelikelytocomenext.
Justthinkofhowmanytimes youhavecompletedsomeoneelseâ€™ssentence.
Thus, evenifwehadnootherreasontoprefer suchin-orderdecodings, theywouldbeusefulifonlybecausewehavebetterintuitionsfor whatshouldbelikelywhenpredictinginthisorder.
Second, by factorizing in order, we can assign probabilities to arbitrarily long sequences usingthesamelanguagemodel.
Toconvertaprobabilityoversteps1throughğ‘¡intoonethat extendstowordğ‘¡â€š1wesimplymultiplybytheconditionalprobabilityoftheadditionalto- Third, wehavestrongerpredictivemodelsforpredictingadjacentwordsthanwordsatar- bitraryotherlocations.
Whileallordersoffactorizationarevalid, theydonotnecessarily allrepresentequallyeasypredictivemodelingproblems.
Thisistruenotonlyforlanguage, butforotherkindsofdataaswell, e.
g., whenthedataiscausallystructured.
Forexample, webelievethatfutureeventscannotinfluencethepast.
Hence, ifwechangeğ‘¥ ğ‘¡, wemaybe abletoinfluencewhathappensforğ‘¥ ğ‘¡â€š1 goingforwardbutnottheconverse.
Thatis, ifwe changeğ‘¥ ğ‘¡, thedistributionoverpasteventswillnotchange.
Insomecontexts, thismakes iteasiertopredict ğ‘ƒâ€ğ‘¥ ğ‘¡â€š1 j ğ‘¥ ğ‘¡ â€ thantopredict ğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡â€š1 â€.
Forinstance, insomecases, wecanfind ğ‘¥ ğ‘¡â€š1 = ğ‘“â€ğ‘¥ ğ‘¡ â€ â€šğœ– forsomeadditivenoise ğœ–, whereastheconverseisnot true (Hoyeretal.,2009).
Thisisgreatnews, sinceitistypicallytheforwarddirectionthatwe areinterestedinestimating.
Thebookby Petersetal.
(2017)containsmoreonthistopic.
Webarelyscratchthesurfaceofit.
9.1.3 Training Before we focus our attention on text data, letâ€™s first try this out with some continuous- valuedsyntheticdata.
Here, our1000syntheticdatawillfollowthetrigonometricsinfunction, appliedto0.01 332 Recurrent Neural Networks timesthetimestep.
Tomaketheproblemalittlemoreinteresting, wecorrupteachsample withadditivenoise.
Fromthissequenceweextracttrainingexamples, eachconsistingof featuresandalabel.
class Data(d2l.
Data Module): def __init__(self, batch_size=16, T=1000, num_train=600, tau=4): self.
save_hyperparameters() self.
time = torch.
arange(1, T + 1, dtype=torch.
float32) data = Data() d2l.
plot(data.
time, data.
x, 'time', 'x', xlim=[1, 1000], figsize=(6, 3)) To begin, we try a model that acts as if the data satisfied a ğœth-order Markov condition, andthuspredictsğ‘¥ ğ‘¡ usingonlythepastğœobservations.
Thusforeachtimestepwehavean examplewithlabelğ‘¦ =ğ‘¥ ğ‘¡ andfeaturesxğ‘¡ = Â»ğ‘¥ ğ‘¡ ğœ ,...,ğ‘¥ ğ‘¡ 1 â€¦.
Theastutereadermighthave noticedthatthisresultsin1000 ğœexamples, sincewelacksufficienthistoryforğ‘¦ 1 ,...,ğ‘¦ ğœ.
Whilewecouldpadthefirstğœsequenceswithzeros, tokeepthingssimple, wedropthem fornow.
Theresultingdatasetcontainsğ‘‡ ğœexamples, whereeachinputtothemodelhas sequencelengthğœ.
Wecreateadataiteratoronthefirst600examples, coveringaperiodof thesinfunction.
@d2l.
add_to_class(Data) def get_dataloader(self, train): features = [self.
x[i : self.
T-self.
tau+i] for i in range(self.
tau)] self.
features = torch.
stack(features, 1) self.
labels = self.
x[self.
tau:].
reshape((-1, 1)) i = slice(0, self.
num_train) if train else slice(self.
num_train, None) return self.
get_tensorloader([self.
features, self.
labels], train, i) Inthisexampleourmodelwillbeastandardlinearregression.
model = d2l.
Linear Regression(lr=0.01) trainer = d2l.
Trainer(max_epochs=5) trainer.
fit(model, data) 333 Workingwith Sequences 9.1.4 Prediction Toevaluateourmodel, wefirstcheckhowwellitperformsatone-step-aheadprediction.
onestep_preds = model(data.
features).
detach().
numpy() d2l.
plot(data.
time[data.
tau:], [data.
labels, onestep_preds], 'time', 'x', legend=['labels', '1-step preds'], figsize=(6, 3)) Thesepredictionslookgood, evenneartheendatğ‘¡ =1000.
Butwhatifweonlyobservedsequencedataupuntiltimestep604(n_train + tau)and wishedtomakepredictionsseveralstepsintothefuture? Unfortunately, wecannotdirectly computetheone-step-aheadpredictionfortimestep609, becausewedonotknowthecor- respondinginputs, havingseenonlyuptoğ‘¥ .
Wecanaddressthisproblembypluggingin 604 ourearlierpredictionsasinputstoourmodelformakingsubsequentpredictions, projecting forward, onestepatatime, untilreachingthedesiredtimestep: ğ‘¥Ë† = ğ‘“â€ğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥ â€, 605 601 602 603 604 ğ‘¥Ë† = ğ‘“â€ğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥Ë† â€, 606 602 603 604 605 ğ‘¥Ë† = ğ‘“â€ğ‘¥ ,ğ‘¥ ,ğ‘¥Ë† ,ğ‘¥Ë† â€, 607 603 604 605 606 ğ‘¥Ë† = ğ‘“â€ğ‘¥ ,ğ‘¥Ë† ,ğ‘¥Ë† ,ğ‘¥Ë† â€, (9.1.6) 608 604 605 606 607 ğ‘¥Ë† = ğ‘“â€ğ‘¥Ë† ,ğ‘¥Ë† ,ğ‘¥Ë† ,ğ‘¥Ë† â€, 609 605 606 607 608 .
.
.
Generally, foranobservedsequenceğ‘¥ 1 ,...,ğ‘¥ ğ‘¡, itspredictedoutputğ‘¥Ë†ğ‘¡â€šğ‘˜ attimestepğ‘¡â€šğ‘˜ 334 Recurrent Neural Networks iscalledthe ğ‘˜-step-aheadprediction.
Sincewehaveobserveduptoğ‘¥ , its ğ‘˜-step-ahead 604 predictionisğ‘¥Ë† 604â€šğ‘˜.
Inotherwords, wewillhavetokeeponusingourownpredictionsto makemultistep-aheadpredictions.
Letâ€™sseehowwellthisgoes.
multistep_preds = torch.
zeros(data.
T) multistep_preds[:] = data.
x for i in range(data.
num_train + data.
tau, data.
T): multistep_preds[i] = model( multistep_preds[i - data.
tau: i].
reshape((1, -1))) multistep_preds = multistep_preds.
detach().
numpy() [onestep_preds, multistep_preds[data.
num_train+data.
tau:]], 'time', 'x', legend=['1-step preds', 'multistep preds'], figsize=(6, 3)) Unfortunately, inthiscasewefailspectacularly.
Thepredictionsdecaytoaconstantpretty quicklyafterafewsteps.
Whydidthealgorithmperformsomuchworsewhenpredicting furtherintothefuture? Ultimately, thisisdowntothefactthaterrorsbuildup.
Letâ€™ssay thatafterstep1wehavesomeerrorğœ– = ğœ–Â¯.
Nowtheinput forstep2isperturbedbyğœ– , 1 1 hencewesuffersomeerrorintheorderofğœ– =ğœ–Â¯â€šğ‘ğœ– forsomeconstantğ‘, andsoon.
The 2 1 predictions can diverge rapidly from the true observations.
You may already be familiar withthiscommonphenomenon.
Forinstance, weatherforecastsforthenext24hourstend tobeprettyaccuratebutbeyondthat, accuracydeclinesrapidly.
Wewilldiscussmethods forimprovingthisthroughoutthischapterandbeyond.
Letâ€™stakeacloserlookatthedifficultiesinğ‘˜-step-aheadpredictionsbycomputingpredic- tionsontheentiresequenceforğ‘˜ =1,4,16,64.
def k_step_pred(k): features = [] for i in range(data.
tau): features.
append(data.
x[i : i+data.
T-data.
tau-k+1]) # The (i+tau)-th element stores the (i+1)-step-ahead predictions for i in range(k): preds = model(torch.
stack(features[i : i+data.
tau], 1)) features.
append(preds.
reshape(-1)) return features[data.
tau:] 335 Workingwith Sequences steps = (1, 4, 16, 64) preds = k_step_pred(steps[-1]) d2l.
plot(data.
time[data.
tau+steps[-1]-1:], [preds[k - 1].
detach().
numpy() for k in steps], 'time', 'x', legend=[f'{k}-step preds' for k in steps], figsize=(6, 3)) Thisclearlyillustrateshowthequalityofthepredictionchangesaswetrytopredictfurther intothefuture.
Whilethe4-step-aheadpredictionsstilllookgood, anythingbeyondthatis almostuseless.
9.1.5 Summary There is quite a difference in difficulty between interpolation and extrapolation.
Conse- quently, ifyouhaveasequence, alwaysrespectthetemporalorderofthedatawhentraining, i.
e., nevertrainonfuturedata.
Giventhiskindofdata, sequencemodelsrequirespecialized statisticaltoolsforestimation.
Twopopularchoicesareautoregressivemodelsandlatent- variableautoregressivemodels.
Forcausalmodels(e.
g., timegoingforward), estimating the forward direction is typically a lot easier than the reverse direction.
For an observed sequenceuptotimestepğ‘¡, itspredictedoutputattimestepğ‘¡â€šğ‘˜istheğ‘˜-step-aheadpredic- tion.
Aswepredictfurtherintimebyincreasing ğ‘˜, theerrorsaccumulateandthequality ofthepredictiondegrades, oftendramatically.
9.1.6 Exercises 1.
Improvethemodelintheexperimentofthissection.
1.
Incorporatemorethanthepastfourobservations? Howmanydoyoureallyneed? 2.
Howmanypastobservationswouldyouneediftherewasnonoise? Hint: youcan writesinandcosasadifferentialequation.
3.
Canyouincorporateolderobservationswhilekeepingthetotalnumberoffeatures constant? Doesthisimproveaccuracy? Why? 4.
Changetheneuralnetworkarchitectureandevaluatetheperformance.
Youmaytrain thenewmodelwithmoreepochs.
Whatdoyouobserve? 336 Recurrent Neural Networks 2.
An investor wants to find a good security to buy.
They look at past returns to decide whichoneislikelytodowell.
Whatcouldpossiblygowrongwiththisstrategy? 3.
Doescausalityalsoapplytotext? Towhichextent? 4.
Giveanexampleforwhenalatentautoregressivemodelmightbeneededtocapturethe dynamicofthedata.
Discussions136.
136 9.2 Converting Raw Text into Sequence Data Throughoutthisbook, wewilloftenworkwithtextdatarepresentedassequencesofwords, characters, orwordpieces.
Togetgoing, wewillneedsomebasictoolsforconvertingraw text into sequences of the appropriate form.
Typical preprocessing pipelines execute the followingsteps: 1.
Loadtextasstringsintomemory.
2.
Splitthestringsintotokens(e.
g., wordsorcharacters).
3.
Build a vocabulary dictionary to associate each vocabulary element with a numerical index.
4.
Convertthetextintosequencesofnumericalindices.
import collections import random import re import torch from d2l import torch as d2l 9.2.1 Readingthe Dataset Here, wewillworkwith H.
G.
Wellsâ€™The Time Machine137, abookcontainingjustover 137 30,000words.
Whilerealapplicationswilltypicallyinvolvesignificantlylargerdatasets, this is sufficient to demonstrate the preprocessing pipeline.
The following _download methodreadstherawtextintoastring.
class Time Machine(d2l.
Data Module): #@save """The Time Machine dataset.""" def _download(self): fname = d2l.
download(d2l.
DATA_URL + 'timemachine.
txt', self.
root, '090b5e7e70c295757f55df93cb0a180b9691891a') with open(fname) as f: return f.
read() (continuesonnextpage) 337 Converting Raw Textinto Sequence Data (continuedfrompreviouspage) data = Time Machine() raw_text = data._download() raw_text[:60] 'The Time Machine, by H.
G.
Wells [1898]nnnnn Innn The Time Tra' Forsimplicity, weignorepunctuationandcapitalizationwhenpreprocessingtherawtext.
@d2l.
add_to_class(Time Machine) #@save def _preprocess(self, text): return re.
sub('[^A-Za-z]+', ' ', text).
lower() text = data._preprocess(raw_text) text[:60] 'the time machine by h g wells i the time traveller for so it' 9.2.2 Tokenization Tokens are the atomic (indivisible) units of text.
Each time step corresponds to 1 token, butwhatpreciselyconstitutesatokenisadesignchoice.
Forexample, wecouldrepresent thesentenceâ€œBabyneedsanewpairofshoesâ€asasequenceof7words, wherethesetof allwordscomprisealargevocabulary(typicallytensorhundredsofthousandsofwords).
Or we would represent the same sentence as a much longer sequence of 30 characters, usingamuchsmallervocabulary(thereareonly256distinct ASCIIcharacters).
Below, we tokenizeourpreprocessedtextintoasequenceofcharacters.
@d2l.
add_to_class(Time Machine) #@save def _tokenize(self, text): return list(text) tokens = data._tokenize(text) ','.
join(tokens[:30]) 't, h, e, , t, i, m, e, , m, a, c, h, i, n, e, , b, y, , h, , g, , w, e, l, l, s, ' 9.2.3 Vocabulary Thesetokensarestillstrings.
However, theinputstoourmodelsmustultimatelyconsistof numericalinputs.
Next, weintroduceaclassforconstructingvocabularies, i.
e., objectsthat associateeachdistincttokenvaluewithauniqueindex.
First, wedeterminethesetofunique tokensinourtrainingcorpus.
Wethenassignanumericalindextoeachuniquetoken.
Rare vocabularyelementsareoftendroppedforconvenience.
Wheneverweencounteratokenat trainingortesttimethathadnotbeenpreviouslyseenorwasdroppedfromthevocabulary, werepresentitbyaspecialâ€œ<unk>â€token, signifyingthatthisisanunknownvalue.
338 Recurrent Neural Networks class Vocab: #@save """Vocabulary for text.""" def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]): # Flatten a 2D list if needed if tokens and isinstance(tokens[0], list): tokens = [token for line in tokens for token in line] # Count token frequencies counter = collections.
Counter(tokens) self.
token_freqs = sorted(counter.
items(), key=lambda x: x[1], reverse=True) # The list of unique tokens self.
idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [ token for token, freq in self.
token_freqs if freq >= min_freq]))) self.
token_to_idx = {token: idx for idx, token in enumerate(self.
idx_to_token)} def __len__(self): return len(self.
idx_to_token) def __getitem__(self, tokens): if not isinstance(tokens, (list, tuple)): return self.
token_to_idx.
get(tokens, self.
unk) return [self.__getitem__(token) for token in tokens] def to_tokens(self, indices): if hasattr(indices, '__len__') and len(indices) > 1: return [self.
idx_to_token[int(index)] for index in indices] return self.
idx_to_token[indices] @property def unk(self): # Index for the unknown token return self.
token_to_idx['<unk>'] We now construct a vocabulary for our dataset, converting the sequence of strings into a listofnumericalindices.
Notethatwehavenotlostanyinformationandcaneasilyconvert ourdatasetbacktoitsoriginal(string)representation.
vocab = Vocab(tokens) indices = vocab[tokens[:10]] print('indices:', indices) print('words:', vocab.
to_tokens(indices)) indices: [21, 9, 6, 0, 21, 10, 14, 6, 0, 14] words: ['t', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm'] 9.2.4 Putting It All Together Using the above classes and methods, we package everything into the following build methodofthe Time Machineclass, whichreturnscorpus, alistoftokenindices, andvocab, the vocabulary of The Time Machine corpus.
The modifications we did here are: (i) we tokenizetextintocharacters, notwords, tosimplifythetraininginlatersections;(ii)corpus 339 Converting Raw Textinto Sequence Data isasinglelist, notalistoftokenlists, sinceeachtextlinein The Time Machinedatasetis notnecessarilyasentenceorparagraph.
@d2l.
add_to_class(Time Machine) #@save def build(self, raw_text, vocab=None): tokens = self._tokenize(self._preprocess(raw_text)) if vocab is None: vocab = Vocab(tokens) corpus = [vocab[token] for token in tokens] return corpus, vocab corpus, vocab = data.
build(raw_text) len(corpus), len(vocab) (173428, 28) 9.2.5 Exploratory Language Statistics Usingtherealcorpusandthe Vocabclassdefinedoverwords, wecaninspectbasicstatistics concerningworduseinourcorpus.
Below, weconstructavocabularyfromwordsusedin The Time Machineandprintthetenmostfrequentlyoccurringofthem.
words = text.
split() vocab = Vocab(words) vocab.
token_freqs[:10] [('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)] Notethatthetenmostfrequentwordsarenotallthatdescriptive.
Youmightevenimagine that we might see a very similar list if we had chosen any book at random.
Articles like â€œtheâ€andâ€œaâ€, pronounslikeâ€œiâ€andâ€œmyâ€, andprepositionslikeâ€œofâ€,â€œtoâ€, andâ€œinâ€occur often because they serve common syntactic roles.
Such words that are common but not particularly descriptive are often called stop words and, in previous generations of text classifiersbasedonso-calledbag-of-wordsrepresentations, theyweremostoftenfiltered out.
However, theycarrymeaninganditisnotnecessarytofilterthemoutwhenworking with modern RNN- and Transformer-based neural models.
If you look further down the list, you will notice that word frequency decays quickly.
The 10th most frequent word is lessthan1 5ascommonasthemostpopular.
Wordfrequencytendstofollowapowerlaw distribution(specificallythe Zipfian)aswegodowntheranks.
Togetabetteridea, weplot thefigureofthewordfrequency.
340 Recurrent Neural Networks freqs = [freq for token, freq in vocab.
token_freqs] d2l.
plot(freqs, xlabel='token: x', ylabel='frequency: n(x)', xscale='log', yscale='log') Afterdealingwiththefirstfewwordsasexceptions, alltheremainingwordsroughlyfollow astraightlineonalogâ€“logplot.
Thisphenomenoniscapturedby Zipfâ€™slaw, whichstates thatthefrequencyğ‘› ğ‘– oftheğ‘–thmostfrequentwordis: 1 ğ‘› ğ‘– / ğ‘–ğ›¼ , (9.2.1) whichisequivalentto logğ‘› ğ‘– = ğ›¼logğ‘–â€šğ‘, (9.2.2) whereğ›¼istheexponentthatcharacterizesthedistributionandğ‘isaconstant.
Thisshould alreadygiveuspauseforthoughtifwewanttomodelwordsbycountingstatistics.
After all, we will significantly overestimate the frequency of the tail, also known as the infre- quentwords.
Butwhatabouttheotherwordcombinations, suchastwoconsecutivewords (bigrams), threeconsecutivewords(trigrams), andbeyond? Letâ€™sseewhetherthebigram frequencybehavesinthesamemannerasthesingleword(unigram)frequency.
bigram_tokens = ['--'.
join(pair) for pair in zip(words[:-1], words[1:])] bigram_vocab = Vocab(bigram_tokens) bigram_vocab.
token_freqs[:10] [('of--the', 309), ('in--the', 169), ('i--had', 130), ('i--was', 112), ('and--the', 109), ('the--time', 102), ('it--was', 99), ('to--the', 85), ('as--i', 78), ('of--a', 73)] Onethingisnotablehere.
Outofthetenmostfrequentwordpairs, ninearecomposedof bothstopwordsandonlyoneisrelevanttotheactualbookâ€”â€œthetimeâ€.
Furthermore, letâ€™s seewhetherthetrigramfrequencybehavesinthesamemanner.
341 Converting Raw Textinto Sequence Data trigram_tokens = ['--'.
join(triple) for triple in zip( words[:-2], words[1:-1], words[2:])] trigram_vocab = Vocab(trigram_tokens) trigram_vocab.
token_freqs[:10] [('the--time--traveller', 59), ('the--time--machine', 30), ('the--medical--man', 24), ('it--seemed--to', 16), ('it--was--a', 15), ('here--and--there', 15), ('seemed--to--me', 14), ('i--did--not', 14), ('i--saw--the', 13), ('i--began--to', 13)] Now, letâ€™s visualize the token frequency among these three models: unigrams, bigrams, andtrigrams.
bigram_freqs = [freq for token, freq in bigram_vocab.
token_freqs] trigram_freqs = [freq for token, freq in trigram_vocab.
token_freqs] d2l.
plot([freqs, bigram_freqs, trigram_freqs], xlabel='token: x', ylabel='frequency: n(x)', xscale='log', yscale='log', legend=['unigram', 'bigram', 'trigram']) Thisfigureisquiteexciting.
First, beyondunigramwords, sequencesofwordsalsoappear tobefollowing Zipfâ€™slaw, albeitwithasmallerexponent ğ›¼ in(9.2.1), dependingonthe sequencelength.
Second, thenumberofdistinct ğ‘›-gramsisnotthatlarge.
Thisgivesus hope that there is quite a lot of structure in language.
Third, many ğ‘›-grams occur very rarely.
This makes certain methods unsuitable for language modeling and motivates the useofdeeplearningmodels.
Wewilldiscussthisinthenextsection.
9.2.6 Summary Text is among the most common forms of sequence data encountered in deep learning.
Commonchoicesforwhatconstitutesatokenarecharacters, words, andwordpieces.
To preprocesstext, weusually(i)splittextintotokens; (ii)buildavocabularytomaptoken strings to numerical indices; and (iii) convert text data into token indices for models to 342 Recurrent Neural Networks manipulate.
Inpractice, thefrequencyofwordstendstofollow Zipfâ€™slaw.
Thisistruenot justforindividualwords(unigrams), butalsoforğ‘›-grams.
9.2.7 Exercises 1.
Intheexperimentofthissection, tokenizetextintowordsandvarythemin_freqargu- mentvalueofthe Vocabinstance.
Qualitativelycharacterizehowchangesinmin_freq impactthesizeoftheresultingvocabulary.
2.
Estimatetheexponentof Zipfiandistributionforunigrams, bigrams, andtrigramsinthis corpus.
3.
Find some other sources of data (download a standard machine learning dataset, pick anotherpublicdomainbook, scrapeawebsite, etc).
Foreach, tokenizethedataatboth the word and character levels.
How do the vocabulary sizes compare with The Time Machinecorpusatequivalentvaluesofmin_freq.
Estimatetheexponentofthe Zipfian distribution corresponding to the unigram and bigram distributions for these corpora.
Howdotheycomparewiththevaluesthatyouobservedfor The Time Machinecorpus? 138 Discussions138.
9.3 Language Models In Section9.2, wesawhowtomaptextsequencesintotokens, wherethesetokenscanbe viewed as a sequence of discrete observations such as words or characters.
Assume that thetokensinatextsequenceoflengthğ‘‡ areinturnğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘‡.
Thegoaloflanguage modelsistoestimatethejointprobabilityofthewholesequence: wherestatisticaltoolsin Section9.1canbeapplied.
Language models are incredibly useful.
For instance, an ideal language model should generate natural text on its own, simply by drawing one token at a time ğ‘¥ ğ‘¡ ğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 â€.
Quite unlike the monkey using a typewriter, all text emerging from such amodelwouldpassasnaturallanguage, e.
g., Englishtext.
Furthermore, itwouldbesuffi- cientforgeneratingameaningfuldialog, simplybyconditioningthetextonpreviousdialog fragments.
Clearlywearestillveryfarfromdesigningsuchasystem, sinceitwouldneed tounderstandthetextratherthanjustgenerategrammaticallysensiblecontent.
Nonetheless, languagemodelsareofgreatserviceevenintheirlimitedform.
Forinstance, thephrasesâ€œtorecognizespeechâ€andâ€œtowreckanicebeachâ€soundverysimilar.
Thiscan causeambiguityinspeechrecognition, whichiseasilyresolvedthroughalanguagemodel thatrejectsthesecondtranslationasoutlandish.
Likewise, inadocumentsummarization algorithmitisworthwhileknowingthatâ€œdogbitesmanâ€ismuchmorefrequentthanâ€œman 343 Language Models bitesdogâ€, orthatâ€œIwanttoeatgrandmaâ€isaratherdisturbingstatement, whereasâ€œIwant toeat, grandmaâ€ismuchmorebenign.
import torch from d2l import torch as d2l 9.3.1 Learning Language Models Theobviousquestionishowweshouldmodeladocument, orevenasequenceoftokens.
Supposethatwetokenizetextdataatthewordlevel.
Letâ€™sstartbyapplyingbasicprobability rules: ğ‘‡ ğ‘¡=1 For example, the probability of a text sequence containing four words would be given as: ğ‘ƒâ€deep, learning, is, funâ€ (9.3.3) =ğ‘ƒâ€deepâ€ğ‘ƒâ€learning j deepâ€ğ‘ƒâ€is j deep, learningâ€ğ‘ƒâ€fun j deep, learning, isâ€.
Markov Modelsandğ‘›-grams Amongthosesequencemodelanalysesin Section9.1, letâ€™sapply Markovmodelstolan- guagemodeling.
Adistributionoversequencessatisfiesthe Markovpropertyoffirstorder Thisleadstoanumberofapproximationsthatwecouldapplytomodelasequence: ğ‘ƒâ€ğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥ â€ = ğ‘ƒâ€ğ‘¥ â€ğ‘ƒâ€ğ‘¥ â€ğ‘ƒâ€ğ‘¥ â€ğ‘ƒâ€ğ‘¥ â€, 1 2 3 4 1 2 3 4 ğ‘ƒâ€ğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥ â€ = ğ‘ƒâ€ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ â€, (9.3.4) 1 2 3 4 1 2 1 3 2 4 3 ğ‘ƒâ€ğ‘¥ ,ğ‘¥ ,ğ‘¥ ,ğ‘¥ â€ = ğ‘ƒâ€ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ ,ğ‘¥ â€ğ‘ƒâ€ğ‘¥ j ğ‘¥ ,ğ‘¥ â€.
1 2 3 4 1 2 1 3 1 2 4 2 3 The probability formulae that involve one, two, and three variables are typically referred toasunigram, bigram, andtrigrammodels, respectively.
Inordertocomputethelanguage model, we need to calculate the probability of words and the conditional probability of a word given the previous few words.
Note that such probabilities are language model parameters.
Word Frequency 139 Here, weassumethatthetrainingdatasetisalargetextcorpus, suchasall Wikipediaentries, Project Gutenberg139, and all text posted on the web.
The probability of words can be calculated from the relative word frequency of a given word in the training dataset.
For example, theestimateğ‘ƒË†â€deepâ€canbecalculatedastheprobabilityofanysentencestarting withthewordâ€œdeepâ€.
Aslightlylessaccurateapproachwouldbetocountalloccurrences 344 Recurrent Neural Networks ofthewordâ€œdeepâ€anddivideitbythetotalnumberofwordsinthecorpus.
Thisworks fairlywell, particularlyforfrequentwords.
Movingon, wecouldattempttoestimate ğ‘›â€deep, learningâ€ ğ‘ƒË†â€learning j deepâ€ = , (9.3.5) ğ‘›â€deepâ€ whereğ‘›â€ğ‘¥â€andğ‘›â€ğ‘¥,ğ‘¥0â€arethenumberofoccurrencesofsingletonsandconsecutiveword pairs, respectively.
Unfortunately, estimating the probability of a word pair is somewhat moredifficult, sincetheoccurrencesofâ€œdeeplearningâ€arealotlessfrequent.
Inparticular, for some unusual word combinations it may be tricky to find enough occurrences to get accurate estimates.
As suggested by the empirical results in Section 9.2.5, things take a turnfortheworseforthree-wordcombinationsandbeyond.
Therewillbemanyplausible three-wordcombinationsthatwelikelywillnotseeinourdataset.
Unlessweprovidesome solutiontoassignsuchwordcombinationsanonzerocount, wewillnotbeabletousethem inalanguagemodel.
Ifthedatasetissmallorifthewordsareveryrare, wemightnotfind evenasingleoneofthem.
Laplace Smoothing Acommonstrategyistoperformsomeformof Laplacesmoothing.
Thesolutionistoadd asmallconstanttoallcounts.
Denotebyğ‘›thetotalnumberofwordsinthetrainingsetand ğ‘šthenumberofuniquewords.
Thissolutionhelpswithsingletons, e.
g., via ğ‘›â€ğ‘¥â€â€šğœ– ğ‘š ğ‘ƒË†â€ğ‘¥â€ = 1 , ğ‘›â€šğœ– 1 ğ‘›â€ğ‘¥,ğ‘¥0â€â€šğœ– ğ‘ƒË†â€ğ‘¥0â€ ğ‘ƒË†â€ğ‘¥0 j ğ‘¥â€ = 2 , (9.3.6) ğ‘›â€ğ‘¥â€â€šğœ– 2 ğ‘›â€ğ‘¥,ğ‘¥0,ğ‘¥00â€â€šğœ– ğ‘ƒË†â€ğ‘¥00â€ ğ‘ƒË†â€ğ‘¥00 j ğ‘¥,ğ‘¥0â€ = 3 .
ğ‘›â€ğ‘¥,ğ‘¥0â€â€šğœ– 3 Hereğœ– ,ğœ– , andğœ– arehyperparameters.
Takeğœ– asanexample: whenğœ– =0, nosmoothing 1 2 3 1 1 isapplied; whenğœ– approachespositiveinfinity, ğ‘ƒË†â€ğ‘¥â€ approachestheuniformprobability 1 1 ğ‘š.
The above is a rather primitive variant of what other techniques can accomplish (Woodetal.,2011).
Unfortunately, modelslikethisgetunwieldyratherquicklyforthefollowingreasons.
First, asdiscussedin Section9.2.5, manyğ‘›-gramsoccurveryrarely, making Laplacesmoothing ratherunsuitableforlanguagemodeling.
Second, weneedtostoreallcounts.
Third, this entirelyignoresthemeaningofthewords.
Forinstance,â€œcatâ€andâ€œfelineâ€shouldoccurin relatedcontexts.
Itisquitedifficulttoadjustsuchmodelstoadditionalcontexts, whereas, deeplearningbasedlanguagemodelsarewellsuitedtotakethisintoaccount.
Last, long wordsequencesarealmostcertaintobenovel, henceamodelthatsimplycountsthefre- quencyofpreviouslyseenwordsequencesisboundtoperformpoorlythere.
Therefore, we focusonusingneuralnetworksforlanguagemodelingintherestofthechapter.
9.3.2 Perplexity 345 Language Models Next, letâ€™s discuss about how to measure the quality of the language model, which we willthenusetoevaluateourmodelsinthesubsequentsections.
Onewayistocheckhow surprising the text is.
A good language model is able to predict, with high accuracy, the tokensthatcomenext.
Considerthefollowingcontinuationsofthephraseâ€œItisrainingâ€, asproposedbydifferentlanguagemodels: 1.
â€œItisrainingoutsideâ€ 2.
â€œItisrainingbananatreeâ€ 3.
â€œItisrainingpiouw; kcjpwepoiutâ€ Intermsofquality, Example1isclearlythebest.
Thewordsaresensibleandlogicallyco- herent.
Whileitmightnotquiteaccuratelyreflectwhichwordfollowssemantically(â€œin San Franciscoâ€andâ€œinwinterâ€wouldhavebeenperfectlyreasonableextensions), themodelis abletocapturewhichkindofwordfollows.
Example2isconsiderablyworsebyproducing a nonsensical extension.
Nonetheless, at least the model has learned how to spell words andsomedegreeofcorrelationbetweenwords.
Last, Example3indicatesapoorlytrained modelthatdoesnotfitdataproperly.
Wemightmeasurethequalityofthemodelbycomputingthelikelihoodofthesequence.
Unfortunatelythisisanumberthatishardtounderstandanddifficulttocompare.
Afterall, shortersequencesaremuchmorelikelytooccurthanthelongerones, henceevaluatingthe modelon Tolstoyâ€™smagnumopus Warand Peacewillinevitablyproduceamuchsmaller likelihoodthan, say, on Saint-Exuperyâ€™snovella The Little Prince.
Whatismissingisthe equivalentofanaverage.
Information theory comes handy here.
We defined entropy, surprisal, and cross-entropy whenweintroducedthesoftmaxregression(Section4.1.3).
Ifwewanttocompresstext, wecanaskaboutpredictingthenexttokengiventhecurrentsetoftokens.
Abetterlanguage modelshouldallowustopredictthenexttokenmoreaccurately.
Thus, itshouldallowusto spendfewerbitsincompressingthesequence.
Sowecanmeasureitbythecross-entropy lossaveragedoveralltheğ‘›tokensofasequence: ğ‘› 1 ğ‘¡=1 whereğ‘ƒisgivenbyalanguagemodelandğ‘¥ ğ‘¡ istheactualtokenobservedattimestepğ‘¡from thesequence.
Thismakestheperformanceondocumentsofdifferentlengthscomparable.
For historical reasons, scientists in natural language processing prefer to use a quantity calledperplexity.
Inanutshell, itistheexponentialof(9.3.7): ! ğ‘› 1 ğ‘¡=1 Perplexitycanbebestunderstoodasthereciprocalofthegeometricmeanofthenumberof realchoicesthatwehavewhendecidingwhichtokentopicknext.
Letâ€™slookatanumber ofcases: 346 Recurrent Neural Networks In the best case scenario, the model always perfectly estimates the probability of the targettokenas1.
Inthiscasetheperplexityofthemodelis1.
Intheworstcasescenario, themodelalwayspredictstheprobabilityofthetargettoken as0.
Inthissituation, theperplexityispositiveinfinity.
Atthebaseline, themodelpredictsauniformdistributionoveralltheavailabletokensof thevocabulary.
Inthiscase, theperplexityequalsthenumberofuniquetokensofthe vocabulary.
In fact, if we were to store the sequence without any compression, this wouldbethebestwecoulddoforencodingit.
Hence, thisprovidesanontrivialupper boundthatanyusefulmodelmustbeat.
9.3.3 Partitioning Sequences Wewilldesignlanguagemodelsusingneuralnetworksanduseperplexitytoevaluatehow good the model is at predicting the next token given the current set of tokens in text se- quences.
Before introducing the model, letâ€™s assume that it processes a minibatch of se- quenceswithpredefinedlengthatatime.
Nowthequestionishowtoreadminibatchesof inputsequencesandtargetsequencesatrandom.
Suppose that the dataset takes the form of a sequence ofğ‘‡ token indices in corpus.
We willpartitionitintosubsequences, whereeachsubsequencehasğ‘›tokens(timesteps).
To iterateover(almost)allthetokensoftheentiredatasetforeachepochandobtainallpossible length-ğ‘› subsequences, wecanintroducerandomness.
Moreconcretely, atthebeginning ofeachepoch, discardthefirstğ‘‘tokens, whereğ‘‘ 2 Â»0,ğ‘›â€isuniformlysampledatrandom.
Therestofthesequenceisthenpartitionedintoğ‘š = bâ€ğ‘‡ ğ‘‘â€ ğ‘›csubsequences.
Denoteby xğ‘¡ = Â»ğ‘¥ ğ‘¡ ,...,ğ‘¥ ğ‘¡â€šğ‘› 1 â€¦ thelength-ğ‘›subsequencestartingfromtokenğ‘¥ ğ‘¡ attimestepğ‘¡.
The resultingğ‘špartitionedsubsequencesarexğ‘‘ , xğ‘‘â€šğ‘› ,..., xğ‘‘â€šğ‘›â€ğ‘š 1â€ .
Eachsubsequencewill beusedasaninputsequenceintothelanguagemodel.
Forlanguagemodeling, thegoalistopredictthenexttokenbasedonthetokenswehave seensofar; hencethetargets(labels)aretheoriginalsequence, shiftedbyonetoken.
The targetsequenceforanyinputsequencexğ‘¡ isxğ‘¡â€š1 withlengthğ‘›.
t .3.1 Obtainingfivepairsofinputsequencesandtargetsequencesfrompartitionedlength-5 subsequences.
.3.1showsanexampleofobtainingfivepairsofinputsequencesandtargetsequences withğ‘›=5andğ‘‘ =2.
@d2l.
add_to_class(d2l.
Time Machine) #@save def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000): super(d2l.
Time Machine, self).__init__() self.
save_hyperparameters() corpus, self.
vocab = self.
build(self._download()) (continuesonnextpage) 347 Language Models (continuedfrompreviouspage) array = torch.
tensor([corpus[i: i+num_steps+1] for i in range(len(corpus)-num_steps)]) self.
X, self.
Y = array[:,:-1], array[:,1:] To train language models, we will randomly sample pairs of input sequences and target sequencesinminibatches.
Thefollowingdataloaderrandomlygeneratesaminibatchfrom the dataset each time.
The argument batch_size specifies the number of subsequence examplesineachminibatchandnum_stepsisthesubsequencelengthintokens.
@d2l.
add_to_class(d2l.
Time Machine) #@save def get_dataloader(self, train): idx = slice(0, self.
num_train) if train else slice( self.
num_train, self.
num_train + self.
num_val) return self.
get_tensorloader([self.
X, self.
Y], train, idx) Aswecanseeinthefollowing, aminibatchoftargetsequencescanbeobtainedbyshifting theinputsequencesbyonetoken.
data = d2l.
Time Machine(batch_size=2, num_steps=10) for X, Y in data.
train_dataloader(): print('X:', X, '\n Y:', Y) break X: tensor([[10, 4, 2, 21, 10, 16, 15, 0, 20, 2], [21, 9, 6, 19, 0, 24, 2, 26, 0, 16]]) Y: tensor([[ 4, 2, 21, 10, 16, 15, 0, 20, 2, 10], [ 9, 6, 19, 0, 24, 2, 26, 0, 16, 9]]) 9.3.4 Summaryand Discussion Language models estimate the joint probability of a text sequence.
For long sequences, ğ‘›-gramsprovideaconvenientmodelbytruncatingthedependence.
However, thereisalot ofstructurebutnotenoughfrequencytodealefficientlywithinfrequentwordcombinations via Laplace smoothing.
Thus, we will focus on neural language modeling in subsequent sections.
To train language models, we can randomly sample pairs of input sequences andtargetsequencesinminibatches.
Aftertraining, wewilluseperplexitytomeasurethe languagemodelquality.
Language models can be scaled up with increased data size, model size, and amount in trainingcompute.
Largelanguagemodelscanperformdesiredtasksbypredictingoutput textgiveninputtextinstructions.
Aswewilldiscusslater(e.
g., Section11.9), atthepresent moment large language models form the basis of state-of-the-art systems across diverse tasks.
348 Recurrent Neural Networks 9.3.5 Exercises 1.
Suppose there are 100,000 words in the training dataset.
How much word frequency andmulti-wordadjacentfrequencydoesafour-gramneedtostore? 2.
Howwouldyoumodeladialogue? 3.
Whatothermethodscanyouthinkofforreadinglongsequencedata? 4.
Considerourmethodfordiscardingauniformlyrandomnumberofthefirstfewtokens atthebeginningofeachepoch.
1.
Doesitreallyleadtoaperfectlyuniformdistributionoverthesequencesonthedocu- ment? 2.
Whatwouldyouhavetodotomakethingsevenmoreuniform? 5.
Ifwewantasequenceexampletobeacompletesentence, whatkindofproblemdoes thisintroduceinminibatchsampling? Howcanwefixit? 140 Discussions140.
9.4 Recurrent Neural Networks In Section 9.3 we described Markov models and ğ‘›-grams for language modeling, where the conditional probability of token ğ‘¥ ğ‘¡ at time step ğ‘¡ only depends on the ğ‘› 1 previous tokens.
If we want to incorporate the possible effect of tokens earlier than time step ğ‘¡ â€ğ‘› 1â€onğ‘¥ ğ‘¡, weneedtoincreaseğ‘›.
However, thenumberofmodelparameterswouldalso increaseexponentiallywithit, asweneedtostore j Vjğ‘› numbersforavocabularyset V.
Hence, ratherthanmodelingğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ ğ‘¡ ğ‘›â€š1 â€itispreferabletousealatentvariable model, where â„ ğ‘¡ 1 isahiddenstatethatstoresthesequenceinformationuptotimestepğ‘¡ 1.
In general, the hidden state at any time stepğ‘¡ could be computed based on both the current inputğ‘¥ ğ‘¡ andtheprevioushiddenstateâ„ ğ‘¡ 1 : â„ ğ‘¡ = ğ‘“â€ğ‘¥ ğ‘¡ ,â„ ğ‘¡ 1 â€.
(9.4.2) Forasufficientlypowerfulfunction ğ‘“ in(9.4.2), thelatentvariablemodelisnotanapprox- imation.
Afterall,â„ ğ‘¡ maysimplystoreallthedataithasobservedsofar.
However, itcould potentiallymakebothcomputationandstorageexpensive.
Recallthatwehavediscussedhiddenlayerswithhiddenunitsin Chapter5.
Itisnoteworthy thathiddenlayersandhiddenstatesrefertotwoverydifferentconcepts.
Hiddenlayersare, as explained, layers that are hidden from view on the path from input to output.
Hidden 349 Recurrent Neural Networks statesaretechnicallyspeakinginputstowhateverwedoatagivenstep, andtheycanonly becomputedbylookingatdataatprevioustimesteps.
Recurrentneuralnetworks(RNNs)areneuralnetworkswithhiddenstates.
Beforeintro- ducingthe RNNmodel, wefirstrevisitthe MLPmodelintroducedin Section5.1.
import torch from d2l import torch as d2l 9.4.1 Neural Networkswithout Hidden States Letâ€™s take a look at an MLP with a single hidden layer.
Let the hidden layerâ€™s activation functionbe ğœ™.
Givenaminibatchofexamples X 2 Rğ‘› ğ‘‘ withbatchsizeğ‘›and ğ‘‘ inputs, thehiddenlayeroutput H2Rğ‘› â„ iscalculatedas H= ğœ™â€XW â€šb â€.
(9.4.3) xh h In(9.4.3), wehavetheweightparameter W 2Rğ‘‘ â„ , thebiasparameterb 2R1 â„ , and xh h thenumberofhiddenunits â„, forthehiddenlayer.
Soarmed, weapplybroadcasting(see Section2.1.4)duringthesummation.
Next, thehiddenlayeroutput Hisusedasinputof theoutputlayer, whichisgivenby O=HW â€šb , (9.4.4) hq q where O 2 Rğ‘› ğ‘ istheoutputvariable, W 2 Râ„ ğ‘ istheweightparameter, andb 2 hq q R1 ğ‘ isthebiasparameteroftheoutputlayer.
Ifitisaclassificationproblem, wecanuse softmaxâ€Oâ€tocomputetheprobabilitydistributionoftheoutputcategories.
Thisisentirelyanalogoustotheregressionproblemwesolvedpreviouslyin Section9.1, henceweomitdetails.
Sufficeittosaythatwecanpickfeature-labelpairsatrandomand learn the parameters of our network via automatic differentiation and stochastic gradient descent.
9.4.2 Recurrent Neural Networkswith Hidden States Matters are entirely different when we have hidden states.
Letâ€™s look at the structure in somemoredetail.
Assumethatwehaveaminibatchofinputs Xğ‘¡ 2 Rğ‘› ğ‘‘ attimestepğ‘¡.
Inotherwords, for aminibatchofğ‘›sequenceexamples, eachrowof Xğ‘¡ correspondstooneexampleattime stepğ‘¡ fromthesequence.
Next, denoteby Hğ‘¡ 2 Rğ‘› â„ thehiddenlayeroutputoftimestep ğ‘¡.
Unlikewith MLP, herewesavethehiddenlayeroutput Hğ‘¡ 1 fromtheprevioustimestep andintroduceanewweightparameter W 2Râ„ â„ todescribehowtousethehiddenlayer hh outputoftheprevioustimestepinthecurrenttimestep.
Specifically, thecalculationofthe hiddenlayeroutputofthecurrenttimestepisdeterminedbytheinputofthecurrenttime steptogetherwiththehiddenlayeroutputoftheprevioustimestep: Hğ‘¡ = ğœ™â€Xğ‘¡W xh â€šHğ‘¡ 1 W hh â€šb h â€.
(9.4.5) 350 Recurrent Neural Networks Comparedwith(9.4.3),(9.4.5)addsonemoreterm Hğ‘¡ 1 W hh andthusinstantiates(9.4.2).
Fromtherelationshipbetweenhiddenlayeroutputs Hğ‘¡ and Hğ‘¡ 1 ofadjacenttimesteps, we know that these variables captured and retained the sequenceâ€™s historical information uptotheircurrenttimestep, justlikethestateormemoryoftheneuralnetworkâ€™scurrent timestep.
Therefore, suchahiddenlayeroutputiscalledahiddenstate.
Sincethehidden stateusesthesamedefinitionoftheprevioustimestepinthecurrenttimestep, thecompu- tationof(9.4.5)isrecurrent.
Hence, aswesaid, neuralnetworkswithhiddenstatesbased on recurrent computation are named recurrent neural networks.
Layers that perform the computationof(9.4.5)in RNNsarecalledrecurrentlayers.
Therearemanydifferentwaysforconstructing RNNs.
Thosewithahiddenstatedefined by(9.4.5)areverycommon.
Fortimestepğ‘¡, theoutputoftheoutputlayerissimilartothe computationinthe MLP: Oğ‘¡ =Hğ‘¡W hq â€šb q .
(9.4.6) Parametersofthe RNNincludetheweights W 2Rğ‘‘ â„, W 2Râ„ â„ , andthebiasb 2 xh hh h R1 â„ ofthehiddenlayer, togetherwiththeweights W 2 Râ„ ğ‘ andthebiasb 2 R1 ğ‘ hq q oftheoutputlayer.
Itisworthmentioningthatevenatdifferenttimesteps, RNNsalways usethesemodelparameters.
Therefore, theparametrizationcostofan RNNdoesnotgrow asthenumberoftimestepsincreases.
.4.1 illustrates the computational logic of an RNN at three adjacent time steps.
At anytimestepğ‘¡, thecomputationofthehiddenstatecanbetreatedas: (i)concatenatingthe input Xğ‘¡ atthecurrenttimestepğ‘¡andthehiddenstate Hğ‘¡ 1 attheprevioustimestepğ‘¡ 1; (ii)feedingtheconcatenationresultintoafullyconnectedlayerwiththeactivationfunction ğœ™.
Theoutputofsuchafullyconnectedlayeristhehiddenstate Hğ‘¡ ofthecurrenttimestep ğ‘¡.
Inthiscase, themodelparametersaretheconcatenationof W and W , andabias xh hh ofb h , allfrom(9.4.5).
Thehiddenstateofthecurrenttimestepğ‘¡, Hğ‘¡, willparticipatein computingthehiddenstate Hğ‘¡â€š1 ofthenexttimestepğ‘¡â€š1.
Whatismore, Hğ‘¡ willalsobe fedintothefullyconnectedoutputlayertocomputetheoutput Oğ‘¡ ofthecurrenttimestep ğ‘¡.
t .4.1 An RNNwithahiddenstate.
Wejustmentionedthatthecalculationof Xğ‘¡W xh â€šHğ‘¡ 1 W hh forthehiddenstateisequiv- alenttomatrixmultiplicationoftheconcatenationof Xğ‘¡ and Hğ‘¡ 1 andtheconcatenation of W and W .
Thoughthiscanbeprovenmathematically, inthefollowingwejustuse xh hh 351 Recurrent Neural Networks a simple code snippet as a demonstration.
To begin with, we define matrices X, W_xh, H, and W_hh, whoseshapesare(3,1),(1,4),(3,4), and(4,4), respectively.
Multiplying Xby W_xh, and Hby W_hh, andthenaddingthesetwoproducts, weobtainamatrixofshape(3, 4).
X, W_xh = torch.
randn(3, 1), torch.
randn(1, 4) H, W_hh = torch.
randn(3, 4), torch.
randn(4, 4) torch.
matmul(X, W_xh) + torch.
matmul(H, W_hh) tensor([[ 1.2526, 0.0580, -3.3460, -0.2519], [-1.3064, 1.4132, -0.1435, 0.3482], [ 3.1495, 0.8172, 1.5167, -0.9038]]) Nowweconcatenatethematrices Xand Halongcolumns(axis1), andthematrices W_xh and W_hhalongrows(axis0).
Thesetwoconcatenationsresultinmatricesofshape(3,5) andofshape(5,4), respectively.
Multiplyingthesetwoconcatenatedmatrices, weobtain thesameoutputmatrixofshape(3,4)asabove.
torch.
matmul(torch.
cat((X, H), 1), torch.
cat((W_xh, W_hh), 0)) tensor([[ 1.2526, 0.0580, -3.3460, -0.2519], [-1.3064, 1.4132, -0.1435, 0.3482], [ 3.1495, 0.8172, 1.5167, -0.9038]]) 9.4.3 RNN-Based Character-Level Language Models Recallthatforlanguagemodelingin Section9.3, weaimtopredictthenexttokenbasedon thecurrentandpasttokens; thusweshifttheoriginalsequencebyonetokenasthetargets (labels).
Bengioetal.
(2003)firstproposedtouseaneuralnetworkforlanguagemodeling.
Inthefollowingweillustratehow RNNscanbeusedtobuildalanguagemodel.
Letthe minibatch size be one, and the sequence of the text be â€œmachineâ€.
To simplify training insubsequentsections, wetokenizetextintocharactersratherthanwordsandconsidera character-level language model.
.4.2 demonstrates how to predict the next charac- terbasedonthecurrentandpreviouscharactersviaan RNNforcharacter-levellanguage modeling.
Duringthetrainingprocess, werunasoftmaxoperationontheoutputfromtheoutputlayer for each time step, and then use the cross-entropy loss to compute the error between the modeloutputandthetarget.
Becauseoftherecurrentcomputationofthehiddenstateinthe hiddenlayer, theoutput, O , oftimestep3in.4.2isdeterminedbythetextsequence 3 â€œmâ€,â€œaâ€, andâ€œcâ€.
Sincethenextcharacterofthesequenceinthetrainingdataisâ€œhâ€, the lossoftimestep3willdependontheprobabilitydistributionofthenextcharactergenerated basedonthefeaturesequenceâ€œmâ€,â€œaâ€,â€œcâ€andthetargetâ€œhâ€ofthistimestep.
Inpractice, eachtokenisrepresentedbya ğ‘‘-dimensionalvector, andweuseabatchsize 352 Recurrent Neural Networks t .4.2 Acharacter-levellanguagemodelbasedonthe RNN.
Theinputandtargetsequencesare â€œmachinâ€andâ€œachineâ€, respectively.
ğ‘› > 1.
Therefore, theinput Xğ‘¡ attimestepğ‘¡ willbeanğ‘› ğ‘‘ matrix, whichisidenticalto whatwediscussedin Section9.4.2.
In the following sections, we will implement RNNs for character-level language mod- els.
9.4.4 Summary A neural network that uses recurrent computation for hidden states is called a recurrent neuralnetwork(RNN).
Thehiddenstateofan RNNcancapturehistoricalinformationof thesequenceuptothecurrenttimestep.
Withrecurrentcomputation, thenumberof RNN modelparametersdoesnotgrowasthenumberoftimestepsincreases.
Asforapplications, an RNNcanbeusedtocreatecharacter-levellanguagemodels.
9.4.5 Exercises 1.
Ifweusean RNNtopredictthenextcharacterinatextsequence, whatistherequired dimensionforanyoutput? 2.
Whycan RNNsexpresstheconditionalprobabilityofatokenatsometimestepbased onalltheprevioustokensinthetextsequence? 3.
Whathappenstothegradientifyoubackpropagatethroughalongsequence? 4.
What are some of the problems associated with the language model described in this section? Discussions141.
141 9.5 Recurrent Neural Network Implementation from Scratch We are now ready to implement an RNN from scratch.
In particular, we will train this RNN to function as a character-level language model (see Section 9.4) and train it on a 353 Recurrent Neural Network Implementationfrom Scratch corpusconsistingoftheentiretextof H.
G.
Wellsâ€™The Time Machine, followingthedata processingstepsoutlinedin Section9.2.
Westartbyloadingthedataset.
%matplotlib inline import math import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 9.5.1 RNNModel Webeginbydefiningaclasstoimplementthe RNNmodel(Section9.4.2).
Notethatthe numberofhiddenunitsnum_hiddensisatunablehyperparameter.
class RNNScratch(d2l.
Module): #@save """The RNN model implemented from scratch.""" def __init__(self, num_inputs, num_hiddens, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
W_xh = nn.
Parameter( torch.
randn(num_inputs, num_hiddens) * sigma) self.
W_hh = nn.
Parameter( torch.
randn(num_hiddens, num_hiddens) * sigma) self.
b_h = nn.
Parameter(torch.
zeros(num_hiddens)) Theforwardmethodbelowdefineshowtocomputetheoutputandhiddenstateatanytime step, giventhecurrentinputandthestateofthemodelattheprevioustimestep.
Notethat the RNN model loops through the outermost dimension of inputs, updating the hidden state one time step at a time.
The model here uses a tanh activation function (Section 5.1.2).
@d2l.
add_to_class(RNNScratch) #@save def forward(self, inputs, state=None): if state is None: # Initial state with shape: (batch_size, num_hiddens) state = torch.
zeros((inputs.
shape[1], self.
num_hiddens), device=inputs.
device) else: state, = state outputs = [] for X in inputs: # Shape of inputs: (num_steps, batch_size, num_inputs) state = torch.
tanh(torch.
matmul(X, self.
W_xh) + torch.
matmul(state, self.
W_hh) + self.
b_h) outputs.
append(state) return outputs, state Wecanfeedaminibatchofinputsequencesintoan RNNmodelasfollows.
batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100 (continuesonnextpage) 354 Recurrent Neural Networks (continuedfrompreviouspage) rnn = RNNScratch(num_inputs, num_hiddens) X = torch.
ones((num_steps, batch_size, num_inputs)) outputs, state = rnn(X) Letâ€™scheckwhetherthe RNNmodelproducesresultsofthecorrectshapestoensurethat thedimensionalityofthehiddenstateremainsunchanged.
def check_len(a, n): #@save """Check the length of a list.""" assert len(a) == n, f'list\'s length {len(a)} != expected length {n}' def check_shape(a, shape): #@save """Check the shape of a tensor.""" assert a.
shape == shape, \ f'tensor\'s shape {a.
shape} != expected shape {shape}' check_len(outputs, num_steps) check_shape(outputs[0], (batch_size, num_hiddens)) check_shape(state, (batch_size, num_hiddens)) 9.5.2 RNN-Based Language Model Thefollowing RNNLMScratchclassdefinesan RNN-basedlanguagemodel, wherewepass inour RNNviathernnargumentofthe__init__method.
Whentraininglanguagemod- els, the inputsand outputs are from the same vocabulary.
Hence, they havethe same di- mension, whichisequaltothevocabularysize.
Notethatweuseperplexitytoevaluatethe model.
As discussed in Section 9.3.2, this ensures that sequences of different length are comparable.
class RNNLMScratch(d2l.
Classifier): #@save """The RNN-based language model implemented from scratch.""" def __init__(self, rnn, vocab_size, lr=0.01): super().__init__() self.
save_hyperparameters() self.
init_params() def init_params(self): self.
W_hq = nn.
Parameter( torch.
randn( self.
b_q = nn.
Parameter(torch.
zeros(self.
vocab_size)) def training_step(self, batch): l = self.
loss(self(*batch[:-1]), batch[-1]) self.
plot('ppl', torch.
exp(l), train=True) return l def validation_step(self, batch): l = self.
loss(self(*batch[:-1]), batch[-1]) self.
plot('ppl', torch.
exp(l), train=False) 355 Recurrent Neural Network Implementationfrom Scratch One-Hot Encoding Recall that each token is represented by a numerical index indicating the position in the vocabularyofthecorrespondingword/character/wordpiece.
Youmightbetemptedtobuild aneuralnetworkwithasingleinputnode(ateachtimestep), wheretheindexcouldbefed inasascalarvalue.
Thisworkswhenwearedealingwithnumericalinputslikepriceor temperature, whereanytwovaluessufficientlyclosetogethershouldbetreatedsimilarly.
Butthisdoesnotquitemakesense.
The45th and46th wordsinourvocabularyhappento beâ€œtheirâ€andâ€œsaidâ€, whosemeaningsarenotremotelysimilar.
Whendealingwithsuchcategoricaldata, themostcommonstrategyistorepresenteach item by a one-hot encoding (recall from Section 4.1.1).
A one-hot encoding is a vector whoselengthisgivenbythesizeofthevocabularyğ‘, whereallentriesaresetto0, except fortheentrycorrespondingtoourtoken, whichissetto1.
Forexample, ifthevocabulary hadfiveelements, thentheone-hotvectorscorrespondingtoindices0and2wouldbethe following.
F.
one_hot(torch.
tensor([0, 2]), 5) tensor([[1, 0, 0, 0, 0], [0, 0, 1, 0, 0]]) Theminibatchesthatwesampleateachiterationwilltaketheshape(batchsize, number of time steps).
Once representing each input as a one-hot vector, we can think of each minibatchasathree-dimensionaltensor, wherethelengthalongthethirdaxisisgivenby thevocabularysize(len(vocab)).
Weoftentransposetheinputsothatwewillobtainan outputofshape(numberoftimesteps, batchsize, vocabularysize).
Thiswillallowusto loop more conveniently through the outermost dimension for updating hidden states of a minibatch, timestepbytimestep(e.
g., intheaboveforwardmethod).
@d2l.
add_to_class(RNNLMScratch) #@save def one_hot(self, X): # Output shape: (num_steps, batch_size, vocab_size) Transforming RNNOutputs The language model uses a fully connected output layer to transform RNN outputs into tokenpredictionsateachtimestep.
@d2l.
add_to_class(RNNLMScratch) #@save def output_layer(self, rnn_outputs): outputs = [torch.
matmul(H, self.
W_hq) + self.
b_q for H in rnn_outputs] return torch.
stack(outputs, 1) @d2l.
add_to_class(RNNLMScratch) #@save (continuesonnextpage) 356 Recurrent Neural Networks (continuedfrompreviouspage) def forward(self, X, state=None): embs = self.
one_hot(X) rnn_outputs, _ = self.
rnn(embs, state) return self.
output_layer(rnn_outputs) Letâ€™scheckwhethertheforwardcomputationproducesoutputswiththecorrectshape.
model = RNNLMScratch(rnn, num_inputs) outputs = model(torch.
ones((batch_size, num_steps), dtype=torch.
int64)) check_shape(outputs, (batch_size, num_steps, num_inputs)) 9.5.3 Gradient Clipping Whileyouarealreadyusedtothinkingofneuralnetworksasâ€œdeepâ€inthesensethatmany layers separate the input and output even within a single time step, the length of the se- quenceintroducesanewnotionofdepth.
Inadditiontothepassingthroughthenetwork intheinput-to-outputdirection, inputsatthefirsttimestepmustpassthroughachainofğ‘‡ layers along the time steps in order to influence the output of the model at the final time step.
Taking the backwards view, in each iteration, we backpropagate gradients through time, resultinginachainofmatrix-productsoflength Oâ€ğ‘‡â€.
Asmentionedin Section5.4, this can result in numerical instability, causing the gradients either to explode or vanish, dependingonthepropertiesoftheweightmatrices.
Dealingwithvanishingandexplodinggradientsisafundamentalproblemwhendesigning RNNsandhasinspiredsomeofthebiggestadvancesinmodernneuralnetworkarchitec- tures.
Inthenextchapter, wewilltalkaboutspecializedarchitecturesthatweredesignedin hopesofmitigatingthevanishinggradientproblem.
However, evenmodern RNNsoften sufferfromexplodinggradients.
Oneinelegantbutubiquitoussolutionistosimplyclipthe gradientsforcingtheresultingâ€œclippedâ€gradientstotakesmallervalues.
Generally speaking, when optimizing some objective by gradient descent, we iteratively updatetheparameterofinterest, sayavectorx, butpushingitinthedirectionofthenegative gradientg(instochasticgradientdescent, wecalculatethisgradientonarandomlysampled minibatch).
Forexample, withlearningrateğœ‚ >0, eachupdatetakestheformx x ğœ‚g.
Letâ€™sfurtherassumethattheobjectivefunction ğ‘“ issufficientlysmooth.
Formally, wesay thattheobjectiveis Lipschitzcontinuouswithconstant ğ¿, meaningthatforanyxandy, wehave jğ‘“â€xâ€ ğ‘“â€yâ€j ğ¿kx yk.
(9.5.1) As you can see, when we update the parameter vector by subtracting ğœ‚g, the change in thevalueoftheobjectivedependsonthelearningrate, thenormofthegradientand ğ¿ as follows: jğ‘“â€xâ€ ğ‘“â€x ğœ‚gâ€j ğ¿ğœ‚kgk.
(9.5.2) Inotherwords, theobjectivecannotchangebymorethanğ¿ğœ‚kgk.
Havingasmallvaluefor 357 Recurrent Neural Network Implementationfrom Scratch thisupperboundmightbeviewedasgoodorbad.
Onthedownside, wearelimitingthe speedatwhichwecanreducethevalueoftheobjective.
Onthebrightside, thislimitsby justhowmuchwecangowronginanyonegradientstep.
Whenwesaythatgradientsexplode, wemeanthat kgk becomesexcessivelylarge.
Inthis worstcase, wemightdosomuchdamageinasinglegradientstepthatwecouldundoall oftheprogressmadeoverthecourseofthousandsoftrainingiterations.
Whengradients canbe so large, neural networktraining often diverges, failingto reduce thevalueof the objective.
Atothertimes, trainingeventuallyconvergesbutisunstableowingtomassive spikesintheloss.
One way to limit the size of ğ¿ğœ‚kgk is to shrink the learning rate ğœ‚ to tiny values.
This has the advantage that we do not bias the updates.
But what if we only rarely get large gradients? Thisdrasticmoveslowsdownourprogressatallsteps, justtodealwiththerare explodinggradientevents.
Apopularalternativeistoadoptagradientclippingheuristic projectingthegradientsgontoaballofsomegivenradiusğœƒ asfollows: ğœƒ g min 1, g.
(9.5.3) kgk Thisensuresthatthegradientnormneverexceedsğœƒandthattheupdatedgradientisentirely alignedwiththeoriginaldirectionofg.
Italsohasthedesirableside-effectoflimitingthe influenceanygivenminibatch(andwithinitanygivensample)canexertontheparameter vector.
Thisbestowsacertaindegreeofrobustnesstothemodel.
Tobeclear, itisahack.
Gradientclippingmeansthatwearenotalwaysfollowingthetruegradientanditishardto reasonanalyticallyaboutthepossiblesideeffects.
However, itisaveryusefulhack, andis widelyadoptedin RNNimplementationsinmostdeeplearningframeworks.
Belowwedefineamethodtoclipgradients, whichisinvokedbythefit_epochmethod ofthed2l.
Trainerclass(see Section3.4).
Notethatwhencomputingthegradientnorm, weareconcatenatingallmodelparameters, treatingthemasasinglegiantparametervec- tor.
@d2l.
add_to_class(d2l.
Trainer) #@save def clip_gradients(self, grad_clip_val, model): params = [p for p in model.
parameters() if p.
requires_grad] norm = torch.
sqrt(sum(torch.
sum((p.
grad ** 2)) for p in params)) if norm > grad_clip_val: for param in params: param.
grad[:] *= grad_clip_val / norm 9.5.4 Training Using The Time Machinedataset(data), wetrainacharacter-levellanguagemodel(model) basedonthe RNN(rnn)implementedfromscratch.
Notethatwefirstcalculatethegra- dients, then clip them, and finally update the model parameters using the clipped gradi- ents.
358 Recurrent Neural Networks data = d2l.
Time Machine(batch_size=1024, num_steps=32) rnn = RNNScratch(num_inputs=len(data.
vocab), num_hiddens=32) model = RNNLMScratch(rnn, vocab_size=len(data.
vocab), lr=1) trainer = d2l.
Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) 9.5.5 Decoding Oncealanguagemodelhasbeenlearned, wecanuseitnotonlytopredictthenexttoken buttocontinuepredictingeachsubsequentone, treatingthepreviouslypredictedtokenas thoughitwerethenextintheinput.
Sometimeswewilljustwanttogeneratetextasthough wewerestartingatthebeginningofadocument.
However, itisoftenusefultoconditionthe languagemodelonauser-suppliedprefix.
Forexample, ifweweredevelopinganautocom- pletefeatureforasearchengineortoassistusersinwritingemails, wewouldwanttofeed inwhattheyhadwrittensofar(theprefix), andthengeneratealikelycontinuation.
The following predict method generates a continuation, one character at a time, after ingesting a user-provided prefix.
When looping through the characters in prefix, we keeppassingthehiddenstatetothenexttimestepbutdonotgenerateanyoutput.
Thisis calledthewarm-upperiod.
Afteringestingtheprefix, wearenowreadytobeginemitting thesubsequentcharacters, eachofwhichwillbefedbackintothemodelastheinputatthe nexttimestep.
@d2l.
add_to_class(RNNLMScratch) #@save def predict(self, prefix, num_preds, vocab, device=None): state, outputs = None, [vocab[prefix[0]]] for i in range(len(prefix) + num_preds - 1): X = torch.
tensor([[outputs[-1]]], device=device) embs = self.
one_hot(X) rnn_outputs, state = self.
rnn(embs, state) if i < len(prefix) - 1: # Warm-up period outputs.
append(vocab[prefix[i + 1]]) else: # Predict num_preds steps Y = self.
output_layer(rnn_outputs) outputs.
append(int(Y.
argmax(axis=2).
reshape(1))) return ''.
join([vocab.
idx_to_token[i] for i in outputs]) Inthefollowing, wespecifytheprefixandhaveitgenerate20additionalcharacters.
359 Recurrent Neural Network Implementationfrom Scratch model.
predict('it has', 20, data.
vocab, d2l.
try_gpu()) 'it has in the the the the ' Whileimplementingtheabove RNNmodelfromscratchisinstructive, itisnotconvenient.
Inthenextsection, wewillseehowtoleveragedeeplearningframeworkstowhipup RNNs usingstandardarchitectures, andtoreapperformancegainsbyrelyingonhighlyoptimized libraryfunctions.
9.5.6 Summary Wecantrain RNN-basedlanguagemodelstogeneratetextfollowingtheuser-providedtext prefix.
A simple RNN language model consists of input encoding, RNN modeling, and outputgeneration.
Duringtraining, gradientclippingcanmitigatetheproblemofexplod- inggradientsbutdoesnotaddresstheproblemofvanishinggradients.
Intheexperiment, weimplementedasimple RNNlanguagemodelandtraineditwithgradientclippingonse- quencesoftext, tokenizedatthecharacterlevel.
Byconditioningonaprefix, wecanusea languagemodeltogeneratelikelycontinuations, whichprovesusefulinmanyapplications, e.
g., autocompletefeatures.
9.5.7 Exercises 1.
Doestheimplementedlanguagemodelpredictthenexttokenbasedonallthepasttokens uptotheveryfirsttokenin The Time Machine? 2.
Whichhyperparametercontrolsthelengthofhistoryusedforprediction? 3.
Show that one-hot encoding is equivalent to picking a different embedding for each object.
4.
Adjustthehyperparameters(e.
g., numberofepochs, numberofhiddenunits, number oftimestepsinaminibatch, andlearningrate)toimprovetheperplexity.
Howlowcan yougowhilestickingwiththissimplearchitecture? 5.
Replaceone-hotencodingwithlearnableembeddings.
Doesthisleadtobetterperfor- mance? 6.
Conductanexperimenttodeterminehowwellthislanguagemodeltrainedon The Time 7.
Conductanotherexperimenttoevaluatetheperplexityofthismodelonbookswritten byotherauthors.
8.
Modifythepredictionmethodsoastousesamplingratherthanpickingthemostlikely nextcharacter.
Whathappens? 360 Recurrent Neural Networks Biasthemodeltowardsmorelikelyoutputs, e.
g., bysamplingfromğ‘â€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 â€ / ğ‘ƒâ€ğ‘¥ ğ‘¡ j ğ‘¥ ğ‘¡ 1 ,...,ğ‘¥ 1 â€ğ›¼ forğ›¼ >1.
9.
Runthecodeinthissectionwithoutclippingthegradient.
Whathappens? 10.
Replace the activation function used in this section with Re LU and repeat the experi- mentsinthissection.
Dowestillneedgradientclipping? Why? 142 Discussions142.
9.6 Concise Implementation of Recurrent Neural Networks Like most of our from-scratch implementations, Section 9.5 was designed to provide in- sightintohoweachcomponentworks.
Butwhenyouareusing RNNseverydayorwriting productioncode, youwillwanttorelymoreonlibrariesthatcutdownonbothimplemen- tationtime(bysupplyinglibrarycodeforcommonmodelsandfunctions)andcomputation time(byoptimizingtheheckoutoftheselibraryimplementations).
Thissectionwillshow youhowtoimplementthesamelanguagemodelmoreefficientlyusingthehigh-level API provided by your deep learning framework.
We begin, as before, by loading The Time Machinedataset.
import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 9.6.1 Definingthe Model Wedefinethefollowingclassusingthe RNNimplementedbyhigh-level APIs.
class RNN(d2l.
Module): #@save """The RNN model implemented with high-level APIs.""" def __init__(self, num_inputs, num_hiddens): super().__init__() self.
save_hyperparameters() self.
rnn = nn.
RNN(num_inputs, num_hiddens) def forward(self, inputs, H=None): return self.
rnn(inputs, H) Inheritingfromthe RNNLMScratchclassin Section9.5, thefollowing RNNLMclassdefines acomplete RNN-basedlanguagemodel.
Notethatweneedtocreateaseparatefullycon- nectedoutputlayer.
361 Concise Implementationof Recurrent Neural Networks class RNNLM(d2l.
RNNLMScratch): #@save """The RNN-based language model implemented with high-level APIs.""" def init_params(self): self.
linear = nn.
Lazy Linear(self.
vocab_size) def output_layer(self, hiddens): return self.
linear(hiddens).
swapaxes(0, 1) 9.6.2 Trainingand Predicting Before training the model, letâ€™s make a prediction with a model initialized with random weights.
Giventhatwehavenottrainedthenetwork, itwillgeneratenonsensicalpredic- tions.
data = d2l.
Time Machine(batch_size=1024, num_steps=32) rnn = RNN(num_inputs=len(data.
vocab), num_hiddens=32) model = RNNLM(rnn, vocab_size=len(data.
vocab), lr=1) model.
predict('it has', 20, data.
vocab) 'it hasoadd dd dd dd dd dd ' Next, wetrainourmodel, leveragingthehigh-level API.
trainer = d2l.
Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) Comparedwith Section9.5, thismodelachievescomparableperplexity, butrunsfasterdue totheoptimizedimplementations.
Asbefore, wecangeneratepredictedtokensfollowing thespecifiedprefixstring.
model.
predict('it has', 20, data.
vocab, d2l.
try_gpu()) 'it has and the trave the t' 9.6.3 Summary 362 Recurrent Neural Networks High-level APIsindeeplearningframeworksprovideimplementationsofstandard RNNs.
Theselibrarieshelpyoutoavoidwastingtimereimplementingstandardmodels.
Moreover, framework implementations are often highly optimized, leading to significant (computa- tional)performancegainswhencomparedwithimplementationsfromscratch.
9.6.4 Exercises 1.
Canyoumakethe RNNmodeloverfitusingthehigh-level APIs? 2.
Implementtheautoregressivemodelof Section9.1usingan RNN.
Discussions143.
143 9.7 Backpropagation Through Time Ifyoucompletedtheexercisesin Section9.5, youwouldhaveseenthatgradientclippingis vitalforpreventingtheoccasionalmassivegradientsfromdestabilizingtraining.
Wehinted thattheexplodinggradientsstemfrombackpropagatingacrosslongsequences.
Beforein- troducingaslewofmodern RNNarchitectures, letâ€™stakeacloserlookathowbackprop- agationworksinsequencemodelsinmathematicaldetail.
Hopefully, thisdiscussionwill bringsomeprecisiontothenotionofvanishingandexplodinggradients.
Ifyourecallour discussionofforwardandbackwardpropagationthroughcomputationalgraphswhenwe introduced MLPs in Section 5.3, then forward propagation in RNNs should be relatively straightforward.
Applying backpropagation in RNNs is called backpropagation through time(Werbos,1990).
Thisprocedurerequiresustoexpand(orunroll)thecomputational graphofan RNNonetimestepatatime.
Theunrolled RNNisessentiallyafeedforward neuralnetworkwiththespecialpropertythatthesameparametersarerepeatedthroughout theunrollednetwork, appearingateachtimestep.
Then, justasinanyfeedforwardneural network, wecanapplythechainrule, backpropagatinggradientsthroughtheunrollednet.
Thegradientwithrespecttoeachparametermustbesummedacrossallplacesthatthepa- rameteroccursintheunrollednet.
Handlingsuchweighttyingshouldbefamiliarfromour chaptersonconvolutionalneuralnetworks.
Complicationsarisebecausesequencescanberatherlong.
Itisnotunusualtoworkwith text sequences consisting of over a thousand tokens.
Note that this poses problems both fromacomputational(toomuchmemory)andoptimization(numericalinstability)stand- point.
Inputfromthefirststeppassesthroughover1000matrixproductsbeforearriving attheoutput, andanother1000matrixproductsarerequiredtocomputethegradient.
We nowanalyzewhatcangowrongandhowtoaddressitinpractice.
9.7.1 Analysisof Gradientsin RNNs Westartwithasimplifiedmodelofhowan RNNworks.
Thismodelignoresdetailsabout thespecificsofthehiddenstateandhowitisupdated.
Themathematicalnotationheredoes 363 Backpropagation Through Time notexplicitlydistinguishscalars, vectors, andmatrices.
Wearejusttryingtodevelopsome intuition.
Inthissimplifiedmodel, wedenoteâ„ ğ‘¡ asthehiddenstate,ğ‘¥ ğ‘¡ asinput, andğ‘œ ğ‘¡ as outputattimestepğ‘¡.
Recallourdiscussionsin Section9.4.2thattheinputandthehidden statecanbeconcatenatedbeforebeingmultipliedbyoneweightvariableinthehiddenlayer.
Thus, weuse ğ‘¤ and ğ‘¤ toindicatetheweightsofthehidden layerandtheoutput layer, h o respectively.
Asaresult, thehiddenstatesandoutputsateachtimestepare â„ ğ‘¡ = ğ‘“â€ğ‘¥ ğ‘¡ ,â„ ğ‘¡ 1 ,ğ‘¤ h â€, (9.7.1) ğ‘œ ğ‘¡ =ğ‘”â€â„ ğ‘¡ ,ğ‘¤ o â€, where ğ‘“ and ğ‘” are transformations of the hidden layer and the output layer, respectively.
each other via recurrent computation.
The forward propagation is fairly straightforward.
Allweneedistoloopthroughthe â€ğ‘¥ ğ‘¡ ,â„ ğ‘¡ ,ğ‘œ ğ‘¡ â€ triplesonetimestepatatime.
Thediscrep- ancybetweenoutputğ‘œ ğ‘¡ andthedesiredtargetğ‘¦ ğ‘¡ isthenevaluatedbyanobjectivefunction acrossalltheğ‘‡ timestepsas ğ‘‡ 1 ğ‘¡=1 Forbackpropagation, mattersareabittrickier, especiallywhenwecomputethegradients withregardtotheparametersğ‘¤ oftheobjectivefunction ğ¿.
Tobespecific, bythechain h rule, ğœ•ğ¿ 1 ğ‘‡ ğœ•ğ‘™â€ğ‘¦ ğ‘¡ ,ğ‘œ ğ‘¡ â€ = ğœ•ğ‘¤ ğ‘‡ ğœ•ğ‘¤ h ğ‘¡=1 h (9.7.3) = 1 ğ‘‡ ğœ•ğ‘™â€ğ‘¦ ğ‘¡ ,ğ‘œ ğ‘¡ â€ ğœ•ğ‘”â€â„ ğ‘¡ ,ğ‘¤ o â€ ğœ•â„ ğ‘¡ .
ğ‘‡ ğœ•ğ‘œ ğœ•â„ ğœ•ğ‘¤ ğ‘¡=1 ğ‘¡ ğ‘¡ h The first and the second factors of the product in (9.7.3) are easy to compute.
The third factorğœ•â„ ğ‘¡ ğœ•ğ‘¤ h iswherethingsgettricky, sinceweneedtorecurrentlycomputetheeffect oftheparameterğ‘¤ h onâ„ ğ‘¡.
Accordingtotherecurrentcomputationin(9.7.1),â„ ğ‘¡ depends onbothâ„ ğ‘¡ 1 andğ‘¤ h , wherecomputationofâ„ ğ‘¡ 1 alsodependsonğ‘¤ h .
Thus, evaluatingthe totalderivateofâ„ ğ‘¡ withrespecttoğ‘¤ h usingthechainruleyields ğœ•â„ ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğœ•â„ ğ‘¡ = ğ‘¡ ğ‘¡ 1 h â€š ğ‘¡ ğ‘¡ 1 h ğ‘¡ 1.
(9.7.4) ğœ•ğ‘¤ ğœ•ğ‘¤ ğœ•â„ ğœ•ğ‘¤ h h ğ‘¡ 1 h Toderivetheabovegradient, assumethatwehavethreesequencesfğ‘ ğ‘¡ g, fğ‘ ğ‘¡ g, fğ‘ ğ‘¡ gsatisfy- ingğ‘ 0 =0andğ‘ ğ‘¡ = ğ‘ ğ‘¡ â€šğ‘ ğ‘¡ ğ‘ ğ‘¡ 1 forğ‘¡ =1,2,....
Thenforğ‘¡ 1, itiseasytoshow ğ‘¡ 1' ğ‘¡ â€œ ğ‘ ğ‘¡ = ğ‘ ğ‘¡ â€š â€º ğ‘ ğ‘— fiğ‘ ğ‘– .
(9.7.5) ğ‘–=1Â«ğ‘—=ğ‘–â€š1 â€¹ 364 Recurrent Neural Networks Bysubstitutingğ‘ ğ‘¡,ğ‘ ğ‘¡, andğ‘ ğ‘¡ accordingto ğœ•â„ ğ‘ ğ‘¡ = ğœ•ğ‘¤ ğ‘¡ , h ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğ‘ ğ‘¡ = ğ‘¡ ğœ•ğ‘¤ ğ‘¡ 1 h , (9.7.6) h ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğ‘ ğ‘¡ = ğ‘¡ ğœ•â„ ğ‘¡ 1 h , ğ‘¡ 1 removetherecurrentcomputationin(9.7.4)with ğœ•â„ ğ‘¡ = ğœ•ğ‘“â€ğ‘¥ ğ‘¡ ,â„ ğ‘¡ 1 ,ğ‘¤ h â€ â€š ğ‘¡ 1' â€º ğ‘¡ ğœ•ğ‘“â€ğ‘¥ ğ‘— ,â„ ğ‘— 1 ,ğ‘¤ h â€â€œ fi ğœ•ğ‘“â€ğ‘¥ ğ‘– ,â„ ğ‘– 1 ,ğ‘¤ h â€ .
(9.7.7) ğœ•ğ‘¤ ğœ•ğ‘¤ ğœ•â„ ğœ•ğ‘¤ h h ğ‘–=1Â«ğ‘—=ğ‘–â€š1 ğ‘— 1 â€¹ h Whilewecanusethechainruletocompute ğœ•â„ ğ‘¡ ğœ•ğ‘¤ h recursively, thischaincangetvery longwheneverğ‘¡ islarge.
Letâ€™sdiscussanumberofstrategiesfordealingwiththisprob- lem.
Full Computation One idea might be to compute the full sum in (9.7.7).
However, this is very slow and gradientscanblowup, sincesubtlechangesintheinitialconditionscanpotentiallyaffect theoutcomealot.
Thatis, wecouldseethingssimilartothebutterflyeffect, whereminimal changesintheinitialconditionsleadtodisproportionatechangesintheoutcome.
Thisis generallyundesirable.
Afterall, wearelookingforrobustestimatorsthatgeneralizewell.
Hencethisstrategyisalmostneverusedinpractice.
Truncating Time Steps Alternatively, wecantruncatethesumin(9.7.7)afterğœ steps.
Thisiswhatwehavebeen discussingsofar.
Thisleadstoanapproximationofthetruegradient, simplybyterminating thesumatğœ•â„ ğ‘¡ ğœ ğœ•ğ‘¤ h .
Inpracticethisworksquitewell.
Itiswhatiscommonlyreferred toastruncatedbackpropgationthroughtime(Jaeger, 2002).
Oneoftheconsequencesof thisisthatthemodelfocusesprimarilyonshort-terminfluenceratherthanlong-termcon- sequences.
Thisisactuallydesirable, sinceitbiasestheestimatetowardssimplerandmore stablemodels.
Randomized Truncation Last, we can replace ğœ•â„ ğ‘¡ ğœ•ğ‘¤ h by a random variable which is correct in expectation but truncates the sequence.
This is achieved by using a sequence of ğœ‰ ğ‘¡ with predefined 0 ğœ‹ ğ‘¡ 1, whereğ‘ƒâ€ğœ‰ ğ‘¡ = 0â€ = 1 ğœ‹ ğ‘¡ andğ‘ƒâ€ğœ‰ ğ‘¡ = ğœ‹ ğ‘¡ 1â€ = ğœ‹ ğ‘¡, thusğ¸Â»ğœ‰ ğ‘¡ â€¦ = 1.
Weusethisto replacethegradientğœ•â„ ğ‘¡ ğœ•ğ‘¤ h in(9.7.4)with ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğœ•ğ‘“â€ğ‘¥ ,â„ ,ğ‘¤ â€ ğœ•â„ ğ‘§ ğ‘¡ = ğ‘¡ ğœ•ğ‘¤ ğ‘¡ 1 h â€šğœ‰ ğ‘¡ ğ‘¡ ğœ•â„ ğ‘¡ 1 h ğœ•ğ‘¤ ğ‘¡ 1.
(9.7.8) h ğ‘¡ 1 h 365 Backpropagation Through Time Itfollowsfromthedefinitionofğœ‰ ğ‘¡ thatğ¸Â»ğ‘§ ğ‘¡ â€¦ = ğœ•â„ ğ‘¡ ğœ•ğ‘¤ h .
Wheneverğœ‰ ğ‘¡ = 0therecurrent computationterminatesatthattimestepğ‘¡.
Thisleadstoaweightedsumofsequencesof varyinglengths, wherelongsequencesarerarebutappropriatelyoverweighted.
Thisidea wasproposedby Tallecand Ollivier(2017).
Comparing Strategies t .7.1 Comparingstrategiesforcomputinggradientsin RNNs.
Fromtoptobottom: randomized truncation, regulartruncation, andfullcomputation.
.7.1illustratesthethreestrategieswhenanalyzingthefirstfewcharactersof The Time Machineusingbackpropagationthroughtimefor RNNs: Thefirstrowistherandomizedtruncationthatpartitionsthetextintosegmentsofvarying lengths.
The second row is the regular truncation that breaks the text into subsequences of the samelength.
Thisiswhatwehavebeendoingin RNNexperiments.
Thethirdrowisthefullbackpropagationthroughtimethatleadstoacomputationally infeasibleexpression.
Unfortunately, whileappealingintheory, randomizedtruncationdoesnotworkmuchbet- terthan regular truncation, mostlikelydue to a number offactors.
First, the effectof an observationafteranumberofbackpropagationstepsintothepastisquitesufficienttocap- turedependenciesinpractice.
Second, theincreasedvariancecounteractsthefactthatthe gradientismoreaccuratewithmoresteps.
Third, weactuallywantmodelsthathaveonly ashortrangeofinteractions.
Hence, regularlytruncatedbackpropagationthroughtimehas aslightregularizingeffectthatcanbedesirable.
9.7.2 Backpropagation Through Timein Detail Afterdiscussingthegeneralprinciple, letâ€™sdiscussbackpropagationthroughtimeindetail.
Incontrasttotheanalysisin Section9.7.1, inthefollowingwewillshowhowtocomputethe gradientsoftheobjectivefunctionwithrespecttoallthedecomposedmodelparameters.
To keep things simple, we consider an RNN without bias parameters, whose activation function in the hidden layer uses the identity mapping (ğœ™â€ğ‘¥â€ = ğ‘¥).
For time step ğ‘¡, let thesingleexampleinputandthetargetbexğ‘¡ 2 Rğ‘‘ and ğ‘¦ ğ‘¡, respectively.
Thehiddenstate hğ‘¡ 2Râ„ andtheoutputoğ‘¡ 2Rğ‘ arecomputedas hğ‘¡ =W hx xğ‘¡ â€šW hh hğ‘¡ 1 , (9.7.9) oğ‘¡ =W qh hğ‘¡ , 366 Recurrent Neural Networks where W 2 Râ„ ğ‘‘ , W 2 Râ„ â„ , and W 2 Rğ‘ â„ aretheweightparameters.
Denote hx hh qh byğ‘™â€oğ‘¡ ,ğ‘¦ ğ‘¡ â€ thelossattimestepğ‘¡.
Ourobjectivefunction, thelossoverğ‘‡ timestepsfrom thebeginningofthesequenceisthus ğ‘‡ 1 ğ¿ = ğ‘‡ ğ‘™â€oğ‘¡ ,ğ‘¦ ğ‘¡ â€.
(9.7.10) ğ‘¡=1 Inordertovisualizethedependenciesamongmodelvariablesandparametersduringcom- putationofthe RNN, wecandrawacomputationalgraphforthemodel, asshownin.7.2.
For example, the computation of the hidden states of time step 3, h , depends on 3 themodelparameters W and W , thehiddenstateoftheprevioustimesteph , andthe hx hh 2 inputofthecurrenttimestepx .
3 t .7.2 Computationalgraphshowingdependenciesforan RNNmodelwiththreetimesteps.
Boxesrepresentvariables(notshaded)orparameters(shaded)andcirclesrepresent operators.
As just mentioned, the model parameters in .7.2 are W , W , and W .
Gen- hx hh qh erally, trainingthismodelrequiresgradientcomputationwithrespecttotheseparameters ğœ•ğ¿ ğœ•W ,ğœ•ğ¿ ğœ•W , andğœ•ğ¿ ğœ•W .
Accordingtothedependenciesin.7.2, wecan hx hh qh traverseintheoppositedirectionofthearrowstocalculateandstorethegradientsinturn.
Toflexiblyexpressthemultiplicationofmatrices, vectors, andscalarsofdifferentshapes inthechainrule, wecontinuetousetheprodoperatorasdescribedin Section5.3.
First of all, differentiating the objective function with respect to the model output at any timestepğ‘¡ isfairlystraightforward: ğœ•ğ¿ = ğœ•ğ‘™â€oğ‘¡ ,ğ‘¦ ğ‘¡ â€ 2Rğ‘.
(9.7.11) ğœ•oğ‘¡ ğ‘‡ ğœ•oğ‘¡ Nowwecancalculatethegradientoftheobjectivewithrespecttotheparameter W in qh theoutputlayer: ğœ•ğ¿ ğœ•W 2Rğ‘ â„ .
Basedon.7.2, theobjectiveğ¿dependson W qh qh viao 1 ,..., oğ‘‡.
Usingthechainruleyields ğœ•W ğœ•ğ¿ qh = ğ‘¡ ğ‘‡ =1 prod ğœ• ğœ• o ğ¿ ğ‘¡ , ğœ• ğœ• W oğ‘¡ qh = ğ‘¡ ğ‘‡ =1 ğœ• ğœ• o ğ¿ ğ‘¡ h > ğ‘¡ , (9.7.12) whereğœ•ğ¿ ğœ•oğ‘¡ isgivenby(9.7.11).
Next, asshownin.7.2, atthefinaltimestepğ‘‡, theobjectivefunction ğ¿ dependson thehiddenstatehğ‘‡ onlyviaoğ‘‡.
Therefore, wecaneasilyfindthegradientğœ•ğ¿ ğœ•hğ‘‡ 2 Râ„ 367 Backpropagation Through Time usingthechainrule: ğœ•ğ¿ =prod ğœ•ğ¿ , ğœ•oğ‘‡ =W > ğœ•ğ¿ .
(9.7.13) ğœ•hğ‘‡ ğœ•oğ‘‡ ğœ•hğ‘‡ qhğœ•oğ‘‡ Itgetstrickierforanytimestepğ‘¡ < ğ‘‡, wheretheobjectivefunction ğ¿ dependsonhğ‘¡ via hğ‘¡â€š1 andoğ‘¡.
Accordingtothechainrule, thegradientofthehiddenstateğœ•ğ¿ ğœ•hğ‘¡ 2 Râ„ at anytimestepğ‘¡ <ğ‘‡ canberecurrentlycomputedas: ğœ•ğ¿ =prod ğœ•ğ¿ , ğœ•hğ‘¡â€š1 â€šprod ğœ•ğ¿ , ğœ•oğ‘¡ =W > ğœ•ğ¿ â€šW > ğœ•ğ¿ .
(9.7.14) ğœ•hğ‘¡ ğœ•hğ‘¡â€š1 ğœ•hğ‘¡ ğœ•oğ‘¡ ğœ•hğ‘¡ hhğœ•hğ‘¡â€š1 qhğœ•oğ‘¡ Foranalysis, expandingtherecurrentcomputationforanytimestep1 ğ‘¡ ğ‘‡gives ğœ•ğ¿ ğ‘‡ ğœ•ğ¿ = W > ğ‘‡ ğ‘– W > .
(9.7.15) ğœ•hğ‘¡ hh qhğœ•oğ‘‡â€šğ‘¡ ğ‘– ğ‘–=ğ‘¡ Wecanseefrom(9.7.15)thatthissimplelinearexamplealreadyexhibitssomekeyprob- lems of long sequence models: it involves potentially very large powers of W> .
In it, hh eigenvalues smaller than 1 vanish and eigenvalues larger than 1 diverge.
This is numer- ically unstable, which manifests itself in the form of vanishing and exploding gradients.
Onewaytoaddressthisistotruncatethetimestepsatacomputationallyconvenientsizeas discussedin Section9.7.1.
Inpractice, thistruncationcanalsobeeffectedbydetachingthe gradientafteragivennumberoftimesteps.
Lateron, wewillseehowmoresophisticated sequencemodelssuchaslongshort-termmemorycanalleviatethisfurther.
Finally,.7.2showsthattheobjectivefunction ğ¿ dependsonmodelparameters W hx and W hh in the hidden layer via hidden states h 1 ,..., hğ‘‡.
To compute gradients with respecttosuchparametersğœ•ğ¿ ğœ•W 2 Râ„ ğ‘‘ andğœ•ğ¿ ğœ•W 2 Râ„ â„ , weapplythechain hx hh rulegiving ğœ•W ğœ•ğ¿ hx = ğ‘¡ ğ‘‡ =1 prod ğœ• ğœ• h ğ¿ ğ‘¡ , ğœ• ğœ• W hğ‘¡ hx = ğ‘¡ ğ‘‡ =1 ğœ• ğœ• h ğ¿ ğ‘¡ x > ğ‘¡ , (9.7.16) ğœ•ğ¿ = ğ‘‡ prod ğœ•ğ¿ , ğœ•hğ‘¡ = ğ‘‡ ğœ•ğ¿ h > , ğœ•W hh ğ‘¡=1 ğœ•hğ‘¡ ğœ•W hh ğ‘¡=1 ğœ•hğ‘¡ ğ‘¡ 1 whereğœ•ğ¿ ğœ•hğ‘¡ whichisrecurrentlycomputedby(9.7.13)and(9.7.14)isthekeyquantity thataffectsthenumericalstability.
Sincebackpropagationthroughtimeistheapplicationofbackpropagationin RNNs, aswe have explained in Section 5.3, training RNNs alternates forward propagation with back- propagationthroughtime.
Moreover, backpropagationthroughtimecomputesandstores theabovegradientsinturn.
Specifically, storedintermediatevaluesarereusedtoavoiddu- plicatecalculations, suchasstoringğœ•ğ¿ ğœ•hğ‘¡ tobeusedincomputationofbothğœ•ğ¿ ğœ•W hx andğœ•ğ¿ ğœ•W .
hh 9.7.3 Summary 368 Recurrent Neural Networks Backpropagation through time is merely an application of backpropagation to sequence modelswithahiddenstate.
Truncation, suchasregularorrandomized, isneededforcom- putationalconvenienceandnumericalstability.
Highpowersofmatricescanleadtodiver- gentorvanishingeigenvalues.
Thismanifestsitselfintheformofexplodingorvanishing gradients.
Forefficientcomputation, intermediatevaluesarecachedduringbackpropaga- tionthroughtime.
9.7.4 Exercises 1.
Assume that we have a symmetric matrix M 2 Rğ‘› ğ‘› with eigenvaluesğœ† ğ‘– whose cor- respondingeigenvectorsarevğ‘– (ğ‘– = 1,...,ğ‘›).
Withoutlossofgenerality, assumethat theyareorderedintheorderjğœ† ğ‘– j jğœ† ğ‘–â€š1 j.
1.
Showthat Mğ‘˜ haseigenvaluesğœ†ğ‘˜ .
ğ‘– 2.
Provethatforarandomvectorx2Rğ‘› , withhighprobability Mğ‘˜xwillbeverymuch alignedwiththeeigenvectorv of M.
Formalizethisstatement.
1 3.
Whatdoestheaboveresultmeanforgradientsin RNNs? 2.
Besides gradient clipping, can you think of any other methods to cope with gradient explosioninrecurrentneuralnetworks? Discussions144.
144 10 Modern Recurrent Neural Networks Thepreviouschapterintroducedthekeyideasbehindrecurrentneuralnetworks(RNNs).
However, justaswithconvolutionalneuralnetworks, therehasbeenatremendousamount of innovation in RNN architectures, culminating in several complex designs that have provensuccessfulinpractice.
Inparticular, themostpopulardesignsfeaturemechanisms formitigatingthenotoriousnumericalinstabilityfacedby RNNs, astypifiedbyvanishing andexplodinggradients.
Recallthatin Chapter9wedealtwithexplodinggradientsbyap- plyingabluntgradientclippingheuristic.
Despitetheefficacyofthishack, itleavesopen theproblemofvanishinggradients.
Inthischapter, weintroducethekeyideasbehindthemostsuccessful RNNarchitecturesfor sequences, whichstemfromtwopapers.
Thefirst, Long Short-Term Memory(Hochreiter and Schmidhuber,1997), introducesthememorycell, aunitofcomputationthatreplaces traditional nodes in the hidden layer of a network.
With these memory cells, networks are able to overcome difficulties with training encountered by earlier recurrent networks.
Intuitively, the memory cell avoids the vanishing gradient problem by keeping values in each memory cellâ€™s internal state cascading along a recurrent edge with weight 1 across manysuccessivetimesteps.
Asetofmultiplicativegateshelpthenetworktodeterminenot onlytheinputstoallowintothememorystate, butwhenthecontentofthememorystate shouldinfluencethemodelâ€™soutput.
Thesecondpaper, Bidirectional Recurrent Neural Networks(Schusterand Paliwal,1997), introducesanarchitectureinwhichinformationfromboththefuture(subsequenttimesteps) andthepast(precedingtimesteps)areusedtodeterminetheoutputatanypointinthese- quence.
This is in contrast to previous networks, in which only past input can affect the output.
Bidirectional RNNshavebecomeamainstayforsequencelabelingtasksinnatu- rallanguageprocessing, amongamyriadofothertasks.
Fortunately, thetwoinnovations arenotmutuallyexclusive, andhavebeensuccessfullycombinedforphonemeclassification (Gravesand Schmidhuber,2005)andhandwritingrecognition(Gravesetal.,2008).
Thefirstsectionsinthischapterwillexplainthe LSTMarchitecture, alighter-weightversion calledthegatedrecurrentunit(GRU), thekeyideasbehindbidirectional RNNsandabrief explanation of how RNN layers are stacked together to form deep RNNs.
Subsequently, wewillexploretheapplicationof RNNsinsequence-to-sequencetasks, introducingma- chine translation along with key ideas such as encoderâ€“decoder architectures and beam search.
369 370 Modern Recurrent Neural Networks 10.1 Long Short-Term Memory (LSTM) Shortlyafterthefirst Elman-style RNNsweretrainedusingbackpropagation(Elman,1990), theproblemsoflearninglong-termdependencies(owingtovanishingandexplodinggra- dients)becamesalient, with Bengioand Hochreiterdiscussingtheproblem(Bengioetal., 1994, Hochreiteretal.,2001).
Hochreiterhadarticulatedthisproblemasearlyas1991in his Masterâ€™sthesis, althoughtheresultswerenotwidelyknownbecausethethesiswaswrit- tenin German.
Whilegradientclippinghelpswithexplodinggradients, handlingvanishing gradientsappearstorequireamoreelaboratesolution.
Oneofthefirstandmostsuccessful techniquesforaddressingvanishinggradientscameintheformofthelongshort-termmem- ory(LSTM)modeldueto Hochreiterand Schmidhuber(1997).
LSTMsresemblestandard recurrentneuralnetworksbuthereeachordinaryrecurrentnodeisreplacedbyamemory cell.
Each memory cell contains an internal state, i.
e., a node with a self-connected re- currentedgeoffixedweight1, ensuringthatthegradientcanpassacrossmanytimesteps withoutvanishingorexploding.
Thetermâ€œlongshort-termmemoryâ€comesfromthefollowingintuition.
Simplerecurrent neuralnetworkshavelong-termmemoryintheformofweights.
Theweightschangeslowly during training, encoding general knowledge about the data.
They also have short-term memory in the form of ephemeral activations, which pass from each node to successive nodes.
The LSTMmodelintroducesanintermediatetypeofstorageviathememorycell.
A memory cell is a composite unit, built from simpler nodes in a specific connectivity pattern, withthenovelinclusionofmultiplicativenodes.
import torch from torch import nn from d2l import torch as d2l 10.1.1 Gated Memory Cell Eachmemorycellisequippedwithaninternalstateandanumberofmultiplicativegates thatdeterminewhether(i)agiveninputshouldimpacttheinternalstate(theinputgate), (ii)theinternalstateshouldbeflushedto0(theforgetgate), and(iii)theinternalstateofa givenneuronshouldbeallowedtoimpactthecellâ€™soutput(theoutputgate).
Gated Hidden State Thekeydistinctionbetweenvanilla RNNsand LSTMsisthatthelattersupportgatingof thehiddenstate.
Thismeansthatwehavededicatedmechanismsforwhenahiddenstate shouldbeupdatedandalsoforwhenitshouldbereset.
Thesemechanismsarelearnedand theyaddresstheconcernslistedabove.
Forinstance, ifthefirsttokenisofgreatimportance wewilllearnnottoupdatethehiddenstateafterthefirstobservation.
Likewise, wewill learntoskipirrelevanttemporaryobservations.
Last, wewilllearntoresetthelatentstate wheneverneeded.
Wediscussthisindetailbelow.
371 Long Short-Term Memory(LSTM) Input Gate, Forget Gate, and Output Gate Thedatafeedingintothe LSTMgatesaretheinputatthecurrenttimestepandthehidden state of the previous time step, as illustrated in .1.1.
Three fully connected layers withsigmoidactivationfunctionscomputethevaluesoftheinput, forget, andoutputgates.
Asaresultofthesigmoidactivation, allvaluesofthethreegatesareintherangeofâ€0,1â€.
Additionally, we require an input node, typically computed with a tanh activation func- tion.
Intuitively, theinputgatedetermineshowmuchoftheinputnodeâ€™svalueshouldbe addedtothecurrentmemorycellinternalstate.
Theforgetgatedetermineswhethertokeep thecurrentvalueofthememoryorflushit.
Andtheoutputgatedetermineswhetherthe memorycellshouldinfluencetheoutputatthecurrenttimestep.
t .1.1 Computingtheinputgate, theforgetgate, andtheoutputgateinan LSTMmodel.
Mathematically, supposethatthereareâ„hiddenunits, thebatchsizeisğ‘›, andthenumber ofinputsisğ‘‘.
Thus, theinputis Xğ‘¡ 2 Rğ‘› ğ‘‘ andthehiddenstateoftheprevioustimestep is Hğ‘¡ 1 2Rğ‘› â„ .
Correspondingly, thegatesattimestepğ‘¡aredefinedasfollows: theinput gateis Iğ‘¡ 2 Rğ‘› â„ , theforgetgateis Fğ‘¡ 2 Rğ‘› â„ , andtheoutputgateis Oğ‘¡ 2 Rğ‘› â„ .
They arecalculatedasfollows: Iğ‘¡ =ğœâ€Xğ‘¡W xi â€šHğ‘¡ 1 W hi â€šb i â€, Fğ‘¡ =ğœâ€Xğ‘¡W xf â€šHğ‘¡ 1 W hf â€šb f â€, (10.1.1) Oğ‘¡ =ğœâ€Xğ‘¡W xo â€šHğ‘¡ 1 W ho â€šb o â€, where W , W , W 2 Rğ‘‘ â„ and W , W , W 2 Râ„ â„ are weight parameters and xi xf xo hi hf ho b, b, b 2 R1 â„ arebiasparameters.
Notethatbroadcasting(see Section2.1.4)istrig- i f o geredduringthesummation.
Weusesigmoidfunctions(asintroducedin Section5.1)to maptheinputvaluestotheintervalâ€0,1â€.
Input Node Nextwedesignthememorycell.
Sincewehavenotspecifiedtheactionofthevariousgates yet, wefirstintroducetheinputnode CËœ ğ‘¡ 2 Rğ‘› â„ .
Itscomputationissimilartothatofthe threegatesdescribedabove, butusesatanhfunctionwithavaluerangefor â€ 1,1â€ asthe activationfunction.
Thisleadstothefollowingequationattimestepğ‘¡: CËœ ğ‘¡ =tanhâ€Xğ‘¡W xc â€šHğ‘¡ 1 W hc â€šb c â€, (10.1.2) 372 Modern Recurrent Neural Networks where W 2 Rğ‘‘ â„ and W 2 Râ„ â„ are weight parameters and b 2 R1 â„ is a bias xc hc c parameter.
Aquickillustrationoftheinputnodeisshownin.1.2.
t .1.2 Computingtheinputnodeinan LSTMmodel.
Memory Cell Internal State In LSTMs, theinputgate Iğ‘¡ governshowmuchwetakenewdataintoaccountvia CËœ ğ‘¡ and theforgetgate Fğ‘¡ addresseshowmuchoftheoldcellinternalstate Cğ‘¡ 1 2Rğ‘› â„ weretain.
Usingthe Hadamard(elementwise)productoperator wearriveatthefollowingupdate equation: Cğ‘¡ =Fğ‘¡ Cğ‘¡ 1 â€šIğ‘¡ CËœ ğ‘¡ .
(10.1.3) Iftheforgetgateisalways1andtheinputgateisalways0, thememorycellinternalstate Cğ‘¡ 1 willremainconstantforever, passingunchangedtoeachsubsequenttimestep.
How- ever, inputgatesandforgetgatesgivethemodeltheflexibilityofbeingabletolearnwhen tokeepthisvalueunchangedandwhentoperturbitinresponsetosubsequentinputs.
In practice, thisdesignalleviatesthevanishinggradientproblem, resultinginmodelsthatare mucheasiertotrain, especiallywhenfacingdatasetswithlongsequencelengths.
Wethusarriveattheflowdiagramin.1.3.
Hidden State Last, weneedtodefinehowtocomputetheoutputofthememorycell, i.
e., thehiddenstate Hğ‘¡ 2 Rğ‘› â„ , as seen by other layers.
This is where the output gate comes into play.
In LSTMs, wefirstapplytanhtothememorycellinternalstateandthenapplyanotherpoint- wisemultiplication, thistimewiththeoutputgate.
Thisensuresthatthevaluesof Hğ‘¡ are alwaysintheintervalâ€ 1,1â€: Hğ‘¡ =Oğ‘¡ tanhâ€Cğ‘¡ â€.
(10.1.4) Whenevertheoutputgateiscloseto1, weallowthememorycellinternalstatetoimpact thesubsequentlayersuninhibited, whereasforoutputgatevaluescloseto0, wepreventthe 373 Long Short-Term Memory(LSTM) t .1.3 Computingthememorycellinternalstateinan LSTMmodel.
currentmemoryfromimpactingotherlayersofthenetworkatthecurrenttimestep.
Note thatamemorycellcanaccrueinformationacrossmanytimestepswithoutimpactingthe restofthenetwork(aslongastheoutputgatetakesvaluescloseto0), andthensuddenly impactthenetworkatasubsequenttimestepassoonastheoutputgateflipsfromvalues t .1.4 Computingthehiddenstateinan LSTMmodel.
10.1.2 Implementationfrom Scratch Nowletâ€™simplementan LSTMfromscratch.
Assameastheexperimentsin Section9.5, wefirstload The Time Machinedataset.
Initializing Model Parameters Next, weneedtodefineandinitializethemodelparameters.
Aspreviously, thehyperpa- rameternum_hiddensdictatesthenumberofhiddenunits.
Weinitializeweightsfollowing a Gaussiandistributionwith0.01standarddeviation, andwesetthebiasesto0.
class LSTMScratch(d2l.
Module): def __init__(self, num_inputs, num_hiddens, sigma=0.01): (continuesonnextpage) 374 Modern Recurrent Neural Networks (continuedfrompreviouspage) super().__init__() self.
save_hyperparameters() init_weight = lambda *shape: nn.
Parameter(torch.
randn(*shape) * sigma) triple = lambda: (init_weight(num_inputs, num_hiddens), init_weight(num_hiddens, num_hiddens), nn.
Parameter(torch.
zeros(num_hiddens))) self.
W_xi, self.
W_hi, self.
b_i = triple() # Input gate self.
W_xf, self.
W_hf, self.
b_f = triple() # Forget gate self.
W_xo, self.
W_ho, self.
b_o = triple() # Output gate self.
W_xc, self.
W_hc, self.
b_c = triple() # Input node Theactualmodelisdefinedasdescribedabove, consistingofthreegatesandaninputnode.
Notethatonlythehiddenstateispassedtotheoutputlayer.
@d2l.
add_to_class(LSTMScratch) def forward(self, inputs, H_C=None): if H_C is None: # Initial state with shape: (batch_size, num_hiddens) H = torch.
zeros((inputs.
shape[1], self.
num_hiddens), device=inputs.
device) C = torch.
zeros((inputs.
shape[1], self.
num_hiddens), device=inputs.
device) else: H, C = H_C outputs = [] for X in inputs: I = torch.
sigmoid(torch.
matmul(X, self.
W_xi) + torch.
matmul(H, self.
W_hi) + self.
b_i) F = torch.
sigmoid(torch.
matmul(X, self.
W_xf) + torch.
matmul(H, self.
W_hf) + self.
b_f) O = torch.
sigmoid(torch.
matmul(X, self.
W_xo) + torch.
matmul(H, self.
W_ho) + self.
b_o) C_tilde = torch.
tanh(torch.
matmul(X, self.
W_xc) + torch.
matmul(H, self.
W_hc) + self.
b_c) C = F * C + I * C_tilde H = O * torch.
tanh(C) outputs.
append(H) return outputs, (H, C) Trainingand Prediction Letâ€™strainan LSTMmodelbyinstantiatingthe RNNLMScratchclassfrom Section9.5.
data = d2l.
Time Machine(batch_size=1024, num_steps=32) lstm = LSTMScratch(num_inputs=len(data.
vocab), num_hiddens=32) model = d2l.
RNNLMScratch(lstm, vocab_size=len(data.
vocab), lr=4) trainer = d2l.
Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) 10.1.3 Concise Implementation 375 Long Short-Term Memory(LSTM) Using high-level APIs, we can directly instantiate an LSTM model.
This encapsulates all the configuration details that we made explicit above.
The code is significantly faster asitusescompiledoperatorsratherthan Pythonformanydetailsthatwespelledoutbe- fore.
class LSTM(d2l.
RNN): def __init__(self, num_inputs, num_hiddens): d2l.
Module.__init__(self) self.
save_hyperparameters() self.
rnn = nn.
LSTM(num_inputs, num_hiddens) def forward(self, inputs, H_C=None): return self.
rnn(inputs, H_C) lstm = LSTM(num_inputs=len(data.
vocab), num_hiddens=32) model = d2l.
RNNLM(lstm, vocab_size=len(data.
vocab), lr=4) trainer.
fit(model, data) model.
predict('it has', 20, data.
vocab, d2l.
try_gpu()) 'it has a the time travelly' LSTMsaretheprototypicallatentvariableautoregressivemodelwithnontrivialstatecon- trol.
Manyvariantsthereofhavebeenproposedovertheyears, e.
g., multiplelayers, resid- ual connections, different types of regularization.
However, training LSTMs and other 376 Modern Recurrent Neural Networks sequencemodels(suchas GRUs)isquitecostlybecauseofthelongrangedependencyof thesequence.
Laterwewillencounteralternativemodelssuchas Transformersthatcanbe usedinsomecases.
10.1.4 Summary While LSTMswerepublishedin1997, theyrosetogreatprominencewithsomevictoriesin predictioncompetitionsinthemid-2000s, andbecamethedominantmodelsforsequence learning from 2011 until the rise of Transformer models, starting in 2017.
Even Tran- formersowesomeoftheirkeyideastoarchitecturedesigninnovationsintroducedbythe LSTM.
LSTMshavethreetypesofgates: inputgates, forgetgates, andoutputgatesthatcontrolthe flowofinformation.
Thehiddenlayeroutputof LSTMincludesthehiddenstateandthe memorycellinternalstate.
Onlythehiddenstateispassedintotheoutputlayerwhilethe memory cell internal state remains entirely internal.
LSTMs can alleviate vanishing and explodinggradients.
10.1.5 Exercises 1.
Adjustthehyperparametersandanalyzetheirinfluenceonrunningtime, perplexity, and theoutputsequence.
2.
How would you need to change the model to generate proper words rather than just sequencesofcharacters? 3.
Comparethecomputationalcostfor GRUs, LSTMs, andregular RNNsforagivenhid- dendimension.
Payspecialattentiontothetrainingandinferencecost.
4.
Sincethecandidatememorycellensuresthatthevaluerangeisbetween 1and1by usingthetanhfunction, whydoesthehiddenstateneedtousethetanhfunctionagain toensurethattheoutputvaluerangeisbetween 1and1? 5.
Implement an LSTM model for time series prediction rather than character sequence prediction.
145 Discussions145.
10.2 Gated Recurrent Units (GRU) As RNNsandparticularlythe LSTMarchitecture(Section10.1)rapidlygainedpopularity during the 2010s, a number of researchers began to experiment with simplified architec- turesinhopesofretainingthekeyideaofincorporatinganinternalstateandmultiplicative gatingmechanismsbutwiththeaimofspeedingupcomputation.
Thegatedrecurrentunit 377 Gated Recurrent Units(GRU) (GRU)(Choetal.,2014)offeredastreamlinedversionofthe LSTMmemorycellthatof- ten achieves comparable performance but with the advantage of being faster to compute (Chungetal.,2014).
import torch from torch import nn from d2l import torch as d2l 10.2.1 Reset Gateand Update Gate Here, the LSTMâ€™sthreegatesarereplacedbytwo: theresetgateandtheupdategate.
As with LSTMs, these gates are given sigmoid activations, forcing their values to lie in the intervalâ€0,1â€.
Intuitively, theresetgatecontrolshowmuchofthepreviousstatewemight stillwanttoremember.
Likewise, anupdategatewouldallowustocontrolhowmuchof thenewstateisjustacopyoftheoldone.
.2.1illustratestheinputsforboththereset and update gates in a GRU, given the input of the current time step and the hidden state oftheprevioustimestep.
Theoutputsofthegatesaregivenbytwofullyconnectedlayers withasigmoidactivationfunction.
t .2.1 Computingtheresetgateandtheupdategateina GRUmodel.
Mathematically, foragiventimestepğ‘¡, supposethattheinputisaminibatch Xğ‘¡ 2 Rğ‘› ğ‘‘ (numberofexamples=ğ‘›; numberofinputs= ğ‘‘)andthehiddenstateoftheprevioustime stepis Hğ‘¡ 1 2 Rğ‘› â„ (numberofhiddenunits= â„).
Thentheresetgate Rğ‘¡ 2 Rğ‘› â„ and updategate Zğ‘¡ 2Rğ‘› â„ arecomputedasfollows: Rğ‘¡ =ğœâ€Xğ‘¡W xr â€šHğ‘¡ 1 W hr â€šb r â€, (10.2.1) Zğ‘¡ =ğœâ€Xğ‘¡W xz â€šHğ‘¡ 1 W hz â€šb z â€, where W , W 2Rğ‘‘ â„ and W , W 2Râ„ â„ areweightparametersandb, b 2R1 â„ xr xz hr hz r z arebiasparameters.
10.2.2 Candidate Hidden State 378 Modern Recurrent Neural Networks Next, weintegratetheresetgate Rğ‘¡withtheregularupdatingmechanismin(9.4.5), leading tothefollowingcandidatehiddenstate HËœ ğ‘¡ 2Rğ‘› â„ attimestepğ‘¡: HËœ ğ‘¡ =tanhâ€Xğ‘¡W xh â€šâ€Rğ‘¡ Hğ‘¡ 1 â€W hh â€šb h â€, (10.2.2) where W 2Rğ‘‘ â„ and W 2Râ„ â„ areweightparameters, b 2R1 â„ isthebias, andthe xh hh h symbol isthe Hadamard(elementwise)productoperator.
Hereweuseatanhactivation function.
Theresultisacandidate, sincewestillneedtoincorporatetheactionoftheupdategate.
Comparingwith(9.4.5), theinfluenceofthepreviousstatescannowbereducedwiththe elementwisemultiplicationof Rğ‘¡ and Hğ‘¡ 1 in(10.2.2).
Whenevertheentriesinthereset gate Rğ‘¡ arecloseto1, werecoveravanilla RNNsuchasthatin(9.4.5).
Forallentriesof theresetgate Rğ‘¡ thatarecloseto0, thecandidatehiddenstateistheresultofan MLPwith Xğ‘¡ asinput.
Anypre-existinghiddenstateisthusresettodefaults.
.2.2illustratesthecomputationalflowafterapplyingtheresetgate.
t .2.2 Computingthecandidatehiddenstateina GRUmodel.
10.2.3 Hidden State Finally, weneedtoincorporatetheeffectoftheupdategate Zğ‘¡.
Thisdeterminestheextent towhichthenewhiddenstate Hğ‘¡ 2 Rğ‘› â„ matchestheoldstate Hğ‘¡ 1 comparedwithhow much it resembles the new candidate state HËœ ğ‘¡.
The update gate Zğ‘¡ can be used for this purpose, simplybytakingelementwiseconvexcombinationsof Hğ‘¡ 1 and HËœ ğ‘¡.
Thisleads tothefinalupdateequationforthe GRU: Hğ‘¡ =Zğ‘¡ Hğ‘¡ 1 â€šâ€1 Zğ‘¡ â€ HËœ ğ‘¡ .
(10.2.3) Whenever the update gate Zğ‘¡ is close to 1, we simply retain the old state.
In this case the information from Xğ‘¡ is ignored, effectively skipping time step ğ‘¡ in the dependency chain.
By contrast, whenever Zğ‘¡ is close to 0, the new latent state Hğ‘¡ approaches the candidatelatentstate HËœ ğ‘¡.
.2.3showsthecomputationalflowaftertheupdategateis inaction.
Insummary, GRUshavethefollowingtwodistinguishingfeatures: 379 Gated Recurrent Units(GRU) t .2.3 Computingthehiddenstateina GRUmodel.
Resetgateshelpcaptureshort-termdependenciesinsequences.
Updategateshelpcapturelong-termdependenciesinsequences.
10.2.4 Implementationfrom Scratch Togainabetterunderstandingofthe GRUmodel, letâ€™simplementitfromscratch.
Initializing Model Parameters Thefirststepistoinitializethemodelparameters.
Wedrawtheweightsfroma Gaussian distributionwithstandarddeviationtobesigmaandsetthebiasto0.
Thehyperparameter num_hiddens defines the number of hidden units.
We instantiate all weights and biases relatingtotheupdategate, theresetgate, andthecandidatehiddenstate.
class GRUScratch(d2l.
Module): def __init__(self, num_inputs, num_hiddens, sigma=0.01): super().__init__() self.
save_hyperparameters() init_weight = lambda *shape: nn.
Parameter(torch.
randn(*shape) * sigma) triple = lambda: (init_weight(num_inputs, num_hiddens), init_weight(num_hiddens, num_hiddens), nn.
Parameter(torch.
zeros(num_hiddens))) self.
W_xz, self.
W_hz, self.
b_z = triple() # Update gate self.
W_xr, self.
W_hr, self.
b_r = triple() # Reset gate self.
W_xh, self.
W_hh, self.
b_h = triple() # Candidate hidden state Definingthe Model Nowwearereadytodefinethe GRUforwardcomputation.
Itsstructureisthesameasthat ofthebasic RNNcell, exceptthattheupdateequationsaremorecomplex.
@d2l.
add_to_class(GRUScratch) def forward(self, inputs, H=None): (continuesonnextpage) 380 Modern Recurrent Neural Networks (continuedfrompreviouspage) if H is None: # Initial state with shape: (batch_size, num_hiddens) H = torch.
zeros((inputs.
shape[1], self.
num_hiddens), device=inputs.
device) outputs = [] for X in inputs: Z = torch.
sigmoid(torch.
matmul(X, self.
W_xz) + torch.
matmul(H, self.
W_hz) + self.
b_z) R = torch.
sigmoid(torch.
matmul(X, self.
W_xr) + torch.
matmul(H, self.
W_hr) + self.
b_r) H_tilde = torch.
tanh(torch.
matmul(X, self.
W_xh) + torch.
matmul(R * H, self.
W_hh) + self.
b_h) H = Z * H + (1 - Z) * H_tilde outputs.
append(H) return outputs, H Training Trainingalanguagemodelon The Time Machinedatasetworksinexactlythesamemanner asin Section9.5.
data = d2l.
Time Machine(batch_size=1024, num_steps=32) gru = GRUScratch(num_inputs=len(data.
vocab), num_hiddens=32) model = d2l.
RNNLMScratch(gru, vocab_size=len(data.
vocab), lr=4) trainer = d2l.
Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) 10.2.5 Concise Implementation In high-level APIs, we can directly instantiate a GRU model.
This encapsulates all the configurationdetailthatwemadeexplicitabove.
class GRU(d2l.
RNN): def __init__(self, num_inputs, num_hiddens): d2l.
Module.__init__(self) self.
save_hyperparameters() self.
rnn = nn.
GRU(num_inputs, num_hiddens) 381 Gated Recurrent Units(GRU) Thecodeissignificantlyfasterintrainingasitusescompiledoperatorsratherthan Python.
gru = GRU(num_inputs=len(data.
vocab), num_hiddens=32) model = d2l.
RNNLM(gru, vocab_size=len(data.
vocab), lr=4) trainer.
fit(model, data) After training, we print out the perplexity on the training set and the predicted sequence followingtheprovidedprefix.
model.
predict('it has', 20, data.
vocab, d2l.
try_gpu()) 'it has so it and the time ' 10.2.6 Summary Compared with LSTMs, GRUs achieve similar performance but tend to be lighter com- putationally.
Generally, comparedwithsimple RNNs, gated RNNS, justlike LSTMsand GRUs, canbettercapturedependenciesforsequenceswithlargetimestepdistances.
GRUs containbasic RNNsastheirextremecasewhenevertheresetgateisswitchedon.
Theycan alsoskipsubsequencesbyturningontheupdategate.
10.2.7 Exercises 1.
Assumethatweonlywanttousetheinputattimestepğ‘¡0 topredicttheoutputattime stepğ‘¡ >ğ‘¡0 .
Whatarethebestvaluesfortheresetandupdategatesforeachtimestep? 2.
Adjustthehyperparametersandanalyzetheirinfluenceonrunningtime, perplexity, and theoutputsequence.
3.
Compareruntime, perplexity, andtheoutputstringsforrnn.
RNNandrnn.
GRUimple- mentationswitheachother.
4.
Whathappensifyouimplementonlypartsofa GRU, e.
g., withonlyaresetgateoronly 146 anupdategate? Discussions146.
382 Modern Recurrent Neural Networks 10.3 Deep Recurrent Neural Networks Upuntilnow, wehavefocusedondefiningnetworksconsistingofasequenceinput, asingle hidden RNNlayer, andanoutputlayer.
Despitehavingjustonehiddenlayerbetweenthe inputatanytimestepandthecorrespondingoutput, thereisasenseinwhichthesenetworks are deep.
Inputs from the first time step can influence the outputs at the final time step ğ‘‡ (often 100s or 1000s of steps later).
These inputs pass through ğ‘‡ applications of the recurrentlayerbeforereachingthefinaloutput.
However, weoftenalsowishtoretainthe ability to express complex relationships between the inputs at a given time step and the outputsatthatsametimestep.
Thusweoftenconstruct RNNsthataredeepnotonlyinthe timedirectionbutalsointheinput-to-outputdirection.
Thisispreciselythenotionofdepth thatwehavealreadyencounteredinourdevelopmentof MLPsanddeep CNNs.
The standard method for building this sort of deep RNN is strikingly simple: we stack the RNNs on top of each other.
Given a sequence of lengthğ‘‡, the first RNN produces a sequenceofoutputs, alsooflengthğ‘‡.
These, inturn, constitutetheinputstothenext RNN layer.
Inthisshortsection, weillustratethisdesignpatternandpresentasimpleexamplefor howtocodeupsuchstacked RNNs.
Below, in.3.1, weillustrateadeep RNNwithğ¿ hiddenlayers.
Eachhiddenstateoperatesonasequentialinputandproducesasequential output.
Moreover, any RNNcell(whiteboxin.3.1)ateachtimestepdependson boththesamelayerâ€™svalueattheprevioustimestepandthepreviouslayerâ€™svalueatthe sametimestep.
t .3.1 Architectureofadeep RNN.
Formally, supposethatwehaveaminibatchinput Xğ‘¡ 2 Rğ‘› ğ‘‘ (numberofexamples= ğ‘›; numberofinputsineachexample= ğ‘‘)attimestepğ‘¡.
Atthesametimestep, letthehidden stateoftheğ‘™th hiddenlayer(ğ‘™ = 1,...,ğ¿)be H â€ğ‘™â€ 2 Rğ‘› â„ (numberofhiddenunits= â„) ğ‘¡ andtheoutputlayervariablebe Oğ‘¡ 2 Rğ‘› ğ‘ (numberofoutputs: ğ‘).
Setting H ğ‘¡ â€0â€ = Xğ‘¡, thehiddenstateoftheğ‘™th hiddenlayerthatusestheactivationfunctionğœ™ ğ‘™ iscalculatedas follows: H ğ‘¡ â€ğ‘™â€ = ğœ™ ğ‘™ â€H ğ‘¡ â€ğ‘™ 1â€ W x â€ğ‘™ h â€ â€šH ğ‘¡ â€ ğ‘™â€ 1 W h â€ğ‘™ h â€ â€šb h â€ğ‘™â€â€, (10.3.1) 383 Deep Recurrent Neural Networks wheretheweights W â€ğ‘™â€ 2Râ„ â„ and W â€ğ‘™â€ 2Râ„ â„ , togetherwiththebiasb â€ğ‘™â€ 2R1 â„ , are xh hh h themodelparametersoftheğ‘™thhiddenlayer.
Attheend, thecalculationoftheoutputlayerisonlybasedonthehiddenstateofthefinal ğ¿thhiddenlayer: Oğ‘¡ =H ğ‘¡ â€ğ¿â€ W hq â€šb q , (10.3.2) wherethe weight W 2 Râ„ ğ‘ and the bias b 2 R1 ğ‘ are the model parameters of the hq q outputlayer.
Justaswith MLPs, thenumberofhiddenlayersğ¿andthenumberofhiddenunitsâ„arehy- perparametersthatwecantune.
Common RNNlayerwidths(â„)areintherangeâ€64,2056â€, andcommondepths(ğ¿)areintherangeâ€1,8â€.
Inaddition, wecaneasilygetadeep-gated RNNbyreplacingthehiddenstatecomputationin(10.3.1)withthatfroman LSTMora GRU.
import torch from torch import nn from d2l import torch as d2l 10.3.1 Implementationfrom Scratch Toimplementamultilayer RNNfromscratch, wecantreateachlayerasan RNNScratch instancewithitsownlearnableparameters.
class Stacked RNNScratch(d2l.
Module): def __init__(self, num_inputs, num_hiddens, num_layers, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
rnns = nn.
Sequential(*[d2l.
RNNScratch( num_inputs if i==0 else num_hiddens, num_hiddens, sigma) for i in range(num_layers)]) Themultilayerforwardcomputationsimplyperformsforwardcomputationlayerbylayer.
@d2l.
add_to_class(Stacked RNNScratch) def forward(self, inputs, Hs=None): outputs = inputs if Hs is None: Hs = [None] * self.
num_layers for i in range(self.
num_layers): outputs, Hs[i] = self.
rnns[i](outputs, Hs[i]) outputs = torch.
stack(outputs, 0) return outputs, Hs As an example, we train a deep GRU model on The Time Machine dataset (same as in Section9.5).
Tokeepthingssimplewesetthenumberoflayersto2.
384 Modern Recurrent Neural Networks data = d2l.
Time Machine(batch_size=1024, num_steps=32) rnn_block = Stacked RNNScratch(num_inputs=len(data.
vocab), num_hiddens=32, num_layers=2) model = d2l.
RNNLMScratch(rnn_block, vocab_size=len(data.
vocab), lr=2) trainer = d2l.
Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) 10.3.2 Concise Implementation Fortunatelymanyofthelogisticaldetailsrequiredtoimplementmultiplelayersofan RNN arereadilyavailableinhigh-level APIs.
Ourconciseimplementationwillusesuchbuilt- in functionalities.
The code generalizes the one we used previously in Section 10.2, let- tingusspecifythenumberoflayersexplicitlyratherthanpickingthedefaultofonlyone layer.
class GRU(d2l.
RNN): #@save """The multilayer GRU model.""" def __init__(self, num_inputs, num_hiddens, num_layers, dropout=0): d2l.
Module.__init__(self) self.
save_hyperparameters() self.
rnn = nn.
GRU(num_inputs, num_hiddens, num_layers, dropout=dropout) Thearchitecturaldecisionssuchaschoosinghyperparametersareverysimilartothoseof Section10.2.
Wepickthesamenumberofinputsandoutputsaswehavedistincttokens, i.
e., vocab_size.
Thenumberofhiddenunitsisstill32.
Theonlydifferenceisthatwenow selectanontrivialnumberofhiddenlayersbyspecifyingthevalueofnum_layers.
gru = GRU(num_inputs=len(data.
vocab), num_hiddens=32, num_layers=2) model = d2l.
RNNLM(gru, vocab_size=len(data.
vocab), lr=2) trainer.
fit(model, data) model.
predict('it has', 20, data.
vocab, d2l.
try_gpu()) 'it has for and the time th' 385 Bidirectional Recurrent Neural Networks 10.3.3 Summary Indeep RNNs, thehiddenstateinformationispassedtothenexttimestepofthecurrent layer and the current time step of the next layer.
There exist many different flavors of deep RNNs, such as LSTMs, GRUs, or vanilla RNNs.
Conveniently, these models are allavailableaspartsofthehigh-level APIsofdeeplearningframeworks.
Initializationof modelsrequirescare.
Overall, deep RNNsrequireconsiderableamountofwork(suchas learningrateandclipping)toensureproperconvergence.
10.3.4 Exercises 1.
Replacethe GRUbyan LSTMandcomparetheaccuracyandtrainingspeed.
2.
Increasethetrainingdatatoincludemultiplebooks.
Howlowcanyougoontheper- plexityscale? 3.
Wouldyouwanttocombinesourcesofdifferentauthorswhenmodelingtext? Whyis thisagoodidea? Whatcouldgowrong? 147 Discussions147.
10.4 Bidirectional Recurrent Neural Networks Sofar, ourworkingexampleofasequencelearningtaskhasbeenlanguagemodeling, where weaimtopredictthenexttokengivenallprevioustokensinasequence.
Inthisscenario, wewishonlytoconditionupontheleftwardcontext, andthustheunidirectionalchainingof astandard RNNseemsappropriate.
However, therearemanyothersequencelearningtasks contextswhereitisperfectlyfinetoconditionthepredictionateverytimesteponboththe leftwardandtherightwardcontext.
Consider, forexample, partofspeechdetection.
Why shouldnâ€™t we take the context in both directions into account when assessing the part of speechassociatedwithagivenword? Anothercommontaskâ€”oftenusefulasapretrainingexercisepriortofine-tuningamodel on an actual task of interestâ€”is to mask out random tokens in a text document and then 386 Modern Recurrent Neural Networks to train a sequence model to predict the values of the missing tokens.
Notethat depend- ingonwhatcomesaftertheblank, thelikelyvalueofthemissingtokenchangesdramati- cally: Iam___.
Iam___hungry.
Iam___hungry, and Icaneathalfapig.
Inthefirstsentenceâ€œhappyâ€seemstobealikelycandidate.
Thewordsâ€œnotâ€andâ€œveryâ€ seem plausible in the second sentence, but â€œnotâ€ seems incompatible with the third sen- tences.
Fortunately, a simple technique transforms any unidirectional RNN into a bidirectional RNN(Schusterand Paliwal,1997).
Wesimplyimplementtwounidirectional RNNlayers chained together in opposite directions and acting on the same input (.4.1).
For thefirst RNNlayer, thefirstinputisx 1 andthelastinputisxğ‘‡, butforthesecond RNN layer, thefirstinputisxğ‘‡ andthelastinputisx 1 .
Toproducetheoutputofthisbidirectional RNNlayer, wesimplyconcatenatetogetherthecorrespondingoutputsofthetwounderlying unidirectional RNNlayers.
t .4.1 Architectureofabidirectional RNN.
Formallyforanytimestepğ‘¡, weconsideraminibatchinput Xğ‘¡ 2 Rğ‘› ğ‘‘ (numberofexam- ples=ğ‘›; numberofinputsineachexample= ğ‘‘)andletthehiddenlayeractivationfunction beğœ™.
Inthebidirectionalarchitecture, theforwardandbackwardhiddenstatesforthistime ! stepare Hğ‘¡ 2 Rğ‘› â„ and Hğ‘¡ 2 Rğ‘› â„ , respectively, where â„isthenumberofhiddenunits.
Theforwardandbackwardhiddenstateupdatesareasfollows: ! ! H ğ‘¡ = ğœ™â€Xğ‘¡W x â€ h ğ‘“â€ â€š H ğ‘¡ 1 W h â€ h ğ‘“â€ â€šb h â€ğ‘“â€â€, (10.4.1) Hğ‘¡ = ğœ™â€Xğ‘¡W x â€ h ğ‘â€ â€šHğ‘¡â€š1 W h â€ h ğ‘â€ â€šb h â€ğ‘â€â€, wheretheweights W â€ğ‘“â€ 2 Rğ‘‘ â„, W â€ğ‘“â€ 2 Râ„ â„, W â€ğ‘â€ 2 Rğ‘‘ â„, and W â€ğ‘â€ 2 Râ„ â„ , and xh hh xh hh thebiasesb â€ğ‘“â€ 2R1 â„ andb â€ğ‘â€ 2R1 â„ areallthemodelparameters.
h h ! Next, we concatenate the forward and backward hidden states Hğ‘¡ and Hğ‘¡ to obtain the hiddenstate Hğ‘¡ 2Rğ‘› 2â„ forfeedingintotheoutputlayer.
Indeepbidirectional RNNswith multiplehiddenlayers, suchinformationispassedonasinputtothenextbidirectionallayer.
387 Bidirectional Recurrent Neural Networks Last, theoutputlayercomputestheoutput Oğ‘¡ 2Rğ‘› ğ‘ (numberofoutputs=ğ‘): Oğ‘¡ =Hğ‘¡W hq â€šb q .
(10.4.2) Here, theweightmatrix W 2 R2â„ ğ‘ andthebiasb 2 R1 ğ‘ arethemodelparameters hq q of the output layer.
While technically, the two directions can have different numbers of hiddenunits, thisdesignchoiceisseldommadeinpractice.
Wenowdemonstrateasimple implementationofabidirectional RNN.
import torch from torch import nn from d2l import torch as d2l 10.4.1 Implementationfrom Scratch Toimplementabidirectional RNNfromscratch, wecanincludetwounidirectional RNNScratch instanceswithseparatelearnableparameters.
class Bi RNNScratch(d2l.
Module): def __init__(self, num_inputs, num_hiddens, sigma=0.01): super().__init__() self.
save_hyperparameters() self.
f_rnn = d2l.
RNNScratch(num_inputs, num_hiddens, sigma) self.
b_rnn = d2l.
RNNScratch(num_inputs, num_hiddens, sigma) self.
num_hiddens *= 2 # The output dimension will be doubled Statesofforwardandbackward RNNsareupdatedseparately, whileoutputsofthesetwo RNNsareconcatenated.
@d2l.
add_to_class(Bi RNNScratch) def forward(self, inputs, Hs=None): f_H, b_H = Hs if Hs is not None else (None, None) f_outputs, f_H = self.
f_rnn(inputs, f_H) b_outputs, b_H = self.
b_rnn(reversed(inputs), b_H) outputs = [torch.
cat((f, b), -1) for f, b in zip( f_outputs, reversed(b_outputs))] return outputs, (f_H, b_H) 10.4.2 Concise Implementation Usingthehigh-level APIs, wecanimplementbidirectional RNNsmoreconcisely.
Herewe takea GRUmodelasanexample.
class Bi GRU(d2l.
RNN): def __init__(self, num_inputs, num_hiddens): d2l.
Module.__init__(self) self.
save_hyperparameters() self.
rnn = nn.
GRU(num_inputs, num_hiddens, bidirectional=True) self.
num_hiddens *= 2 388 Modern Recurrent Neural Networks 10.4.3 Summary In bidirectional RNNs, the hidden state for each time step is simultaneously determined by the data prior to and after the current time step.
Bidirectional RNNs are mostly use- fulforsequenceencodingandtheestimationofobservationsgivenbidirectionalcontext.
Bidirectional RNNsareverycostlytotrainduetolonggradientchains.
10.4.4 Exercises 1.
Ifthedifferentdirectionsuseadifferentnumberofhiddenunits, howwilltheshapeof Hğ‘¡ change? 2.
Designabidirectional RNNwithmultiplehiddenlayers.
3.
Polysemyiscommoninnaturallanguages.
Forexample, thewordâ€œbankâ€hasdifferent meaningsincontextsâ€œiwenttothebanktodepositcashâ€andâ€œiwenttothebanktosit downâ€.
Howcanwedesignaneuralnetworkmodelsuchthatgivenacontextsequence andaword, avectorrepresentationofthewordinthecorrectcontextwillbereturned? Whattypeofneuralarchitecturesispreferredforhandlingpolysemy? Discussions148.
148 10.5 Machine Translation and the Dataset Amongthemajorbreakthroughsthatpromptedwidespreadinterestinmodern RNNswas amajoradvanceintheappliedfieldofstatisticalmachinetranslation.
Here, themodelis presentedwithasentenceinonelanguageandmustpredictthecorrespondingsentencein another.
Notethatherethesentencesmaybeofdifferentlengths, andthatcorresponding words in the two sentences may not occur in the same order, owing to differences in the twolanguageâ€™sgrammaticalstructure.
Many problems have this flavor of mapping between two such â€œunalignedâ€ sequences.
Examplesincludemappingfromdialogpromptstorepliesorfromquestionstoanswers.
Broadly, suchproblemsarecalledsequence-to-sequence(seq2seq)problemsandtheyare ourfocusforboththeremainderofthischapterandmuchof Chapter11.
Inthissection, weintroducethemachinetranslationproblemandanexampledatasetthat wewilluseinthesubsequentexamples.
Fordecades, statisticalformulationsoftranslation betweenlanguageshadbeenpopular(Brownetal.,1990, Brownetal.,1988), evenbefore researchersgotneuralnetworkapproachesworking(methodswereoftenlumpedtogether underthetermneuralmachinetranslation).
Firstwewillneedsomenewcodetoprocessourdata.
Unlikethelanguagemodelingthat wesawin Section9.3, hereeachexampleconsistsoftwoseparatetextsequences, oneinthe source language and another (the translation) in the target language.
The following code snippetswillshowhowtoloadthepreprocesseddataintominibatchesfortraining.
389 Machine Translationandthe Dataset import os import torch from d2l import torch as d2l 10.5.1 Downloadingand Preprocessingthe Dataset Tobegin, wedownloadan Englishâ€“Frenchdatasetthatconsistsofbilingualsentencepairs 149 from the Tatoeba Project149.
Each line in the dataset is a tab-delimited pair consisting ofan Englishtextsequence(thesource)andthetranslated Frenchtextsequence(thetar- get).
Note that each text sequence can be just one sentence, or a paragraph of multiple sentences.
class MTFra Eng(d2l.
Data Module): #@save """The English-French dataset.""" def _download(self): d2l.
extract(d2l.
download( d2l.
DATA_URL+'fra-eng.
zip', self.
root, '94646ad1522d915e7b0f9296181140edcf86a4f5')) with open(self.
root + '/fra-eng/fra.
txt', encoding='utf-8') as f: return f.
read() data = MTFra Eng() raw_text = data._download() print(raw_text[:75]) â†©! com/fra-eng.
zip...
Go.
Va ! Hi.
Salut ! Run! Cours ! Run! Courez ! Who? Qui ? Wow! Ã‡a alors ! Afterdownloadingthedataset, weproceedwithseveralpreprocessingstepsfortherawtext data.
Forinstance, wereplacenon-breakingspacewithspace, convertuppercaselettersto lowercaseones, andinsertspacebetweenwordsandpunctuationmarks.
@d2l.
add_to_class(MTFra Eng) #@save def _preprocess(self, text): # Replace non-breaking space with space text = text.
replace('\u202f', ' ').
replace('\xa0', ' ') # Insert space between words and punctuation marks no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' ' out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text.
lower())] return ''.
join(out) 390 Modern Recurrent Neural Networks text = data._preprocess(raw_text) print(text[:80]) go .
va ! hi .
salut ! run ! cours ! run ! courez ! who ? qui ? wow ! Ã§a alors ! 10.5.2 Tokenization Unlike the character-level tokenization in Section 9.3, for machine translation we prefer word-leveltokenizationhere(todayâ€™sstate-of-the-artmodelsusemorecomplextokeniza- tiontechniques).
Thefollowing_tokenizemethodtokenizesthefirstmax_examplestext sequencepairs, whereeachtokeniseitherawordorapunctuationmark.
Weappendthe special â€œ<eos>â€ token to the end of every sequence to indicate the end of the sequence.
Whenamodelispredictingbygeneratingasequencetokenaftertoken, thegenerationof theâ€œ<eos>â€tokencansuggestthattheoutputsequenceiscomplete.
Intheend, themethod belowreturnstwolistsoftokenlists: srcandtgt.
Specifically, src[i]isalistoftokens fromtheğ‘–th textsequenceinthesourcelanguage(Englishhere)andtgt[i]isthatinthe targetlanguage(Frenchhere).
@d2l.
add_to_class(MTFra Eng) #@save def _tokenize(self, text, max_examples=None): src, tgt = [], [] for i, line in enumerate(text.
split('\n')): if max_examples and i > max_examples: break parts = line.
split('\t') if len(parts) == 2: # Skip empty tokens src.
append([t for t in f'{parts[0]} <eos>'.
split(' ') if t]) tgt.
append([t for t in f'{parts[1]} <eos>'.
split(' ') if t]) return src, tgt src, tgt = data._tokenize(text) src[:6], tgt[:6] ([['go', '.', '<eos>'], ['hi', '.', '<eos>'], ['run', '!', '<eos>'], ['run', '!', '<eos>'], ['who', '?', '<eos>'], ['wow', '!', '<eos>']], [['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>'], (continuesonnextpage) 391 Machine Translationandthe Dataset (continuedfrompreviouspage) ['qui', '?', '<eos>'], ['Ã§a', 'alors', '!', '<eos>']]) Letâ€™splotthehistogramofthenumberoftokenspertextsequence.
Inthissimple Englishâ€“ Frenchdataset, mostofthetextsequenceshavefewerthan20tokens.
#@save def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist): """Plot the histogram for list length pairs.""" d2l.
set_figsize() _, _, patches = d2l.
plt.
hist( [[len(l) for l in xlist], [len(l) for l in ylist]]) d2l.
plt.
xlabel(xlabel) d2l.
plt.
ylabel(ylabel) for patch in patches[1].
patches: patch.
set_hatch('/') d2l.
plt.
legend(legend) show_list_len_pair_hist(['source', 'target'], '# tokens per sequence', 'count', src, tgt); 10.5.3 Loading Sequencesof Fixed Length Recallthatinlanguagemodelingeachexamplesequence, eitherasegmentofonesentence oraspanovermultiplesentences, hadafixedlength.
Thiswasspecifiedbythenum_steps (numberoftimestepsortokens)argumentfrom Section9.3.
Inmachinetranslation, each example is a pair of source and target text sequences, where the two text sequences may havedifferentlengths.
Forcomputationalefficiency, wecanstillprocessaminibatchoftextsequencesatonetime bytruncationandpadding.
Supposethateverysequenceinthesameminibatchshouldhave thesamelengthnum_steps.
Ifatextsequencehasfewerthannum_stepstokens, wewill keep appending the special â€œ<pad>â€ token to its end until its length reaches num_steps.
Otherwise, wewilltruncatethetextsequencebyonlytakingitsfirstnum_stepstokensand discardingtheremaining.
Inthisway, everytextsequencewillhavethesamelengthtobe loadedinminibatchesofthesameshape.
Furthermore, wealsorecordlengthofthesource 392 Modern Recurrent Neural Networks sequenceexcludingpaddingtokens.
Thisinformationwillbeneededbysomemodelsthat wewillcoverlater.
Sincethemachinetranslationdatasetconsistsofpairsoflanguages, wecanbuildtwovo- cabulariesforboththesourcelanguageandthetargetlanguageseparately.
Withword-level tokenization, thevocabularysizewillbesignificantlylargerthanthatusingcharacter-level tokenization.
Toalleviatethis, herewetreatinfrequenttokensthatappearlessthantwice asthesameunknown(â€œ<unk>â€)token.
Aswewillexplainlater(.7.1), whentrain- ingwithtargetsequences, thedecoderoutput(labeltokens)canbethesamedecoderinput (targettokens), shiftedbyonetoken; andthespecialbeginning-of-sequenceâ€œ<bos>â€token willbeusedasthefirstinputtokenforpredictingthetargetsequence(.7.3).
@d2l.
add_to_class(MTFra Eng) #@save def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128): super(MTFra Eng, self).__init__() self.
save_hyperparameters() self.
arrays, self.
src_vocab, self.
tgt_vocab = self._build_arrays( self._download()) @d2l.
add_to_class(MTFra Eng) #@save def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None): def _build_array(sentences, vocab, is_tgt=False): pad_or_trim = lambda seq, t: ( seq[: t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq))) sentences = [pad_or_trim(s, self.
num_steps) for s in sentences] if is_tgt: sentences = [['<bos>'] + s for s in sentences] if vocab is None: vocab = d2l.
Vocab(sentences, min_freq=2) array = torch.
tensor([vocab[s] for s in sentences]) valid_len = (array != vocab['<pad>']).
type(torch.
int32).
sum(1) return array, vocab, valid_len src, tgt = self._tokenize(self._preprocess(raw_text), self.
num_train + self.
num_val) src_array, src_vocab, src_valid_len = _build_array(src, src_vocab) tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True) return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]), src_vocab, tgt_vocab) 10.5.4 Readingthe Dataset Finally, wedefinetheget_dataloadermethodtoreturnthedataiterator.
@d2l.
add_to_class(MTFra Eng) #@save def get_dataloader(self, train): idx = slice(0, self.
num_train) if train else slice(self.
num_train, None) return self.
get_tensorloader(self.
arrays, train, idx) Letâ€™sreadthefirstminibatchfromthe Englishâ€“Frenchdataset.
393 Machine Translationandthe Dataset data = MTFra Eng(batch_size=3) src, tgt, src_valid_len, label = next(iter(data.
train_dataloader())) print('source:', src.
type(torch.
int32)) print('decoder input:', tgt.
type(torch.
int32)) print('source len excluding pad:', src_valid_len.
type(torch.
int32)) print('label:', label.
type(torch.
int32)) source: tensor([[117, 182, 0, 3, 4, 4, 4, 4, 4], [ 62, 72, 2, 3, 4, 4, 4, 4, 4], [ 57, 124, 0, 3, 4, 4, 4, 4, 4]], dtype=torch.
int32) decoder input: tensor([[ 3, 37, 100, 58, 160, 0, 4, 5, 5], [ 3, 6, 2, 4, 5, 5, 5, 5, 5], [ 3, 180, 0, 4, 5, 5, 5, 5, 5]], dtype=torch.
int32) source len excluding pad: tensor([4, 4, 4], dtype=torch.
int32) label: tensor([[ 37, 100, 58, 160, 0, 4, 5, 5, 5], [ 6, 2, 4, 5, 5, 5, 5, 5, 5], [180, 0, 4, 5, 5, 5, 5, 5, 5]], dtype=torch.
int32) We show a pair of source and target sequences processed by the above _build_arrays method(inthestringformat).
@d2l.
add_to_class(MTFra Eng) #@save def build(self, src_sentences, tgt_sentences): raw_text = '\n'.
join([src + '\t' + tgt for src, tgt in zip( src_sentences, tgt_sentences)]) arrays, _, _ = self._build_arrays( raw_text, self.
src_vocab, self.
tgt_vocab) return arrays src, tgt, _, _ = data.
build(['hi .'], ['salut .']) print('source:', data.
src_vocab.
to_tokens(src[0].
type(torch.
int32))) print('target:', data.
tgt_vocab.
to_tokens(tgt[0].
type(torch.
int32))) source: ['hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', ' â†©!<pad>'] target: ['<bos>', 'salut', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', ' â†©!<pad>'] 10.5.5 Summary Innaturallanguageprocessing, machinetranslationreferstothetaskofautomaticallymap- pingfromasequencerepresentingastringoftextinasourcelanguagetoastringrepresent- ingaplausibletranslationinatargetlanguage.
Usingword-leveltokenization, thevocab- ulary size will be significantly larger than that using character-level tokenization, but the sequencelengthswillbemuchshorter.
Tomitigatethelargevocabularysize, wecantreat infrequenttokensassomeâ€œunknownâ€token.
Wecantruncateandpadtextsequencesso thatallofthemwillhavethesamelengthtobeloadedinminibatches.
Modernimplemen- 394 Modern Recurrent Neural Networks tationsoftenbucketsequenceswithsimilarlengthstoavoidwastingexcessivecomputation onpadding.
10.5.6 Exercises 1.
Try different values of the max_examples argument in the _tokenize method.
How doesthisaffectthevocabularysizesofthesourcelanguageandthetargetlanguage? 2.
Text in some languages such as Chinese and Japanese does not have word boundary indicators(e.
g., space).
Isword-leveltokenizationstillagoodideaforsuchcases? Why orwhynot? Discussions150.
150 10.6 The Encoder Decoder Architecture Ingeneralsequence-to-sequenceproblemslikemachinetranslation(Section10.5), inputs andoutputsareofvaryinglengthsthatareunaligned.
Thestandardapproachtohandling this sort of data is to design an encoderâ€“decoder architecture (.6.1) consisting of two major components: an encoder that takes a variable-length sequence as input, and a decoder that acts as a conditional language model, taking in the encoded input and the leftwardscontextofthetargetsequenceandpredictingthesubsequenttokeninthetarget sequence.
t .6.1 Theencoderâ€“decoderarchitecture.
Letâ€™s take machine translation from English to French as an example.
Given an input sequence in English: â€œTheyâ€, â€œareâ€, â€œwatchingâ€, â€œ.â€, this encoderâ€“decoder architecture first encodes the variable-length input into a state, then decodes the state to generate the translatedsequence, tokenbytoken, asoutput: â€œIlsâ€,â€œregardentâ€,â€œ.â€.
Sincetheencoderâ€“ decoder architecture forms the basis of different sequence-to-sequence models in subse- quentsections, thissectionwillconvertthisarchitectureintoaninterfacethatwillbeim- plementedlater.
from torch import nn from d2l import torch as d2l 10.6.1 Encoder Intheencoderinterface, wejustspecifythattheencodertakesvariable-lengthsequencesas input X.
Theimplementationwillbeprovidedbyanymodelthatinheritsthisbase Encoder class.
395 The Encoder Decoder Architecture class Encoder(nn.
Module): #@save """The base encoder interface for the encoder--decoder architecture.""" def __init__(self): super().__init__() # Later there can be additional arguments (e.
g., length excluding padding) def forward(self, X, *args): raise Not Implemented Error 10.6.2 Decoder Inthefollowingdecoderinterface, weaddanadditionalinit_statemethodtoconvertthe encoderoutput(enc_all_outputs)intotheencodedstate.
Notethatthisstepmayrequire extra inputs, such as the valid length of the input, which was explained in Section 10.5.
To generate a variable-length sequence token by token, every time the decoder may map aninput(e.
g., thegeneratedtokenattheprevioustimestep)andtheencodedstateintoan outputtokenatthecurrenttimestep.
class Decoder(nn.
Module): #@save """The base decoder interface for the encoder--decoder architecture.""" def __init__(self): super().__init__() # Later there can be additional arguments (e.
g., length excluding padding) def init_state(self, enc_all_outputs, *args): raise Not Implemented Error def forward(self, X, state): raise Not Implemented Error 10.6.3 Puttingthe Encoderand Decoder Together Intheforwardpropagation, theoutputoftheencoderisusedtoproducetheencodedstate, andthisstatewillbefurtherusedbythedecoderasoneofitsinput.
class Encoder Decoder(d2l.
Classifier): #@save """The base class for the encoder--decoder architecture.""" def __init__(self, encoder, decoder): super().__init__() self.
encoder = encoder self.
decoder = decoder def forward(self, enc_X, dec_X, *args): enc_all_outputs = self.
encoder(enc_X, *args) dec_state = self.
decoder.
init_state(enc_all_outputs, *args) # Return decoder output only return self.
decoder(dec_X, dec_state)[0] Inthenextsection, wewillseehowtoapply RNNstodesignsequence-to-sequencemodels basedonthisencoderâ€“decoderarchitecture.
396 Modern Recurrent Neural Networks 10.6.4 Summary Encoder-decoderarchitecturescanhandleinputsandoutputsthatbothconsistofvariable- lengthsequencesandthusaresuitableforsequence-to-sequenceproblemssuchasmachine translation.
Theencodertakesavariable-lengthsequenceasinputandtransformsitintoa statewithafixedshape.
Thedecodermapstheencodedstateofafixedshapetoavariable- lengthsequence.
10.6.5 Exercises 1.
Suppose that we use neural networks to implement the encoderâ€“decoder architecture.
Dotheencoderandthedecoderhavetobethesametypeofneuralnetwork? 2.
Besidesmachinetranslation, canyouthinkofanotherapplicationwheretheencoderâ€“ decoderarchitecturecanbeapplied? Discussions151.
151 10.7 Sequence-to-Sequence Learning for Machine Translation Inso-calledsequence-to-sequenceproblemssuchasmachinetranslation(asdiscussedin Section10.5), whereinputsandoutputseachconsistofvariable-lengthunalignedsequences, wegenerallyrelyonencoderâ€“decoderarchitectures(Section10.6).
Inthissection, wewill demonstrate the application of an encoderâ€“decoder architecture, where both the encoder and decoder are implemented as RNNs, to the task of machine translation (Cho et al., 2014, Sutskeveretal.,2014).
Here, theencoder RNNwilltakeavariable-lengthsequenceasinputandtransformitinto afixed-shapehiddenstate.
Later, in Chapter11, wewillintroduceattentionmechanisms, whichallowustoaccessencodedinputswithouthavingtocompresstheentireinputintoa singlefixed-lengthrepresentation.
Thentogeneratetheoutputsequence, onetokenatatime, thedecodermodel, consisting ofaseparate RNN, willpredicteachsuccessivetargettokengivenboththeinputsequence andtheprecedingtokensintheoutput.
Duringtraining, thedecoderwilltypicallybecon- ditioned upon the preceding tokens in the official â€œground truthâ€ label.
However, at test time, wewillwanttoconditioneachoutputofthedecoderonthetokensalreadypredicted.
Notethatifweignoretheencoder, thedecoderinasequence-to-sequencearchitecturebe- havesjustlikeanormallanguagemodel.
.7.1illustrateshowtousetwo RNNsfor sequence-to-sequencelearninginmachinetranslation.
In.7.1, thespecialâ€œ<eos>â€tokenmarkstheendofthesequence.
Ourmodelcan stopmakingpredictionsoncethistokenisgenerated.
Attheinitialtimestepofthe RNN decoder, therearetwospecialdesigndecisionstobeawareof: First, webegineveryinput 397 Sequence-to-Sequence Learningfor Machine Translation t .7.1 Sequence-to-sequencelearningwithan RNNencoderandan RNNdecoder.
withaspecialbeginning-of-sequenceâ€œ<bos>â€token.
Second, wemayfeedthefinalhidden stateoftheencoderintothedecoderateverysingledecodingtimestep(Choetal.,2014).
Insomeotherdesigns, suchasthatof Sutskeveretal.
(2014), thefinalhiddenstateofthe RNNencoderisusedtoinitiatethehiddenstateofthedecoderonlyatthefirstdecoding step.
import collections import math import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 10.7.1 Teacher Forcing While running the encoder on the input sequence is relatively straightforward, handling the input and output of the decoder requires more care.
The most common approach is sometimescalledteacherforcing.
Here, theoriginaltargetsequence(tokenlabels)isfed into the decoder as input.
More concretely, the special beginning-of-sequence token and the original target sequence, excluding the final token, are concatenated as input to the decoder, whilethedecoderoutput(labelsfortraining)istheoriginaltargetsequence, shifted by one token: â€œ<bos>â€, â€œIlsâ€, â€œregardentâ€, â€œ.â€ ! â€œIlsâ€, â€œregardentâ€, â€œ.â€, â€œ<eos>â€ (.7.1).
Our implementation in Section 10.5.3 prepared training data for teacher forcing, where shiftingtokensforself-supervisedlearningissimilartothetrainingoflanguagemodelsin Section9.3.
Analternativeapproachistofeedthepredictedtokenfromtheprevioustime stepasthecurrentinputtothedecoder.
In the following, we explain the design depicted in .7.1 in greater detail.
We will train this model for machine translation on the Englishâ€“French dataset as introduced in Section10.5.
10.7.2 Encoder Recallthattheencodertransformsaninputsequenceofvariablelengthintoafixed-shape contextvariablec(see.7.1).
Considerasinglesequenceexample(batchsize1).
Supposetheinputsequenceisğ‘¥ 1 ,...,ğ‘¥ ğ‘‡, suchthatğ‘¥ ğ‘¡ istheğ‘¡thtoken.
Attimestepğ‘¡, the RNNtransformstheinputfeaturevectorxğ‘¡ 398 Modern Recurrent Neural Networks forğ‘¥ ğ‘¡ andthehiddenstatehğ‘¡ 1 fromtheprevioustimestepintothecurrenthiddenstatehğ‘¡.
Wecanuseafunction ğ‘“ toexpressthetransformationofthe RNNâ€™srecurrentlayer: hğ‘¡ = ğ‘“â€xğ‘¡ , hğ‘¡ 1 â€.
(10.7.1) Ingeneral, theencodertransformsthehiddenstatesatalltimestepsintoacontextvariable throughacustomizedfunctionğ‘: c=ğ‘â€h 1 For example, in .7.1, the context variable is just the hidden state hğ‘‡ correspond- ing to the encoder RNNâ€™s representation after processing the final token of the input se- quence.
Inthisexample, wehaveusedaunidirectional RNNtodesigntheencoder, wherethehidden stateonlydependsontheinputsubsequenceatandbeforethetimestepofthehiddenstate.
We can also construct encoders using bidirectional RNNs.
In this case, a hidden state dependsonthesubsequencebeforeandafterthetimestep(includingtheinputatthecurrent timestep), whichencodestheinformationoftheentiresequence.
Now letâ€™s implement the RNN encoder.
Note that we use an embedding layer to obtain the feature vector for each token in the input sequence.
The weight of an embedding layer is a matrix, where the number of rows corresponds to the size of the input vocab- ulary(vocab_size)andnumberofcolumnscorrespondstothefeaturevectorâ€™sdimension (embed_size).
Foranyinputtokenindexğ‘–, theembeddinglayerfetchestheğ‘–throw(starting from0)oftheweightmatrixtoreturnitsfeaturevector.
Hereweimplementtheencoder withamultilayer GRU.
def init_seq2seq(module): #@save """Initialize weights for sequence-to-sequence learning.""" if type(module) == nn.
Linear: nn.
init.
xavier_uniform_(module.
weight) if type(module) == nn.
GRU: for param in module._flat_weights_names: if "weight" in param: nn.
init.
xavier_uniform_(module._parameters[param]) class Seq2Seq Encoder(d2l.
Encoder): #@save """The RNN encoder for sequence-to-sequence learning.""" def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0): super().__init__() self.
embedding = nn.
Embedding(vocab_size, embed_size) self.
rnn = d2l.
GRU(embed_size, num_hiddens, num_layers, dropout) self.
apply(init_seq2seq) def forward(self, X, *args): # X shape: (batch_size, num_steps) embs = self.
embedding(X.
t().
type(torch.
int64)) # embs shape: (num_steps, batch_size, embed_size) outputs, state = self.
rnn(embs) (continuesonnextpage) 399 Sequence-to-Sequence Learningfor Machine Translation (continuedfrompreviouspage) # outputs shape: (num_steps, batch_size, num_hiddens) # state shape: (num_layers, batch_size, num_hiddens) return outputs, state Letâ€™s use a concrete example to illustrate the above encoder implementation.
Below, we instantiateatwo-layer GRUencoderwhosenumberofhiddenunitsis16.
Givenaminibatch ofsequenceinputs X(batchsize= 4; numberoftimesteps= 9), thehiddenstatesofthe final layer at all the time steps (enc_outputs returned by the encoderâ€™s recurrent layers) areatensorofshape(numberoftimesteps, batchsize, numberofhiddenunits).
vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2 batch_size, num_steps = 4, 9 encoder = Seq2Seq Encoder(vocab_size, embed_size, num_hiddens, num_layers) X = torch.
zeros((batch_size, num_steps)) enc_outputs, enc_state = encoder(X) d2l.
check_shape(enc_outputs, (num_steps, batch_size, num_hiddens)) Sinceweareusinga GRUhere, theshapeofthemultilayerhiddenstatesatthefinaltime stepis(numberofhiddenlayers, batchsize, numberofhiddenunits).
d2l.
check_shape(enc_state, (num_layers, batch_size, num_hiddens)) 10.7.3 Decoder Givenatargetoutputsequenceğ‘¦ 1 ,ğ‘¦ 2 ,...,ğ‘¦ ğ‘‡0foreachtimestepğ‘¡0 (weuseğ‘¡0 todifferentiate from the input sequence time steps), the decoder assigns a predicted probability to each possible token occurring at step ğ‘¦ ğ‘¡0â€š1 conditioned upon the previous tokens in the target ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 andthecontextvariablec, i.
e.,ğ‘ƒâ€ğ‘¦ ğ‘¡0â€š1 j ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 , câ€.
Topredictthesubsequenttokenğ‘¡0 â€š1inthetargetsequence, the RNNdecodertakesthe previous stepâ€™s target token ğ‘¦ ğ‘¡0, the hidden RNN state from the previous time step sğ‘¡0 1 , andthecontextvariablecasitsinput, andtransformsthemintothehiddenstatesğ‘¡0 atthe currenttimestep.
Wecanuseafunctionğ‘” toexpressthetransformationofthedecoderâ€™s hiddenlayer: sğ‘¡0 =ğ‘”â€ğ‘¦ ğ‘¡0 1 , c, sğ‘¡0 1 â€.
(10.7.3) Afterobtainingthehiddenstateofthedecoder, wecanuseanoutputlayerandthesoftmax operation to compute the predictive distribution ğ‘â€ğ‘¦ ğ‘¡0â€š1 j ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 , câ€ over the subse- quentoutputtokenğ‘¡0â€š1.
Following.7.1, whenimplementingthedecoderasfollows, wedirectlyusethehid- denstateatthefinaltimestepoftheencodertoinitializethehiddenstateofthedecoder.
Thisrequiresthatthe RNNencoderandthe RNNdecoderhavethesamenumberoflay- ersandhiddenunits.
Tofurtherincorporatetheencodedinputsequenceinformation, the contextvariableisconcatenatedwiththedecoderinputatallthetimesteps.
Topredictthe 400 Modern Recurrent Neural Networks probabilitydistributionoftheoutputtoken, weuseafullyconnectedlayertotransformthe hiddenstateatthefinallayerofthe RNNdecoder.
class Seq2Seq Decoder(d2l.
Decoder): """The RNN decoder for sequence to sequence learning.""" def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0): super().__init__() self.
embedding = nn.
Embedding(vocab_size, embed_size) self.
rnn = d2l.
GRU(embed_size+num_hiddens, num_hiddens, num_layers, dropout) self.
dense = nn.
Lazy Linear(vocab_size) self.
apply(init_seq2seq) def init_state(self, enc_all_outputs, *args): return enc_all_outputs def forward(self, X, state): # X shape: (batch_size, num_steps) # embs shape: (num_steps, batch_size, embed_size) embs = self.
embedding(X.
t().
type(torch.
int32)) enc_output, hidden_state = state # context shape: (batch_size, num_hiddens) context = enc_output[-1] # Broadcast context to (num_steps, batch_size, num_hiddens) context = context.
repeat(embs.
shape[0], 1, 1) # Concat at the feature dimension embs_and_context = torch.
cat((embs, context), -1) outputs, hidden_state = self.
rnn(embs_and_context, hidden_state) outputs = self.
dense(outputs).
swapaxes(0, 1) # outputs shape: (batch_size, num_steps, vocab_size) # hidden_state shape: (num_layers, batch_size, num_hiddens) return outputs, [enc_output, hidden_state] Toillustratetheimplementeddecoder, belowweinstantiateitwiththesamehyperparam- eters from the aforementioned encoder.
As we can see, the output shape of the decoder becomes(batchsize, numberoftimesteps, vocabularysize), wherethefinaldimensionof thetensorstoresthepredictedtokendistribution.
decoder = Seq2Seq Decoder(vocab_size, embed_size, num_hiddens, num_layers) state = decoder.
init_state(encoder(X)) dec_outputs, state = decoder(X, state) d2l.
check_shape(dec_outputs, (batch_size, num_steps, vocab_size)) d2l.
check_shape(state[1], (num_layers, batch_size, num_hiddens)) Thelayersintheabove RNNencoderâ€“decodermodelaresummarizedin.7.2.
10.7.4 Encoderâ€“Decoderfor Sequence-to-Sequence Learning Puttingitalltogetherincodeyieldsthefollowing: 401 Sequence-to-Sequence Learningfor Machine Translation t .7.2 Layersinan RNNencoderâ€“decodermodel.
class Seq2Seq(d2l.
Encoder Decoder): #@save """The RNN encoder--decoder for sequence to sequence learning.""" def __init__(self, encoder, decoder, tgt_pad, lr): super().__init__(encoder, decoder) self.
save_hyperparameters() def validation_step(self, batch): Y_hat = self(*batch[:-1]) self.
plot('loss', self.
loss(Y_hat, batch[-1]), train=False) def configure_optimizers(self): # Adam optimizer is used here return torch.
optim.
Adam(self.
parameters(), lr=self.
lr) 10.7.5 Loss Functionwith Masking At each time step, the decoder predicts a probability distribution for the output tokens.
Aswithlanguagemodeling, wecanapplysoftmaxtoobtainthedistributionandcalculate thecross-entropylossforoptimization.
Recallfrom Section10.5thatthespecialpadding tokensareappendedtotheendofsequencesandsosequencesofvaryinglengthscanbe efficientlyloadedinminibatchesofthesameshape.
However, predictionofpaddingtokens should be excluded from loss calculations.
To this end, we can mask irrelevant entries with zero values so that multiplication of any irrelevant prediction with zero equates to zero.
@d2l.
add_to_class(Seq2Seq) def loss(self, Y_hat, Y): l = super(Seq2Seq, self).
loss(Y_hat, Y, averaged=False) mask = (Y.
reshape(-1) != self.
tgt_pad).
type(torch.
float32) return (l * mask).
sum() / mask.
sum() 10.7.6 Training Now we can create and train an RNN encoderâ€“decoder model for sequence-to-sequence learningonthemachinetranslationdataset.
data = d2l.
MTFra Eng(batch_size=128) embed_size, num_hiddens, num_layers, dropout = 256, 256, 2, 0.2 (continuesonnextpage) 402 Modern Recurrent Neural Networks (continuedfrompreviouspage) encoder = Seq2Seq Encoder( len(data.
src_vocab), embed_size, num_hiddens, num_layers, dropout) decoder = Seq2Seq Decoder( len(data.
tgt_vocab), embed_size, num_hiddens, num_layers, dropout) model = Seq2Seq(encoder, decoder, tgt_pad=data.
tgt_vocab['<pad>'], lr=0.005) trainer = d2l.
Trainer(max_epochs=30, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) 10.7.7 Prediction Topredicttheoutputsequenceateachstep, thepredictedtokenfromtheprevioustimestep isfedintothedecoderasaninput.
Onesimplestrategyistosamplewhichevertokenthat hasbeenassignedbythedecoderthehighestprobabilitywhenpredictingateachstep.
As intraining, attheinitialtimestepthebeginning-of-sequence(â€œ<bos>â€)tokenisfedintothe (â€œ<eos>â€)tokenispredicted, thepredictionoftheoutputsequenceiscomplete.
t .7.3 Predictingtheoutputsequencetokenbytokenusingan RNNencoderâ€“decoder.
Inthenextsection, wewillintroducemoresophisticatedstrategiesbasedonbeamsearch (Section10.8).
@d2l.
add_to_class(d2l.
Encoder Decoder) #@save def predict_step(self, batch, device, num_steps, save_attention_weights=False): batch = [a.
to(device) for a in batch] src, tgt, src_valid_len, _ = batch enc_all_outputs = self.
encoder(src, src_valid_len) dec_state = self.
decoder.
init_state(enc_all_outputs, src_valid_len) (continuesonnextpage) 403 Sequence-to-Sequence Learningfor Machine Translation (continuedfrompreviouspage) outputs, attention_weights = [tgt[:, (0)].
unsqueeze(1), ], [] for _ in range(num_steps): Y, dec_state = self.
decoder(outputs[-1], dec_state) outputs.
append(Y.
argmax(2)) # Save attention weights (to be covered later) if save_attention_weights: attention_weights.
append(self.
decoder.
attention_weights) return torch.
cat(outputs[1:], 1), attention_weights 10.7.8 Evaluationof Predicted Sequences Wecanevaluateapredictedsequencebycomparingitwiththetargetsequence(theground truth).
Butwhatpreciselyistheappropriatemeasureforcomparingsimilaritybetweentwo sequences? Bilingual Evaluation Understudy(BLEU), thoughoriginallyproposedforevaluatingma- chinetranslationresults(Papinenietal.,2002), hasbeenextensivelyusedinmeasuringthe qualityofoutputsequencesfordifferentapplications.
Inprinciple, foranyğ‘›-gram(Section 9.3.1)inthepredictedsequence, BLEUevaluateswhetherthisğ‘›-gramappearsinthetarget sequence.
Denote by ğ‘ ğ‘› the precision of an ğ‘›-gram, defined as the ratio of the number of matched ğ‘›-grams in the predicted and targetsequences to the number of ğ‘›-grams in the predicted sequence.
Toexplain, givenatargetsequence ğ´,ğµ,ğ¶,ğ·,ğ¸,ğ¹, andapredictedsequence ğ´, ğµ, ğµ, ğ¶, ğ·, we have ğ‘ = 4 5, ğ‘ = 3 4, ğ‘ = 1 3, and ğ‘ = 0.
Now let len 1 2 3 4 label and len be the numbers of tokens in the target sequence and the predicted sequence, pred respectively.
Then, BLEUisdefinedas ğ‘˜ exp min 0,1 len label ğ‘1 ğ‘› 2ğ‘› , (10.7.4) len pred ğ‘›=1 whereğ‘˜ isthelongestğ‘›-gramformatching.
Basedonthedefinitionof BLEUin(10.7.4), wheneverthepredictedsequenceisthesame asthetargetsequence, BLEUis1.
Moreover, sincematchinglongerğ‘›-gramsismorediffi- cult, BLEUassignsagreaterweightwhenalongerğ‘›-gramhashighprecision.
Specifically, when ğ‘ ğ‘› isfixed, ğ‘1 ğ‘› 2ğ‘› increasesasğ‘›grows(theoriginalpaperuses ğ‘1 ğ‘› ğ‘› ).
Furthermore, sincepredictingshortersequencestendstoyieldahigher ğ‘ ğ‘› value, thecoefficientbefore the multiplication term in (10.7.4) penalizes shorter predicted sequences.
For example, whenğ‘˜ =2, giventhetargetsequence ğ´, ğµ,ğ¶,ğ·,ğ¸,ğ¹ andthepredictedsequence ğ´, ğµ, although ğ‘ = ğ‘ =1, thepenaltyfactorexpâ€1 6 2â€ 0.14lowersthe BLEU.
1 2 Weimplementthe BLEUmeasureasfollows.
def bleu(pred_seq, label_seq, k): #@save """Compute the BLEU.""" pred_tokens, label_tokens = pred_seq.
split(' '), label_seq.
split(' ') (continuesonnextpage) 404 Modern Recurrent Neural Networks (continuedfrompreviouspage) len_pred, len_label = len(pred_tokens), len(label_tokens) score = math.
exp(min(0, 1 - len_label / len_pred)) for n in range(1, min(k, len_pred) + 1): num_matches, label_subs = 0, collections.
defaultdict(int) for i in range(len_label - n + 1): label_subs[' '.
join(label_tokens[i: i + n])] += 1 for i in range(len_pred - n + 1): if label_subs[' '.
join(pred_tokens[i: i + n])] > 0: num_matches += 1 label_subs[' '.
join(pred_tokens[i: i + n])] -= 1 score *= math.
pow(num_matches / (len_pred - n + 1), math.
pow(0.5, n)) return score Intheend, weusethetrained RNNencoderâ€“decodertotranslateafew Englishsentences into Frenchandcomputethe BLEUoftheresults.
engs = ['go .', 'i lost .', 'he\'s calm .', 'i\'m home .'] fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .'] preds, _ = model.
predict_step( data.
build(engs, fras), d2l.
try_gpu(), data.
num_steps) for en, fr, p in zip(engs, fras, preds): translation = [] for token in data.
tgt_vocab.
to_tokens(p): if token == '<eos>': break translation.
append(token) print(f'{en} => {translation}, bleu,' f'{bleu(" ".
join(translation), fr, k=2):.3f}') go .
=> ['va', '!'], bleu,1.000 i lost .
=> ["j'ai", 'perdu', '.'], bleu,1.000 he's calm .
=> ['elle', 'court', '.'], bleu,0.000 i'm home .
=> ['je', 'suis', 'chez', 'moi', '.'], bleu,1.000 10.7.9 Summary Followingthedesignoftheencoderâ€“decoderarchitecture, wecanusetwo RNNstodesign amodelforsequence-to-sequencelearning.
Inencoderâ€“decodertraining, theteacherforc- ingapproachfeedsoriginaloutputsequences(incontrasttopredictions)intothedecoder.
When implementing the encoder and the decoder, we can use multilayer RNNs.
We can usemaskstofilteroutirrelevantcomputations, suchaswhencalculatingtheloss.
Foreval- uating output sequences, BLEU is a popular measure that matches ğ‘›-grams between the predictedsequenceandthetargetsequence.
10.7.10 Exercises 1.
Canyouadjustthehyperparameterstoimprovethetranslationresults? 2.
Reruntheexperimentwithoutusingmasksinthelosscalculation.
Whatresultsdoyou observe? Why? 405 Beam Search 3.
Iftheencoderandthedecoderdifferinthenumberoflayersorthenumberofhidden units, howcanweinitializethehiddenstateofthedecoder? 4.
Intraining, replaceteacherforcingwithfeedingthepredictionattheprevioustimestep intothedecoder.
Howdoesthisinfluencetheperformance? 5.
Reruntheexperimentbyreplacing GRUwith LSTM.
6.
Arethereanyotherwaystodesigntheoutputlayerofthedecoder? 152 Discussions152.
10.8 Beam Search In Section 10.7, we introduced the encoderâ€“decoder architecture, and the standard tech- niques for training them end-to-end.
However, when it came to test-time prediction, we mentionedonlythegreedystrategy, whereweselectateachtimestepthetokengiventhe highestpredictedprobabilityofcomingnext, until, atsometimestep, wefindthatwehave predictedthespecialend-of-sequenceâ€œ<eos>â€token.
Inthissection, wewillbeginbyfor- malizingthisgreedysearchstrategyandidentifyingsomeproblemsthatpractitionerstend toruninto.
Subsequently, wecomparethisstrategywithtwoalternatives: exhaustivesearch (illustrativebutnotpractical)andbeamsearch(thestandardmethodinpractice).
Letâ€™sbeginbysettingupourmathematicalnotation, borrowingconventionsfrom Section 10.7.
Atanytimestepğ‘¡0 , thedecoderoutputspredictionsrepresentingtheprobabilityof eachtokeninthevocabularycomingnextinthesequence(thelikelyvalueof ğ‘¦ ğ‘¡0â€š1 ), con- ditioned on the previous tokens ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 and the context variable c, produced by the encodertorepresenttheinputsequence.
Toquantifycomputationalcost, denoteby Y the outputvocabulary(includingthespecialend-of-sequencetokenâ€œ<eos>â€).
Letâ€™salsospec- ifythemaximumnumberoftokensofanoutputsequenceasğ‘‡0 .
Ourgoalistosearchfor anidealoutputfromall Oâ€j Yjğ‘‡0â€ possibleoutputsequences.
Notethatthisslightlyover- estimatesthenumberofdistinctoutputsbecausetherearenosubsequenttokensoncethe â€œ<eos>â€tokenoccurs.
However, forourpurposes, thisnumberroughlycapturesthesize ofthesearchspace.
10.8.1 Greedy Search Consider the simple greedysearchstrategyfrom Section 10.7.
Here, at anytime stepğ‘¡0 , wesimplyselectthetokenwiththehighestconditionalprobabilityfrom Y, i.
e., ğ‘¦ ğ‘¡0 =argmaxğ‘ƒâ€ğ‘¦ j ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 1 , câ€.
(10.8.1) ğ‘¦2Y Onceourmodeloutputsâ€œ<eos>â€(orwereachthemaximumlengthğ‘‡0 )theoutputsequence iscompleted.
406 Modern Recurrent Neural Networks Thisstrategymightlookreasonable, andinfactitisnotsobad! Consideringhowcomputa- tionallyundemandingitis, youâ€™dbehardpressedtogetmorebangforyourbuck.
However, ifweputasideefficiencyforaminute, itmightseemmorereasonabletosearchforthemost likelysequence, notthesequenceof(greedilyselected)mostlikelytokens.
Itturnsoutthat thesetwoobjectscanbequitedifferent.
Themostlikelysequenceistheonethatmaximizes Ë› theexpression ğ‘‡ ğ‘¡0 0 =1 ğ‘ƒâ€ğ‘¦ ğ‘¡0 j ğ‘¦ 1 ,...,ğ‘¦ ğ‘¡0 1 , câ€.
Inourmachinetranslationexample, ifthe decoder truly recovered the probabilities of the underlying generative process, then this wouldgiveusthemostlikelytranslation.
Unfortunately, thereisnoguaranteethatgreedy searchwillgiveusthissequence.
Letâ€™sillustrateitwithanexample.
Supposethattherearefourtokensâ€œAâ€,â€œBâ€,â€œCâ€, and â€œ<eos>â€intheoutputdictionary.
In.8.1, thefournumbersundereachtimesteprep- resenttheconditionalprobabilitiesofgeneratingâ€œAâ€,â€œBâ€,â€œCâ€, andâ€œ<eos>â€respectively, atthattimestep.
t .8.1 Ateachtimestep, greedysearchselectsthetokenwiththehighestconditionalprobability.
Ateachtimestep, greedysearchselectsthetokenwiththehighestconditionalprobability.
Therefore, theoutputsequenceâ€œAâ€,â€œBâ€,â€œCâ€, andâ€œ<eos>â€willbepredicted(.8.1).
selectthetokenâ€œCâ€, whichhasthesecondhighestconditionalprobability.
t .8.2 Thefournumbersundereachtimesteprepresenttheconditionalprobabilitiesof generatingâ€œAâ€,â€œBâ€,â€œCâ€, andâ€œ<eos>â€atthattimestep.
Attimestep2, thetokenâ€œCâ€, whichhasthesecondhighestconditionalprobability, isselected.
Sincetheoutputsubsequencesattimesteps1and2, onwhichtimestep3isbased, have probability of each token at time step 3 has also changed in .8.2.
Suppose that we choose the token â€œBâ€ at time step 3.
Now time step 4 is conditional on the output subsequenceatthefirstthreetimestepsâ€œAâ€,â€œCâ€, andâ€œBâ€, whichhaschangedfromâ€œAâ€, â€œBâ€, andâ€œCâ€in.8.1.
Therefore, theconditionalprobabilityofgeneratingeachtoken conditionalprobabilityoftheoutputsequenceâ€œAâ€,â€œCâ€,â€œBâ€, andâ€œ<eos>â€in.8.2 407 Beam Search Inthisexample, theoutputsequenceâ€œAâ€,â€œBâ€,â€œCâ€, andâ€œ<eos>â€obtainedbythegreedy searchisnotoptimal.
10.8.2 Exhaustive Search Ifthegoalistoobtainthemostlikelysequence, wemayconsiderusingexhaustivesearch: enumerateallthepossibleoutputsequenceswiththeirconditionalprobabilities, andthen outputtheonethatscoresthehighestpredictedprobability.
While this would certainly give us what we desire, it would come at a prohibitive com- putational cost of Oâ€j Yjğ‘‡0â€, exponential in the sequence length and with an enormous base given by the vocabulary size.
For example, when j Yj = 10000 andğ‘‡0 = 10, both small numbers when compared with ones in real applications, we will need to evaluate 1000010 = 1040 sequences, which is already beyond the capabilities of any foreseeable computers.
Ontheotherhand, thecomputationalcostofgreedysearchis Oâ€j Yjğ‘‡0â€: mirac- ulouslycheapbutfarfromoptimal.
Forexample, whenj Yj =10000andğ‘‡0 =10, weonly needtoevaluate10000 10=105sequences.
10.8.3 Beam Search You could view sequence decoding strategies as lying on a spectrum, with beam search striking a compromise between the efficiency of greedy search and the optimality of ex- haustive search.
The most straightforward version of beam search is characterized by a single hyperparameter, the beam size, ğ‘˜.
Letâ€™s explain this terminology.
At time step 1, we select the ğ‘˜ tokenswith the highest predicted probabilities.
Each of them will be the first token of ğ‘˜ candidate output sequences, respectively.
At each subsequent time step, basedontheğ‘˜ candidateoutputsequencesattheprevioustimestep, wecontinuetoselect ğ‘˜ candidateoutputsequenceswiththehighestpredictedprobabilitiesfrom ğ‘˜j Yj possible choices.
t .8.3 Theprocessofbeamsearch(beamsize=2; maximumlengthofanoutputsequence=3).
Thecandidateoutputsequencesare A, C, AB, CE, ABD, and CED.
.8.3 demonstrates the process of beam search with an example.
Suppose that the outputvocabularycontainsonlyfiveelements: Y = fğ´,ğµ,ğ¶,ğ·,ğ¸g, whereoneofthemis 408 Modern Recurrent Neural Networks â€œ<eos>â€.
Letthebeamsizebetwoandthemaximumlengthofanoutputsequencebethree.
Attimestep1, supposethatthetokenswiththehighestconditionalprobabilitiesğ‘ƒâ€ğ‘¦ j câ€ 1 are ğ´andğ¶.
Attimestep2, forallğ‘¦ 2Y, wecompute 2 ğ‘ƒâ€ğ´,ğ‘¦ j câ€ = ğ‘ƒâ€ğ´ j câ€ğ‘ƒâ€ğ‘¦ j ğ´, câ€, 2 2 (10.8.2) ğ‘ƒâ€ğ¶,ğ‘¦ j câ€ = ğ‘ƒâ€ğ¶ j câ€ğ‘ƒâ€ğ‘¦ j ğ¶, câ€, 2 2 andpickthelargesttwoamongthesetenvalues, sayğ‘ƒâ€ğ´,ğµ j câ€andğ‘ƒâ€ğ¶,ğ¸ j câ€.
Thenat timestep3, forallğ‘¦ 2Y, wecompute 3 ğ‘ƒâ€ğ´,ğµ,ğ‘¦ j câ€ = ğ‘ƒâ€ğ´,ğµ j câ€ğ‘ƒâ€ğ‘¦ j ğ´,ğµ, câ€, 3 3 (10.8.3) ğ‘ƒâ€ğ¶,ğ¸,ğ‘¦ j câ€ = ğ‘ƒâ€ğ¶,ğ¸ j câ€ğ‘ƒâ€ğ‘¦ j ğ¶,ğ¸, câ€, 3 3 andpickthelargesttwoamongthesetenvalues, say ğ‘ƒâ€ğ´,ğµ,ğ· j câ€ and ğ‘ƒâ€ğ¶,ğ¸,ğ· j câ€.
Asaresult, wegetsixcandidatesoutputsequences: (i) ğ´;(ii)ğ¶;(iii) ğ´, ğµ;(iv)ğ¶,ğ¸;(v) ğ´,ğµ,ğ·; and(vi)ğ¶,ğ¸,ğ·.
In the end, we obtain the set of final candidate output sequences based on these six se- quences(e.
g., discardportionsincludingandafterâ€œ<eos>â€).
Thenwechoosetheoutput sequencewhichmaximizesthefollowingscore: ğ¿ 1 1 ğ‘¡0=1 here ğ¿ is the length of the final candidate sequence and ğ›¼ is usually set to 0.75.
Since a longersequencehasmorelogarithmictermsinthesummationof(10.8.4), thetermğ¿ğ›¼ in thedenominatorpenalizeslongsequences.
The computational cost of beam search is Oâ€ğ‘˜j Yjğ‘‡0â€.
This result is in between that of greedysearchandthatofexhaustivesearch.
Greedysearchcanbetreatedasaspecialcase ofbeamsearcharisingwhenthebeamsizeissetto1.
10.8.4 Summary Sequencesearchingstrategiesincludegreedysearch, exhaustivesearch, andbeamsearch.
Beamsearchprovidesatrade-offbetweenaccuracyandcomputationalcostviatheflexible choiceofthebeamsize.
10.8.5 Exercises 1.
Canwetreatexhaustivesearchasaspecialtypeofbeamsearch? Whyorwhynot? 2.
Applybeamsearchinthemachinetranslationproblemin Section10.7.
Howdoesthe beamsizeaffectthetranslationresultsandthepredictionspeed? 3.
Weusedlanguagemodelingforgeneratingtextfollowinguser-providedprefixesin Sec- tion9.5.
Whichkindofsearchstrategydoesituse? Canyouimproveit? 153 Discussions153.
11 Attention Mechanisms and Transformers Theearliestyearsofthedeeplearningboomweredrivenprimarilybyresultsproducedus- ingthemultilayerperceptron, convolutionalnetwork, andrecurrentnetworkarchitectures.
Remarkably, the model architectures that underpinned many of deep learningâ€™s break- throughsinthe2010shadchangedremarkablylittlerelativetotheirantecedentsdespitethe lapseofnearly30years.
Whileplentyofnewmethodologicalinnovationsmadetheirway into most practitionerâ€™s toolkitsâ€”Re LU activations, residual layers, batch normalization, dropout, and adaptive learning rate schedules come to mindâ€”the core underlying archi- tectureswereclearlyrecognizableasscaled-upimplementationsofclassicideas.
Despite thousandsofpapersproposingalternativeideas, modelsresemblingclassicalconvolutional neuralnetworks(Chapter7)retainedstate-of-the-artstatusincomputervisionandmodels resembling Sepp Hochreiterâ€™soriginaldesignforthe LSTMrecurrentneuralnetwork(Sec- tion10.1), dominatedmostapplicationsinnaturallanguageprocessing.
Arguably, tothat point, therapidemergenceofdeeplearningappearedtobeprimarilyattributabletoshifts intheavailablecomputationalresources(thankstoinnovationsinparallelcomputingwith GPUs)andtheavailabilityofmassivedataresources(thankstocheapstorageand Internet services).
Whilethesefactorsmayindeedremaintheprimarydriversbehindthistechnol- ogyâ€™sincreasingpowerwearealsowitnessing, atlonglast, aseachangeinthelandscape ofdominantarchitectures.
At the present moment, the dominant models for nearly all natural language processing tasksarebasedonthe Transformerarchitecture.
Givenanynewtaskinnaturallanguage processing, thedefaultfirst-passapproachistograbalarge Transformer-basedpretrained model,(e.
g., BERT(Devlinetal.,2018), ELECTRA(Clarketal.,2020), Ro BERTa(Liu et al., 2019), or Longformer (Beltagy et al., 2020)) adapting the output layers as neces- sary, andfine-tuningthemodelontheavailabledataforthedownstreamtask.
Ifyouhave beenpayingattentiontothelastfewyearsofbreathlessnewscoveragecenteredon Ope- n AIâ€™slargelanguagemodels, thenyouhavebeentrackingaconversationcenteredonthe GPT-2 and GPT-3 Transformer-based models (Brown et al., 2020, Radford et al., 2019).
Meanwhile, thevision Transformerhasemergedasadefaultmodelfordiversevisiontasks, includingimagerecognition, objectdetection, semanticsegmentation, andsuperresolution (Dosovitskiyetal., 2021, Liu etal., 2021).
Transformers alsoshowedupascompetitive methodsforspeechrecognition(Gulatietal.,2020), reinforcementlearning(Chenetal., 2021), andgraphneuralnetworks(Dwivediand Bresson,2020).
The core idea behind the Transformer model is the attention mechanism, an innovation that was originally envisioned as an enhancement for encoderâ€“decoder RNNs applied to 409 410 Attention Mechanismsand Transformers sequence-to-sequenceapplications, suchasmachinetranslations(Bahdanauetal.,2014).
You might recall that in the first sequence-to-sequence models for machine translation (Sutskeveretal.,2014), theentireinputwascompressedbytheencoderintoasinglefixed- lengthvectortobefedintothedecoder.
Theintuitionbehindattentionisthatratherthan compressing the input, it might be better for the decoder to revisit the input sequence at everystep.
Moreover, ratherthanalwaysseeingthesamerepresentationoftheinput, one mightimaginethatthedecodershouldselectivelyfocusonparticularpartsoftheinputse- quence at particular decoding steps.
Bahdanauâ€™s attention mechanism provided a simple meansbywhichthedecodercoulddynamicallyattendtodifferentpartsoftheinputateach decoding step.
The high-level idea is that the encoder could produce a representation of lengthequaltotheoriginalinputsequence.
Then, atdecodingtime, thedecodercan(via somecontrol mechanism)receiveasinputa contextvectorconsistingof a weightedsum oftherepresentationsontheinputateachtimestep.
Intuitively, theweightsdeterminethe extenttowhicheachstepâ€™scontextâ€œfocusesâ€oneachinputtoken, andthekeyistomake thisprocessforassigningtheweightsdifferentiablesothatitcanbelearnedalongwithall oftheotherneuralnetworkparameters.
Initially, the idea was a remarkably successful enhancement to the recurrent neural net- works that already dominated machine translation applications.
The models performed betterthantheoriginalencoderâ€“decodersequence-to-sequencearchitectures.
Furthermore, researchersnotedthatsomenicequalitativeinsightssometimesemergedfrominspecting thepatternofattentionweights.
Intranslationtasks, attentionmodelsoftenassignedhigh attentionweightstocross-lingualsynonymswhengeneratingthecorrespondingwordsin thetargetlanguage.
Forexample, whentranslatingthesentenceâ€œmyfeethurtâ€toâ€œjâ€™aimal aupiedsâ€, theneuralnetworkmightassignhighattentionweightstotherepresentationof â€œfeetâ€ when generating the corresponding French word â€œpiedsâ€.
These insights spurred claims that attention models confer â€œinterpretabilityâ€ although what precisely the atten- tionweightsmeanâ€”i.
e., how, ifatall, theyshouldbeinterpretedremainsahazyresearch topic.
However, attentionmechanismssoonemergedasmoresignificantconcerns, beyondtheir usefulnessasanenhancementforencoderâ€“decoderrecurrentneuralnetworksandtheirpu- tativeusefulnessforpickingoutsalientinputs.
Vaswanietal.
(2017)proposedthe Trans- former architecture for machine translation, dispensing with recurrent connections alto- gether, andinsteadrelyingoncleverlyarrangedattentionmechanismstocaptureallrela- tionshipsamonginputandoutputtokens.
Thearchitectureperformedremarkablywell, and by2018the Transformerbeganshowingupinthemajorityofstate-of-the-artnaturallan- guageprocessingsystems.
Moreover, atthesametime, thedominantpracticeinnaturallan- guageprocessingbecametopretrainlarge-scalemodelsonenormousgenericbackground corporatooptimizesomeself-supervisedpretrainingobjective, andthentofine-tunethese modelsusingtheavailabledownstreamdata.
Thegapbetween Transformersandtraditional architecturesgrewespeciallywidewhenappliedinthispretrainingparadigm, andthusthe ascendanceof Transformerscoincidedwiththeascendenceofsuchlarge-scalepretrained models, nowsometimescalledfoundationmodels(Bommasanietal.,2021).
Inthischapter, weintroduceattentionmodels, startingwiththemostbasicintuitionsand 411 Queries, Keys, and Values thesimplestinstantiationsoftheidea.
Wethenworkourwayuptothe Transformerarchi- tecture, thevision Transformer, andthelandscapeofmodern Transformer-basedpretrained models.
11.1 Queries, Keys, and Values So far all the networks we have reviewed crucially relied on the input being of a well- definedsize.
Forinstance, theimagesin Image Netareofsize224 224pixelsand CNNs are specifically tuned to this size.
Even in natural language processing the input size for RNNsiswelldefinedandfixed.
Variablesizeisaddressedbysequentiallyprocessingone tokenatatime, orbyspeciallydesignedconvolutionkernels(Kalchbrenneretal.,2014).
Thisapproachcanleadtosignificantproblemswhentheinputistrulyofvaryingsizewith varyinginformationcontent, suchasin Section10.7inthetransformationoftext(Sutskever et al., 2014).
In particular, for long sequences it becomes quite difficult to keep track of everythingthathasalreadybeengeneratedorevenviewedbythenetwork.
Evenexplicit trackingheuristicssuchasproposedby Yangetal.
(2016)onlyofferlimitedbenefit.
Comparethistodatabases.
Intheirsimplestformtheyarecollectionsofkeys(ğ‘˜)andvalues (ğ‘£).
Forinstance, ourdatabase D mightconsistoftuples{(â€œZhangâ€,â€œAstonâ€),(â€œLiptonâ€, â€œZacharyâ€), (â€œLiâ€, â€œMuâ€), (â€œSmolaâ€, â€œAlexâ€), (â€œHuâ€, â€œRachelâ€), (â€œWernessâ€, â€œBrentâ€)} with the last name being the key and the first name being the value.
We can operate on D, forinstancewiththeexactquery(ğ‘)forâ€œLiâ€whichwouldreturnthevalueâ€œMuâ€.
If (â€œLiâ€,â€œMuâ€)wasnotarecordin D, therewouldbenovalidanswer.
Ifwealsoallowedfor approximatematches, wewouldretrieve(â€œLiptonâ€,â€œZacharyâ€)instead.
Thisquitesimple andtrivialexamplenonethelessteachesusanumberofusefulthings: We can design queries ğ‘ that operate on (ğ‘˜,ğ‘£) pairs in such a manner as to be valid regardlessofthedatabasesize.
Thesamequerycanreceivedifferentanswers, accordingtothecontentsofthedatabase.
Theâ€œcodeâ€beingexecutedforoperatingonalargestatespace(thedatabase)canbequite simple(e.
g., exactmatch, approximatematch, top-ğ‘˜).
Thereisnoneedtocompressorsimplifythedatabasetomaketheoperationseffective.
Clearlywewouldnothaveintroducedasimpledatabasehereifitwasnâ€™tforthepurposeof explainingdeeplearning.
Indeed, thisleadstooneofthemostexcitingconceptsintroduced indeeplearninginthepastdecade: theattentionmechanism(Bahdanauetal.,2014).
We will cover the specifics of its application to machine translation later.
For now, simply considerthefollowing: denoteby D d = ef fâ€k 1 , v 1 â€,...â€kğ‘š , vğ‘š â€gadatabaseofğ‘štuplesof keysandvalues.
Moreover, denotebyqaquery.
Thenwecandefinetheattentionover D 412 Attention Mechanismsand Transformers as ğ‘š Attentionâ€q, Dâ€ d = ef ğ›¼â€q, kğ‘– â€vğ‘– , (11.1.1) ğ‘–=1 where ğ›¼â€q, kğ‘– â€ 2 R (ğ‘– = 1,...,ğ‘š) are scalar attention weights.
The operation itself is typicallyreferredtoasattentionpooling.
Thenameattentionderivesfromthefactthatthe operationpaysparticularattentiontothetermsforwhichtheweightğ›¼ issignificant(i.
e., large).
Assuch, theattentionover Dgeneratesalinearcombinationofvaluescontainedin thedatabase.
Infact, thiscontainstheaboveexampleasaspecialcasewhereallbutone weightiszero.
Wehaveanumberofspecialcases: Theweightsğ›¼â€q, kğ‘– â€arenonnegative.
Inthiscasetheoutputoftheattentionmechanism iscontainedintheconvexconespannedbythevaluesvğ‘–.
Ë Theweightsğ›¼â€q, kğ‘– â€formaconvexcombination, i.
e., ğ‘– ğ›¼â€q, kğ‘– â€ =1andğ›¼â€q, kğ‘– â€ 0 forallğ‘–.
Thisisthemostcommonsettingindeeplearning.
Exactlyoneoftheweightsğ›¼â€q, kğ‘– â€is1, whileallothersare0.
Thisisakintoatraditional databasequery.
Allweightsareequal, i.
e.,ğ›¼â€q, kğ‘– â€ = ğ‘š 1 forallğ‘–.
Thisamountstoaveragingacrossthe entiredatabase, alsocalledaveragepoolingindeeplearning.
Acommonstrategyforensuringthattheweightssumupto1istonormalizethemvia ğ›¼â€q, kğ‘– â€ = Ë ğ›¼ ğ‘— ğ›¼ â€q â€q , k , k ğ‘– â€ ğ‘— â€ .
(11.1.2) Inparticular, toensurethattheweightsarealsononnegative, onecanresorttoexponenti- ation.
Thismeansthatwecannowpickanyfunctionğ‘â€q, kâ€ andthenapplythesoftmax operationusedformultinomialmodelstoitvia ğ›¼â€q, kğ‘– â€ = Ë e ğ‘— x e p x â€ p ğ‘ â€ â€ ğ‘ q â€ , q k , ğ‘– k â€â€ ğ‘— â€â€ .
(11.1.3) Thisoperationisreadilyavailableinalldeeplearningframeworks.
Itisdifferentiableand itsgradientnevervanishes, allofwhicharedesirablepropertiesinamodel.
Notethough, the attention mechanism introduced above is not the only option.
For instance, we can designanon-differentiableattentionmodelthatcanbetrainedusingreinforcementlearning methods(Mnihetal.,2014).
Asonewouldexpect, trainingsuchamodelisquitecomplex.
Consequentlythebulkofmodernattentionresearchfollowstheframeworkoutlinedin.1.1.
Wethusfocusourexpositiononthisfamilyofdifferentiablemechanisms.
Whatisquiteremarkableisthattheactualâ€œcodeâ€forexecutingonthesetofkeysandvalues, namelythequery, canbequiteconcise, eventhoughthespacetooperateonissignificant.
Thisisadesirablepropertyforanetworklayerasitdoesnotrequiretoomanyparametersto learn.
Justasconvenientisthefactthatattentioncanoperateonarbitrarilylargedatabases withouttheneedtochangethewaytheattentionpoolingoperationisperformed.
413 Queries, Keys, and Values t .1.1 Theattentionmechanismcomputesalinearcombinationovervaluesv viaattention i pooling, whereweightsarederivedaccordingtothecompatibilitybetweenaqueryqand keysk .
i import torch from d2l import torch as d2l 11.1.1 Visualization Oneofthebenefitsoftheattentionmechanismisthatitcanbequiteintuitive, particularly when the weights are nonnegative and sum to 1.
In this case we might interpret large weights as a way for the model to select components of relevance.
While this is a good intuition, itisimportanttorememberthatitisjustthat, anintuition.
Regardless, wemay want to visualize its effect on the given set of keys when applying a variety of different queries.
Thisfunctionwillcomeinhandylater.
Wethusdefinetheshow_heatmapsfunction.
Notethatitdoesnottakeamatrix(ofattention weights) as its input but rather a tensor with four axes, allowing for an array of different queries and weights.
Consequently the input matrices has the shape (number of rows for display, number of columns for display, number of queries, number of keys).
This will come in handy later on when we want to visualize the workings that are to design Transformers.
#@save def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap='Reds'): """Show heatmaps of matrices.""" d2l.
use_svg_display() num_rows, num_cols, _, _ = matrices.
shape fig, axes = d2l.
plt.
subplots(num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False) for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)): for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)): pcm = ax.
imshow(matrix.
detach().
numpy(), cmap=cmap) if i == num_rows - 1: ax.
set_xlabel(xlabel) if j == 0: ax.
set_ylabel(ylabel) if titles: (continuesonnextpage) 414 Attention Mechanismsand Transformers (continuedfrompreviouspage) ax.
set_title(titles[j]) fig.
colorbar(pcm, ax=axes, shrink=0.6); As a quick sanity check letâ€™s visualize the identity matrix, representing a case where the attentionweightis1onlywhenthequeryandthekeyarethesame.
attention_weights = torch.
eye(10).
reshape((1, 1, 10, 10)) show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries') 11.1.2 Summary The attention mechanism allows us to aggregate data from many (key, value) pairs.
So farourdiscussionwasquiteabstract, simplydescribingawaytopooldata.
Wehavenot explained yet where those mysterious queries, keys, and values might arise from.
Some intuitionmighthelphere: forinstance, inaregressionsetting, thequerymightcorrespond to the location where the regression should be carried out.
The keys are the locations wherepastdatawasobservedandthevaluesarethe(regression)valuesthemselves.
This istheso-called Nadarayaâ€“Watsonestimator(Nadaraya,1964, Watson,1964)thatwewill bestudyinginthenextsection.
Bydesign, theattentionmechanismprovidesadifferentiablemeansofcontrolbywhicha neuralnetworkcanselectelementsfromasetandtoconstructanassociatedweightedsum overrepresentations.
11.1.3 Exercises 1.
Supposethatyouwantedtoreimplementapproximate(key, query)matchesasusedin classicaldatabases, whichattentionfunctionwouldyoupick? 2.
Suppose that the attention function is given by ğ‘â€q, kğ‘– â€ = q>kğ‘– and that kğ‘– = vğ‘– for ğ‘– =1,...,ğ‘š.
Denoteby ğ‘â€kğ‘–; qâ€ theprobabilitydistributionoverkeyswhenusingthe softmaxnormalizationin(11.1.3).
Provethatr q Attentionâ€q, Dâ€ =Covğ‘â€kğ‘–; qâ€ Â»kğ‘– â€¦.
3.
Designadifferentiablesearchengineusingtheattentionmechanism.
4.
Reviewthedesignofthe Squeezeand Excitation Networks(Huetal.,2018)andinterpret themthroughthelensoftheattentionmechanism.
415 Attention Poolingby Similarity Discussions154.
154 11.2 Attention Pooling by Similarity Now that we have introduced the primary components of the attention mechanism, letâ€™s usetheminaratherclassicalsetting, namelyregressionandclassificationviakernelden- sity estimation (Nadaraya, 1964, Watson, 1964).
This detour simply provides additional background: itisentirelyoptionalandcanbeskippedifneeded.
Attheircore, Nadarayaâ€“ Watsonestimatorsrelyonsomesimilaritykernelğ›¼â€q, kâ€relatingqueriesqtokeysk.
Some commonkernelsare 1 ğ›¼â€q, kâ€ =exp kq kk2 Gaussian; 2 (11.2.1) ğ›¼â€q, kâ€ =1ifkq kk 1 Boxcar; ğ›¼â€q, kâ€ =maxâ€0,1 kq kkâ€ Epanechikov.
Therearemanymorechoicesthatwecouldpick.
Seea Wikipediaarticle155 foramore 155 extensivereviewandhowthechoiceofkernelsisrelatedtokerneldensityestimation, some- timesalsocalled Parzen Windows(Parzen,1957).
Allofthekernelsareheuristicandcan betuned.
Forinstance, wecanadjustthewidth, notonlyonaglobalbasisbutevenona per-coordinatebasis.
Regardless, allofthemleadtothefollowingequationforregression andclassificationalike: ğ‘“â€qâ€ = ğ‘– vğ‘– Ë ğ›¼ ğ‘— ğ›¼ â€q â€ , q k , ğ‘– k â€ ğ‘— â€ .
(11.2.2) Inthecaseofa(scalar)regressionwithobservationsâ€xğ‘– ,ğ‘¦ ğ‘– â€forfeaturesandlabelsrespec- tively, vğ‘– = ğ‘¦ ğ‘– arescalars, kğ‘– = xğ‘– arevectors, andthequeryqdenotesthenewlocation where ğ‘“ should be evaluated.
In the case of (multiclass) classification, we use one-hot- encodingofğ‘¦ ğ‘– toobtainvğ‘–.
Oneoftheconvenientpropertiesofthisestimatoristhatitre- quiresnotraining.
Evenmoreso, ifwesuitablynarrowthekernelwithincreasingamounts of data, the approach is consistent (Mack and Silverman, 1982), i.
e., it will converge to somestatisticallyoptimalsolution.
Letâ€™sstartbyinspectingsomekernels.
import numpy as np import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l d2l.
use_svg_display() 11.2.1 Kernelsand Data Allthekernelsğ›¼â€k, qâ€ definedinthissectionaretranslationandrotationinvariant; that is, ifweshiftandrotatekandqinthesamemanner, thevalueofğ›¼ remainsunchanged.
416 Attention Mechanismsand Transformers Forsimplicitywethuspickscalarargumentsğ‘˜,ğ‘ 2Randpickthekeyğ‘˜ =0astheorigin.
Thisyields: # Define some kernels def gaussian(x): return torch.
exp(-x**2 / 2) def boxcar(x): return torch.
abs(x) < 1.0 def constant(x): return 1.0 + 0 * x def epanechikov(x): return torch.
max(1 - torch.
abs(x), torch.
zeros_like(x)) fig, axes = d2l.
plt.
subplots(1, 4, sharey=True, figsize=(12, 3)) kernels = (gaussian, boxcar, constant, epanechikov) names = ('Gaussian', 'Boxcar', 'Constant', 'Epanechikov') x = torch.
arange(-2.5, 2.5, 0.1) for kernel, name, ax in zip(kernels, names, axes): ax.
set_xlabel(name) d2l.
plt.
show() Different kernels correspond to different notions of range and smoothness.
For instance, the boxcar kernel only attends to observations within a distance of 1 (or some otherwise definedhyperparameter)anddoessoindiscriminately.
Tosee Nadarayaâ€“Watsonestimationinaction, letâ€™sdefinesometrainingdata.
Inthefol- lowingweusethedependency ğ‘¦ ğ‘– =2sinâ€ğ‘¥ ğ‘– â€â€šğ‘¥ ğ‘– â€šğœ–, (11.2.3) whereğœ– isdrawnfromanormaldistributionwithzeromeanandunitvariance.
Wedraw 40trainingexamples.
417 Attention Poolingby Similarity def f(x): return 2 * torch.
sin(x) + x n = 40 x_train, _ = torch.
sort(torch.
rand(n) * 5) y_train = f(x_train) + torch.
randn(n) x_val = torch.
arange(0, 5, 0.1) y_val = f(x_val) 11.2.2 Attention Poolingvia Nadarayaâ€“Watson Regression Now that we have data and kernels, all we need is a function that computes the kernel regressionestimates.
Notethatwealsowanttoobtaintherelativekernelweightsinorder toperformsomeminordiagnostics.
Hencewefirstcomputethekernelbetweenalltraining features(covariates)x_trainandallvalidationfeaturesx_val.
Thisyieldsamatrix, which wesubsequentlynormalize.
Whenmultipliedwiththetraininglabelsy_trainweobtain theestimates.
Recall attention pooling in (11.1.1).
Let each validation feature be a query, and each training featureâ€“label pair be a keyâ€“value pair.
As a result, the normalized relative ker- nelweights(attention_wbelow)aretheattentionweights.
def nadaraya_watson(x_train, y_train, x_val, kernel): dists = x_train.
reshape((-1, 1)) - x_val.
reshape((1, -1)) # Each column/row corresponds to each query/key k = kernel(dists).
type(torch.
float32) # Normalization over keys for each query attention_w = k / k.
sum(0) y_hat = y_train@attention_w return y_hat, attention_w Letâ€™shavealookatthekindofestimatesthatthedifferentkernelsproduce.
def plot(x_train, y_train, x_val, y_val, kernels, names, attention=False): fig, axes = d2l.
plt.
subplots(1, 4, sharey=True, figsize=(12, 3)) for kernel, name, ax in zip(kernels, names, axes): y_hat, attention_w = nadaraya_watson(x_train, y_train, x_val, kernel) if attention: pcm = ax.
imshow(attention_w.
detach().
numpy(), cmap='Reds') else: ax.
plot(x_val, y_hat) ax.
plot(x_val, y_val, 'm--') ax.
plot(x_train, y_train, 'o', alpha=0.5); ax.
set_xlabel(name) if not attention: ax.
legend(['y_hat', 'y']) if attention: fig.
colorbar(pcm, ax=axes, shrink=0.7) 418 Attention Mechanismsand Transformers plot(x_train, y_train, x_val, y_val, kernels, names) The first thing that stands out is that all three nontrivial kernels (Gaussian, Boxcar, and Epanechikov)producefairlyworkableestimatesthatarenottoofarfromthetruefunction.
Ë Onlytheconstantkernelthatleadstothetrivialestimate ğ‘“â€ğ‘¥â€ = ğ‘› 1 ğ‘– ğ‘¦ ğ‘– producesarather unrealisticresult.
Letâ€™sinspecttheattentionweightingabitmoreclosely: plot(x_train, y_train, x_val, y_val, kernels, names, attention=True) Thevisualizationclearlyshowswhytheestimatesfor Gaussian, Boxcar, and Epanechikov areverysimilar: afterall, theyarederivedfromverysimilarattentionweights, despitethe differentfunctionalformofthekernel.
Thisraisesthequestionastowhetherthisisalways thecase.
11.2.3 Adapting Attention Pooling Wecouldreplac ethe Gaussian kernelwithoneofadifferentwidth.
Thatis, wecoulduse ğ›¼â€q, kâ€ = exp 1 kq kk2 where ğœ2 determines the width of the kernel.
Letâ€™s see 2ğœ2 whetherthisaffectstheoutcomes.
sigmas = (0.1, 0.2, 0.5, 1) names = ['Sigma ' + str(sigma) for sigma in sigmas] def gaussian_with_width(sigma): return (lambda x: torch.
exp(-x**2 / (2*sigma**2))) kernels = [gaussian_with_width(sigma) for sigma in sigmas] plot(x_train, y_train, x_val, y_val, kernels, names) 419 Attention Poolingby Similarity Clearly, thenarrowerthekernel, thelesssmooththeestimate.
Atthesametime, itadapts bettertothelocalvariations.
Letâ€™slookatthecorrespondingattentionweights.
plot(x_train, y_train, x_val, y_val, kernels, names, attention=True) As we would expect, the narrower the kernel, the narrower the range of large attention weights.
Itisalsoclearthatpickingthesamewidthmightnotbeideal.
Infact, Silverman (1986) proposed a heuristic that depends on the local density.
Many more such â€œtricksâ€ have been proposed.
For instance, Norelli et al.
(2022) used a similar nearest-neighbor interpolationtechniquefordesigningcross-modalimageandtextrepresentations.
Theastutereadermightwonderwhyweareprovidingthisdeepdiveforamethodthatisover halfacenturyold.
First, itisoneoftheearliestprecursorsofmodernattentionmechanisms.
Second, itisgreatforvisualization.
Third, andjustasimportantly, itdemonstratesthelimits ofhand-craftedattentionmechanisms.
Amuchbetterstrategyistolearnthemechanism, bylearningtherepresentationsforqueriesandkeys.
Thisiswhatwewillembarkoninthe followingsections.
11.2.4 Summary Nadarayaâ€“Watson kernel regression is an early precursor of the current attention mecha- nisms.
Itcanbeuseddirectlywithlittletonotrainingortuning, eitherforclassificationor regression.
The attention weight is assigned according to the similarity (or distance) be- tweenqueryandkey, andaccordingtohowmanysimilarobservationsareavailable.
11.2.5 Exercises 420 Attention Mechanismsand Transformers Ë 1.
Parzen windows density estimates are given by ğ‘Ë†â€xâ€ = ğ‘› 1 ğ‘– ğ‘˜â€x, xğ‘– â€.
Prove that for binary classification the function ğ‘Ë†â€x,ğ‘¦ = 1â€ ğ‘Ë†â€x,ğ‘¦ = 1â€, as obtained by Parzen windowsisequivalentto Nadarayaâ€“Watsonclassification.
2.
Implementstochasticgradientdescenttolearnagoodvalueforkernelwidthsin Nadarayaâ€“ Watsonregression.
1.
Whathappensifyoujustusetheaboveestimatestominimizeâ€ğ‘“â€x i â€ ğ‘¦ ğ‘– â€2directly? Hint: ğ‘¦ ğ‘– ispartofthetermsusedtocompute ğ‘“.
2.
Remove â€xğ‘– ,ğ‘¦ ğ‘– â€ from the estimate for ğ‘“â€xğ‘– â€ and optimize over the kernel widths.
Doyoustillobserveoverfitting? 3.
Assumethatallxlieontheunitsphere, i.
e., allsatisfy kxk = 1.
Canyousimplifythe kx xğ‘– k2termintheexponential? Hint: wewilllaterseethatthisisverycloselyrelated todotproductattention.
4.
Recallthat Mackand Silverman(1982)provedthat Nadarayaâ€“Watsonestimationiscon- sistent.
Howquicklyshouldyoureducethescalefortheattentionmechanismasyouget moredata? Providesomeintuitionforyouranswer.
Doesitdependonthedimension- alityofthedata? How? 156 Discussions156.
11.3 Attention Scoring Functions In Section11.2, weusedanumberofdifferentdistance-basedkernels, includinga Gaussian kerneltomodelinteractionsbetweenqueriesandkeys.
Asitturnsout, distancefunctions areslightlymoreexpensivetocomputethandotproducts.
Assuch, withthesoftmaxop- erationtoensurenonnegativeattentionweights, muchoftheworkhasgoneintoattention t .3.1 Computingtheoutputofattentionpoolingasaweightedaverageofvalues, whereweights arecomputedwiththeattentionscoringfunctiona andthesoftmaxoperation.
421 Attention Scoring Functions import math import torch from torch import nn from d2l import torch as d2l 11.3.1 Dot Product Attention Letâ€™sreviewtheattentionfunction(withoutexponentiation)fromthe Gaussiankernelfor amoment: 1 1 1 ğ‘â€q, kğ‘– â€ = kq kğ‘– k2 =q > kğ‘– kkğ‘– k2 kqk2.
(11.3.1) 2 2 2 First, note that the final term depends on q only.
As such it is identical for all â€q, kğ‘– â€ pairs.
Normalizingtheattentionweightsto1, asisdonein(11.1.3), ensuresthatthisterm disappearsentirely.
Second, notethatbothbatchandlayernormalization(tobediscussed later)leadtoactivationsthathavewell-bounded, andoftenconstant, norms kkğ‘– k.
Thisis thecase, forinstance, wheneverthekeyskğ‘– weregeneratedbyalayernorm.
Assuch, we candropitfromthedefinitionofğ‘withoutanymajorchangeintheoutcome.
Last, weneedtokeeptheorderofmagnitudeoftheargumentsintheexponentialfunction under control.
Assume that all the elements of the query q 2 Rğ‘‘ and the key kğ‘– 2 Rğ‘‘ areindependentandidenticallydrawnrandomvariableswithzeromeanandunitvariance.
Thedotproductbetweenbothvectorshaszeromeanandavarianceof ğ‘‘.
Toensurethat thevarianceofthedotproductstillremains1regardlessofvectorlength, weusethpescaled dotproductattentionscoringfunction.
Thatis, werescalethedotproductby1 ğ‘‘.
We thusarriveatthefirstcommonlyusedattentionfunctionthatisused, e.
g., in Transformers (Vaswanietal.,2017): p ğ‘â€q, kğ‘– â€ =q > kğ‘– ğ‘‘.
(11.3.2) Note that attention weights ğ›¼ still need normalizing.
We can simplify this further via (11.1.3)byusingthesoftmaxoperation: p ğ›¼â€q, kğ‘– â€ =softmaxâ€ğ‘â€q, kğ‘– â€â€ = Ë expâ€q>kğ‘– ğ‘‘ p â€ .
(11.3.3) ğ‘—=1 expâ€q>kğ‘— ğ‘‘â€ As it turns out, all popular attention mechanisms use the softmax, hence we will limit ourselvestothatintheremainderofthischapter.
11.3.2 Convenience Functions Weneedafewfunctionstomaketheattentionmechanismefficienttodeploy.
Thisincludes toolsfordealingwithstringsofvariablelengths(commonfornaturallanguageprocessing) andtoolsforefficientevaluationonminibatches(batchmatrixmultiplication).
Masked Softmax Operation One of the most popular applications of the attention mechanism is to sequence models.
Henceweneedtobeabletodealwithsequencesofdifferentlengths.
Insomecases, such 422 Attention Mechanismsand Transformers sequences may end up in the same minibatch, necessitating padding with dummy tokens forshortersequences(see Section10.5foranexample).
Thesespecialtokensdonotcarry meaning.
Forinstance, assumethatwehavethefollowingthreesentences: Dive into Deep Learning Learn to code <blank> Hello world <blank> <blank> Ë Sin Ë cewedonotwantblanksinourattentionmodelwesimplyneedtolimit ğ‘– ğ‘› =1 ğ›¼â€q, kğ‘– â€vğ‘– to ğ‘™ ğ‘–=1 ğ›¼â€q, kğ‘– â€vğ‘–forhoweverlong,ğ‘™ ğ‘›, theactualsentenceis.
Sinceitissuchacommon problem, ithasaname: themaskedsoftmaxoperation.
Letâ€™simplementit.
Actually, theimplementationcheatseversoslightlybysettingthevalues ofvğ‘–, forğ‘– > ğ‘™, tozero.
Moreover, itsetstheattentionweightstoalargenegativenumber, suchas 106, inordertomaketheircontributiontogradientsandvaluesvanishinpractice.
Thisisdonesincelinearalgebrakernelsandoperatorsareheavilyoptimizedfor GPUsand itisfastertobeslightlywastefulincomputationratherthantohavecodewithconditional (ifthenelse)statements.
def masked_softmax(X, valid_lens): #@save """Perform softmax operation by masking elements on the last axis.""" # X: 3D tensor, valid_lens: 1D or 2D tensor def _sequence_mask(X, valid_len, value=0): maxlen = X.
size(1) mask = torch.
arange((maxlen), dtype=torch.
float32, device=X.
device)[None, :] < valid_len[:, None] X[~mask] = value return X if valid_lens is None: return nn.
functional.
softmax(X, dim=-1) else: shape = X.
shape if valid_lens.
dim() == 1: valid_lens = torch.
repeat_interleave(valid_lens, shape[1]) else: valid_lens = valid_lens.
reshape(-1) # On the last axis, replace masked elements with a very large negative # value, whose exponentiation outputs 0 X = _sequence_mask(X.
reshape(-1, shape[-1]), valid_lens, value=-1e6) return nn.
functional.
softmax(X.
reshape(shape), dim=-1) Toillustratehowthisfunctionworks, consideraminibatchoftwoexamplesofsize2 4, wheretheirvalidlengthsare2and3, respectively.
Asaresultofthemaskedsoftmaxoper- ation, valuesbeyondthevalidlengthsforeachpairofvectorsareallmaskedaszero.
masked_softmax(torch.
rand(2, 2, 4), torch.
tensor([2, 3])) tensor([[[0.4448, 0.5552, 0.0000, 0.0000], [0.4032, 0.5968, 0.0000, 0.0000]], (continuesonnextpage) 423 Attention Scoring Functions (continuedfrompreviouspage) [[0.2795, 0.2805, 0.4400, 0.0000], [0.2798, 0.3092, 0.4110, 0.0000]]]) If we need more fine-grained control to specify the valid length for each of the two vec- tors of every example, we simply use a two-dimensional tensor of valid lengths.
This yields: masked_softmax(torch.
rand(2, 2, 4), torch.
tensor([[1, 3], [2, 4]])) tensor([[[1.0000, 0.0000, 0.0000, 0.0000], [0.4109, 0.2794, 0.3097, 0.0000]], [[0.3960, 0.6040, 0.0000, 0.0000], [0.2557, 0.1833, 0.2420, 0.3190]]]) Batch Matrix Multiplication Anothercommonlyusedoperationistomultiplybatchesofmatricesbyoneanother.
This comesinhandywhenwehaveminibatchesofqueries, keys, andvalues.
Morespecifically, assumethat Q= Â»Q 1 , Q 2 ,..., Qğ‘› â€¦ 2Rğ‘› ğ‘ ğ‘, (11.3.4) K= Â»K 1 , K 2 ,..., Kğ‘› â€¦ 2Rğ‘› ğ‘ ğ‘.
Thenthebatchmatrixmultiplication(BMM)computestheelementwiseproduct BMMâ€Q, Kâ€ = Â»Q 1 K 1 , Q 2 K 2 Letâ€™sseethisinactioninadeeplearningframework.
Q = torch.
ones((2, 3, 4)) K = torch.
ones((2, 4, 6)) d2l.
check_shape(torch.
bmm(Q, K), (2, 3, 6)) 11.3.3 Scaled Dot Product Attention Letâ€™sreturntothedotproductattentionintroducedin(11.3.2).
Ingeneral, itrequiresthat both the query and the key have the same vector length, say ğ‘‘, even though this can be addressedeasilybyreplacing q>k with q>Mk where M isamatrixsuitablychosenfor translatingbetweenbothspaces.
Fornowassumethatthedimensionsmatch.
In practice, we often think of minibatches for efficiency, such as computing attention for ğ‘›queriesandğ‘š key-valuepairs, wherequeriesandkeysareoflengthğ‘‘ andvaluesareof length ğ‘£.
The scaled dot product attention of queries Q 2 Rğ‘› ğ‘‘ , keys K 2 Rğ‘š ğ‘‘ , and 424 Attention Mechanismsand Transformers values V 2Rğ‘š ğ‘£ thuscanbewrittenas QK> softmax p V 2Rğ‘› ğ‘£.
(11.3.6) ğ‘‘ Notethatwhenapplyingthistoaminibatch, weneedthebatchmatrixmultiplicationintro- ducedin(11.3.5).
Inthefollowingimplementationofthescaleddotproductattention, we usedropoutformodelregularization.
class Dot Product Attention(nn.
Module): #@save """Scaled dot product attention.""" def __init__(self, dropout): super().__init__() self.
dropout = nn.
Dropout(dropout) # Shape of queries: (batch_size, no.
of queries, d) # Shape of keys: (batch_size, no.
of key-value pairs, d) # Shape of values: (batch_size, no.
of key-value pairs, value dimension) # Shape of valid_lens: (batch_size,) or (batch_size, no.
of queries) def forward(self, queries, keys, values, valid_lens=None): d = queries.
shape[-1] # Swap the last two dimensions of keys with keys.
transpose(1, 2) scores = torch.
bmm(queries, keys.
transpose(1, 2)) / math.
sqrt(d) self.
attention_weights = masked_softmax(scores, valid_lens) return torch.
bmm(self.
dropout(self.
attention_weights), values) To illustrate how the Dot Product Attention class works, we use the same keys, values, and valid lengths from the earlier toy example for additive attention.
For the purpose of ourexampleweassumethatwehaveaminibatchsizeof2, atotalof10keysandvalues, andthatthedimensionalityofthevaluesis4.
Lastly, weassumethatthevalidlengthper observationis2and6respectively.
Giventhat, weexpecttheoutputtobea2 1 4tensor, i.
e., onerowperexampleoftheminibatch.
queries = torch.
normal(0, 1, (2, 1, 2)) keys = torch.
normal(0, 1, (2, 10, 2)) values = torch.
normal(0, 1, (2, 10, 4)) valid_lens = torch.
tensor([2, 6]) attention = Dot Product Attention(dropout=0.5) attention.
eval() d2l.
check_shape(attention(queries, keys, values, valid_lens), (2, 1, 4)) Letâ€™scheckwhethertheattentionweightsactuallyvanishforanythingbeyondthesecond andsixthcolumnrespectively(becauseofsettingthevalidlengthto2and6).
d2l.
show_heatmaps(attention.
attention_weights.
reshape((1, 1, 2, 10)), xlabel='Keys', ylabel='Queries') 11.3.4 Additive Attention Whenqueriesqandkeyskarevectorsofdifferentdimension, wecaneitheruseamatrixto addressthemismatchviaq>Mk, orwecanuseadditiveattentionasthescoringfunction.
425 Attention Scoring Functions Another benefit is that, as its name indicates, the attention is additive.
This can lead to someminorcomputationalsavings.
Givenaqueryq 2 Rğ‘ andakeyk 2 Rğ‘˜ , theadditive attentionscoringfunction(Bahdanauetal.,2014)isgivenby ğ‘â€q, kâ€ =w > ğ‘£tanhâ€Wğ‘qâ€šWğ‘˜kâ€ 2R, (11.3.7) where Wğ‘ 2 Râ„ ğ‘ , Wğ‘˜ 2 Râ„ ğ‘˜ , andwğ‘£ 2 Râ„ arethelearnableparameters.
Thisterm isthenfedintoasoftmaxtoensurebothnonnegativityandnormalization.
Anequivalent interpretationof (11.3.7)isthatthequeryandkeyareconcatenatedandfedintoan MLP withasinglehiddenlayer.
Usingtanhastheactivationfunctionanddisablingbiasterms, weimplementadditiveattentionasfollows: class Additive Attention(nn.
Module): #@save """Additive attention.""" def __init__(self, num_hiddens, dropout, **kwargs): super(Additive Attention, self).__init__(**kwargs) self.
W_k = nn.
Lazy Linear(num_hiddens, bias=False) self.
W_q = nn.
Lazy Linear(num_hiddens, bias=False) self.
w_v = nn.
Lazy Linear(1, bias=False) self.
dropout = nn.
Dropout(dropout) def forward(self, queries, keys, values, valid_lens): queries, keys = self.
W_q(queries), self.
W_k(keys) # After dimension expansion, shape of queries: (batch_size, no.
of # queries, 1, num_hiddens) and shape of keys: (batch_size, 1, no.
of # key-value pairs, num_hiddens).
Sum them up with broadcasting features = queries.
unsqueeze(2) + keys.
unsqueeze(1) features = torch.
tanh(features) # There is only one output of self.
w_v, so we remove the last # one-dimensional entry from the shape.
Shape of scores: (batch_size, # no.
of queries, no.
of key-value pairs) scores = self.
w_v(features).
squeeze(-1) self.
attention_weights = masked_softmax(scores, valid_lens) # Shape of values: (batch_size, no.
of key-value pairs, value # dimension) return torch.
bmm(self.
dropout(self.
attention_weights), values) Letâ€™sseehow Additive Attentionworks.
Inourtoyexamplewepickqueries, keysand valuesofsizeâ€2,1,20â€,â€2,10,2â€andâ€2,10,4â€, respectively.
Thisisidenticaltoourchoice for Dot Product Attention, exceptthatnowthequeriesare20-dimensional.
Likewise, we pickâ€2,6â€asthevalidlengthsforthesequencesintheminibatch.
queries = torch.
normal(0, 1, (2, 1, 20)) (continuesonnextpage) 426 Attention Mechanismsand Transformers (continuedfrompreviouspage) attention = Additive Attention(num_hiddens=8, dropout=0.1) attention.
eval() d2l.
check_shape(attention(queries, keys, values, valid_lens), (2, 1, 4)) Whenreviewingtheattentionfunctionweseeabehaviorthatisqualitativelyquitesimilar tothatof Dot Product Attention.
Thatis, onlytermswithinthechosenvalidlengthâ€2,6â€ arenonzero.
d2l.
show_heatmaps(attention.
attention_weights.
reshape((1, 1, 2, 10)), xlabel='Keys', ylabel='Queries') 11.3.5 Summary Inthissectionweintroducedthetwokeyattentionscoringfunctions: dotproductandaddi- tiveattention.
Theyareeffectivetoolsforaggregatingacrosssequencesofvariablelength.
Inparticular, thedotproductattentionisthemainstayofmodern Transformerarchitectures.
157 Whenqueriesandkeysarevectorsofdifferentlengths, wecanusetheadditiveattention scoringfunctioninstead.
Optimizingtheselayersisoneofthekeyareasofadvanceinre- centyears.
Forinstance, NVIDIAâ€™s Transformer Library157 and Megatron(Shoeybietal., 2019)cruciallyrelyonefficientvariantsoftheattentionmechanism.
Wewilldiveintothis inquiteabitmoredetailaswereview Transformersinlatersections.
11.3.6 Exercises 1.
Implementdistance-basedattentionbymodifyingthe Dot Product Attentioncode.
Note thatyouonlyneedthesquarednormsofthekeyskkğ‘– k2foranefficientimplementation.
2.
Modifythedotproductattentiontoallowforqueriesandkeysofdifferentdimension- 158 alitiesbyemployingamatrixtoadjustdimensions.
3.
How does the computational cost scale with the dimensionality of the keys, queries, values, andtheirnumber? Whataboutthememorybandwidthrequirements? Discussions158.
427 The Bahdanau Attention Mechanism 11.4 The Bahdanau Attention Mechanism Whenweencounteredmachinetranslationin Section10.7, wedesignedanencoderâ€“decoder architectureforsequence-to-sequencelearningbasedontwo RNNs(Sutskeveretal.,2014).
Specifically, the RNN encoder transforms a variable-length sequence into a fixed-shape contextvariable.
Then, the RNNdecodergeneratestheoutput(target)sequencetokenby tokenbasedonthegeneratedtokensandthecontextvariable.
ally, in an RNN all relevant information about a source sequence is translated into some internal fixed-dimensional state representation by the encoder.
It is this very state that is usedbythedecoderasthecompleteandexclusivesourceofinformationforgeneratingthe translatedsequence.
Inotherwords, thesequence-to-sequencemechanismtreatstheinter- mediatestateasasufficientstatisticofwhateverstringmighthaveservedasinput.
t .4.1 Sequence-to-sequencemodel.
Thestate, asgeneratedbytheencoder, istheonlypieceof informationsharedbetweentheencoderandthedecoder.
Whilethisisquitereasonableforshortsequences, itisclearthatitisinfeasibleforlongones, suchasabookchapterorevenjustaverylongsentence.
Afterall, beforetoolongtherewill simplynotbeenoughâ€œspaceâ€intheintermediaterepresentationtostoreallthatisimportant inthesourcesequence.
Consequentlythedecoderwillfailtotranslatelongandcomplex sentences.
One of the first to encounter this was Graves (2013) who tried to design an RNNtogeneratehandwrittentext.
Sincethesourcetexthasarbitrarylengththeydesigneda differentiableattentionmodeltoaligntextcharacterswiththemuchlongerpentrace, where thealignmentmovesonlyinonedirection.
This, inturn, drawsondecodingalgorithmsin speechrecognition, e.
g., hidden Markovmodels(Rabinerand Juang,1993).
Inspiredbytheideaoflearningtoalign, Bahdanauetal.
(2014)proposedadifferentiable attentionmodelwithouttheunidirectionalalignmentlimitation.
Whenpredictingatoken, ifnotalltheinputtokensarerelevant, themodelaligns(orattends)onlytopartsoftheinput sequencethataredeemedrelevanttothecurrentprediction.
Thisisthenusedtoupdatethe currentstatebeforegeneratingthenexttoken.
Whilequiteinnocuousinitsdescription, this Bahdanauattentionmechanismhasarguablyturnedintooneofthemostinfluentialideas ofthepastdecadeindeeplearning, givingriseto Transformers(Vaswanietal.,2017)and manyrelatednewarchitectures.
428 Attention Mechanismsand Transformers import torch from torch import nn from d2l import torch as d2l 11.4.1 Model We follow the notation introduced by the sequence-to-sequence architecture of Section textvariablecsummarizingthesourcesentence, asfixed, wedynamicallyupdateit, asa functionofboththeoriginaltext(encoderhiddenstateshğ‘¡)andthetextthatwasalready generated(decoderhiddenstatessğ‘¡0 1 ).
Thisyieldscğ‘¡0, whichisupdatedafteranydecod- ing time stepğ‘¡0 .
Suppose that the input sequence is of lengthğ‘‡.
In this case the context variableistheoutputofattentionpooling: ğ‘‡ cğ‘¡0 = ğ›¼â€sğ‘¡0 1 , hğ‘¡ â€hğ‘¡ .
(11.4.1) ğ‘¡=1 We used sğ‘¡0 1 as the query, and hğ‘¡ as both the key and the value.
Note that cğ‘¡0 is then usedtogeneratethestatesğ‘¡0 andtogenerateanewtoken: see(10.7.3).
Inparticular, the attentionweightğ›¼iscomputedasin(11.3.3)usingtheadditiveattentionscoringfunction definedby(11.3.7).
This RNNencoderâ€“decoderarchitectureusingattentionisdepictedin .4.2.
Notethatlaterthismodelwasmodifiedsoastoincludethealreadygenerated tokensinthedecoderasfurthercontext(i.
e., theattentionsumdoesnotstopatğ‘‡ butrather it proceeds up to ğ‘¡0 1).
For instance, see Chan et al.
(2015) for a description of this strategy, asappliedtospeechrecognition.
t .4.2 Layersinan RNNencoderâ€“decodermodelwiththe Bahdanauattentionmechanism.
11.4.2 Definingthe Decoderwith Attention Toimplementthe RNNencoderâ€“decoderwithattention, weonlyneedtoredefinethede- coder(omittingthegeneratedsymbolsfromtheattentionfunctionsimplifiesthedesign).
Letâ€™sbeginwiththebaseinterfacefordecoderswithattentionbydefiningthequiteunsur- prisinglynamed Attention Decoderclass.
429 The Bahdanau Attention Mechanism class Attention Decoder(d2l.
Decoder): #@save """The base attention-based decoder interface.""" def __init__(self): super().__init__() @property def attention_weights(self): raise Not Implemented Error We need to implement the RNN decoder in the Seq2Seq Attention Decoder class.
The stateofthedecoderisinitializedwith(i)thehiddenstatesofthelastlayeroftheencoder atalltimesteps, usedaskeysandvaluesforattention;(ii)thehiddenstateoftheencoder atalllayersatthefinaltimestep, whichservestoinitializethehiddenstateofthedecoder; and(iii)thevalidlengthoftheencoder, toexcludethepaddingtokensinattentionpooling.
Ateachdecodingtimestep, thehiddenstateofthefinallayerofthedecoder, obtainedat theprevioustimestep, isusedasthequeryoftheattentionmechanism.
Boththeoutputof theattentionmechanismandtheinputembeddingareconcatenatedtoserveastheinputof the RNNdecoder.
class Seq2Seq Attention Decoder(Attention Decoder): def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0): super().__init__() self.
attention = d2l.
Additive Attention(num_hiddens, dropout) self.
embedding = nn.
Embedding(vocab_size, embed_size) self.
rnn = nn.
GRU( embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout) self.
dense = nn.
Lazy Linear(vocab_size) self.
apply(d2l.
init_seq2seq) def init_state(self, enc_outputs, enc_valid_lens): # Shape of outputs: (num_steps, batch_size, num_hiddens).
# Shape of hidden_state: (num_layers, batch_size, num_hiddens) outputs, hidden_state = enc_outputs return (outputs.
permute(1, 0, 2), hidden_state, enc_valid_lens) def forward(self, X, state): # Shape of enc_outputs: (batch_size, num_steps, num_hiddens).
# Shape of hidden_state: (num_layers, batch_size, num_hiddens) enc_outputs, hidden_state, enc_valid_lens = state # Shape of the output X: (num_steps, batch_size, embed_size) X = self.
embedding(X).
permute(1, 0, 2) outputs, self._attention_weights = [], [] for x in X: # Shape of query: (batch_size, 1, num_hiddens) query = torch.
unsqueeze(hidden_state[-1], dim=1) # Shape of context: (batch_size, 1, num_hiddens) context = self.
attention( query, enc_outputs, enc_outputs, enc_valid_lens) # Concatenate on the feature dimension x = torch.
cat((context, torch.
unsqueeze(x, dim=1)), dim=-1) (continuesonnextpage) 430 Attention Mechanismsand Transformers (continuedfrompreviouspage) # Reshape x as (1, batch_size, embed_size + num_hiddens) out, hidden_state = self.
rnn(x.
permute(1, 0, 2), hidden_state) outputs.
append(out) self._attention_weights.
append(self.
attention.
attention_weights) # After fully connected layer transformation, shape of outputs: # (num_steps, batch_size, vocab_size) outputs = self.
dense(torch.
cat(outputs, dim=0)) return outputs.
permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens] @property def attention_weights(self): return self._attention_weights Inthefollowing, wetesttheimplementeddecoderwithattentionusingaminibatchoffour sequences, eachofwhichareseventimestepslong.
vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2 batch_size, num_steps = 4, 7 encoder = d2l.
Seq2Seq Encoder(vocab_size, embed_size, num_hiddens, num_layers) decoder = Seq2Seq Attention Decoder(vocab_size, embed_size, num_hiddens, num_layers) X = torch.
zeros((batch_size, num_steps), dtype=torch.
long) state = decoder.
init_state(encoder(X), None) output, state = decoder(X, state) d2l.
check_shape(output, (batch_size, num_steps, vocab_size)) d2l.
check_shape(state[0], (batch_size, num_steps, num_hiddens)) d2l.
check_shape(state[1][0], (batch_size, num_hiddens)) 11.4.3 Training Now that we specified the new decoder we can proceed analogously to Section 10.7.6: specify the hyperparameters, instantiate a regular encoder and a decoder with attention, andtrainthismodelformachinetranslation.
data = d2l.
MTFra Eng(batch_size=128) embed_size, num_hiddens, num_layers, dropout = 256, 256, 2, 0.2 encoder = d2l.
Seq2Seq Encoder( len(data.
src_vocab), embed_size, num_hiddens, num_layers, dropout) decoder = Seq2Seq Attention Decoder( len(data.
tgt_vocab), embed_size, num_hiddens, num_layers, dropout) model = d2l.
Seq2Seq(encoder, decoder, tgt_pad=data.
tgt_vocab['<pad>'], lr=0.005) trainer = d2l.
Trainer(max_epochs=30, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) Afterthemodelistrained, weuseittotranslateafew Englishsentencesinto Frenchand computetheir BLEUscores.
431 The Bahdanau Attention Mechanism engs = ['go .', 'i lost .', 'he\'s calm .', 'i\'m home .'] fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .'] preds, _ = model.
predict_step( data.
build(engs, fras), d2l.
try_gpu(), data.
num_steps) for en, fr, p in zip(engs, fras, preds): translation = [] for token in data.
tgt_vocab.
to_tokens(p): if token == '<eos>': break translation.
append(token) print(f'{en} => {translation}, bleu,' f'{d2l.
bleu(" ".
join(translation), fr, k=2):.3f}') go .
=> ['va', '!'], bleu,1.000 i lost .
=> ["j'ai", 'perdu', '.'], bleu,1.000 he's calm .
=> ['il', 'court', '.'], bleu,0.000 i'm home .
=> ['je', 'suis', 'chez', 'moi', '.'], bleu,1.000 Letâ€™svisualizetheattentionweightswhentranslatingthelast Englishsentence.
Weseethat eachqueryassignsnon-uniformweightsoverkeyâ€“valuepairs.
Itshowsthatateachdecod- ing step, different parts of the input sequences are selectively aggregated in the attention pooling.
_, dec_attention_weights = model.
predict_step( data.
build([engs[-1]], [fras[-1]]), d2l.
try_gpu(), data.
num_steps, True) attention_weights = torch.
cat( [step[0][0][0] for step in dec_attention_weights], 0) attention_weights = attention_weights.
reshape((1, 1, -1, data.
num_steps)) # Plus one to include the end-of-sequence token d2l.
show_heatmaps( attention_weights[:, :, :, : len(engs[-1].
split()) + 1].
cpu(), xlabel='Key positions', ylabel='Query positions') 11.4.4 Summary Whenpredictingatoken, ifnotalltheinputtokensarerelevant, the RNNencoderâ€“decoder withthe Bahdanauattentionmechanismselectivelyaggregatesdifferentpartsoftheinput 432 Attention Mechanismsand Transformers sequence.
Thisisachievedbytreatingthestate(contextvariable)asanoutputofadditive attentionpooling.
Inthe RNNencoderâ€“decoder, the Bahdanauattentionmechanismtreats the decoder hidden state at the previous time step as the query, and the encoder hidden statesatallthetimestepsasboththekeysandvalues.
11.4.5 Exercises 1.
Replace GRUwith LSTMintheexperiment.
2.
Modifytheexperimenttoreplacetheadditiveattentionscoringfunctionwiththescaled dot-product.
Howdoesitinfluencethetrainingefficiency? Discussions159.
159 11.5 Multi-Head Attention In practice, given the same set of queries, keys, and values we may want our model to combine knowledge from different behaviors of the same attention mechanism, such as capturingdependenciesofvariousranges(e.
g., shorter-rangevs.
longer-range)withinase- quence.
Thus, itmaybebeneficialtoallowourattentionmechanismtojointlyusedifferent representationsubspacesofqueries, keys, andvalues.
Tothisend, insteadofperformingasingleattentionpooling, queries, keys, andvaluescan be transformed with â„ independently learned linear projections.
Then these â„ projected queries, keys, andvaluesarefedintoattentionpoolinginparallel.
Intheend,â„attention- poolingoutputsareconcatenatedandtransformedwithanotherlearnedlinearprojectionto produce the final output.
This design is called multi-head attention, where eachof the â„ attentionpoolingoutputsisahead(Vaswanietal.,2017).
Usingfullyconnectedlayersto performlearnablelineartransformations,.5.1describesmulti-headattention.
import math import torch from torch import nn from d2l import torch as d2l 433 Multi-Head Attention t .5.1 Multi-headattention, wheremultipleheadsareconcatenatedthenlinearlytransformed.
11.5.1 Model Before providing the implementation of multi-head attention, letâ€™s formalize this model mathematically.
Given a query q 2 Rğ‘‘ğ‘, a key k 2 Rğ‘‘ğ‘˜, and a value v 2 Rğ‘‘ğ‘£, each attentionheadhğ‘– (ğ‘– =1,...,â„)iscomputedas hğ‘– = ğ‘“â€W ğ‘– â€ğ‘â€ q, W ğ‘– â€ğ‘˜â€ k, W ğ‘– â€ğ‘£â€ vâ€ 2Rğ‘ğ‘£, (11.5.1) where W â€ğ‘â€ 2 Rğ‘ğ‘ ğ‘‘ğ‘, W â€ğ‘˜â€ 2 Rğ‘ğ‘˜ ğ‘‘ğ‘˜, and W â€ğ‘£â€ 2 Rğ‘ğ‘£ ğ‘‘ğ‘£ arelearnableparameters ğ‘– ğ‘– ğ‘– and ğ‘“ is attention pooling, such as additive attention and scaled dot product attention in Section11.3.
Themulti-headattentionoutputisanotherlineartransformationvialearnable parameters Wğ‘œ 2Rğ‘ğ‘œ â„ğ‘ğ‘£ oftheconcatenationofâ„heads: 2 3 6h 17 6 .
7 Wğ‘œ 6 6 .
.
7 7 2Rğ‘ğ‘œ.
(11.5.2) 6 7 4hâ„5 Basedonthisdesign, eachheadmayattendtodifferentpartsoftheinput.
Moresophisti- catedfunctionsthanthesimpleweightedaveragecanbeexpressed.
11.5.2 Implementation In our implementation, we choose the scaled dot product attention for each head of the multi-headattention.
Toavoidsignificantgrowthofcomputationalcostandparametriza- tion cost, we set ğ‘ ğ‘ = ğ‘ ğ‘˜ = ğ‘ ğ‘£ = ğ‘ ğ‘œ â„.
Notethat â„ heads can be computed in parallel if weset the number of outputs of linear transformations forthe query, key, and valueto ğ‘ ğ‘ â„= ğ‘ ğ‘˜ â„= ğ‘ ğ‘£ â„= ğ‘ ğ‘œ.
Inthefollowingimplementation,ğ‘ ğ‘œisspecifiedviatheargument num_hiddens.
class Multi Head Attention(d2l.
Module): #@save """Multi-head attention.""" def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs): super().__init__() self.
num_heads = num_heads self.
attention = d2l.
Dot Product Attention(dropout) self.
W_q = nn.
Lazy Linear(num_hiddens, bias=bias) self.
W_k = nn.
Lazy Linear(num_hiddens, bias=bias) self.
W_v = nn.
Lazy Linear(num_hiddens, bias=bias) (continuesonnextpage) 434 Attention Mechanismsand Transformers (continuedfrompreviouspage) self.
W_o = nn.
Lazy Linear(num_hiddens, bias=bias) def forward(self, queries, keys, values, valid_lens): # Shape of queries, keys, or values: # (batch_size, no.
of queries or key-value pairs, num_hiddens) # Shape of valid_lens: (batch_size,) or (batch_size, no.
of queries) # After transposing, shape of output queries, keys, or values: # (batch_size * num_heads, no.
of queries or key-value pairs, # num_hiddens / num_heads) queries = self.
transpose_qkv(self.
W_q(queries)) keys = self.
transpose_qkv(self.
W_k(keys)) values = self.
transpose_qkv(self.
W_v(values)) if valid_lens is not None: # On axis 0, copy the first item (scalar or vector) for num_heads # times, then copy the next item, and so on valid_lens = torch.
repeat_interleave( valid_lens, repeats=self.
num_heads, dim=0) # Shape of output: (batch_size * num_heads, no.
of queries, # num_hiddens / num_heads) output = self.
attention(queries, keys, values, valid_lens) # Shape of output_concat: (batch_size, no.
of queries, num_hiddens) output_concat = self.
transpose_output(output) return self.
W_o(output_concat) Toallowforparallelcomputationofmultipleheads, theabove Multi Head Attentionclass uses two transposition methods as defined below.
Specifically, the transpose_output methodreversestheoperationofthetranspose_qkvmethod.
@d2l.
add_to_class(Multi Head Attention) #@save def transpose_qkv(self, X): """Transposition for parallel computation of multiple attention heads.""" # Shape of input X: (batch_size, no.
of queries or key-value pairs, # num_hiddens).
Shape of output X: (batch_size, no.
of queries or # key-value pairs, num_heads, num_hiddens / num_heads) X = X.
reshape(X.
shape[0], X.
shape[1], self.
num_heads, -1) # Shape of output X: (batch_size, num_heads, no.
of queries or key-value # pairs, num_hiddens / num_heads) X = X.
permute(0, 2, 1, 3) # Shape of output: (batch_size * num_heads, no.
of queries or key-value # pairs, num_hiddens / num_heads) return X.
reshape(-1, X.
shape[2], X.
shape[3]) @d2l.
add_to_class(Multi Head Attention) #@save def transpose_output(self, X): """Reverse the operation of transpose_qkv.""" X = X.
reshape(-1, self.
num_heads, X.
shape[1], X.
shape[2]) X = X.
permute(0, 2, 1, 3) return X.
reshape(X.
shape[0], X.
shape[1], -1) Letâ€™s test our implemented Multi Head Attention class using a toy example where keys 435 Self-Attentionand Positional Encoding and values are the same.
As a result, the shape of the multi-head attention output is (batch_size, num_queries, num_hiddens).
num_hiddens, num_heads = 100, 5 attention = Multi Head Attention(num_hiddens, num_heads, 0.5) batch_size, num_queries, num_kvpairs = 2, 4, 6 valid_lens = torch.
tensor([3, 2]) X = torch.
ones((batch_size, num_queries, num_hiddens)) Y = torch.
ones((batch_size, num_kvpairs, num_hiddens)) d2l.
check_shape(attention(X, Y, Y, valid_lens), (batch_size, num_queries, num_hiddens)) 11.5.3 Summary Multi-headattentioncombinesknowledgeofthesameattentionpoolingviadifferentrepre- sentationsubspacesofqueries, keys, andvalues.
Tocomputemultipleheadsofmulti-head attentioninparallel, propertensormanipulationisneeded.
11.5.4 Exercises 1.
Visualizeattentionweightsofmultipleheadsinthisexperiment.
2.
Suppose that we have a trained model based on multi-head attention and we want to prunelessimportantattentionheadstoincreasethepredictionspeed.
Howcanwede- signexperimentstomeasuretheimportanceofanattentionhead? 160 Discussions160.
11.6 Self-Attention and Positional Encoding Indeeplearning, weoftenuse CNNsor RNNstoencodesequences.
Nowwithattention mechanisms in mind, imagine feeding a sequenceof tokens into an attention mechanism suchthatateverystep, eachtokenhasitsownquery, keys, andvalues.
Here, whencomput- ingthevalueofatokenâ€™srepresentationatthenextlayer, thetokencanattend(viaitsquery vector) to any otherâ€™s token (matching based on their key vectors).
Using the full set of query-keycompatibilityscores, wecancompute, foreachtoken, arepresentationbybuild- ingtheappropriateweightedsumovertheothertokens.
Becauseeverytokenisattending to each other token (unlike the case where decoder steps attend to encoder steps), such architecturesaretypicallydescribedasself-attentionmodels(Linetal.,2017, Vaswaniet al., 2017), and elsewhere described as intra-attention model (Cheng et al., 2016, Parikh etal.,2016, Paulusetal.,2017).
Inthissection, wewilldiscusssequenceencodingusing self-attention, includingusingadditionalinformationforthesequenceorder.
436 Attention Mechanismsand Transformers import math import torch from torch import nn from d2l import torch as d2l 11.6.1 Self-Attention Given a sequence of input tokens x 1 ,..., xğ‘› where any xğ‘– 2 Rğ‘‘ (1 ğ‘– ğ‘›), its self- attentionoutputsasequenceofthesamelengthy 1 ,..., yğ‘›, where yğ‘– = ğ‘“â€xğ‘– ,â€x 1 , x 1 according to the definition of attention pooling in (11.1.1).
Using multi-head attention, thefollowingcodesnippetcomputestheself-attentionofatensorwithshape(batchsize, number of time steps or sequence length in tokens, ğ‘‘).
The output tensor has the same shape.
num_hiddens, num_heads = 100, 5 attention = d2l.
Multi Head Attention(num_hiddens, num_heads, 0.5) batch_size, num_queries, valid_lens = 2, 4, torch.
tensor([3, 2]) X = torch.
ones((batch_size, num_queries, num_hiddens)) d2l.
check_shape(attention(X, X, X, valid_lens), (batch_size, num_queries, num_hiddens)) 11.6.2 Comparing CNNs, RNNs, and Self-Attention Letâ€™s compare architectures for mapping a sequence of ğ‘› tokens to another one of equal length, whereeachinputoroutputtokenisrepresentedbyağ‘‘-dimensionalvector.
Specif- ically, wewillconsider CNNs, RNNs, andself-attention.
Wewillcomparetheircomputa- tionalcomplexity, sequentialoperations, andmaximumpathlengths.
Notethatsequential operationspreventparallelcomputation, whileashorterpathbetweenanycombinationof sequencepositionsmakesiteasiertolearnlong-rangedependencieswithinthesequence (Hochreiteretal.,2001).
Letâ€™sregardanytextsequenceasaâ€œone-dimensionalimageâ€.
Similarly, one-dimensional CNNscanprocesslocalfeaturessuchasğ‘›-gramsintext.
Givenasequenceoflengthğ‘›, con- sideraconvolutionallayerwhosekernelsizeisğ‘˜, andwhosenumbersofinputandoutput channelsarebothğ‘‘.
Thecomputationalcomplexityoftheconvolutionallayeris Oâ€ğ‘˜ğ‘›ğ‘‘2â€.
As.6.1shows, CNNsarehierarchical, sothereare Oâ€1â€ sequentialoperationsand themaximumpathlengthis Oâ€ğ‘› ğ‘˜â€.
Forexample, x andx arewithinthereceptivefield 1 5 ofatwo-layer CNNwithkernelsize3in.6.1.
Whenupdatingthehiddenstateof RNNs, multiplicationoftheğ‘‘ ğ‘‘weightmatrixandthe ğ‘‘-dimensionalhiddenstatehasacomputationalcomplexityof Oâ€ğ‘‘2â€.
Sincethesequence length is ğ‘›, the computational complexity of the recurrent layer is Oâ€ğ‘›ğ‘‘2â€.
According to .6.1, there are Oâ€ğ‘›â€ sequential operations that cannot be parallelized and the maximumpathlengthisalso Oâ€ğ‘›â€.
437 Self-Attentionand Positional Encoding t .6.1 Comparing CNN(paddingtokensareomitted), RNN, andself-attentionarchitectures.
Inself-attention, thequeries, keys, andvaluesareallğ‘› ğ‘‘ matrices.
Considerthescaled dotproductattentionin(11.3.6), whereanğ‘› ğ‘‘matrixismultipliedbyağ‘‘ ğ‘›matrix, then theoutputğ‘› ğ‘›matrixismultipliedbyanğ‘› ğ‘‘matrix.
Asaresult, theself-attentionhasa Oâ€ğ‘›2ğ‘‘â€ computationalcomplexity.
Aswecanseefrom.6.1, eachtokenisdirectly connectedtoanyothertokenviaself-attention.
Therefore, computationcanbeparallelwith Oâ€1â€sequentialoperationsandthemaximumpathlengthisalso Oâ€1â€.
Allinall, both CNNsandself-attentionenjoyparallelcomputationandself-attentionhas theshortestmaximumpathlength.
However, thequadraticcomputationalcomplexitywith respect to the sequence length makes self-attention prohibitively slow for very long se- quences.
11.6.3 Positional Encoding Unlike RNNs, which recurrently process tokens of a sequence one-by-one, self-attention ditchessequentialoperationsinfavorofparallelcomputation.
Notethatself-attentionby itselfdoesnotpreservetheorderofthesequence.
Whatdowedoifitreallymattersthat themodelknowsinwhichordertheinputsequencearrived? Thedominantapproachforpreservinginformationabouttheorderoftokensistorepresent thistothemodelasanadditionalinputassociatedwitheachtoken.
Theseinputsarecalled positionalencodings, andtheycaneitherbelearnedorfixedapriori.
Wenowdescribea simpleschemeforfixedpositionalencodingsbasedonsineandcosinefunctions(Vaswani etal.,2017).
Supposethattheinputrepresentation X 2 Rğ‘› ğ‘‘ containsthe ğ‘‘-dimensionalembeddings for ğ‘› tokens of a sequence.
The positional encoding outputs X â€š P using a positional embedding matrix P 2 Rğ‘› ğ‘‘ of the same shape, whose element on the ğ‘–th row and the 438 Attention Mechanismsand Transformers â€2ğ‘—â€thortheâ€2ğ‘— â€š1â€thcolumnis ğ‘– ğ‘ ğ‘–,2ğ‘— =sin 100002ğ‘— ğ‘‘ , (11.6.2) ğ‘– ğ‘ ğ‘–,2ğ‘—â€š1 =cos 100002ğ‘— ğ‘‘ .
Atfirstglance, thistrigonometricfunctiondesignlooksweird.
Beforewegiveexplanations ofthisdesign, letâ€™sfirstimplementitinthefollowing Positional Encodingclass.
class Positional Encoding(nn.
Module): #@save """Positional encoding.""" def __init__(self, num_hiddens, dropout, max_len=1000): super().__init__() self.
dropout = nn.
Dropout(dropout) # Create a long enough P self.
P = torch.
zeros((1, max_len, num_hiddens)) X = torch.
arange(max_len, dtype=torch.
float32).
reshape( -1, 1) / torch.
pow(10000, torch.
arange( 0, num_hiddens, 2, dtype=torch.
float32) / num_hiddens) self.
P[:, :, 0::2] = torch.
sin(X) self.
P[:, :, 1::2] = torch.
cos(X) def forward(self, X): X = X + self.
P[:, : X.
shape[1], :].
to(X.
device) return self.
dropout(X) Inthepositionalembeddingmatrix P, rowscorrespondtopositionswithinasequenceand columns represent different positional encoding dimensions.
In the example below, we canseethatthe6th andthe7th columnsofthepositionalembeddingmatrixhaveahigher frequencythanthe8thandthe9thcolumns.
Theoffsetbetweenthe6thandthe7th(samefor the8thandthe9th)columnsisduetothealternationofsineandcosinefunctions.
encoding_dim, num_steps = 32, 60 pos_encoding = Positional Encoding(encoding_dim, 0) X = pos_encoding(torch.
zeros((1, num_steps, encoding_dim))) P = pos_encoding.
P[:, : X.
shape[1], :] d2l.
plot(torch.
arange(num_steps), P[0, :, 6:10].
T, xlabel='Row (position)', figsize=(6, 2.5), legend=["Col %d" % d for d in torch.
arange(6, 10)]) 439 Self-Attentionand Positional Encoding Absolute Positional Information Toseehowthemonotonicallydecreasedfrequencyalongtheencodingdimensionrelates toabsolutepositionalinformation, letâ€™sprintoutthebinaryrepresentationsof0,1,...,7.
As wecan see, the lowestbit, the second-lowestbit, and the third-lowest bit alternate on everynumber, everytwonumbers, andeveryfournumbers, respectively.
for i in range(8): print(f'{i} in binary is {i:>03b}') 0 in binary is 000 1 in binary is 001 2 in binary is 010 3 in binary is 011 4 in binary is 100 5 in binary is 101 6 in binary is 110 7 in binary is 111 In binary representations, a higher bit has a lower frequency than a lower bit.
Similarly, as demonstrated in the heat map below, the positional encoding decreases frequencies alongtheencodingdimensionbyusingtrigonometricfunctions.
Sincetheoutputsarefloat numbers, suchcontinuousrepresentationsaremorespace-efficientthanbinaryrepresenta- tions.
P = P[0, :, :].
unsqueeze(0).
unsqueeze(0) d2l.
show_heatmaps(P, xlabel='Column (encoding dimension)', ylabel='Row (position)', figsize=(3.5, 4), cmap='Blues') Relative Positional Information Besidescapturingabsolutepositionalinformation, theabovepositionalencodingalsoal- lowsamodeltoeasilylearntoattendbyrelativepositions.
Thisisbecauseforanyfixed 440 Attention Mechanismsand Transformers position offset ğ›¿, the positional encoding at positionğ‘– â€šğ›¿ can be represented by a linear projectionofthatatpositionğ‘–.
This projection can be explained mathematically.
Denoting ğœ” ğ‘— = 1 100002ğ‘— ğ‘‘ , any pair of â€ğ‘ ğ‘–,2ğ‘— ,ğ‘ ğ‘–,2ğ‘—â€š1 â€ in(11.6.2)canbelinearlyprojectedto â€ğ‘ ğ‘–â€šğ›¿,2ğ‘— ,ğ‘ ğ‘–â€šğ›¿,2ğ‘—â€š1 â€ foranyfixed offsetğ›¿: cosâ€ğ›¿ğœ” ğ‘— â€ sinâ€ğ›¿ğœ” ğ‘— â€ ğ‘ ğ‘–,2ğ‘— = cosâ€ğ›¿ğœ” ğ‘— â€sinâ€ğ‘–ğœ” ğ‘— â€â€šsinâ€ğ›¿ğœ” ğ‘— â€cosâ€ğ‘–ğœ” ğ‘— â€ sinâ€ğ›¿ğœ” ğ‘— â€ cosâ€ğ›¿ğœ” ğ‘— â€ ğ‘ ğ‘–,2ğ‘—â€š1 sinâ€ğ›¿ğœ” ğ‘— â€sinâ€ğ‘–ğœ” ğ‘— â€â€šcosâ€ğ›¿ğœ” ğ‘— â€cosâ€ğ‘–ğœ” ğ‘— â€ sin â€ğ‘–â€šğ›¿â€ğœ” ğ‘— = cos â€ğ‘–â€šğ›¿â€ğœ” ğ‘— ğ‘ = ğ‘–â€šğ›¿,2ğ‘— , ğ‘ ğ‘–â€šğ›¿,2ğ‘—â€š1 (11.6.3) wherethe2 2projectionmatrixdoesnotdependonanypositionindexğ‘–.
11.6.4 Summary Inself-attention, thequeries, keys, andvaluesallcomefromthesameplace.
Both CNNs andself-attentionenjoyparallelcomputationandself-attentionhastheshortestmaximum pathlength.
However, thequadraticcomputationalcomplexitywithrespecttothesequence lengthmakesself-attentionprohibitivelyslowforverylongsequences.
Tousethesequence orderinformation, wecaninjectabsoluteorrelativepositionalinformationbyaddingpo- sitionalencodingtotheinputrepresentations.
11.6.5 Exercises 1.
Suppose that we design a deep architecture to represent a sequence by stacking self- attentionlayerswithpositionalencoding.
Whatcouldthepossibleissuesbe? 2.
Canyoudesignalearnablepositionalencodingmethod? 3.
Canweassigndifferentlearnedembeddingsaccordingtodifferentoffsetsbetweenqueries andkeysthatarecomparedinself-attention? Hint: youmayrefertorelativeposition embeddings(Huangetal.,2018, Shawetal.,2018).
161 Discussions161.
11.7 The Transformer Architecture We have compared CNNs, RNNs, and self-attention in Section 11.6.2.
Notably, self- attentionenjoysbothparallelcomputationandtheshortestmaximumpathlength.
There- fore, it is appealing to design deep architectures by using self-attention.
Unlike earlier self-attentionmodelsthatstillrelyon RNNsforinputrepresentations(Chengetal.,2016, 441 The Transformer Architecture Lin et al., 2017, Paulus et al., 2017), the Transformer model is solely based on attention mechanismswithoutanyconvolutionalorrecurrentlayer(Vaswanietal.,2017).
Though originallyproposedforsequence-to-sequencelearningontextdata, Transformershavebeen pervasiveinawiderangeofmoderndeeplearningapplications, suchasinareastodowith language, vision, speech, andreinforcementlearning.
import math import pandas as pd import torch from torch import nn from d2l import torch as d2l 11.7.1 Model Asaninstanceoftheencoderâ€“decoderarchitecture, theoverallarchitectureofthe Trans- formerispresentedin.7.1.
Aswecansee, the Transformeriscomposedofanen- coderandadecoder.
Incontrastto Bahdanauattentionforsequence-to-sequencelearning in.4.2, theinput(source)andoutput(target)sequenceembeddingsareaddedwith positionalencodingbeforebeingfedintotheencoderandthedecoderthatstackmodules basedonself-attention.
Nowweprovideanoverviewofthe Transformerarchitecturein.7.1.
Atahighlevel, the Transformer encoder is a stack of multiple identical layers, where each layer has two sublayers (either is denoted as sublayer).
The first is a multi-head self-attention pooling and the second is a positionwise feed-forward network.
Specifically, in the encoder self- attention, queries, keys, andvaluesareallfromtheoutputsofthepreviousencoderlayer.
Inspired by the Res Net design of Section 8.6, a residual connection is employed around bothsublayers.
Inthe Transformer, foranyinputx 2 Rğ‘‘ atanypositionofthesequence, werequirethatsublayerâ€xâ€ 2 Rğ‘‘ sothattheresidualconnectionxâ€šsublayerâ€xâ€ 2 Rğ‘‘ is feasible.
Thisadditionfromtheresidualconnectionisimmediatelyfollowedbylayernor- malization(Baetal.,2016).
Asaresult, the Transformerencoderoutputsağ‘‘-dimensional vectorrepresentationforeachpositionoftheinputsequence.
The Transformerdecoderisalsoastackofmultipleidenticallayerswithresidualconnec- tionsandlayernormalizations.
Aswellasthetwosublayersdescribedintheencoder, the decoder inserts a third sublayer, known as the encoderâ€“decoder attention, between these two.
Intheencoderâ€“decoderattention, queriesarefromtheoutputsofthedecoderâ€™sself- attentionsublayer, andthekeysandvaluesarefromthe Transformerencoderoutputs.
In thedecoderself-attention, queries, keys, andvaluesareallfromtheoutputsoftheprevious decoderlayer.
However, eachpositioninthedecoderisallowedonlytoattendtoallposi- tionsinthedecoderuptothatposition.
Thismaskedattentionpreservestheautoregressive property, ensuringthatthepredictiononlydependsonthoseoutputtokensthathavebeen generated.
Wehavealreadydescribedandimplementedmulti-headattentionbasedonscaleddotprod- uctsin Section11.5andpositionalencodingin Section11.6.3.
Inthefollowing, wewill implementtherestofthe Transformermodel.
442 Attention Mechanismsand Transformers t .7.1 The Transformerarchitecture.
11.7.2 Positionwise Feed-Forward Networks The positionwise feed-forward network transforms the representation at all the sequence positionsusingthesame MLP.
Thisiswhywecallitpositionwise.
Intheimplementation below, theinput Xwithshape(batchsize, numberoftimestepsorsequencelengthintokens, numberofhiddenunitsorfeaturedimension)willbetransformedbyatwo-layer MLPinto anoutputtensorofshape(batchsize, numberoftimesteps, ffn_num_outputs).
class Position Wise FFN(nn.
Module): #@save """The positionwise feed-forward network.""" def __init__(self, ffn_num_hiddens, ffn_num_outputs): super().__init__() self.
dense1 = nn.
Lazy Linear(ffn_num_hiddens) self.
relu = nn.
Re LU() self.
dense2 = nn.
Lazy Linear(ffn_num_outputs) def forward(self, X): return self.
dense2(self.
relu(self.
dense1(X))) Thefollowingexampleshowsthattheinnermostdimensionofatensorchangestothenum- 443 The Transformer Architecture berofoutputsinthepositionwisefeed-forwardnetwork.
Sincethesame MLPtransforms atallthepositions, whentheinputsatallthesepositionsarethesame, theiroutputsarealso identical.
ffn = Position Wise FFN(4, 8) ffn.
eval() ffn(torch.
ones((2, 3, 4)))[0] â†©!5163], â†©!5163], â†©!5163]], grad_fn=<Select Backward0>) 11.7.3 Residual Connectionand Layer Normalization Now letâ€™s focus on the â€œadd & normâ€ component in .7.1.
As we described at the beginningofthissection, thisisaresidualconnectionimmediatelyfollowedbylayernor- malization.
Botharekeytoeffectivedeeparchitectures.
In Section 8.5, we explained how batch normalization recenters and rescales across the exampleswithinaminibatch.
Asdiscussedin Section8.5.2, layernormalizationisthesame asbatchnormalizationexceptthattheformernormalizesacrossthefeaturedimension, thus enjoyingbenefitsofscaleindependenceandbatchsizeindependence.
Despiteitspervasive applications in computer vision, batch normalization is usually empirically less effective thanlayernormalizationin natural languageprocessing tasks, wherethe inputsareoften variable-lengthsequences.
The following code snippet compares the normalization across different dimensions by layernormalizationandbatchnormalization.
ln = nn.
Layer Norm(2) bn = nn.
Lazy Batch Norm1d() X = torch.
tensor([[1, 2], [2, 3]], dtype=torch.
float32) # Compute mean and variance from X in the training mode print('layer norm:', ln(X), '\nbatch norm:', bn(X)) layer norm: tensor([[-1.0000, 1.0000], [-1.0000, 1.0000]], grad_fn=<Native Layer Norm Backward0>) batch norm: tensor([[-1.0000, -1.0000], [ 1.0000, 1.0000]], grad_fn=<Native Batch Norm Backward0>) Now we can implement the Add Norm class using a residual connection followed by layer normalization.
Dropoutisalsoappliedforregularization.
444 Attention Mechanismsand Transformers class Add Norm(nn.
Module): #@save """The residual connection followed by layer normalization.""" def __init__(self, norm_shape, dropout): super().__init__() self.
dropout = nn.
Dropout(dropout) self.
ln = nn.
Layer Norm(norm_shape) def forward(self, X, Y): return self.
ln(self.
dropout(Y) + X) Theresidualconnectionrequiresthatthetwoinputsareofthesameshapesothattheoutput tensoralsohasthesameshapeaftertheadditionoperation.
add_norm = Add Norm(4, 0.5) shape = (2, 3, 4) d2l.
check_shape(add_norm(torch.
ones(shape), torch.
ones(shape)), shape) 11.7.4 Encoder Withalltheessentialcomponentstoassemblethe Transformerencoder, letâ€™sstartbyim- plementingasinglelayerwithintheencoder.
Thefollowing Transformer Encoder Block classcontainstwosublayers: multi-headself-attentionandpositionwisefeed-forwardnet- works, where a residual connection followed by layer normalization is employed around bothsublayers.
class Transformer Encoder Block(nn.
Module): #@save """The Transformer encoder block.""" def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias=False): super().__init__() self.
attention = d2l.
Multi Head Attention(num_hiddens, num_heads, dropout, use_bias) self.
addnorm1 = Add Norm(num_hiddens, dropout) self.
ffn = Position Wise FFN(ffn_num_hiddens, num_hiddens) self.
addnorm2 = Add Norm(num_hiddens, dropout) def forward(self, X, valid_lens): Y = self.
addnorm1(X, self.
attention(X, X, X, valid_lens)) return self.
addnorm2(Y, self.
ffn(Y)) Aswecansee, nolayerinthe Transformerencoderchangestheshapeofitsinput.
X = torch.
ones((2, 100, 24)) valid_lens = torch.
tensor([3, 2]) encoder_blk = Transformer Encoder Block(24, 48, 8, 0.5) encoder_blk.
eval() d2l.
check_shape(encoder_blk(X, valid_lens), X.
shape) Inthefollowing Transformerencoderimplementation, westacknum_blksinstancesofthe above Transformer Encoder Block classes.
Since we use the fixed positional encoding 445 The Transformer Architecture whosevaluesarealwaysbetween 1and1, wemultiplyvaluesofthelearnableinputem- beddingsbythesquarerootoftheembeddingdimensiontorescalebeforesummingupthe inputembeddingandthepositionalencoding.
class Transformer Encoder(d2l.
Encoder): #@save """The Transformer encoder.""" def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, use_bias=False): super().__init__() self.
num_hiddens = num_hiddens self.
embedding = nn.
Embedding(vocab_size, num_hiddens) self.
pos_encoding = d2l.
Positional Encoding(num_hiddens, dropout) self.
blks = nn.
Sequential() for i in range(num_blks): self.
blks.
add_module("block"+str(i), Transformer Encoder Block( num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias)) def forward(self, X, valid_lens): # Since positional encoding values are between -1 and 1, the embedding # values are multiplied by the square root of the embedding dimension # to rescale before they are summed up X = self.
pos_encoding(self.
embedding(X) * math.
sqrt(self.
num_hiddens)) self.
attention_weights = [None] * len(self.
blks) for i, blk in enumerate(self.
blks): X = blk(X, valid_lens) self.
attention_weights[ i] = blk.
attention.
attention.
attention_weights return X Belowwespecifyhyperparameterstocreateatwo-layer Transformerencoder.
Theshapeof the Transformerencoderoutputis(batchsize, numberoftimesteps, num_hiddens).
encoder = Transformer Encoder(200, 24, 48, 8, 2, 0.5) d2l.
check_shape(encoder(torch.
ones((2, 100), dtype=torch.
long), valid_lens), (2, 100, 24)) 11.7.5 Decoder As shown in .7.1, the Transformer decoder is composed of multiple identical lay- ers.
Eachlayerisimplementedinthefollowing Transformer Decoder Blockclass, which containsthreesublayers: decoderself-attention, encoderâ€“decoderattention, andposition- wise feed-forward networks.
These sublayers employa residual connection around them followedbylayernormalization.
As we described earlier in this section, in the masked multi-head decoder self-attention (the first sublayer), queries, keys, and values all come from the outputs of the previous decoder layer.
When training sequence-to-sequence models, tokens at all the positions (time steps) of the output sequence are known.
However, during prediction the output sequence is generated token by token; thus, at any decoder time step only the generated tokenscanbeusedinthedecoderself-attention.
Topreserveautoregressioninthedecoder, 446 Attention Mechanismsand Transformers its masked self-attention specifies dec_valid_lens so that any query only attends to all positionsinthedecoderuptothequeryposition.
class Transformer Decoder Block(nn.
Module): # The i-th block in the Transformer decoder def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i): super().__init__() self.
i = i self.
attention1 = d2l.
Multi Head Attention(num_hiddens, num_heads, dropout) self.
addnorm1 = Add Norm(num_hiddens, dropout) self.
attention2 = d2l.
Multi Head Attention(num_hiddens, num_heads, dropout) self.
addnorm2 = Add Norm(num_hiddens, dropout) self.
ffn = Position Wise FFN(ffn_num_hiddens, num_hiddens) self.
addnorm3 = Add Norm(num_hiddens, dropout) def forward(self, X, state): enc_outputs, enc_valid_lens = state[0], state[1] # During training, all the tokens of any output sequence are processed # at the same time, so state[2][self.
i] is None as initialized.
When # decoding any output sequence token by token during prediction, # state[2][self.
i] contains representations of the decoded output at # the i-th block up to the current time step if state[2][self.
i] is None: key_values = X else: key_values = torch.
cat((state[2][self.
i], X), dim=1) state[2][self.
i] = key_values if self.
training: batch_size, num_steps, _ = X.
shape # Shape of dec_valid_lens: (batch_size, num_steps), where every # row is [1, 2, ..., num_steps] dec_valid_lens = torch.
arange( 1, num_steps + 1, device=X.
device).
repeat(batch_size, 1) else: dec_valid_lens = None # Self-attention X2 = self.
attention1(X, key_values, key_values, dec_valid_lens) Y = self.
addnorm1(X, X2) # Encoder-decoder attention.
Shape of enc_outputs: # (batch_size, num_steps, num_hiddens) Y2 = self.
attention2(Y, enc_outputs, enc_outputs, enc_valid_lens) Z = self.
addnorm2(Y, Y2) return self.
addnorm3(Z, self.
ffn(Z)), state To facilitate scaled dot product operations in the encoderâ€“decoder attention and addition operationsintheresidualconnections, thefeaturedimension(num_hiddens)ofthedecoder isthesameasthatoftheencoder.
decoder_blk = Transformer Decoder Block(24, 48, 8, 0.5, 0) X = torch.
ones((2, 100, 24)) state = [encoder_blk(X, valid_lens), valid_lens, [None]] d2l.
check_shape(decoder_blk(X, state)[0], X.
shape) 447 The Transformer Architecture Now we construct the entire Transformer decoder composed of num_blks instances of Transformer Decoder Block.
Intheend, afullyconnectedlayercomputestheprediction forallthevocab_sizepossibleoutputtokens.
Bothofthedecoderself-attentionweights andtheencoderâ€“decoderattentionweightsarestoredforlatervisualization.
class Transformer Decoder(d2l.
Attention Decoder): def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout): super().__init__() self.
num_hiddens = num_hiddens self.
num_blks = num_blks self.
embedding = nn.
Embedding(vocab_size, num_hiddens) self.
pos_encoding = d2l.
Positional Encoding(num_hiddens, dropout) self.
blks = nn.
Sequential() for i in range(num_blks): self.
blks.
add_module("block"+str(i), Transformer Decoder Block( num_hiddens, ffn_num_hiddens, num_heads, dropout, i)) self.
dense = nn.
Lazy Linear(vocab_size) def init_state(self, enc_outputs, enc_valid_lens): return [enc_outputs, enc_valid_lens, [None] * self.
num_blks] def forward(self, X, state): X = self.
pos_encoding(self.
embedding(X) * math.
sqrt(self.
num_hiddens)) self._attention_weights = [[None] * len(self.
blks) for _ in range (2)] for i, blk in enumerate(self.
blks): X, state = blk(X, state) # Decoder self-attention weights self._attention_weights[0][ i] = blk.
attention1.
attention.
attention_weights # Encoder-decoder attention weights self._attention_weights[1][ i] = blk.
attention2.
attention.
attention_weights return self.
dense(X), state @property def attention_weights(self): return self._attention_weights 11.7.6 Training Letâ€™s instantiate an encoderâ€“decoder model by following the Transformer architecture.
Herewespecifythatboththe Transformerencoderandthe Transformerdecoderhavetwo layers using 4-head attention.
As in Section 10.7.6, we train the Transformer model for sequence-to-sequencelearningonthe Englishâ€“Frenchmachinetranslationdataset.
data = d2l.
MTFra Eng(batch_size=128) num_hiddens, num_blks, dropout = 256, 2, 0.2 ffn_num_hiddens, num_heads = 64, 4 encoder = Transformer Encoder( len(data.
src_vocab), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout) decoder = Transformer Decoder( (continuesonnextpage) 448 Attention Mechanismsand Transformers (continuedfrompreviouspage) len(data.
tgt_vocab), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout) model = d2l.
Seq2Seq(encoder, decoder, tgt_pad=data.
tgt_vocab['<pad>'], lr=0.001) trainer = d2l.
Trainer(max_epochs=30, gradient_clip_val=1, num_gpus=1) trainer.
fit(model, data) After training, we use the Transformer model to translate a few English sentences into Frenchandcomputetheir BLEUscores.
engs = ['go .', 'i lost .', 'he\'s calm .', 'i\'m home .'] fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .'] preds, _ = model.
predict_step( data.
build(engs, fras), d2l.
try_gpu(), data.
num_steps) for en, fr, p in zip(engs, fras, preds): translation = [] for token in data.
tgt_vocab.
to_tokens(p): if token == '<eos>': break translation.
append(token) print(f'{en} => {translation}, bleu,' f'{d2l.
bleu(" ".
join(translation), fr, k=2):.3f}') go .
=> ['va', '!'], bleu,1.000 i lost .
=> ['je', 'perdu', '.'], bleu,0.687 he's calm .
=> ['il', 'est', 'mouillÃ©', '.'], bleu,0.658 i'm home .
=> ['je', 'suis', 'chez', 'moi', '.'], bleu,1.000 Letâ€™s visualize the Transformer attention weights when translating the final English sen- tenceinto French.
Theshapeoftheencoderself-attentionweightsis(numberofencoder layers, numberofattentionheads, num_stepsornumberofqueries, num_stepsornumber ofkey-valuepairs).
_, dec_attention_weights = model.
predict_step( data.
build([engs[-1]], [fras[-1]]), d2l.
try_gpu(), data.
num_steps, True) enc_attention_weights = torch.
cat(model.
encoder.
attention_weights, 0) shape = (num_blks, num_heads, -1, data.
num_steps) enc_attention_weights = enc_attention_weights.
reshape(shape) (continuesonnextpage) 449 The Transformer Architecture (continuedfrompreviouspage) d2l.
check_shape(enc_attention_weights, (num_blks, num_heads, data.
num_steps, data.
num_steps)) In the encoder self-attention, both queries and keyscome from the same inputsequence.
Since padding tokens do not carry meaning, with specified valid length of the input se- quence no query attends to positions of padding tokens.
In the following, two layers of multi-headattentionweightsarepresentedrowbyrow.
Eachheadindependentlyattends basedonaseparaterepresentationsubspaceofqueries, keys, andvalues.
d2l.
show_heatmaps( enc_attention_weights.
cpu(), xlabel='Key positions', ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5)) Tovisualizethedecoderself-attentionweightsandtheencoderâ€“decoderattentionweights, we need more data manipulations.
For example, we fill the masked attention weights with zero.
Note that the decoder self-attention weights and the encoderâ€“decoder atten- tionweightsbothhavethesamequeries: thebeginning-of-sequencetokenfollowedbythe outputtokensandpossiblyend-of-sequencetokens.
dec_attention_weights_2d = [head[0].
tolist() for step in dec_attention_weights for attn in step for blk in attn for head in blk] dec_attention_weights_filled = torch.
tensor( pd.
Data Frame(dec_attention_weights_2d).
fillna(0.0).
values) shape = (-1, 2, num_blks, num_heads, data.
num_steps) dec_attention_weights = dec_attention_weights_filled.
reshape(shape) dec_self_attention_weights, dec_inter_attention_weights = \ dec_attention_weights.
permute(1, 2, 3, 0, 4) d2l.
check_shape(dec_self_attention_weights, (num_blks, num_heads, data.
num_steps, data.
num_steps)) d2l.
check_shape(dec_inter_attention_weights, (num_blks, num_heads, data.
num_steps, data.
num_steps)) 450 Attention Mechanismsand Transformers Because of the autoregressive property of the decoder self-attention, no query attends to keyâ€“valuepairsafterthequeryposition.
d2l.
show_heatmaps( dec_self_attention_weights[:, :, :, :], xlabel='Key positions', ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5)) Similartothecaseintheencoderself-attention, viathespecifiedvalidlengthoftheinput sequence, noqueryfromtheoutputsequenceattendstothosepaddingtokensfromtheinput sequence.
d2l.
show_heatmaps( dec_inter_attention_weights, xlabel='Key positions', ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5)) Althoughthe Transformerarchitecturewasoriginallyproposedforsequence-to-sequence learning, aswewilldiscoverlaterinthebook, eitherthe Transformerencoderorthe Trans- formerdecoderisoftenindividuallyusedfordifferentdeeplearningtasks.
11.7.7 Summary 451 Transformersfor Vision The Transformerisaninstanceoftheencoderâ€“decoderarchitecture, thougheithertheen- coder or the decoder can be used individually in practice.
In the Transformer architec- ture, multi-head self-attention is used for representing the input sequence and the output sequence, though the decoder has to preserve the autoregressive property via a masked version.
Boththeresidualconnectionsandthelayernormalizationinthe Transformerare important for training a very deep model.
The positionwise feed-forward network in the Transformer model transforms the representation at all the sequence positions using the same MLP.
11.7.8 Exercises 1.
Train a deeper Transformer in the experiments.
How does it affect the training speed andthetranslationperformance? 2.
Is it a good idea to replace scaled dot product attention with additive attention in the Transformer? Why? 3.
Forlanguagemodeling, shouldweusethe Transformerencoder, decoder, orboth? How wouldyoudesignthismethod? 4.
Whatchallengescan Transformersfaceifinputsequencesareverylong? Why? 5.
How would you improve the computational and memory efficiency of Transformers? Hint: youmayrefertothesurveypaperby Tayetal.
(2020).
Discussions162.
162 11.8 Transformers for Vision The Transformer architecture was initially proposed for sequence-to-sequence learning, with a focus on machine translation.
Subsequently, Transformers emerged as the model ofchoiceinvariousnaturallanguageprocessingtasks(Brownetal., 2020, Devlinetal., 2018, Radfordetal.,2018, Radfordetal.,2019, Raffeletal.,2020).
However, inthefieldof computervisionthedominantarchitecturehasremainedthe CNN(Chapter8).
Naturally, researchersstartedtowonderifitmightbepossibletodobetterbyadapting Transformer modelstoimagedata.
Thisquestionsparkedimmenseinterestinthecomputervisioncom- munity.
Recently, Ramachandranetal.
(2019)proposedaschemeforreplacingconvolu- tionwithself-attention.
However, itsuseofspecializedpatternsinattentionmakesithard toscaleupmodelsonhardwareaccelerators.
Then, Cordonnieretal.
(2020)theoretically provedthatself-attentioncanlearntobehavesimilarlytoconvolution.
Empirically,2 2 patchesweretakenfromimagesasinputs, butthesmallpatchsizemakesthemodelonly applicabletoimagedatawithlowresolutions.
Withoutspecificconstraintsonpatchsize, vision Transformers(Vi Ts)extractpatchesfrom imagesandfeedthemintoa Transformerencodertoobtainaglobalrepresentation, which 452 Attention Mechanismsand Transformers willfinallybetransformedforclassification(Dosovitskiyetal.,2021).
Notably, Transform- ersshowbetterscalabilitythan CNNs: andwhentraininglargermodelsonlargerdatasets, vision Transformersoutperform Res Netsbyasignificantmargin.
Similartothelandscape ofnetworkarchitecturedesigninnaturallanguageprocessing, Transformershavealsobe- comeagame-changerincomputervision.
import torch from torch import nn from d2l import torch as d2l 11.8.1 Model .8.1depictsthemodelarchitectureofvision Transformers.
Thisarchitectureconsists ofastemthatpatchifiesimages, abodybasedonthemultilayer Transformerencoder, and aheadthattransformstheglobalrepresentationintotheoutputlabel.
t Aspecialâ€œ<cls>â€tokenandthenineflattenedimagepatchesaretransformedviapatch embeddingandn Transformerencoderblocksintotenrepresentations, respectively.
The â€œ<cls>â€representationisfurthertransformedintotheoutputlabel.
Consider an input image with height â„, width ğ‘¤, and ğ‘ channels.
Specifying the patch height and width both as ğ‘, the image is split into a sequence of ğ‘š = â„ğ‘¤ ğ‘2 patches, whereeachpatchisflattenedtoavectoroflengthğ‘ğ‘2.
Inthisway, imagepatchescanbe 453 Transformersfor Vision treatedsimilarlytotokensintextsequencesby Transformerencoders.
Aspecialâ€œ<cls>â€ (class) token and the ğ‘š flattened image patches are linearly projected into a sequence of ğ‘šâ€š1vectors, summedwithlearnablepositionalembeddings.
Themultilayer Transformer encodertransformsğ‘šâ€š1inputvectorsintothesamenumberofoutputvectorrepresenta- tionsofthesamelength.
Itworksexactlythesamewayastheoriginal Transformerencoder in.7.1, onlydifferinginthepositionofnormalization.
Sincetheâ€œ<cls>â€tokenat- tends to all the image patches via self-attention (see .6.1), its representation from the Transformerencoderoutputwillbefurthertransformedintotheoutputlabel.
11.8.2 Patch Embedding Toimplementavision Transformer, letâ€™sstartwithpatchembeddingin.8.1.
Split- tinganimageintopatchesandlinearlyprojectingtheseflattenedpatchescanbesimplified asasingleconvolutionoperation, whereboththekernelsizeandthestridesizearesetto thepatchsize.
class Patch Embedding(nn.
Module): def __init__(self, img_size=96, patch_size=16, num_hiddens=512): super().__init__() def _make_tuple(x): if not isinstance(x, (list, tuple)): return (x, x) return x img_size, patch_size = _make_tuple(img_size), _make_tuple(patch_size) self.
num_patches = (img_size[0] // patch_size[0]) * ( img_size[1] // patch_size[1]) self.
conv = nn.
Lazy Conv2d(num_hiddens, kernel_size=patch_size, stride=patch_size) def forward(self, X): # Output shape: (batch size, no.
of patches, no.
of channels) return self.
conv(X).
flatten(2).
transpose(1, 2) Inthefollowingexample, takingimageswithheightandwidthof img_sizeasinputs, the patchembeddingoutputs(img_size//patch_size)**2patchesthatarelinearlyprojected tovectorsoflengthnum_hiddens.
img_size, patch_size, num_hiddens, batch_size = 96, 16, 512, 4 patch_emb = Patch Embedding(img_size, patch_size, num_hiddens) X = torch.
zeros(batch_size, 3, img_size, img_size) d2l.
check_shape(patch_emb(X), (batch_size, (img_size//patch_size)**2, num_hiddens)) 11.8.3 Vision Transformer Encoder The MLPofthevision Transformerencoderisslightlydifferentfromthepositionwise FFN oftheoriginal Transformerencoder(see Section11.7.2).
First, heretheactivationfunction usesthe Gaussianerrorlinearunit(GELU), whichcanbeconsideredasasmootherversion ofthe Re LU(Hendrycksand Gimpel,2016).
Second, dropoutisappliedtotheoutputof eachfullyconnectedlayerinthe MLPforregularization.
454 Attention Mechanismsand Transformers class Vi TMLP(nn.
Module): def __init__(self, mlp_num_hiddens, mlp_num_outputs, dropout=0.5): super().__init__() self.
dense1 = nn.
Lazy Linear(mlp_num_hiddens) self.
gelu = nn.
GELU() self.
dropout1 = nn.
Dropout(dropout) self.
dense2 = nn.
Lazy Linear(mlp_num_outputs) self.
dropout2 = nn.
Dropout(dropout) def forward(self, x): return self.
dropout2(self.
dense2(self.
dropout1(self.
gelu( self.
dense1(x))))) Thevision Transformerencoderblockimplementationjustfollowsthepre-normalization designin.8.1, wherenormalizationisappliedrightbeforemulti-headattentionor the MLP.
Incontrasttopost-normalization(â€œadd&normâ€in.7.1), wherenormal- izationisplacedrightafterresidualconnections, pre-normalizationleadstomoreeffective orefficienttrainingfor Transformers(Baevskiand Auli,2018, Wangetal.,2019, Xionget al.,2020).
class Vi TBlock(nn.
Module): def __init__(self, num_hiddens, norm_shape, mlp_num_hiddens, num_heads, dropout, use_bias=False): super().__init__() self.
ln1 = nn.
Layer Norm(norm_shape) self.
attention = d2l.
Multi Head Attention(num_hiddens, num_heads, dropout, use_bias) self.
ln2 = nn.
Layer Norm(norm_shape) self.
mlp = Vi TMLP(mlp_num_hiddens, num_hiddens, dropout) def forward(self, X, valid_lens=None): X = X + self.
attention(*([self.
ln1(X)] * 3), valid_lens) return X + self.
mlp(self.
ln2(X)) Justasin Section11.7.4, novision Transformerencoderblockchangesitsinputshape.
X = torch.
ones((2, 100, 24)) encoder_blk = Vi TBlock(24, 24, 48, 8, 0.5) encoder_blk.
eval() d2l.
check_shape(encoder_blk(X), X.
shape) 11.8.4 Putting It All Together Theforwardpassofvision Transformersbelowisstraightforward.
First, inputimagesare fedintoan Patch Embeddinginstance, whoseoutputisconcatenatedwiththeâ€œ<cls>â€token embedding.
Theyaresummedwithlearnablepositionalembeddingsbeforedropout.
Then theoutputisfedintothe Transformerencoderthatstacksnum_blksinstancesofthe Vi T- Block class.
Finally, the representation of the â€œ<cls>â€ tokenis projected by the network head.
455 Transformersfor Vision class Vi T(d2l.
Classifier): """Vision Transformer.""" def __init__(self, img_size, patch_size, num_hiddens, mlp_num_hiddens, num_heads, num_blks, emb_dropout, blk_dropout, lr=0.1, use_bias=False, num_classes=10): super().__init__() self.
save_hyperparameters() self.
patch_embedding = Patch Embedding( img_size, patch_size, num_hiddens) self.
cls_token = nn.
Parameter(torch.
zeros(1, 1, num_hiddens)) num_steps = self.
patch_embedding.
num_patches + 1 # Add the cls token # Positional embeddings are learnable self.
pos_embedding = nn.
Parameter( torch.
randn(1, num_steps, num_hiddens)) self.
dropout = nn.
Dropout(emb_dropout) self.
blks = nn.
Sequential() for i in range(num_blks): self.
blks.
add_module(f"{i}", Vi TBlock( num_hiddens, num_hiddens, mlp_num_hiddens, num_heads, blk_dropout, use_bias)) self.
head = nn.
Sequential(nn.
Layer Norm(num_hiddens), nn.
Linear(num_hiddens, num_classes)) def forward(self, X): X = self.
patch_embedding(X) X = torch.
cat((self.
cls_token.
expand(X.
shape[0], -1, -1), X), 1) X = self.
dropout(X + self.
pos_embedding) for blk in self.
blks: X = blk(X) return self.
head(X[:, 0]) 11.8.5 Training Trainingavision Transformeronthe Fashion-MNISTdatasetisjustlikehow CNNswere trainedin Chapter8.
img_size, patch_size = 96, 16 num_hiddens, mlp_num_hiddens, num_heads, num_blks = 512, 2048, 8, 2 emb_dropout, blk_dropout, lr = 0.1, 0.1, 0.1 model = Vi T(img_size, patch_size, num_hiddens, mlp_num_hiddens, num_heads, num_blks, emb_dropout, blk_dropout, lr) trainer = d2l.
Trainer(max_epochs=10, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=128, resize=(img_size, img_size)) trainer.
fit(model, data) 11.8.6 Summaryand Discussion Youmayhavenoticedthatforsmalldatasetslike Fashion-MNIST, ourimplementedvision Transformerdoesnotoutperformthe Res Netin Section8.6.
Similarobservationscanbe madeevenonthe Image Netdataset(1.2millionimages).
Thisisbecause Transformerslack thoseusefulprinciplesinconvolution, suchastranslationinvarianceandlocality(Section 7.1).
However, the picture changes when training larger models on larger datasets (e.
g., 456 Attention Mechanismsand Transformers 300 million images), where vision Transformers outperform Res Nets by a large margin in image classification, demonstrating intrinsic superiority of Transformers in scalability (Dosovitskiyetal.,2021).
Theintroductionofvision Transformershaschangedtheland- scapeofnetworkdesignformodelingimagedata.
Theyweresoonshowntobeeffectiveon the Image Netdatasetwithdata-efficienttrainingstrategiesof Dei T(Touvronetal.,2021).
However, thequadraticcomplexityofself-attention(Section11.6)makesthe Transformer architecture less suitable for higher-resolution images.
Towards a general-purpose back- bone network in computer vision, Swin Transformers addressed the quadratic computa- tionalcomplexitywithrespecttoimagesize(Section11.6.2)andreinstatedconvolution- likepriors, extendingtheapplicabilityof Transformerstoarangeofcomputervisiontasks beyondimageclassificationwithstate-of-the-artresults(Liuetal.,2021).
11.8.7 Exercises 1.
Howdoesthevalueofimg_sizeaffecttrainingtime? 2.
Instead of projecting the â€œ<cls>â€ token representation to the output, how would you projecttheaveragedpatchrepresentations? Implementthischangeandseehowitaffects theaccuracy.
3.
Canyoumodifyhyperparameterstoimprovetheaccuracyofthevision Transformer? Discussions163.
163 11.9 Large-Scale Pretraining with Transformers Sofarinourimageclassificationandmachinetranslationexperiments, modelshavebeen trainedondatasetswithinputâ€“outputexamplesfromscratchtoperformspecifictasks.
For example, a Transformerwastrainedwith Englishâ€“Frenchpairs(Section11.7)sothatthis model can translate input English text into French.
As a result, each model becomes a specificexpertthatissensitivetoevenaslightshiftindatadistribution(Section4.7).
For bettergeneralizedmodels, orevenmorecompetentgeneraliststhatcanperformmultiple tasks with or without adaptation, pretraining models on large data has been increasingly common.
457 Large-Scale Pretrainingwith Transformers Givenlargerdataforpretraining, the Transformerarchitectureperformsbetterwithanin- creasedmodelsizeandtrainingcompute, demonstratingsuperiorscalingbehavior.
Specif- ically, performanceof Transformer-basedlanguagemodelsscalesasapowerlawwiththe amountofmodelparameters, trainingtokens, andtrainingcompute(Kaplanetal.,2020).
Thescalabilityof Transformersisalsoevidencedbythesignificantlyboostedperformance fromlargervision Transformerstrainedonlargerdata(discussedin Section11.8).
More recent success stories include Gato, a generalist model that can play Atari, caption im- ages, chat, andactasarobot(Reedetal.,2022).
Gatoisasingle Transformerthatscales wellwhenpretrainedondiversemodalities, includingtext, images, jointtorques, andbut- tonpresses.
Notably, allsuchmultimodaldataisserializedintoaflatsequenceoftokens, whichcanbeprocessedakintotexttokens(Section11.7)orimagepatches(Section11.8) by Transformers.
Prior to the compelling success of pretraining Transformers for multimodal data, Trans- formerswereextensivelypretrainedwithawealthoftext.
Originallyproposedformachine translation, the Transformerarchitecturein.7.1consistsofanencoderforrepresent- inginputsequencesandadecoderforgeneratingtargetsequences.
Primarily, Transformers canbeusedinthreedifferentmodes: encoder-only, encoderâ€“decoder, anddecoder-only.
Toconcludethischapter, wewillreviewthesethreemodesandexplainthescalabilityin pretraining Transformers.
11.9.1 Encoder-Only Whenonlythe Transformerencoderisused, asequenceofinputtokensisconvertedintothe samenumberofrepresentationsthatcanbefurtherprojectedintooutput(e.
g., classifica- tion).
ATransformerencoderconsistsofself-attentionlayers, whereallinputtokensattend toeachother.
Forexample, vision Transformersdepictedin.8.1areencoder-only, convertingasequenceofinputimagepatchesintotherepresentationofaspecialâ€œ<cls>â€ token.
Since this representation depends on all input tokens, it is further projected into classificationlabels.
Thisdesignwasinspiredbyanearlierencoder-only Transformerpre- trainedontext: BERT(Bidirectional Encoder Representationsfrom Transformers)(Devlin etal.,2018).
Pretraining BERT BERT is pretrained on text sequences using masked language modeling: input text with randomlymaskedtokensisfedintoa Transformerencodertopredictthemaskedtokens.
As illustrated in .9.1, an original text sequence â€œIâ€, â€œloveâ€, â€œthisâ€, â€œredâ€, â€œcarâ€ is prepended with the â€œ<cls>â€ token, and the â€œ<mask>â€ token randomly replaces â€œloveâ€; then the cross-entropy loss between the masked token â€œloveâ€ and its prediction is to be minimized during pretraining.
Note that there is no constraint in the attention pattern of Transformer encoders (right of .9.1) so all tokens can attend to each other.
Thus, prediction of â€œloveâ€ depends on input tokens before and after it in the sequence.
This is why BERTisaâ€œbidirectionalencoderâ€.
Withoutneedformanuallabeling, large-scaletext datafrombooksand Wikipediacanbeusedforpretraining BERT.
458 Attention Mechanismsand Transformers t .9.1 Left: Pretraining BERTwithmaskedlanguagemodeling.
Predictionofthemaskedâ€œloveâ€ tokendependsonallinputtokensbeforeandafterâ€œloveâ€.
Right: Attentionpatterninthe Transformerencoder.
Eachtokenalongtheverticalaxisattendstoallinputtokensalong thehorizontalaxis.
Fine-Tuning BERT Thepretrained BERTcanbefine-tunedtodownstreamencodingtasksinvolvingsingletext ortextpairs.
Duringfine-tuning, additionallayerscanbeaddedto BERTwithrandomized parameters: theseparametersandthosepretrained BERTparameterswillbeupdatedtofit trainingdataofdownstreamtasks.
t .9.2 Fine-tuning BERTforsentimentanalysis.
.9.2illustratesfine-tuningof BERTforsentimentanalysis.
The Transformerencoder isapretrained BERT, whichtakesatextsequenceasinputandfeedstheâ€œ<cls>â€represen- tation(globalrepresentationoftheinput)intoanadditionalfullyconnectedlayertopredict the sentiment.
During fine-tuning, the cross-entropy loss between the prediction and the label on sentiment analysis data is minimized via gradient-based algorithms, where the additionallayeristrainedfromscratchwhilepretrainedparametersof BERTareupdated.
BERT does more than sentiment analysis.
The general language representations learned bythe350-million-parameter BERTfrom250billiontrainingtokensadvancedthestateof theartfornaturallanguagetaskssuchassingletextclassification, textpairclassificationor regression, texttagging, andquestionanswering.
Youmaynotethatthesedownstreamtasksincludetextpairunderstanding.
BERTpretrain- ing has another loss for predicting whether one sentence immediately follows the other.
However, thislosswaslaterfoundtobelessusefulwhenpretraining Ro BERTa, a BERT variant of the same size, on 2000 billion tokens (Liu et al., 2019).
Other derivatives of 459 Large-Scale Pretrainingwith Transformers BERTimprovedmodelarchitecturesorpretrainingobjectives, suchas ALBERT(enforc- ingparametersharing)(Lanetal.,2019), Span BERT(representingandpredictingspansof text)(Joshietal.,2020), Distil BERT(lightweightviaknowledgedistillation)(Sanhetal., 2019), and ELECTRA(replacedtokendetection)(Clarketal.,2020).
Moreover, BERTin- spired Transformerpretrainingincomputervision, suchaswithvision Transformers(Doso- vitskiyetal.,2021), Swin Transformers(Liuetal.,2021), and MAE(maskedautoencoders) (Heetal.,2022).
11.9.2 Encoderâ€“Decoder Since a Transformer encoder converts a sequence of input tokens into the same number ofoutputrepresentations, theencoder-onlymodecannotgenerateasequenceofarbitrary lengthasinmachinetranslation.
Asoriginallyproposedformachinetranslation, the Trans- former architecture can be outfitted with a decoder that autoregressively predicts the tar- getsequenceofarbitrarylength, tokenbytoken, conditionalonbothencoderoutputand decoder output: (i) for conditioning on encoder output, encoderâ€“decoder cross-attention (multi-headattentionofdecoderin.7.1)allowstargettokenstoattendtoallinput tokens;(ii)conditioningondecoderoutputisachievedbyaso-calledcausalattention(this nameiscommonintheliteraturebutismisleadingasithaslittleconnectiontotheproper studyofcausality)pattern(maskedmulti-headattentionofdecoderin.7.1), where anytargettokencanonlyattendtopastandpresenttokensinthetargetsequence.
Topretrainencoderâ€“decoder Transformersbeyondhuman-labeledmachinetranslationdata, BART (Lewis et al., 2019) and T5 (Raffel et al., 2020) are two concurrently proposed encoderâ€“decoder Transformerspretrainedonlarge-scaletextcorpora.
Bothattempttore- constructoriginaltextintheirpretrainingobjectives, whiletheformeremphasizesnoising input(e.
g., masking, deletion, permutation, androtation)andthelatterhighlightsmultitask unificationwithcomprehensiveablationstudies.
Pretraining T5 Asanexampleofthepretrained Transformerencoderâ€“decoder, T5(Text-to-Text Transfer Transformer)unifiesmanytasksasthesametext-to-textproblem: foranytask, theinput oftheencoderisataskdescription(e.
g.,â€œSummarizeâ€,â€œ:â€) followedbytaskinput(e.
g., a sequence of tokens from an article), and the decoder predicts the task output (e.
g., a sequenceoftokenssummarizingtheinputarticle).
Toperformastext-to-text, T5istrained togeneratesometargettextconditionaloninputtext.
To obtain input and output from any original text, T5 is pretrained to predict consecu- tive spans.
Specifically, tokens from text are randomly replaced by special tokens where eachconsecutivespanisreplacedbythesamespecialtoken.
Considertheexamplein.9.3, where the original text is â€œIâ€, â€œloveâ€, â€œthisâ€, â€œredâ€, â€œcarâ€.
Tokens â€œloveâ€, â€œredâ€, â€œcarâ€ are randomly replaced by special tokens.
Since â€œredâ€ and â€œcarâ€ are a consecutive span, theyarereplacedbythesamespecialtoken.
Asaresult, theinputsequenceisâ€œIâ€, â€œ<X>â€, â€œthisâ€, â€œ<Y>â€, and the target sequence is â€œ<X>â€, â€œloveâ€, â€œ<Y>â€, â€œredâ€, â€œcarâ€, â€œ<Z>â€, whereâ€œ<Z>â€isanotherspecialtokenmarkingtheend.
Asshownin.9.3, 460 Attention Mechanismsand Transformers t .9.3 Left: Pretraining T5bypredictingconsecutivespans.
Theoriginalsentenceisâ€œIâ€,â€œloveâ€, â€œthisâ€,â€œredâ€,â€œcarâ€, whereâ€œloveâ€isreplacedbyaspecialâ€œ<X>â€token, andconsecutive â€œredâ€,â€œcarâ€arereplacedbyaspecialâ€œ<Y>â€token.
Thetargetsequenceendswitha specialâ€œ<Z>â€token.
Right: Attentionpatterninthe Transformerencoderâ€“decoder.
Inthe encoderself-attention(lowersquare), allinputtokensattendtoeachother; Inthe encoderâ€“decodercross-attention(upperrectangle), eachtargettokenattendstoallinput tokens; Inthedecoderself-attention(uppertriangle), eachtargettokenattendstopresent andpasttargettokensonly(causal).
thedecoderhasacausalattentionpatterntopreventitselffromattendingtofuturetokens duringsequenceprediction.
In T5, predicting consecutive span is also referred to as reconstructing corrupted text.
Withthisobjective, T5ispretrainedwith1000billiontokensfromthe C4(Colossal Clean Crawled Corpus) data, which consists of clean English text from the web (Raffel et al., 2020).
Fine-Tuning T5 Similarto BERT, T5needstobefine-tuned(updating T5parameters)ontask-specifictrain- ing data to perform this task.
Major differences from BERT fine-tuning include: (i) T5 inputincludestaskdescriptions;(ii)T5cangeneratesequenceswitharbitrarylengthwith its Transformerdecoder;(iii)Noadditionallayersarerequired.
.9.4explainsfine-tuning T5usingtextsummarizationasanexample.
Inthisdown- stream task, the task description tokens â€œSummarizeâ€, â€œ:â€ followed by the article tokens areinputtotheencoder.
Afterfine-tuning, the11-billion-parameter T5(T5-11B)achievedstate-of-the-artresultson Sincereleased, T5hasbeenextensivelyusedinlaterresearch.
Forexample, switch Trans- formersaredesignedbasedon T5toactivateasubsetoftheparametersforbettercomputa- tionalefficiency(Fedusetal.,2022).
Inatext-to-imagemodelcalled Imagen, textisinput toafrozen T5encoder(T5-XXL)with4.6billionparameters(Sahariaetal.,2022).
The 461 Large-Scale Pretrainingwith Transformers t .9.4 Fine-tuning T5fortextsummarization.
Boththetaskdescriptionandarticletokensare fedintothe Transformerencoderforpredictingthesummary.
photorealistictext-to-imageexamplesin.9.5suggestthatthe T5encoderalonemay effectivelyrepresenttextevenwithoutfine-tuning.
t .9.5 Text-to-imageexamplesbythe Imagenmodel, whosetextencoderisfrom T5(figures takenfrom Sahariaetal.
(2022)).
11.9.3 Decoder-Only Wehavereviewedencoder-onlyandencoderâ€“decoder Transformers.
Alternatively, decoder- only Transformersremovetheentireencoderandthedecodersublayerwiththeencoderâ€“ decoder cross-attention from the original encoderâ€“decoder architecture depicted in .7.1.
Nowadays, decoder-only Transformershavebeenthedefactoarchitectureinlarge- scalelanguagemodeling(Section9.3), whichleveragestheworldâ€™sabundantunlabeledtext corporaviaself-supervisedlearning.
GPTand GPT-2 Usinglanguagemodelingasthetrainingobjective, the GPT(generativepre-training)model choosesa Transformerdecoderasitsbackbone(Radfordetal.,2018).
Following the autoregressive language model training as described in Section 9.3.3, .9.6illustrates GPTpretrainingwitha Transformerencoder, wherethetargetsequenceis theinputsequenceshiftedbyonetoken.
Notethattheattentionpatterninthe Transformer 462 Attention Mechanismsand Transformers t .9.6 Left: Pretraining GPTwithlanguagemodeling.
Thetargetsequenceistheinputsequence shiftedbyonetoken.
Bothâ€œ<bos>â€andâ€œ<eos>â€arespecialtokensmarkingthe beginningandendofsequences, respectively.
Right: Attentionpatterninthe Transformer decoder.
Eachtokenalongtheverticalaxisattendstoonlyitspasttokensalongthe horizontalaxis(causal).
decoderenforcesthateachtokencanonlyattendtoitspasttokens(futuretokenscannotbe attendedtobecausetheyhavenotyetbeenchosen).
GPT has 100 million parameters and needs to be fine-tuned for individual downstream tasks.
A much larger Transformer-decoder language model, GPT-2, was introduced one yearlater(Radfordetal.,2019).
Comparedwiththeoriginal Transformerdecoderin GPT, pre-normalization (discussed in Section 11.8.3) and improved initialization and weight- scalingwereadoptedin GPT-2.
Pretrainedon40GBoftext, the1.5-billion-parameter GPT- 2 obtained the state-of-the-art results on language modeling benchmarks and promising resultsonmultipleothertaskswithoutupdatingtheparametersorarchitecture.
GPT-3and Beyond GPT-2demonstratedpotentialofusingthesamelanguagemodelformultipletaskswithout updatingthemodel.
Thisismorecomputationallyefficientthanfine-tuning, whichrequires modelupdatesviagradientcomputation.
Beforeexplainingthemorecomputationallyefficientuseoflanguagemodelswithoutpa- rameterupdate, recall Section9.5thatalanguagemodelcanbetrainedtogenerateatext sequenceconditionalonsomeprefixtextsequence.
Thus, apretrainedlanguagemodelmay generatethetaskoutputasasequencewithoutparameterupdate, conditionalonaninput sequencewiththetaskdescription, task-specificinputâ€“outputexamples, andaprompt(task input).
This learning paradigm is called in-context learning (Brown et al., 2020), which can be further categorized into zero-shot, one-shot, and few-shot, when there is no, one, andafewtask-specificinputâ€“outputexamples(.9.7).
Thesethreesettingsweretestedin GPT-3(Brownetal.,2020), whoselargestversionuses data and model size about two orders of magnitude larger than those in GPT-2.
GPT-3 usesthesame Transformerdecoderarchitectureasitsdirectpredecessor GPT-2exceptthat attentionpatterns(attherightin .9.6)aresparseratalternatinglayers.
Pretrained 463 Large-Scale Pretrainingwith Transformers t .9.7 Zero-shot, one-shot, few-shotin-contextlearningwithlanguagemodels(Transformer decoders).
Noparameterupdateisneeded.
t .9.8 Aggregateperformanceof GPT-3forall42accuracy-denominatedbenchmarks(caption adaptedandfiguretakenfrom Brownetal.
(2020)).
with 300 billion tokens, GPT-3 performs better with larger model size, where few-shot performanceincreasesmostrapidly(.9.8).
Thesubsequent GPT-4modeldidnotfullydisclosetechnicaldetailsinitsreport(Open AI, 2023).
By contrast with its predecessors, GPT-4 is a large-scale, multimodal model that cantakebothtextandimagesasinputandgeneratetextoutput.
11.9.4 Scalability .9.8 empirically demonstrates scalability of Transformers in the GPT-3 language model.
Forlanguagemodeling, morecomprehensiveempiricalstudiesonthescalability 464 Attention Mechanismsand Transformers of Transformers have led researchers to see promise in training larger Transformers with moredataandcompute(Kaplanetal.,2020).
t .9.9 Transformerlanguagemodelperformanceimprovessmoothlyasweincreasethemodel size, datasetsize, andamountofcomputeusedfortraining.
Foroptimalperformanceall threefactorsmustbescaledupintandem.
Empiricalperformancehasapower-law relationshipwitheachindividualfactorwhennotbottleneckedbytheothertwo(caption adaptedandfiguretakenfrom Kaplanetal.
(2020)).
Asshownin.9.9, power-lawscalingcanbeobservedintheperformancewithre- specttothemodelsize(numberofparameters, excludingembeddinglayers), datasetsize (numberoftrainingtokens), andamountoftrainingcompute(Peta FLOP/s-days, excluding embeddinglayers).
Ingeneral, increasingallthesethreefactorsintandemleadstobetter performance.
However, how to increase them in tandem still remains a matter of debate (Hoffmannetal.,2022).
t As well as increased performance, large models also enjoy better sample efficiency than small models.
.9.10 shows that large models need fewer training samples (tokens processed) to perform at the same level achieved by small models, and performance is scaledsmoothlywithcompute.
The empirical scaling behaviors in Kaplan et al.
(2020) have been tested in subsequent large Transformermodels.
Forexample, GPT-3supportedthishypothesiswithtwomore ordersofmagnitudein.9.11.
465 Large-Scale Pretrainingwith Transformers t .9.11 GPT-3performance(cross-entropyvalidationloss)followsapower-lawtrendwiththe amountofcomputeusedfortraining.
Thepower-lawbehaviorobservedin Kaplanetal.
(2020)continuesforanadditionaltwoordersofmagnitudewithonlysmalldeviations fromthepredictedcurve.
Embeddingparametersareexcludedfromcomputeand parametercounts(captionadaptedandfiguretakenfrom Brownetal.
(2020)).
11.9.5 Large Language Models Thescalabilityof Transformersinthe GPTserieshasinspiredsubsequentlargelanguage models.
The GPT-2Transformerdecoderwasusedfortrainingthe530-billion-parameter Megatron-Turing NLG (Smith et al., 2022) with 270 billion training tokens.
Following the GPT-2design, the280-billion-parameter Gopher(Raeetal.,2021)pretrainedwith300 billiontokens, performedcompetitivelyacrossdiversetasks.
Inheritingthesamearchitec- ture and using the same compute budget of Gopher, Chinchilla (Hoffmann et al., 2022) is a substantially smaller (70 billion parameters) model that trains for much longer (1.4 trilliontrainingtokens), outperforming Gopheronmanytasksandwithmoreemphasison the number of tokens than on the number of parameters.
To continue the scaling line of language modeling, Pa LM (Pathway Language Model) (Chowdhery et al., 2022), a 540- billion-parameter Transformerdecoderwithmodifieddesignspretrainedon780billionto- kens, outperformedaveragehumanperformanceonthe BIG-Benchbenchmark(Srivastava etal.,2022).
Itslaterversion, Pa LM2(Aniletal.,2023), scaleddataandmodelroughly1:1 andimprovedmultilingualandreasoningcapabilities.
Otherlargelanguagemodels, such as Minerva (Lewkowycz et al., 2022) that further trains a generalist (Pa LM) and Galac- tica (Taylor et al., 2022) that is not trained on a general corpus, have shown promising quantitativeandscientificreasoningcapabilities.
Open-sourcedreleases, suchas OPT(Open Pretrained Transformers)(Zhangetal.,2022), BLOOM(Scaoetal., 2022), and FALCON(Penedoetal., 2023), democratizedresearch anduseoflargelanguagemodels.
Focusingoncomputationalefficiencyatinferencetime, the open-sourced Llama 1 (Touvron et al., 2023a) outperformed much larger models by trainingonmoretokensthanhadbeentypicallyused.
Theupdated Llama2(Touvronet al.,2023b)furtherincreasedthepretrainingcorpusby40%, leadingtoproductmodelsthat maymatchtheperformanceofcompetitiveclose-sourcedmodels.
466 Attention Mechanismsand Transformers Weietal.
(2022)discussedemergentabilitiesoflargelanguagemodelsthatarepresentin largermodels, butnotinsmallermodels.
However, simplyincreasingmodelsizedoesnot inherently make models follow human instructions better.
Sanh et al.
(2021), Wei et al.
(2021)havefoundthatfine-tuninglargelanguagemodelsonarangeofdatasetsdescribed viainstructionscanimprovezero-shotperformanceonheld-outtasks.
Usingreinforcement learningfromhumanfeedback, Ouyangetal.
(2022)fine-tuned GPT-3tofollowadiverse setofinstructions.
Followingtheresultant Instruct GPTwhichalignslanguagemodelswith humanintentviafine-tuning(Ouyangetal.,2022), Chat GPT164 cangeneratehuman-like 164 responses(e.
g., codedebuggingandcreativewriting)basedonconversationswithhumans andcanperformmanynaturallanguageprocessingtaskszero-shot(Qinetal.,2023).
Baiet al.
(2022)replacedhumaninputs(e.
g., human-labeleddata)withmodeloutputstopartially automate the instruction tuning process, which is also known as reinforcement learning from AIfeedback.
Largelanguagemodelsofferanexcitingprospectofformulatingtextinputtoinducemodels toperformdesiredtasksviain-contextlearning, whichisalsoknownasprompting.
No- tably, chain-of-thought prompting (Wei et al., 2022), an in-context learning method with few-shotâ€œquestion, intermediatereasoningsteps, answerâ€demonstrations, elicitsthecom- plexreasoningcapabilitiesoflargelanguagemodelsinordertosolvemathematical, com- monsense, andsymbolicreasoningtasks.
Samplingmultiplereasoningpaths(Wangetal., 2023), diversifying few-shot demonstrations (Zhang et al., 2023), and reducing complex problemstosub-problems(Zhouetal.,2023)canallimprovethereasoningaccuracy.
In fact, withsimplepromptslikeâ€œLetâ€™sthinkstepbystepâ€justbeforeeachanswer, largelan- guagemodelscanevenperformzero-shotchain-of-thoughtreasoningwithdecentaccuracy (Kojimaetal.,2022).
Evenformultimodalinputsconsistingofbothtextandimages, lan- guage models can perform multimodal chain-of-thought reasoning with higher accuracy thanusingtextinputonly(Zhangetal.,2023).
11.9.6 Summaryand Discussion Transformers have been pretrained as encoder-only (e.
g., BERT), encoderâ€“decoder (e.
g., T5), and decoder-only (e.
g., GPT series).
Pretrained models may be adapted to perform Transformerssuggeststhatbetterperformancebenefitsfromlargermodels, moretraining data, and more training compute.
Since Transformers were first designed and pretrained fortextdata, thissectionleansslightlytowardsnaturallanguageprocessing.
Nonetheless, those models discussed above can be often found in more recent models across multiple modalities.
For example, (i) Chinchilla (Hoffmann et al., 2022) was further extended to Flamingo(Alayracetal.,2022), avisuallanguagemodelforfew-shotlearning;(ii)GPT-2 (Radfordetal., 2019)andthevision Transformerencodetextandimagesin CLIP(Con- trastive Language-Image Pre-training) (Radford et al., 2021), whose image and text em- beddingswerelateradoptedinthe DALL-E2text-to-imagesystem(Rameshetal.,2022).
Althoughtherehavebeennosystematicstudieson Transformerscalabilityinmultimodal pretrainingyet, anall-Transformertext-to-imagemodelcalled Parti(Yuetal.,2022)shows potential of scalability across modalities: a larger Parti is more capable of high-fidelity imagegenerationandcontent-richtextunderstanding(.9.12).
467 Large-Scale Pretrainingwith Transformers t .9.12 Imageexamplesgeneratedfromthesametextbythe Partimodelofincreasingsizes (350M,750M,3B,20B)(examplestakenfrom Yuetal.
(2022)).
11.9.7 Exercises 1.
Is it possible to fine-tune T5 using a minibatch consisting of different tasks? Why or whynot? Howaboutfor GPT-2? 2.
Givenapowerfullanguagemodel, whatapplicationscanyouthinkof? 3.
Saythatyouareaskedtofine-tunealanguagemodeltoperformtextclassificationby addingadditionallayers.
Wherewillyouaddthem? Why? 4.
Consider sequence-to-sequence problems (e.
g., machine translation) where the input sequenceisalwaysavailablethroughoutthetargetsequenceprediction.
Whatcouldbe limitationsofmodelingwithdecoder-only Transformers? Why? Discussions165.
165 12 Optimization Algorithms Ifyoureadthebookinsequenceuptothispointyoualreadyusedanumberofoptimization algorithmstotraindeeplearningmodels.
Theywerethetoolsthatallowedustocontinue updatingmodelparametersandtominimizethevalueofthelossfunction, asevaluatedon thetrainingset.
Indeed, anyonecontentwith treatingoptimizationasablackboxdevice to minimize objective functions in a simple setting might well content oneself with the knowledgethatthereexistsanarrayofincantationsofsuchaprocedure(withnamessuch asâ€œSGDâ€andâ€œAdamâ€).
To do well, however, some deeper knowledge is required.
Optimization algorithms are importantfordeeplearning.
Ontheonehand, trainingacomplexdeeplearningmodelcan takehours, days, orevenweeks.
Theperformanceoftheoptimizationalgorithmdirectly affects the modelâ€™s training efficiency.
On the other hand, understanding the principles ofdifferentoptimizationalgorithmsandtheroleoftheirhyperparameterswillenableusto tunethehyperparametersinatargetedmannertoimprovetheperformanceofdeeplearning models.
Inthischapter, weexplorecommondeeplearningoptimizationalgorithmsindepth.
Al- mostalloptimizationproblemsarisingindeeplearningarenonconvex.
Nonetheless, the designandanalysisofalgorithmsinthecontextofconvexproblemshaveproventobevery instructive.
Itisforthatreasonthatthischapterincludesaprimeronconvexoptimization andtheproofforaverysimplestochasticgradientdescentalgorithmonaconvexobjective function.
12.1 Optimization and Deep Learning Inthissection, wewilldiscusstherelationshipbetweenoptimizationanddeeplearningas wellasthechallengesofusingoptimizationindeeplearning.
Foradeeplearningproblem, wewillusuallydefinealossfunctionfirst.
Oncewehavethelossfunction, wecanusean optimizationalgorithminattempttominimizetheloss.
Inoptimization, alossfunctionis oftenreferredtoastheobjectivefunctionoftheoptimizationproblem.
Bytraditionandcon- ventionmostoptimizationalgorithmsareconcernedwithminimization.
Ifweeverneedto maximizeanobjectivethereisasimplesolution: justflipthesignontheobjective.
468 469 Optimizationand Deep Learning 12.1.1 Goalof Optimization Although optimization provides a way to minimize the loss function for deep learning, inessence, thegoalsof optimizationanddeeplearning arefundamentallydifferent.
The formerisprimarilyconcernedwithminimizinganobjectivewhereasthelatterisconcerned withfindingasuitablemodel, givenafiniteamountofdata.
In Section3.6, wediscussedthe differencebetweenthesetwogoalsindetail.
Forinstance, trainingerrorandgeneralization errorgenerallydiffer: sincetheobjectivefunctionoftheoptimizationalgorithmisusuallya lossfunctionbasedonthetrainingdataset, thegoalofoptimizationistoreducethetraining error.
However, thegoalofdeeplearning(ormorebroadly, statisticalinference)istoreduce thegeneralizationerror.
Toaccomplishthelatterweneedtopayattentiontooverfittingin additiontousingtheoptimizationalgorithmtoreducethetrainingerror.
%matplotlib inline import numpy as np import torch from mpl_toolkits import mplot3d from d2l import torch as d2l To illustrate the aforementioned different goals, letâ€™s consider the empirical risk and the risk.
As described in Section 4.7.3, the empirical risk is an average loss on the training datasetwhiletheriskistheexpectedlossontheentirepopulationofdata.
Belowwedefine twofunctions: theriskfunctionfandtheempiricalriskfunctiong.
Supposethatwehave onlyafiniteamountoftrainingdata.
Asaresult, heregislesssmooththanf.
def f(x): return x * torch.
cos(np.
pi * x) def g(x): return f(x) + 0.2 * torch.
cos(5 * np.
pi * x) The graph below illustrates that the minimum of the empirical risk on a training dataset maybeatadifferentlocationfromtheminimumoftherisk(generalizationerror).
def annotate(text, xy, xytext): #@save d2l.
plt.
gca().
annotate(text, xy=xy, xytext=xytext, arrowprops=dict(arrowstyle='->')) x = torch.
arange(0.5, 1.5, 0.01) d2l.
set_figsize((4.5, 2.5)) d2l.
plot(x, [f(x), g(x)], 'x', 'risk') annotate('min of\nempirical risk', (1.0, -1.2), (0.5, -1.1)) annotate('min of risk', (1.1, -1.05), (0.95, -0.5)) 12.1.2 Optimization Challengesin Deep Learning Inthischapter, wearegoingtofocusspecificallyontheperformanceofoptimizationalgo- rithmsinminimizingtheobjectivefunction, ratherthanamodelâ€™sgeneralizationerror.
In Section3.1wedistinguishedbetweenanalyticalsolutionsandnumericalsolutionsinopti- 470 Optimization Algorithms mizationproblems.
Indeeplearning, mostobjectivefunctionsarecomplicatedanddonot have analytical solutions.
Instead, we must use numerical optimization algorithms.
The optimizationalgorithmsinthischapterallfallintothiscategory.
Therearemanychallengesindeeplearningoptimization.
Someofthemostvexingones arelocalminima, saddlepoints, andvanishinggradients.
Letâ€™shavealookatthem.
Local Minima Foranyobjectivefunction ğ‘“â€ğ‘¥â€, ifthevalueof ğ‘“â€ğ‘¥â€atğ‘¥issmallerthanthevaluesof ğ‘“â€ğ‘¥â€ atanyotherpointsinthevicinityofğ‘¥, then ğ‘“â€ğ‘¥â€ couldbealocalminimum.
Ifthevalue of ğ‘“â€ğ‘¥â€ atğ‘¥ istheminimumoftheobjectivefunctionovertheentiredomain, then ğ‘“â€ğ‘¥â€ is theglobalminimum.
Forexample, giventhefunction ğ‘“â€ğ‘¥â€ =ğ‘¥ cosâ€ğœ‹ğ‘¥â€for 1.0 ğ‘¥ 2.0, (12.1.1) wecanapproximatethelocalminimumandglobalminimumofthisfunction.
x = torch.
arange(-1.0, 2.0, 0.01) d2l.
plot(x, [f(x), ], 'x', 'f(x)') annotate('local minimum', (-0.3, -0.25), (-0.77, -1.0)) annotate('global minimum', (1.1, -0.95), (0.6, 0.8)) Theobjectivefunctionofdeeplearningmodelsusuallyhasmanylocaloptima.
Whenthe numerical solution of an optimization problem is near the local optimum, the numerical 471 Optimizationand Deep Learning solutionobtainedbythefinaliterationmayonlyminimizetheobjectivefunctionlocally, rather than globally, as the gradient of the objective functionâ€™s solutions approaches or becomes zero.
Only some degree of noise might knock the parameter out of the local minimum.
Infact, thisisoneofthebeneficialpropertiesofminibatchstochasticgradient descent where the natural variation of gradients over minibatches is able to dislodge the parametersfromlocalminima.
Saddle Points Besideslocalminima, saddlepointsareanotherreasonforgradientstovanish.
Asaddle pointisanylocationwhereallgradientsofafunctionvanishbutwhichisneitheraglobal noralocalminimum.
Considerthefunction ğ‘“â€ğ‘¥â€ =ğ‘¥3.
Itsfirstandsecondderivativevan- ishforğ‘¥ =0.
Optimizationmightstallatthispoint, eventhoughitisnotaminimum.
x = torch.
arange(-2.0, 2.0, 0.01) d2l.
plot(x, [x**3], 'x', 'f(x)') annotate('saddle point', (0, -0.2), (-0.52, -5.0)) Saddlepointsinhigherdimensionsareevenmoreinsidious, astheexamplebelowshows.
Considerthefunction ğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘¥2 ğ‘¦2.
Ithasitssaddlepointatâ€0,0â€.
Thisisamaximum withrespecttoğ‘¦andaminimumwithrespecttoğ‘¥.
Moreover, itlookslikeasaddle, which iswherethismathematicalpropertygotitsname.
x, y = torch.
meshgrid( z = x**2 - y**2 ax = d2l.
plt.
figure().
add_subplot(111, projection='3d') ax.
plot_wireframe(x, y, z, **{'rstride': 10, 'cstride': 10}) ax.
plot([0], [0], [0], 'rx') ticks = [-1, 0, 1] d2l.
plt.
xticks(ticks) d2l.
plt.
yticks(ticks) ax.
set_zticks(ticks) d2l.
plt.
xlabel('x') d2l.
plt.
ylabel('y'); Weassumethattheinputofafunctionisağ‘˜-dimensionalvectoranditsoutputisascalar, 472 Optimization Algorithms soits Hessianmatrixwillhaveğ‘˜ eigenvalues.
Thesolutionofthefunctioncouldbealocal minimum, alocalmaximum, orasaddlepointatapositionwherethefunctiongradientis zero: Whentheeigenvaluesofthefunctionâ€™s Hessianmatrixatthezero-gradientpositionare allpositive, wehavealocalminimumforthefunction.
Whentheeigenvaluesofthefunctionâ€™s Hessianmatrixatthezero-gradientpositionare allnegative, wehavealocalmaximumforthefunction.
Whentheeigenvaluesofthefunctionâ€™s Hessianmatrixatthezero-gradientpositionare negativeandpositive, wehaveasaddlepointforthefunction.
Forhigh-dimensionalproblemsthelikelihoodthatatleastsomeoftheeigenvaluesareneg- ativeisquitehigh.
Thismakessaddlepointsmorelikelythanlocalminima.
Wewilldiscuss someexceptionstothissituationinthenextsectionwhenintroducingconvexity.
Inshort, convexfunctionsarethosewheretheeigenvaluesofthe Hessianarenevernegative.
Sadly, though, mostdeeplearningproblemsdonotfallintothiscategory.
Nonethelessitisagreat tooltostudyoptimizationalgorithms.
Vanishing Gradients Probably the most insidious problem to encounter is the vanishing gradient.
Recall our commonly-used activation functions and their derivatives in Section 5.1.2.
For instance, assumethatwewanttominimizethefunction ğ‘“â€ğ‘¥â€ =tanhâ€ğ‘¥â€andwehappentogetstarted at ğ‘¥ = 4.
As we can see, the gradient of ğ‘“ is close to nil.
More specifically, ğ‘“0â€ğ‘¥â€ = 1 tanh2â€ğ‘¥â€ and thus ğ‘“0â€4â€ = 0.0013.
Consequently, optimization will get stuck for a longtimebeforewemakeprogress.
Thisturnsouttobeoneofthereasonsthattraining deep learning models was quite tricky prior to the introduction of the Re LU activation function.
x = torch.
arange(-2.0, 5.0, 0.01) d2l.
plot(x, [torch.
tanh(x)], 'x', 'f(x)') annotate('vanishing gradient', (4, 1), (2, 0.0)) Aswesaw, optimizationfordeeplearningisfullofchallenges.
Fortunatelythereexistsa robust rangeof algorithms that perform welland that are easy to use evenforbeginners.
473 Optimizationand Deep Learning Furthermore, itisnotreallynecessarytofindthebestsolution.
Localoptimaorevenap- proximatesolutionsthereofarestillveryuseful.
12.1.3 Summary Minimizingthetrainingerrordoesnotguaranteethatwefindthebestsetofparameters tominimizethegeneralizationerror.
Theoptimizationproblemsmayhavemanylocalminima.
Theproblemmayhaveevenmoresaddlepoints, asgenerallytheproblemsarenotconvex.
Vanishing gradients can cause optimization to stall.
Often a reparametrization of the problemhelps.
Goodinitializationoftheparameterscanbebeneficial, too.
12.1.4 Exercises 1.
Consider a simple MLP with a single hidden layer of, say, ğ‘‘ dimensions in the hid- den layer and a single output.
Show that for any local minimum there are at least ğ‘‘! equivalentsolutionsthatbehaveidentically.
2.
Assumethatwehaveasymmetricrandommatrix Mwheretheentries ğ‘€ ğ‘–ğ‘— = ğ‘€ ğ‘—ğ‘– are eachdrawnfromsomeprobabilitydistribution ğ‘ ğ‘–ğ‘—.
Furthermoreassumethat ğ‘ ğ‘–ğ‘— â€ğ‘¥â€ = ğ‘ ğ‘–ğ‘— 1.
Provethatthedistributionovereigenvaluesisalsosymmetric.
Thatis, foranyeigen- vectorvtheprobabilitythattheassociatedeigenvalueğœ†satisfiesğ‘ƒâ€ğœ† >0â€ = ğ‘ƒâ€ğœ† < 0â€.
2.
Whydoestheabovenotimplyğ‘ƒâ€ğœ† >0â€ =0.5? 3.
Whatotherchallengesinvolvedindeeplearningoptimizationcanyouthinkof? 4.
Assumethatyouwanttobalancea(real)ballona(real)saddle.
1.
Whyisthishard? 166 2.
Canyouexploitthiseffectalsoforoptimizationalgorithms? Discussions166.
474 Optimization Algorithms 12.2 Convexity Convexityplaysavitalroleinthedesignofoptimizationalgorithms.
Thisislargelydue tothefactthatitismucheasiertoanalyzeandtestalgorithmsinsuchacontext.
Inother words, ifthealgorithmperformspoorlyevenintheconvexsetting, typicallyweshouldnot hopetoseegreatresultsotherwise.
Furthermore, eventhoughtheoptimizationproblemsin deeplearningaregenerallynonconvex, theyoftenexhibitsomepropertiesofconvexones nearlocalminima.
Thiscanleadtoexcitingnewoptimizationvariantssuchas(Izmailov etal.,2018).
%matplotlib inline import numpy as np import torch from mpl_toolkits import mplot3d from d2l import torch as d2l 12.2.1 Definitions Beforeconvexanalysis, weneedtodefineconvexsetsandconvexfunctions.
Theyleadto mathematicaltoolsthatarecommonlyappliedtomachinelearning.
Convex Sets Setsarethebasisofconvexity.
Simplyput, aset X inavectorspaceisconvexifforany ğ‘,ğ‘ 2 X the line segment connecting ğ‘ and ğ‘ is also in X.
In mathematical terms this meansthatforallğœ† 2 Â»0,1â€¦ wehave ğœ†ğ‘â€šâ€1 ğœ†â€ğ‘ 2Xwheneverğ‘,ğ‘ 2X.
(12.2.1) linesegmentsthatarenotcontainedinit.
Theothertwosetssuffernosuchproblem.
t .2.1 Thefirstsetisnonconvexandtheothertwoareconvex.
Definitionsontheirownarenotparticularlyusefulunlessyoucandosomethingwiththem.
Inthiscasewecanlookatintersectionsasshownin.2.2.
Assumethat Xand Yare convexsets.
Then X\Y isalsoconvex.
Toseethis, consideranyğ‘,ğ‘ 2X\Y.
Since X and Y areconvex, thelinesegmentsconnecting ğ‘ and ğ‘ arecontainedinboth X and Y.
Giventhat, theyalsoneedtobecontainedin X\Y, thusprovingourtheorem.
475 Convexity t .2.2 Theintersectionbetweentwoconvexsetsisconvex.
Wecanstrengthenthisresultwithlittleeffort: givenconvexsets X ğ‘–, theirintersection\ ğ‘– X ğ‘– isconvex.
Toseethattheconverseisnottrue, considertwodisjointsets X\Y = ;.
Now pickğ‘ 2Xandğ‘ 2Y.
Thelinesegmentin.2.3connectingğ‘andğ‘needstocontain somepartthatisneitherin Xnorin Y, sinceweassumedthat X\Y = ;.
Hencetheline segmentisnotin X[Yeither, thusprovingthatingeneralunionsofconvexsetsneednot beconvex.
t .2.3 Theunionoftwoconvexsetsneednotbeconvex.
Typicallytheproblemsindeeplearningaredefinedonconvexsets.
Forinstance, Rğ‘‘ , the setofğ‘‘-dimensionalvectorsofrealnumbers, isaconvexset(afterall, thelinebetweenany twopointsin Rğ‘‘ remainsin Rğ‘‘ ).
Insomecasesweworkwithvariablesofboundedlength, suchasballsofradiusğ‘Ÿ asdefinedbyfxjx2Rğ‘‘ andkxk ğ‘Ÿg.
Convex Functions Nowthatwehaveconvexsetswecanintroduceconvexfunctions ğ‘“.
Givenaconvexset X, afunction ğ‘“ : X ! Risconvexifforallğ‘¥,ğ‘¥0 2Xandforallğœ† 2 Â»0,1â€¦ wehave ğœ†ğ‘“â€ğ‘¥â€â€šâ€1 ğœ†â€ğ‘“â€ğ‘¥0â€ ğ‘“â€ğœ†ğ‘¥â€šâ€1 ğœ†â€ğ‘¥0â€.
(12.2.2) To illustrate this letâ€™s plot a fewfunctions and check which ones satisfy the requirement.
Belowwedefineafewfunctions, bothconvexandnonconvex.
f = lambda x: 0.5 * x**2 # Convex g = lambda x: torch.
cos(np.
pi * x) # Nonconvex h = lambda x: torch.
exp(0.5 * x) # Convex x, segment = torch.
arange(-2, 2, 0.01), torch.
tensor([-1.5, 1]) d2l.
use_svg_display() _, axes = d2l.
plt.
subplots(1, 3, figsize=(9, 3)) for ax, func in zip(axes, [f, g, h]): d2l.
plot([x, segment], [func(x), func(segment)], axes=ax) 476 Optimization Algorithms Asexpected, thecosinefunctionisnonconvex, whereastheparabolaandtheexponential functionare.
Notethattherequirementthat Xisaconvexsetisnecessaryforthecondition tomakesense.
Otherwisetheoutcomeof ğ‘“â€ğœ†ğ‘¥â€šâ€1 ğœ†â€ğ‘¥0â€mightnotbewelldefined.
Jensenâ€™s Inequality Givenaconvexfunction ğ‘“, oneofthemostusefulmathematicaltoolsis Jensenâ€™sinequality.
Itamountstoageneralizationofthedefinitionofconvexity: ! ğ›¼ ğ‘– ğ‘“â€ğ‘¥ ğ‘– â€ ğ‘“ ğ›¼ ğ‘– ğ‘¥ ğ‘– andğ¸ ğ‘‹ Â»ğ‘“â€ğ‘‹â€â€¦ ğ‘“ â€ğ¸ ğ‘‹ Â»ğ‘‹â€¦â€, (12.2.3) ğ‘– ğ‘– Ë whereğ›¼ ğ‘– arenonnegativerealnumberssuchthat ğ‘– ğ›¼ ğ‘– =1andğ‘‹ isarandomvariable.
In otherwords, theexpectationofaconvexfunctionisnolessthantheconvexfunctionofan expectation, wherethelatterisusuallyasimplerexpression.
Toprovethefirstinequality werepeatedlyapplythedefinitionofconvexitytooneterminthesumatatime.
One of the common applications of Jensenâ€™s inequality is to bound a more complicated expression by a simpler one.
For example, its application can be with regard to the log- likelihoodofpartiallyobservedrandomvariables.
Thatis, weuse ğ¸ ğ‘Œ ğ‘ƒâ€ğ‘Œâ€ Â» logğ‘ƒâ€ğ‘‹ jğ‘Œâ€â€¦ logğ‘ƒâ€ğ‘‹â€, (12.2.4) fl since ğ‘ƒâ€ğ‘Œâ€ğ‘ƒâ€ğ‘‹ j ğ‘Œâ€ğ‘‘ğ‘Œ = ğ‘ƒâ€ğ‘‹â€.
This can be used in variational methods.
Here ğ‘Œ is typically the unobserved random variable, ğ‘ƒâ€ğ‘Œâ€ is the best guess of how it might be distributed, andğ‘ƒâ€ğ‘‹â€ isthedistributionwithğ‘Œ integratedout.
Forinstance, inclustering ğ‘Œ mightbetheclusterlabelsand ğ‘ƒâ€ğ‘‹ j ğ‘Œâ€ isthegenerativemodelwhenapplyingcluster labels.
12.2.2 Properties Convex functions have many useful properties.
We describe a few commonly-used ones below.
477 Convexity Local Minima Are Global Minima Firstandforemost, thelocalminimaofconvexfunctionsarealsotheglobalminima.
We canproveitbycontradictionasfollows.
Consideraconvexfunction ğ‘“ definedonaconvexset X.
Supposethatğ‘¥ 2 X isalocal minimum: thereexistsasmallpositivevalueğ‘sothatforğ‘¥ 2Xthatsatisfies0< jğ‘¥ ğ‘¥ j ğ‘wehave ğ‘“â€ğ‘¥ â€ < ğ‘“â€ğ‘¥â€.
Assume that the local minimum ğ‘¥ is not the global minimum of ğ‘“: there exists ğ‘¥0 2 X for which ğ‘“â€ğ‘¥0â€ < ğ‘“â€ğ‘¥ â€.
There also exists ğœ† 2 Â»0,1â€ such as ğœ† = 1 ğ‘ so that jğ‘¥ ğ‘¥0j 0< jğœ†ğ‘¥ â€šâ€1 ğœ†â€ğ‘¥0 ğ‘¥ j ğ‘.
However, accordingtothedefinitionofconvexfunctions, wehave ğ‘“â€ğœ†ğ‘¥ â€šâ€1 ğœ†â€ğ‘¥0â€ ğœ†ğ‘“â€ğ‘¥ â€â€šâ€1 ğœ†â€ğ‘“â€ğ‘¥0â€ <ğœ†ğ‘“â€ğ‘¥ â€â€šâ€1 ğœ†â€ğ‘“â€ğ‘¥ â€ (12.2.5) = ğ‘“â€ğ‘¥ â€, which contradicts with our statement that ğ‘¥ is a local minimum.
Therefore, there does not exist ğ‘¥0 2 X for which ğ‘“â€ğ‘¥0â€ < ğ‘“â€ğ‘¥ â€.
The local minimum ğ‘¥ is also the global minimum.
Forinstance, theconvexfunction ğ‘“â€ğ‘¥â€ = â€ğ‘¥ 1â€2 hasalocalminimumatğ‘¥ =1, whichis alsotheglobalminimum.
f = lambda x: (x - 1) ** 2 d2l.
set_figsize() d2l.
plot([x, segment], [f(x), f(segment)], 'x', 'f(x)') The fact that the local minima for convex functions are also the global minima is very convenient.
Itmeansthatifweminimizefunctionswecannotâ€œgetstuckâ€.
Note, though, thatthisdoesnotmeanthattherecannotbemorethanoneglobalminimumorthatthere mightevenexistone.
Forinstance, thefunction ğ‘“â€ğ‘¥â€ =maxâ€jğ‘¥j 1,0â€attainsitsminimum valueovertheinterval Â» 1,1â€¦.
Conversely, thefunction ğ‘“â€ğ‘¥â€ = expâ€ğ‘¥â€ doesnotattaina minimumvalueon R: forğ‘¥ ! 1itasymptotesto0, butthereisnoğ‘¥ forwhich ğ‘“â€ğ‘¥â€ = 0.
478 Optimization Algorithms Below Setsof Convex Functions Are Convex We can conveniently define convex sets via below sets of convex functions.
Concretely, givenaconvexfunction ğ‘“ definedonaconvexset X, anybelowset S ğ‘ d = ef fğ‘¥jğ‘¥ 2Xand ğ‘“â€ğ‘¥â€ ğ‘g (12.2.6) isconvex.
Letâ€™sprovethisquickly.
Recallthatforanyğ‘¥,ğ‘¥0 2S ğ‘weneedtoshowthatğœ†ğ‘¥â€šâ€1 ğœ†â€ğ‘¥0 2 S ğ‘ aslongasğœ† 2 Â»0,1â€¦.
Since ğ‘“â€ğ‘¥â€ ğ‘and ğ‘“â€ğ‘¥0â€ ğ‘, bythedefinitionofconvexitywe have ğ‘“â€ğœ†ğ‘¥â€šâ€1 ğœ†â€ğ‘¥0â€ ğœ†ğ‘“â€ğ‘¥â€â€šâ€1 ğœ†â€ğ‘“â€ğ‘¥0â€ ğ‘.
(12.2.7) Convexityand Second Derivatives Wheneverthesecondderivativeofafunction ğ‘“ : Rğ‘› ! Rexistsitisveryeasytocheck whether ğ‘“ is convex.
All we need to do is check whether the Hessian of ğ‘“ is positive semidefinite: r2ğ‘“ 0, i.
e., denoting the Hessian matrix r2ğ‘“ by H, x>Hx 0 for all x2Rğ‘› .
Forinstance, thefunction ğ‘“â€xâ€ = 1kxk2isconvexsincer2ğ‘“ =1, i.
e., its Hessian 2 isanidentitymatrix.
Formally, atwice-differentiableone-dimensionalfunction ğ‘“ : R! Risconvexifandonly if its second derivative ğ‘“00 0.
For any twice-differentiable multidimensional function ğ‘“ : Rğ‘› ! R, itisconvexifandonlyifits Hessianr2ğ‘“ 0.
First, weneedtoprovetheone-dimensionalcase.
Toseethatconvexityof ğ‘“ implies ğ‘“00 0 weusethefactthat 1 1 ğ‘¥â€šğœ– ğ‘¥ ğœ– ğ‘“â€ğ‘¥â€šğœ–â€â€š ğ‘“â€ğ‘¥ ğœ–â€ ğ‘“ â€š = ğ‘“â€ğ‘¥â€.
(12.2.8) 2 2 2 2 Sincethesecondderivativeisgivenbythelimitoverfinitedifferencesitfollowsthat ğ‘“â€ğ‘¥â€šğœ–â€â€š ğ‘“â€ğ‘¥ ğœ–â€ 2ğ‘“â€ğ‘¥â€ ğ‘“00â€ğ‘¥â€ = lim 0.
(12.2.9) ğœ–!0 ğœ–2 To see that ğ‘“00 0 implies that ğ‘“ is convex we use the fact that ğ‘“00 0 implies that ğ‘“0 is a monotonically nondecreasing function.
Let ğ‘ < ğ‘¥ < ğ‘ be three points in R, where ğ‘¥ = â€1 ğœ†â€ğ‘ â€š ğœ†ğ‘ and ğœ† 2 â€0,1â€.
According to the mean value theorem, there exist ğ›¼ 2 Â»ğ‘,ğ‘¥â€¦ and ğ›½ 2 Â»ğ‘¥,ğ‘â€¦ suchthat ğ‘“â€ğ‘¥â€ ğ‘“â€ğ‘â€ ğ‘“â€ğ‘â€ ğ‘“â€ğ‘¥â€ ğ‘“0â€ğ›¼â€ = and ğ‘“0â€ğ›½â€ = .
(12.2.10) ğ‘¥ ğ‘ ğ‘ ğ‘¥ Bymonotonicity ğ‘“0â€ğ›½â€ ğ‘“0â€ğ›¼â€, hence ğ‘¥ ğ‘ ğ‘ ğ‘¥ ğ‘“â€ğ‘â€â€š ğ‘“â€ğ‘â€ ğ‘“â€ğ‘¥â€.
(12.2.11) ğ‘ ğ‘ ğ‘ ğ‘ Sinceğ‘¥ = â€1 ğœ†â€ğ‘â€šğœ†ğ‘, wehave ğœ†ğ‘“â€ğ‘â€â€šâ€1 ğœ†â€ğ‘“â€ğ‘â€ ğ‘“â€â€1 ğœ†â€ğ‘â€šğœ†ğ‘â€, (12.2.12) 479 Convexity thusprovingconvexity.
Second, weneedalemmabeforeprovingthemultidimensionalcase: ğ‘“ : Rğ‘› ! Risconvex ifandonlyifforallx, y 2Rğ‘› ğ‘”â€ğ‘§â€ d = ef ğ‘“â€ğ‘§xâ€šâ€1 ğ‘§â€yâ€whereğ‘§ 2 Â»0,1â€¦ (12.2.13) isconvex.
Toprovethatconvexityof ğ‘“ impliesthatğ‘”isconvex, wecanshowthatforallğ‘,ğ‘,ğœ† 2 Â»0,1â€¦ (thus0 ğœ†ğ‘â€šâ€1 ğœ†â€ğ‘ 1) ğ‘”â€ğœ†ğ‘â€šâ€1 ğœ†â€ğ‘â€ =ğ‘“ â€â€ğœ†ğ‘â€šâ€1 ğœ†â€ğ‘â€xâ€šâ€1 ğœ†ğ‘ â€1 ğœ†â€ğ‘â€yâ€ =ğ‘“ â€ğœ†â€ğ‘xâ€šâ€1 ğ‘â€yâ€â€šâ€1 ğœ†â€â€ğ‘xâ€šâ€1 ğ‘â€yâ€â€ (12.2.14) ğœ†ğ‘“ â€ğ‘xâ€šâ€1 ğ‘â€yâ€â€šâ€1 ğœ†â€ğ‘“ â€ğ‘xâ€šâ€1 ğ‘â€yâ€ =ğœ†ğ‘”â€ğ‘â€â€šâ€1 ğœ†â€ğ‘”â€ğ‘â€.
Toprovetheconverse, wecanshowthatforallğœ† 2 Â»0,1â€¦ ğ‘“â€ğœ†xâ€šâ€1 ğœ†â€yâ€ =ğ‘”â€ğœ† 1â€šâ€1 ğœ†â€ 0â€ (12.2.15) ğœ†ğ‘”â€1â€â€šâ€1 ğœ†â€ğ‘”â€0â€ =ğœ†ğ‘“â€xâ€â€šâ€1 ğœ†â€ğ‘“â€yâ€.
Finally, usingthelemmaaboveandtheresultoftheone-dimensionalcase, themultidimen- sionalcasecanbeprovenasfollows.
Amultidimensionalfunction ğ‘“ : Rğ‘› ! Risconvex ifandonlyifforallx, y 2 Rğ‘› ğ‘”â€ğ‘§â€ d = ef ğ‘“â€ğ‘§xâ€šâ€1 ğ‘§â€yâ€, whereğ‘§ 2 Â»0,1â€¦, isconvex.
Ac- cordingtotheone-dimensionalcase, thisholdsifandonlyifğ‘”00 = â€x yâ€>Hâ€x yâ€ 0 (H d = ef r2ğ‘“)forallx, y 2 Rğ‘› , whichisequivalentto H 0perthedefinitionofpositive semidefinitematrices.
12.2.3 Constraints Oneofthenicepropertiesofconvexoptimizationisthatitallowsustohandleconstraintsef- ficiently.
Thatis, itallowsustosolveconstrainedoptimizationproblemsoftheform: minimize ğ‘“â€xâ€ x (12.2.16) subjecttoğ‘ ğ‘– â€xâ€ 0forallğ‘– 2 f1,...,ğ‘›g, where ğ‘“ istheobjectiveandthefunctionsğ‘ ğ‘–areconstraintfunctions.
Toseewhatthisdoes considerthecasewhereğ‘ â€xâ€ = kxk 1.
Inthiscasetheparametersxareconstrainedto 1 2 theunitball.
Ifasecondconstraintisğ‘ â€xâ€ =v>xâ€šğ‘, thenthiscorrespondstoallxlying 2 onahalf-space.
Satisfyingbothconstraintssimultaneouslyamountstoselectingasliceof aball.
480 Optimization Algorithms Lagrangian Ingeneral, solvingaconstrainedoptimizationproblemisdifficult.
Onewayofaddressing itstemsfromphysicswitharathersimpleintuition.
Imagineaballinsideabox.
Theball willrolltotheplacethatislowestandtheforcesofgravitywillbebalancedoutwiththe forcesthatthesidesoftheboxcanimposeontheball.
Inshort, thegradientoftheobjective function(i.
e., gravity)willbeoffsetbythegradientoftheconstraintfunction(theballneed toremaininsidetheboxbyvirtueofthewallsâ€œpushingbackâ€).
Notethatsomeconstraints maynotbeactive: thewallsthatarenottouchedbytheballwillnotbeabletoexertany forceontheball.
Skipping over the derivation of the Lagrangian ğ¿, the above reasoning can be expressed viathefollowingsaddlepointoptimizationproblem: ğ‘› ğ‘–=1 Herethevariablesğ›¼ ğ‘– (ğ‘– =1,...,ğ‘›)aretheso-called Lagrangemultipliersthatensurethat constraintsareproperlyenforced.
Theyarechosenjustlargeenoughtoensurethatğ‘ ğ‘– â€xâ€ 0forallğ‘–.
Forinstance, foranyxwhereğ‘ ğ‘– â€xâ€ < 0naturally, weâ€™denduppickingğ›¼ ğ‘– = 0.
Moreover, thisisasaddlepointoptimizationproblemwhereonewantstomaximizeğ¿with respecttoallğ›¼ ğ‘– andsimultaneouslyminimizeitwithrespecttox.
Thereisarichbodyof literatureexplaininghowtoarriveatthefunction ğ¿â€x,ğ›¼ 1 ,...,ğ›¼ ğ‘› â€.
Forourpurposesitis sufficienttoknowthatthesaddlepointofğ¿iswheretheoriginalconstrainedoptimization problemissolvedoptimally.
Penalties Onewayofsatisfyingconstrainedoptimizationproblemsatleastapproximatelyistoadapt the Lagrangianğ¿.
Ratherthansatisfyingğ‘ ğ‘– â€xâ€ 0wesimplyaddğ›¼ ğ‘– ğ‘ ğ‘– â€xâ€totheobjective function ğ‘“â€ğ‘¥â€.
Thisensuresthattheconstraintswillnotbeviolatedtoobadly.
Infact, wehavebeenusingthistrickallalong.
Considerweightdecayin Section3.7.
Init weadd ğœ†kwk2totheobjectivefunctiontoensurethatwdoesnotgrowtoolarge.
Fromthe 2 constrainedoptimizationpointofviewwecanseethatthiswillensurethatkwk2 ğ‘Ÿ2 0 forsomeradiusğ‘Ÿ.
Adjustingthevalueofğœ†allowsustovarythesizeofw.
Ingeneral, addingpenaltiesisagoodwayofensuringapproximateconstraintsatisfaction.
Inpracticethisturnsouttobemuchmorerobustthanexactsatisfaction.
Furthermore, for nonconvexproblemsmanyofthepropertiesthatmaketheexactapproachsoappealingin theconvexcase(e.
g., optimality)nolongerhold.
Projections An alternative strategy for satisfying constraints is projections.
Again, we encountered thembefore, e.
g., when dealing with gradientclipping in Section9.5.
There weensured 481 Convexity thatagradienthaslengthboundedbyğœƒ via g g minâ€1,ğœƒ kgkâ€.
(12.2.18) Thisturnsouttobeaprojectionofgontotheballofradiusğœƒ.
Moregenerally, aprojection onaconvexset Xisdefinedas Proj X â€xâ€ =argminkx x 0k, (12.2.19) x02X whichistheclosestpointin Xtox.
t .2.4 Convex Projections.
Themathematicaldefinitionofprojectionsmaysoundabitabstract.
.2.4explainsit somewhatmoreclearly.
Initwehavetwoconvexsets, acircleandadiamond.
Pointsinside bothsets(yellow)remainunchangedduringprojections.
Pointsoutsidebothsets(black) areprojectedtothepointsinsidethesets(red)thatareclosettotheoriginalpoints(black).
Whileforâ„“ ballsthisleavesthedirectionunchanged, thisneednotbethecaseingeneral, 2 ascanbeseeninthecaseofthediamond.
Oneoftheusesforconvexprojectionsistocomputesparseweightvectors.
Inthiscasewe projectweightvectorsontoanâ„“ ball, whichisageneralizedversionofthediamondcase 1 in.2.4.
12.2.4 Summary Inthecontextofdeeplearningthemainpurposeofconvexfunctionsistomotivateopti- mization algorithms and help us understand them in detail.
In the following we will see howgradientdescentandstochasticgradientdescentcanbederivedaccordingly.
Intersectionsofconvexsetsareconvex.
Unionsarenot.
Theexpectationofaconvexfunctionisnolessthantheconvexfunctionofanexpectation (Jensenâ€™sinequality).
Atwice-differentiablefunctionisconvexifandonlyifits Hessian(amatrixofsecond derivatives)ispositivesemidefinite.
Convex constraints can be added via the Lagrangian.
In practice we may simply add themwithapenaltytotheobjectivefunction.
Projectionsmaptopointsintheconvexsetclosesttotheoriginalpoints.
482 Optimization Algorithms 12.2.5 Exercises 1.
Assume that we want to verify convexity of a set by drawing all lines between points withinthesetandcheckingwhetherthelinesarecontained.
1.
Provethatitissufficienttocheckonlythepointsontheboundary.
2.
Provethatitissufficienttocheckonlytheverticesoftheset.
2.
Denoteby B ğ‘ Â»ğ‘Ÿâ€¦ d = ef fxjx 2 Rğ‘‘ andkxk ğ‘ ğ‘Ÿgtheballofradiusğ‘Ÿ usingthe ğ‘-norm.
Provethat B ğ‘ Â»ğ‘Ÿâ€¦ isconvexforall ğ‘ 1.
3.
Givenconvexfunctions ğ‘“ andğ‘”, showthatmaxâ€ğ‘“,ğ‘”â€isconvex, too.
Provethatminâ€ğ‘“,ğ‘”â€ isnotconvex.
4.
Provethatthenormalizationofthesoftmaxfunctionisconvex.
Morespecificallyprove Ë theconvexityof ğ‘“â€ğ‘¥â€ =log ğ‘–expâ€ğ‘¥ ğ‘– â€.
5.
Provethatlinearsubspaces, i.
e., X = fxj Wx=bg, areconvexsets.
6.
Provethatinthecaseoflinearsubspaceswithb=0theprojection Proj canbewritten X as Mxforsomematrix M.
7.
Showthatfortwice-differentiableconvexfunctions ğ‘“ wecanwrite ğ‘“â€ğ‘¥â€šğœ–â€ = ğ‘“â€ğ‘¥â€â€š ğœ–ğ‘“0â€ğ‘¥â€â€š 1ğœ–2ğ‘“00â€ğ‘¥â€šğœ‰â€forsomeğœ‰ 2 Â»0,ğœ–â€¦.
2 8.
Given a convex set X and two vectors x and y, prove that projections never increase distances, i.
e., kx yk k Proj â€xâ€ Proj â€yâ€k.
X X 167 Discussions167.
12.3 Gradient Descent In this section we are going to introduce the basic concepts underlying gradient descent.
Althoughitisrarelyuseddirectlyindeeplearning, anunderstandingofgradientdescentis keytounderstandingstochasticgradientdescentalgorithms.
Forinstance, theoptimization problemmightdivergeduetoanoverlylargelearningrate.
Thisphenomenoncanalready beseeningradientdescent.
Likewise, preconditioningisacommontechniqueingradient descent and carries over to more advanced algorithms.
Letâ€™s start with a simple special case.
12.3.1 One-Dimensional Gradient Descent Gradient descent in one dimension is an excellent example to explain why the gradient descent algorithm may reduce the value of the objective function.
Consider some con- tinuously differentiable real-valued function ğ‘“ : R ! R.
Using a Taylor expansion we 483 Gradient Descent obtain ğ‘“â€ğ‘¥â€šğœ–â€ = ğ‘“â€ğ‘¥â€â€šğœ–ğ‘“0â€ğ‘¥â€â€šOâ€ğœ–2â€.
(12.3.1) Thatis, infirst-orderapproximation ğ‘“â€ğ‘¥ â€šğœ–â€ isgivenbythefunctionvalue ğ‘“â€ğ‘¥â€ andthe firstderivative ğ‘“0â€ğ‘¥â€ atğ‘¥.
Itisnotunreasonabletoassumethatforsmallğœ– movinginthe directionofthenegativegradientwilldecrease ğ‘“.
Tokeepthingssimplewepickafixed stepsizeğœ‚ >0andchooseğœ– = ğœ‚ğ‘“0â€ğ‘¥â€.
Pluggingthisintothe Taylorexpansionabovewe get ğ‘“â€ğ‘¥ ğœ‚ğ‘“0â€ğ‘¥â€â€ = ğ‘“â€ğ‘¥â€ ğœ‚ğ‘“02â€ğ‘¥â€â€šOâ€ğœ‚2ğ‘“02â€ğ‘¥â€â€.
(12.3.2) Ifthederivative ğ‘“0â€ğ‘¥â€ â‰ 0doesnotvanishwemakeprogresssinceğœ‚ğ‘“02â€ğ‘¥â€ >0.
Moreover, we can always choose ğœ‚ small enough for the higher-order terms to become irrelevant.
Hencewearriveat ğ‘“â€ğ‘¥ ğœ‚ğ‘“0â€ğ‘¥â€â€ âª… ğ‘“â€ğ‘¥â€.
(12.3.3) Thismeansthat, ifweuse ğ‘¥ ğ‘¥ ğœ‚ğ‘“0â€ğ‘¥â€ (12.3.4) toiterateğ‘¥, thevalueoffunction ğ‘“â€ğ‘¥â€mightdecline.
Therefore, ingradientdescentwefirst chooseaninitialvalueğ‘¥ andaconstantğœ‚ > 0andthenusethemtocontinuouslyiterateğ‘¥ untilthestopconditionisreached, forexample, whenthemagnitudeofthegradientjğ‘“0â€ğ‘¥â€j issmallenoughorthenumberofiterationshasreachedacertainvalue.
Forsimplicitywechoosetheobjectivefunction ğ‘“â€ğ‘¥â€ = ğ‘¥2 toillustratehowtoimplement gradientdescent.
Althoughweknowthatğ‘¥ = 0isthesolutiontominimize ğ‘“â€ğ‘¥â€, westill usethissimplefunctiontoobservehowğ‘¥changes.
%matplotlib inline import numpy as np import torch from d2l import torch as d2l def f(x): # Objective function return x ** 2 def f_grad(x): # Gradient (derivative) of the objective function return 2 * x Next, we use ğ‘¥ = 10 as the initial value and assume ğœ‚ = 0.2.
Using gradient descent to iterate ğ‘¥ for 10 times we can see that, eventually, the value of ğ‘¥ approaches the optimal solution.
def gd(eta, f_grad): x = 10.0 results = [x] (continuesonnextpage) 484 Optimization Algorithms (continuedfrompreviouspage) for i in range(10): x -= eta * f_grad(x) results.
append(float(x)) print(f'epoch 10, x: {x: f}') return results results = gd(0.2, f_grad) epoch 10, x: 0.060466 Theprogressofoptimizingoverğ‘¥canbeplottedasfollows.
def show_trace(results, f): n = max(abs(min(results)), abs(max(results))) f_line = torch.
arange(-n, n, 0.01) d2l.
set_figsize() d2l.
plot([f_line, results], [[f(x) for x in f_line], [ f(x) for x in results]], 'x', 'f(x)', fmts=['-', '-o']) show_trace(results, f) Learning Rate Thelearningrateğœ‚canbesetbythealgorithmdesigner.
Ifweusealearningratethatistoo small, itwillcauseğ‘¥ toupdateveryslowly, requiringmoreiterationstogetabettersolu- tion.
Toshowwhathappensinsuchacase, considertheprogressinthesameoptimization problem for ğœ‚ = 0.05.
As we can see, even after 10 steps we are still very far from the optimalsolution.
show_trace(gd(0.05, f_grad), f) epoch 10, x: 3.486784 Conversely, if we use an excessively high learning rate, jğœ‚ğ‘“0â€ğ‘¥â€j might be too large for thefirst-order Taylorexpansionformula.
Thatis, theterm Oâ€ğœ‚2ğ‘“02â€ğ‘¥â€â€ in(12.3.2)might 485 Gradient Descent becomesignificant.
Inthiscase, wecannotguaranteethattheiterationofğ‘¥willbeableto lowerthevalueof ğ‘“â€ğ‘¥â€.
Forexample, whenwesetthelearningratetoğœ‚ =1.1,ğ‘¥overshoots theoptimalsolutionğ‘¥ =0andgraduallydiverges.
show_trace(gd(1.1, f_grad), f) epoch 10, x: 61.917364 Local Minima Toillustratewhathappensfornonconvexfunctionsconsiderthecaseof ğ‘“â€ğ‘¥â€ =ğ‘¥ cosâ€ğ‘ğ‘¥â€ for some constant ğ‘.
This function has infinitely many local minima.
Depending on our choiceofthelearningrateanddependingonhowwellconditionedtheproblemis, wemay endupwithoneofmanysolutions.
Theexamplebelowillustrateshowan(unrealistically) highlearningratewillleadtoapoorlocalminimum.
c = torch.
tensor(0.15 * np.
pi) def f(x): # Objective function return x * torch.
cos(c * x) def f_grad(x): # Gradient of the objective function return torch.
cos(c * x) - c * x * torch.
sin(c * x) show_trace(gd(2, f_grad), f) 486 Optimization Algorithms epoch 10, x: -1.528166 12.3.2 Multivariate Gradient Descent Nowthatwehaveabetterintuitionoftheunivariatecase, letâ€™sconsiderthesituationwhere x = Â»ğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘‘ â€¦> .
That is, the objective function ğ‘“ : Rğ‘‘ ! R maps vectors into scalars.
Correspondingly its gradient is multivariate, too.
It is a vector consisting of ğ‘‘ partialderivatives: ğœ•ğ‘“â€xâ€ ğœ•ğ‘“â€xâ€ ğœ•ğ‘“â€xâ€ > ğœ•ğ‘¥ ğœ•ğ‘¥ ğœ•ğ‘¥ 1 2 ğ‘‘ Eachpartialderivativeelement ğœ•ğ‘“â€xâ€ ğœ•ğ‘¥ ğ‘– inthegradientindicatestherateofchangeof ğ‘“ at x with respect to the input ğ‘¥ ğ‘–.
As before in the univariate case we can use the cor- responding Taylor approximation for multivariate functions to get some idea of what we shoulddo.
Inparticular, wehavethat ğ‘“â€xâ€šğâ€ = ğ‘“â€xâ€â€šğ>rğ‘“â€xâ€â€šOâ€kğk2â€.
(12.3.6) Inotherwords, uptosecond-ordertermsinğthedirectionofsteepestdescentisgivenbythe negativegradient rğ‘“â€xâ€.
Choosingasuitablelearningrateğœ‚ >0yieldstheprototypical gradientdescentalgorithm: x x ğœ‚rğ‘“â€xâ€.
(12.3.7) Toseehowthealgorithmbehavesinpracticeletâ€™sconstructanobjectivefunction ğ‘“â€xâ€ = ğ‘¥2â€š2ğ‘¥2 withatwo-dimensionalvectorx = Â»ğ‘¥ ,ğ‘¥ â€¦> asinputandascalarasoutput.
The 1 2 1 2 gradientisgivenbyrğ‘“â€xâ€ = Â»2ğ‘¥ ,4ğ‘¥ â€¦> .
Wewillobservethetrajectoryofxbygradient 1 2 descentfromtheinitialposition Â» 5, 2â€¦.
Tobeginwith, weneedtwomorehelperfunctions.
Thefirstusesanupdatefunctionandap- pliesit20timestotheinitialvalue.
Thesecondhelpervisualizesthetrajectoryofx.
def train_2d(trainer, steps=20, f_grad=None): #@save """Optimize a 2D objective function with a customized trainer.""" # `s1` and `s2` are internal state variables that will be used in Momentum, â†©! adagrad, RMSProp (continuesonnextpage) 487 Gradient Descent (continuedfrompreviouspage) x1, x2, s1, s2 = -5, -2, 0, 0 results = [(x1, x2)] for i in range(steps): if f_grad: x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad) else: x1, x2, s1, s2 = trainer(x1, x2, s1, s2) results.
append((x1, x2)) print(f'epoch {i + 1}, x1: {float(x1): f}, x2: {float(x2): f}') return results def show_trace_2d(f, results): #@save """Show the trace of 2D variables during optimization.""" d2l.
set_figsize() d2l.
plt.
plot(*zip(*results), '-o', color='#ff7f0e') torch.
arange(-3.0, 1.0, 0.1), indexing='ij') d2l.
plt.
contour(x1, x2, f(x1, x2), colors='#1f77b4') d2l.
plt.
xlabel('x1') d2l.
plt.
ylabel('x2') Next, we observe the trajectory of the optimization variable x for learning rate ğœ‚ = 0.1.
Wecanseethatafter20stepsthevalueofxapproachesitsminimumatÂ»0,0â€¦.
Progressis fairlywell-behavedalbeitratherslow.
def f_2d(x1, x2): # Objective function return x1 ** 2 + 2 * x2 ** 2 def f_2d_grad(x1, x2): # Gradient of the objective function return (2 * x1, 4 * x2) def gd_2d(x1, x2, s1, s2, f_grad): g1, g2 = f_grad(x1, x2) return (x1 - eta * g1, x2 - eta * g2, 0, 0) eta = 0.1 show_trace_2d(f_2d, train_2d(gd_2d, f_grad=f_2d_grad)) epoch 20, x1: -0.057646, x2: -0.000073 488 Optimization Algorithms 12.3.3 Adaptive Methods Aswecouldseein Section12.3.1, gettingthelearningrateğœ‚ â€œjustrightâ€istricky.
Ifwe pickittoosmall, wemakelittleprogress.
Ifwepickittoolarge, thesolutionoscillatesand intheworstcaseitmightevendiverge.
Whatifwecoulddetermineğœ‚automaticallyorget ridofhavingtoselectalearningrateatall? Second-ordermethodsthatlooknotonlyatthe valueandgradientoftheobjectivefunctionbutalsoatitscurvaturecanhelpinthiscase.
Whilethesemethodscannotbeappliedtodeeplearningdirectlyduetothecomputational cost, they provide useful intuition into how to design advanced optimization algorithms thatmimicmanyofthedesirablepropertiesofthealgorithmsoutlinedbelow.
Newtonâ€™s Method Reviewingthe Taylorexpansionofsomefunction ğ‘“ : Rğ‘‘ ! Rthereisnoneedtostopafter thefirstterm.
Infact, wecanwriteitas 1 ğ‘“â€xâ€šğâ€ = ğ‘“â€xâ€â€šğ>rğ‘“â€xâ€â€š ğ>r2ğ‘“â€xâ€ğ â€šOâ€kğk3â€.
(12.3.8) 2 Toavoidcumbersomenotationwedefine H d = ef r2ğ‘“â€xâ€ tobethe Hessianof ğ‘“, whichis a ğ‘‘ ğ‘‘ matrix.
Forsmall ğ‘‘ andsimpleproblems Hiseasytocompute.
Fordeepneural networks, ontheotherhand, Hmaybeprohibitivelylarge, duetothecostofstoring Oâ€ğ‘‘2â€ entries.
Furthermore it may be too expensive to compute via backpropagation.
For now letâ€™signoresuchconsiderationsandlookatwhatalgorithmwewouldget.
Afterall, theminimumof ğ‘“ satisfiesrğ‘“ =0.
Followingcalculusrulesin Section2.4.3, by takingderivativesof (12.3.8)withregardtoğ andignoringhigher-ordertermswearrive at rğ‘“â€xâ€â€šHğ =0andhenceğ = H 1rğ‘“â€xâ€.
(12.3.9) Thatis, weneedtoinvertthe Hessian Haspartoftheoptimizationproblem.
As a simple example, for ğ‘“â€ğ‘¥â€ = 1ğ‘¥2 we have rğ‘“â€ğ‘¥â€ = ğ‘¥ and H = 1.
Hence for any ğ‘¥ 2 weobtainğœ– = ğ‘¥.
Inotherwords, asinglestepissufficienttoconvergeperfectlywithout theneedforanyadjustment! Alas, wegotabitluckyhere: the Taylorexpansionwasexact since ğ‘“â€ğ‘¥â€šğœ–â€ = 1ğ‘¥2â€šğœ–ğ‘¥â€š 1ğœ–2.
2 2 Letâ€™s see what happens in other problems.
Given a convex hyperbolic cosine function ğ‘“â€ğ‘¥â€ = coshâ€ğ‘ğ‘¥â€ for some constant ğ‘, we can see that the global minimum at ğ‘¥ = 0 is reachedafterafewiterations.
c = torch.
tensor(0.5) def f(x): # Objective function return torch.
cosh(c * x) def f_grad(x): # Gradient of the objective function return c * torch.
sinh(c * x) (continuesonnextpage) 489 Gradient Descent (continuedfrompreviouspage) def f_hess(x): # Hessian of the objective function return c**2 * torch.
cosh(c * x) def newton(eta=1): x = 10.0 results = [x] for i in range(10): x -= eta * f_grad(x) / f_hess(x) results.
append(float(x)) print('epoch 10, x:', x) return results show_trace(newton(), f) epoch 10, x: tensor(0.) Now letâ€™s consider a nonconvex function, such as ğ‘“â€ğ‘¥â€ = ğ‘¥cosâ€ğ‘ğ‘¥â€ for some constant ğ‘.
Afterall, notethatin Newtonâ€™smethodweendupdividingbythe Hessian.
Thismeansthat ifthesecondderivativeisnegativewemaywalkintothedirectionofincreasingthevalue of ğ‘“.
Thatisafatalflawofthealgorithm.
Letâ€™sseewhathappensinpractice.
c = torch.
tensor(0.15 * np.
pi) def f(x): # Objective function return x * torch.
cos(c * x) def f_grad(x): # Gradient of the objective function return torch.
cos(c * x) - c * x * torch.
sin(c * x) def f_hess(x): # Hessian of the objective function return - 2 * c * torch.
sin(c * x) - x * c**2 * torch.
cos(c * x) show_trace(newton(), f) epoch 10, x: tensor(26.8341) Thiswentspectacularlywrong.
Howcanwefixit? Onewaywouldbetoâ€œfixâ€the Hessian by taking its absolute value instead.
Another strategy is to bring back the learning rate.
490 Optimization Algorithms Thisseemstodefeatthepurpose, butnotquite.
Havingsecond-orderinformationallows us to be cautious whenever the curvature is large and to take longer steps whenever the objectivefunctionisflatter.
Letâ€™sseehowthisworkswithaslightlysmallerlearningrate, sayğœ‚ =0.5.
Aswecansee, wehavequiteanefficientalgorithm.
show_trace(newton(0.5), f) epoch 10, x: tensor(7.2699) Convergence Analysis Weonlyanalyzetheconvergencerateof Newtonâ€™smethodforsomeconvexandthreetimes differentiableobjectivefunction ğ‘“, wherethesecondderivativeisnonzero, i.
e., ğ‘“00 > 0.
Themultivariateproofisastraightforwardextensionoftheone-dimensionalargumentbe- lowandomittedsinceitdoesnothelpusmuchintermsofintuition.
Denotebyğ‘¥â€ğ‘˜â€ thevalueofğ‘¥attheğ‘˜thiterationandletğ‘’â€ğ‘˜â€ d = efğ‘¥â€ğ‘˜â€ ğ‘¥ bethedistancefrom optimalityatthe ğ‘˜th iteration.
By Taylorexpansionwehavethatthecondition ğ‘“0â€ğ‘¥ â€ = 0 canbewrittenas 1 0= ğ‘“0â€ğ‘¥â€ğ‘˜â€ ğ‘’â€ğ‘˜â€â€ = ğ‘“0â€ğ‘¥â€ğ‘˜â€â€ ğ‘’â€ğ‘˜â€ğ‘“00â€ğ‘¥â€ğ‘˜â€â€â€š â€ğ‘’â€ğ‘˜â€â€2ğ‘“000â€ğœ‰â€ğ‘˜â€â€, (12.3.10) 2 whichholdsforsomeğœ‰â€ğ‘˜â€ 2 Â»ğ‘¥â€ğ‘˜â€ ğ‘’â€ğ‘˜â€,ğ‘¥â€ğ‘˜â€â€¦.
Dividingtheaboveexpansionby ğ‘“00â€ğ‘¥â€ğ‘˜â€â€ 491 Gradient Descent yields ğ‘“0â€ğ‘¥â€ğ‘˜â€â€ 1 ğ‘“000â€ğœ‰â€ğ‘˜â€â€ ğ‘’â€ğ‘˜â€ = â€ğ‘’â€ğ‘˜â€â€2 .
(12.3.11) ğ‘“00â€ğ‘¥â€ğ‘˜â€â€ 2 ğ‘“00â€ğ‘¥â€ğ‘˜â€â€ Recallthatwehavetheupdateğ‘¥â€ğ‘˜â€š1â€ =ğ‘¥â€ğ‘˜â€ ğ‘“0â€ğ‘¥â€ğ‘˜â€â€ ğ‘“00â€ğ‘¥â€ğ‘˜â€â€.
Plugginginthisupdate equationandtakingtheabsolutevalueofbothsides, wehave 1 ğ‘“000â€ğœ‰â€ğ‘˜â€â€ ğ‘’â€ğ‘˜â€š1â€ = â€ğ‘’â€ğ‘˜â€â€2 .
(12.3.12) 2 ğ‘“00â€ğ‘¥â€ğ‘˜â€â€ Consequently, wheneverweareinaregionofbounded ğ‘“000â€ğœ‰â€ğ‘˜â€â€ â€2ğ‘“00â€ğ‘¥â€ğ‘˜â€â€â€ ğ‘, we haveaquadraticallydecreasingerror ğ‘’â€ğ‘˜â€š1â€ ğ‘â€ğ‘’â€ğ‘˜â€â€2.
(12.3.13) As anasid e, opt imiz ationresearcherscallthislinearconvergence, whereasaconditionsuch as ğ‘’â€ğ‘˜â€š1â€ ğ›¼ ğ‘’â€ğ‘˜â€ wouldbecalledaconstantrateofconvergence.
Notethatthisanalysis comeswithanumberofcaveats.
First, wedonotreallyhavemuchofaguaranteewhenwe willreachtheregionofrapidconvergence.
Instead, weonlyknowthatoncewereachit, convergencewillbeveryquick.
Second, thisanalysisrequiresthat ğ‘“ iswell-behavedupto higher-orderderivatives.
Itcomesdowntoensuringthat ğ‘“ doesnothaveanyâ€œsurprisingâ€ propertiesintermsofhowitmightchangeitsvalues.
Preconditioning Quiteunsurprisinglycomputingandstoringthefull Hessianisveryexpensive.
Itisthus desirable to find alternatives.
One way to improve matters is preconditioning.
It avoids computingthe Hessianinitsentiretybutonlycomputesthediagonalentries.
Thisleadsto updatealgorithmsoftheform x x ğœ‚diagâ€Hâ€ 1rğ‘“â€xâ€.
(12.3.14) Whilethisisnotquiteasgoodasthefull Newtonâ€™smethod, itisstillmuchbetterthannot using it.
To see why this might be a good idea consider a situation where one variable denotes height in millimeters and the other one denotes height in kilometers.
Assuming thatforboththenaturalscaleisinmeters, wehaveaterriblemismatchinparametrizations.
Fortunately, usingpreconditioningremovesthis.
Effectivelypreconditioningwithgradient descentamountstoselectingadifferentlearningrateforeachvariable(coordinateofvector x).
Aswewillseelater, preconditioningdrivessomeoftheinnovationinstochasticgradient descentoptimizationalgorithms.
Gradient Descentwith Line Search Oneofthekeyproblemsingradientdescentisthatwemightovershootthegoalormake insufficientprogress.
Asimplefixfortheproblemistouselinesearchinconjunctionwith gradient descent.
That is, we use the direction given by rğ‘“â€xâ€ and then perform binary searchastowhichlearningrateğœ‚minimizes ğ‘“â€x ğœ‚rğ‘“â€xâ€â€.
492 Optimization Algorithms This algorithm converges rapidly (for an analysis and proof see e.
g., Boyd and Vanden- berghe (2004)).
However, for the purpose of deep learning this is not quite so feasible, sinceeachstepofthelinesearchwouldrequireustoevaluatetheobjectivefunctiononthe entiredataset.
Thisiswaytoocostlytoaccomplish.
12.3.4 Summary Learningratesmatter.
Toolargeandwediverge, toosmallandwedonotmakeprogress.
Gradientdescentcangetstuckinlocalminima.
Inhighdimensionsadjustingthelearningrateiscomplicated.
Preconditioningcanhelpwithscaleadjustment.
Newtonâ€™smethodisalotfasteronceithasstartedworkingproperlyinconvexproblems.
Bewareofusing Newtonâ€™smethodwithoutanyadjustmentsfornonconvexproblems.
12.3.5 Exercises 1.
Experimentwithdifferentlearningratesandobjectivefunctionsforgradientdescent.
2.
Implementlinesearchtominimizeaconvexfunctionintheinterval Â»ğ‘,ğ‘â€¦.
1.
Do you need derivatives for binary search, i.
e., to decide whether to pick Â»ğ‘,â€ğ‘ â€š ğ‘â€ 2â€¦ or Â»â€ğ‘â€šğ‘â€ 2,ğ‘â€¦.
2.
Howrapidistherateofconvergenceforthealgorithm? 3.
Implementthealgorithmandapplyittominimizinglogâ€expâ€ğ‘¥â€â€šexpâ€ 2ğ‘¥ 3â€â€.
3.
Designanobjectivefunctiondefinedon R2wheregradientdescentisexceedinglyslow.
Hint: scaledifferentcoordinatesdifferently.
4.
Implementthelightweightversionof Newtonâ€™smethodusingpreconditioning: 1.
Usediagonal Hessianaspreconditioner.
168 2.
Usetheabsolutevaluesofthatratherthantheactual(possiblysigned)values.
3.
Applythistotheproblemabove.
5.
Apply the algorithm above to a number of objective functions (convex or not).
What happensifyourotatecoordinatesby45degrees? Discussions168.
493 Stochastic Gradient Descent 12.4 Stochastic Gradient Descent Inearlierchapterswekeptusingstochasticgradientdescentinourtrainingprocedure, how- ever, withoutexplainingwhyitworks.
Toshedsomelightonit, wejustdescribedthebasic principlesofgradientdescentin Section12.3.
Inthissection, wegoontodiscussstochastic gradientdescentingreaterdetail.
%matplotlib inline import math import torch from d2l import torch as d2l 12.4.1 Stochastic Gradient Updates Indeeplearning, theobjectivefunctionisusuallytheaverageofthelossfunctionsforeach example in the training dataset.
Given a training dataset of ğ‘› examples, we assume that ğ‘“ ğ‘– â€xâ€ is the loss function with respect to the training example of indexğ‘–, where x is the parametervector.
Thenwearriveattheobjectivefunction ğ‘› 1 ğ‘“â€xâ€ = ğ‘› ğ‘“ ğ‘– â€xâ€.
(12.4.1) ğ‘–=1 Thegradientoftheobjectivefunctionatxiscomputedas ğ‘› 1 rğ‘“â€xâ€ = ğ‘› rğ‘“ ğ‘– â€xâ€.
(12.4.2) ğ‘–=1 Ifgradientdescentisused, thecomputationalcostforeachindependentvariableiteration is Oâ€ğ‘›â€, which grows linearly with ğ‘›.
Therefore, when the training dataset is larger, the costofgradientdescentforeachiterationwillbehigher.
Stochastic gradient descent (SGD) reduces computational cost at each iteration.
At each iterationofstochasticgradientdescent, weuniformlysampleanindexğ‘– 2 f1,...,ğ‘›g for dataexamplesatrandom, andcomputethegradientrğ‘“ ğ‘– â€xâ€toupdatex: x x ğœ‚rğ‘“ ğ‘– â€xâ€, (12.4.3) whereğœ‚isthelearningrate.
Wecanseethatthecomputationalcostforeachiterationdrops from Oâ€ğ‘›â€ of the gradient descent to the constant Oâ€1â€.
Moreover, we want to empha- sizethatthestochasticgradientrğ‘“ ğ‘– â€xâ€ isanunbiasedestimateofthefullgradientrğ‘“â€xâ€ because ğ‘› 1 E ğ‘– rğ‘“ ğ‘– â€xâ€ = ğ‘› rğ‘“ ğ‘– â€xâ€ =rğ‘“â€xâ€.
(12.4.4) ğ‘–=1 Thismeansthat, onaverage, thestochasticgradientisagoodestimateofthegradient.
Now, wewillcompareitwithgradientdescentbyaddingrandomnoisewithameanof0 andavarianceof1tothegradienttosimulateastochasticgradientdescent.
494 Optimization Algorithms def f(x1, x2): # Objective function return x1 ** 2 + 2 * x2 ** 2 def f_grad(x1, x2): # Gradient of the objective function return 2 * x1, 4 * x2 def sgd(x1, x2, s1, s2, f_grad): g1, g2 = f_grad(x1, x2) # Simulate noisy gradient g1 += torch.
normal(0.0, 1, (1,)).
item() g2 += torch.
normal(0.0, 1, (1,)).
item() eta_t = eta * lr() return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0) def constant_lr(): return 1 eta = 0.1 lr = constant_lr # Constant learning rate d2l.
show_trace_2d(f, d2l.
train_2d(sgd, steps=50, f_grad=f_grad)) epoch 50, x1: 0.225517, x2: -0.076646 As we can see, the trajectory of the variables in the stochastic gradient descent is much more noisy than the one we observed in gradient descent in Section 12.3.
This is due to the stochastic nature of the gradient.
That is, even when we arrive near the minimum, wearestillsubjecttotheuncertaintyinjectedbytheinstantaneousgradientviağœ‚rğ‘“ ğ‘– â€xâ€.
Even after 50 steps the quality is still not so good.
Even worse, it will not improve after additionalsteps(weencourageyoutoexperimentwithalargernumberofstepstoconfirm this).
Thisleavesuswiththeonlyalternative: changethelearningrateğœ‚.
However, ifwe pickthistoosmall, wewillnotmakeanymeaningfulprogressinitially.
Ontheotherhand, if we pick it too large, we will not get a good solution, as seen above.
The only way to resolve these conflicting goals is to reduce the learning rate dynamically as optimization progresses.
Thisisalsothereasonforaddingalearningratefunctionlrintothesgdstepfunction.
In 495 Stochastic Gradient Descent theexampleaboveanyfunctionalityforlearningrateschedulingliesdormantaswesetthe associatedlrfunctiontobeconstant.
12.4.2 Dynamic Learning Rate Replacingğœ‚withatime-dependentlearningrateğœ‚â€ğ‘¡â€addstothecomplexityofcontrolling convergenceofanoptimizationalgorithm.
Inparticular, weneedtofigureouthowrapidly ğœ‚ should decay.
If it is too quick, we will stop optimizing prematurely.
If we decrease it too slowly, we waste too much time on optimization.
The following are a few basic strategiesthatareusedinadjustingğœ‚overtime(wewilldiscussmoreadvancedstrategies later): ğœ‚â€ğ‘¡â€ =ğœ‚ ğ‘– ifğ‘¡ ğ‘– ğ‘¡ ğ‘¡ ğ‘–â€š1 piecewiseconstant ğœ‚â€ğ‘¡â€ =ğœ‚ ğ‘’ ğœ†ğ‘¡ exponentialdecay (12.4.5) 0 ğœ‚â€ğ‘¡â€ =ğœ‚ â€ğ›½ğ‘¡â€š1â€ ğ›¼ polynomialdecay 0 Inthefirstpiecewiseconstantscenariowedecreasethelearningrate, e.
g., wheneverprogress inoptimizationstalls.
Thisisacommonstrategyfortrainingdeepnetworks.
Alternatively wecoulddecreaseitmuchmoreaggressivelybyanexponentialdecay.
Unfortunatelythis oftenleadstoprematurestoppingbeforethealgorithmhasconverged.
Apopularchoiceis polynomialdecaywithğ›¼ = 0.5.
Inthecaseofconvexoptimizationthereareanumberof proofsthatshowthatthisrateiswellbehaved.
Letâ€™sseewhattheexponentialdecaylookslikeinpractice.
def exponential_lr(): # Global variable that is defined outside this function and updated inside global t t += 1 return math.
exp(-0.1 * t) t = 1 lr = exponential_lr d2l.
show_trace_2d(f, d2l.
train_2d(sgd, steps=1000, f_grad=f_grad)) epoch 1000, x1: -0.758829, x2: -0.115584 Asexpected, thevarianceintheparametersissignificantlyreduced.
However, thiscomes 496 Optimization Algorithms atthe expenseof failingto convergeto the optimal solution x = â€0,0â€.
Evenafter 1000 iterationstepsarewearestillveryfarawayfromtheoptimalsolution.
Indeed, thealgorithm failstoconvergeatall.
Ontheotherhand, ifweuseapolynomialdecaywherethelearning rate decays with the inverse square root of the number of steps, convergence gets better afteronly50steps.
def polynomial_lr(): # Global variable that is defined outside this function and updated inside global t t += 1 return (1 + 0.1 * t) ** (-0.5) t = 1 lr = polynomial_lr d2l.
show_trace_2d(f, d2l.
train_2d(sgd, steps=50, f_grad=f_grad)) epoch 50, x1: 0.144834, x2: 0.041688 Thereexistmanymorechoicesforhowtosetthelearningrate.
Forinstance, wecouldstart withasmallrate, thenrapidlyrampupandthendecreaseitagain, albeitmoreslowly.
We couldevenalternatebetweensmallerandlargerlearningrates.
Thereexistsalargevariety ofsuchschedules.
Fornowletâ€™sfocusonlearningrateschedulesforwhichacomprehen- sivetheoreticalanalysisispossible, i.
e., onlearningratesinaconvexsetting.
Forgeneral nonconvexproblemsitisverydifficulttoobtainmeaningfulconvergenceguarantees, since ingeneralminimizingnonlinearnonconvexproblemsis NPhard.
Forasurveyseee.
g., the 169 excellentlecturenotes169 of Tibshirani2015.
12.4.3 Convergence Analysisfor Convex Objectives The following convergence analysis of stochastic gradient descent for convex objective functionsisoptionalandprimarilyservestoconveymoreintuitionabouttheproblem.
We limitourselvestooneofthesimplestproofs(Nesterovand Vial,2000).
Significantlymore advancedprooftechniquesexist, e.
g., whenevertheobjectivefunctionisparticularlywell behaved.
Supposethattheobjectivefunction ğ‘“â€ğƒ, xâ€ isconvexinxforallğƒ.
Moreconcretely, we 497 Stochastic Gradient Descent considerthestochasticgradientdescentupdate: xğ‘¡â€š1 =xğ‘¡ ğœ‚ ğ‘¡ ğœ• x ğ‘“â€ğƒ ğ‘¡ , xâ€, (12.4.6) where ğ‘“â€ğƒ ğ‘¡ , xâ€istheobjectivefunctionwithrespecttothetrainingexampleğƒ ğ‘¡ drawnfrom somedistributionatstepğ‘¡ andxisthemodelparameter.
Denoteby ğ‘…â€xâ€ = ğ¸ ğƒ Â»ğ‘“â€ğƒ, xâ€â€¦ (12.4.7) the expected risk and by ğ‘… its minimum with regard to x.
Last let x be the minimizer (weassumethatitexistswithinthedomainwherexisdefined).
Inthiscasewecantrack thedistancebetweenthecurrentparameterxğ‘¡ attimeğ‘¡ andtheriskminimizerx andsee whetheritimprovesovertime: kxğ‘¡â€š1 x k2 =kxğ‘¡ ğœ‚ ğ‘¡ ğœ• x ğ‘“â€ğƒ ğ‘¡ , xâ€ x k2 (12.4.8) =kxğ‘¡ x k2â€šğœ‚ ğ‘¡ 2kğœ• x ğ‘“â€ğƒ ğ‘¡ , xâ€k2 2ğœ‚ ğ‘¡ xğ‘¡ x ,ğœ• x ğ‘“â€ğƒ ğ‘¡ , xâ€ .
Weassumethattheâ„“ 2 normofstochasticgradientğœ• x ğ‘“â€ğƒ ğ‘¡ , xâ€isboundedbysomeconstant ğ¿, hencewehavethat ğœ‚2kğœ• ğ‘“â€ğƒ , xâ€k2 ğœ‚2ğ¿2.
(12.4.9) ğ‘¡ x ğ‘¡ ğ‘¡ We are mostly interested in how the distance between xğ‘¡ and x changes in expectation.
Infact, foranyspecificsequenceofstepsthedistancemightwellincrease, dependingon whicheverğƒ ğ‘¡ weencounter.
Henceweneedtoboundthedotproduct.
Sinceforanyconvex function ğ‘“ it holds that ğ‘“â€yâ€ ğ‘“â€xâ€ â€š hğ‘“0â€xâ€, y xi for all x and y, by convexity we have ğ‘“â€ğƒ ğ‘¡ , x â€ ğ‘“â€ğƒ ğ‘¡ , xğ‘¡ â€â€š x xğ‘¡ ,ğœ• x ğ‘“â€ğƒ ğ‘¡ , xğ‘¡ â€ .
(12.4.10) distancebetweenparametersattimeğ‘¡â€š1asfollows: kxğ‘¡ x k2 kxğ‘¡â€š1 x k2 2ğœ‚ ğ‘¡ â€ğ‘“â€ğƒ ğ‘¡ , xğ‘¡ â€ ğ‘“â€ğƒ ğ‘¡ , x â€â€ ğœ‚ ğ‘¡ 2ğ¿2.
(12.4.11) Thismeansthatwemakeprogressaslongasthedifferencebetweencurrentlossandthe optimallossoutweighsğœ‚ ğ‘¡ ğ¿2 2.
Sincethisdifferenceisboundtoconvergetozeroitfollows thatthelearningrateğœ‚ ğ‘¡ alsoneedstovanish.
Nextwetakeexpectationsover(12.4.11).
Thisyields ğ¸ kxğ‘¡ x k2 ğ¸ kxğ‘¡â€š1 x k2 2ğœ‚ ğ‘¡ Â»ğ¸Â»ğ‘…â€xğ‘¡ â€â€¦ ğ‘… â€¦ ğœ‚ ğ‘¡ 2ğ¿2.
(12.4.12) The last step involves summing over the inequalities for ğ‘¡ 2 f1,...,ğ‘‡g.
Since the sum telescopesandbydroppingthelowertermweobtain ! ğ‘‡ ğ‘‡ kx 1 x k2 2 ğœ‚ ğ‘¡ Â»ğ¸Â»ğ‘…â€xğ‘¡ â€â€¦ ğ‘… â€¦ ğ¿2 ğœ‚ ğ‘¡ 2.
(12.4.13) ğ‘¡=1 ğ‘¡=1 498 Optimization Algorithms Note that we exploited that x is given and thus the expectation can be dropped.
Last 1 define Ë xÂ¯ d = ef Ë ğ‘‡ ğ‘¡=1 ğœ‚ ğ‘¡xğ‘¡ .
(12.4.14) ğ‘‡ ğœ‚ ğ‘¡=1 ğ‘¡ Since Ë ! Ë ğ¸ ğ‘‡ ğ‘¡=Ë1 ğ‘‡ ğœ‚ ğ‘¡ ğ‘… ğœ‚ â€xğ‘¡ â€ = ğ‘‡ ğ‘¡=1Ë ğœ‚ ğ‘¡ ğ‘‡ ğ¸Â» ğœ‚ ğ‘…â€xğ‘¡ â€â€¦ = ğ¸Â»ğ‘…â€xğ‘¡ â€â€¦, (12.4.15) ğ‘¡=1 ğ‘¡ ğ‘¡=1 ğ‘¡ Ë by Jensenâ€™s inequality (settingğ‘– = ğ‘¡, ğ›¼ ğ‘– = ğœ‚ ğ‘¡ ğ‘‡ ğ‘¡=1 ğœ‚ ğ‘¡ in (12.2.3)) and convexity of ğ‘… it followsthatğ¸Â»ğ‘…â€xğ‘¡ â€â€¦ ğ¸Â»ğ‘…â€xÂ¯â€â€¦, thus ğ‘‡ ğ‘‡ ğœ‚ ğ‘¡ ğ¸Â»ğ‘…â€xğ‘¡ â€â€¦ ğœ‚ ğ‘¡ ğ¸ Â»ğ‘…â€xÂ¯â€â€¦.
(12.4.16) ğ‘¡=1 ğ‘¡=1 Pluggingthisintotheinequality(12.4.13)yieldsthebound Ë ğ‘Ÿ2â€šğ¿2 ğ‘‡ ğœ‚2 Â»ğ¸Â»xÂ¯â€¦â€¦ ğ‘… Ë ğ‘¡=1 ğ‘¡ , (12.4.17) 2 ğ‘‡ ğ‘¡=1 ğœ‚ ğ‘¡ whereğ‘Ÿ2 d = ef kx x k2isaboundonthedistancebetweentheinitialchoiceofparameters 1 and the final outcome.
In short, the speed of convergence depends on how the norm of stochasticgradientisbounded(ğ¿)andhowfarawayfromoptimalitytheinitialparameter valueis(ğ‘Ÿ).
NotethattheboundisintermsofxÂ¯ ratherthanxğ‘‡.
ThisisthecasesincexÂ¯ is asmoothedversionoftheopptimizationpath.
Wheneverğ‘Ÿ,ğ¿, andp ğ‘‡ areknownwecanpick thelearningratpeğœ‚ = ğ‘Ÿ â€ğ¿ ğ‘‡â€.
Thisyieldsasupperboundğ‘Ÿğ¿ ğ‘‡.
Thatis, weconverge withrate Oâ€1 ğ‘‡â€totheoptimalsolution.
12.4.4 Stochastic Gradientsand Finite Samples So far we have played a bit fast and loose when it comes to talking about stochastic gra- dient descent.
We posited that we draw instances ğ‘¥ ğ‘–, typically with labels ğ‘¦ ğ‘– from some distribution ğ‘â€ğ‘¥,ğ‘¦â€ and that we use this to update the model parameters in some man- ner.
In particular, for a finite sample size we simply argued that the discrete distribution Ë ğ‘â€ğ‘¥,ğ‘¦â€ = ğ‘› 1 ğ‘– ğ‘› =1 ğ›¿ ğ‘¥ğ‘– â€ğ‘¥â€ğ›¿ ğ‘¦ğ‘– â€ğ‘¦â€forsomefunctionsğ›¿ ğ‘¥ğ‘– andğ›¿ ğ‘¦ğ‘– allowsustoperformstochas- ticgradientdescentoverit.
However, this is not really what we did.
In the toy examples in the current section we simplyaddednoisetoanotherwisenon-stochasticgradient, i.
e., wepretendedtohavepairs â€ğ‘¥ ğ‘– ,ğ‘¦ ğ‘– â€.
Itturnsoutthatthisisjustifiedhere(seetheexercisesforadetaileddiscussion).
More troubling is that in all previous discussions we clearly did not do this.
Instead we iteratedoverallinstancesexactlyonce.
Toseewhythisispreferableconsidertheconverse, namelythatwearesamplingğ‘›observationsfromthediscretedistributionwithreplacement.
Theprobabilityofchoosinganelementğ‘–atrandomis1 ğ‘›.
Thustochooseitatleastonce is ğ‘ƒâ€chooseğ‘–â€ =1 ğ‘ƒâ€omitğ‘–â€ =1 â€1 1 ğ‘›â€ğ‘› 1 ğ‘’ 1 0.63.
(12.4.18) 499 Stochastic Gradient Descent Asimilarreasoningshowsthattheprobabilityofpickingsomesample(i.
e., trainingexam- ple)exactlyonceisgivenby ğ‘› 1 1 ğ‘› 1 ğ‘› 1 ğ‘› 1 = 1 ğ‘’ 1 0.37.
(12.4.19) 1 ğ‘› ğ‘› ğ‘› 1 ğ‘› Sampling with replacement leads to an increased variance and decreased data efficiency relative to sampling without replacement.
Hence, in practice we perform the latter (and thisisthedefaultchoicethroughoutthisbook).
Lastnotethatrepeatedpassesthroughthe trainingdatasettraverseitinadifferentrandomorder.
12.4.5 Summary For convex problems we can prove that for a wide choice of learning rates stochastic gradientdescentwillconvergetotheoptimalsolution.
Fordeeplearningthisisgenerallynotthecase.
However, theanalysisofconvexprob- lemsgivesususefulinsightintohowtoapproachoptimization, namelytoreducethe learningrateprogressively, albeitnottooquickly.
Problems occur when the learning rate is too small or too large.
In practice a suitable learningrateisoftenfoundonlyaftermultipleexperiments.
When there are more examples in the training dataset, it costs more to compute each iterationforgradientdescent, sostochasticgradientdescentispreferredinthesecases.
Optimalityguaranteesforstochasticgradientdescentareingeneralnotavailableinnon- convex cases since the number of local minima that require checking might well be exponential.
12.4.6 Exercises 1.
Experiment with different learning rate schedules for stochastic gradient descent and with different numbers of iterations.
In particular, plot the distance from the optimal solutionâ€0,0â€asafunctionofthenumberofiterations.
2.
Provethatforthefunction ğ‘“â€ğ‘¥ ,ğ‘¥ â€ = ğ‘¥2â€š2ğ‘¥2 addingnormalnoisetothegradientis 1 2 1 2 equivalenttominimizingalossfunction ğ‘“â€x, wâ€ = â€ğ‘¥ ğ‘¤ â€2â€š2â€ğ‘¥ ğ‘¤ â€2 wherex 1 1 2 2 isdrawnfromanormaldistribution.
3.
Compareconvergenceofstochasticgradientdescentwhenyousamplefromfâ€ğ‘¥ 1 ,ğ‘¦ 1 â€,...,â€ğ‘¥ ğ‘› ,ğ‘¦ ğ‘› â€g withreplacementandwhenyousamplewithoutreplacement.
4.
Howwouldyouchangethestochasticgradientdescentsolverifsomegradient(orrather somecoordinateassociatedwithit)wasconsistentlylargerthanalltheothergradients? 5.
Assume that ğ‘“â€ğ‘¥â€ = ğ‘¥2â€1â€šsinğ‘¥â€.
How many local minima does ğ‘“ have? Can you 170 change ğ‘“ insuchawaythattominimizeitoneneedstoevaluateallthelocalminima? Discussions170.
500 Optimization Algorithms 12.5 Minibatch Stochastic Gradient Descent So far we encountered two extremes in the approach to gradient-based learning: Section 12.3usesthefulldatasettocomputegradientsandtoupdateparameters, onepassatatime.
Conversely Section12.4processesonetrainingexampleatatimetomakeprogress.
Either ofthemhasitsowndrawbacks.
Gradientdescentisnotparticularlydataeï¬€icientwhenever dataisverysimilar.
Stochasticgradientdescentisnotparticularlycomputationallyeï¬€icient since CPUs and GPUs cannot exploit the full power of vectorization.
This suggests that theremightbesomethinginbetween, andinfact, thatiswhatwehavebeenusingsofarin theexampleswediscussed.
12.5.1 Vectorizationand Caches At the heart of the decision to use minibatches is computational efficiency.
This is most easilyunderstoodwhenconsideringparallelizationtomultiple GPUsandmultipleservers.
Inthiscaseweneedtosendatleastoneimagetoeach GPU.
With8GPUsperserverand 16serverswealreadyarriveataminibatchsizenosmallerthan128.
Thingsareabitmoresubtlewhenitcomestosingle GPUsoreven CPUs.
Thesedevices havemultipletypesofmemory, oftenmultipletypesofcomputationalunitsanddifferent bandwidthconstraintsbetweenthem.
Forinstance, a CPUhasasmallnumberofregisters and then the L1, L2, and in some cases even L3 cache (which is shared among different processor cores).
These caches are of increasing size and latency (and at the same time theyareofdecreasingbandwidth).
Sufficetosay, theprocessoriscapableofperforming manymoreoperationsthanwhatthemainmemoryinterfaceisabletoprovide.
First, a 2GHz CPU with 16 cores and AVX-512 vectorization can process up to 2 109 16 32 = 1012 bytespersecond.
Thecapabilityof GPUseasilyexceedsthisnumberbya factorof100.
Ontheotherhand, amidrangeserverprocessormightnothavemuchmore than100GB/sbandwidth, i.
e., lessthanonetenthofwhatwouldberequiredtokeepthe processor fed.
To make matters worse, not all memory access is created equal: memory interfacesaretypically64bitwideorwider(e.
g., on GPUsupto384bit), hencereadinga singlebyteincursthecostofamuchwideraccess.
Second, thereissignificantoverheadforthefirstaccesswhereassequentialaccessisrela- tivelycheap(thisisoftencalledaburstread).
Therearemanymorethingstokeepinmind, such as caching when we have multiple sockets, chiplets, and other structures.
See this 171 Wikipediaarticle171 foramorein-depthdiscussion.
The way to alleviate these constraints is to use a hierarchy of CPU caches that are actu- allyfastenoughtosupplytheprocessorwithdata.
Thisisthedrivingforcebehindbatch- ingindeeplearning.
Tokeepmatterssimple, considermatrix-matrixmultiplication, say A = BC.
Wehaveanumberofoptionsforcalculating A.
Forinstance, wecouldtrythe following: 501 Minibatch Stochastic Gradient Descent 1.
Wecouldcompute Ağ‘–ğ‘— = Bğ‘–,: C :,ğ‘—, i.
e., wecouldcomputeitelementwisebymeansof dotproducts.
2.
We could compute A :,ğ‘— = BC :,ğ‘—, i.
e., we could compute it one column at a time.
Likewisewecouldcompute Aonerow Ağ‘–,: atatime.
3.
Wecouldsimplycompute A=BC.
4.
We could break B and C into smaller block matrices and compute A one block at a time.
Ifwefollowthefirstoption, wewillneedtocopyonerowandonecolumnvectorintothe CPUeachtimewewanttocomputeanelement Ağ‘–ğ‘—.
Evenworse, duetothefactthatmatrix elements are aligned sequentially we are thus required to access many disjoint locations for one of the two vectors as we read them from memory.
The second option is much morefavorable.
Init, weareabletokeepthecolumnvector C :,ğ‘— inthe CPUcachewhile we keep on traversing through B.
This halves the memory bandwidth requirement with correspondinglyfasteraccess.
Ofcourse, option3ismostdesirable.
Unfortunately, most matricesmightnotentirelyfitintocache(thisiswhatwearediscussingafterall).
However, option4offersapracticallyusefulalternative: wecanmoveblocksofthematrixintocache andmultiplythemlocally.
Optimizedlibrariestakecareofthisforus.
Letâ€™shavealookat howefficienttheseoperationsareinpractice.
Beyondcomputationalefficiency, theoverheadintroducedby Pythonandbythedeeplearn- ing framework itself is considerable.
Recall that each time we execute a command the Python interpreter sends a command to the MXNet engine which needs to insert it into the computational graph and deal with it during scheduling.
Such overhead can be quite detrimental.
Inshort, itishighlyadvisabletousevectorization(andmatrices)whenever possible.
%matplotlib inline import time import numpy as np import torch from torch import nn from d2l import torch as d2l A = torch.
zeros(256, 256) B = torch.
randn(256, 256) C = torch.
randn(256, 256) Sincewewillbenchmarktherunningtimefrequentlyintherestofthebook, letâ€™sdefinea timer.
class Timer: #@save """Record multiple running times.""" def __init__(self): self.
times = [] self.
start() (continuesonnextpage) 502 Optimization Algorithms (continuedfrompreviouspage) def start(self): """Start the timer.""" self.
tik = time.
time() def stop(self): """Stop the timer and record the time in a list.""" self.
times.
append(time.
time() - self.
tik) return self.
times[-1] def avg(self): """Return the average time.""" return sum(self.
times) / len(self.
times) def sum(self): """Return the sum of time.""" return sum(self.
times) def cumsum(self): """Return the accumulated time.""" return np.
array(self.
times).
cumsum().
tolist() timer = Timer() Element-wiseassignmentsimplyiteratesoverallrowsandcolumnsof Band Crespectively toassignthevalueto A.
# Compute A = BC one element at a time timer.
start() for i in range(256): for j in range(256): A[i, j] = torch.
dot(B[i, :], C[:, j]) timer.
stop() 1.7845737934112549 Afasterstrategyistoperformcolumn-wiseassignment.
# Compute A = BC one column at a time timer.
start() for j in range(256): A[:, j] = torch.
mv(B, C[:, j]) timer.
stop() 0.06541275978088379 Last, themosteffectivemanneristoperformtheentireoperationinoneblock.
Notethat multiplyinganytwomatrices B2Rğ‘š ğ‘› and C2Rğ‘› ğ‘ takesapproximately2ğ‘šğ‘›ğ‘floating pointoperations, whenscalarmultiplicationandadditionarecountedasseparateoperations 503 Minibatch Stochastic Gradient Descent (fusedinpractice).
Thus, multiplyingtwo256 256matricestakes0.03billionfloating pointoperations.
Letâ€™sseewhattherespectivespeedoftheoperationsis.
# Compute A = BC in one go timer.
start() A = torch.
mm(B, C) timer.
stop() gigaflops = [0.03 / i for i in timer.
times] print(f'performance in Gigaflops: element {gigaflops[0]:.3f}, ' f'column {gigaflops[1]:.3f}, full {gigaflops[2]:.3f}') performance in Gigaflops: element 0.017, column 0.459, full 51.633 12.5.2 Minibatches Inthepastwetookitforgrantedthatwewouldreadminibatchesofdataratherthansingle observationstoupdateparameters.
Wenowgiveabriefjustificationforit.
Processingsin- gleobservationsrequiresustoperformmanysinglematrix-vector(orevenvector-vector) multiplications, whichisquiteexpensiveandwhichincursasignificantoverheadonbehalf oftheunderlyingdeeplearningframework.
Thisappliesbothtoevaluatinganetworkwhen appliedtodata(oftenreferredtoasinference)andwhencomputinggradientstoupdatepa- rameters.
Thatis, thisapplieswheneverweperformw w ğœ‚ ğ‘¡gğ‘¡ where gğ‘¡ =ğœ• w ğ‘“â€xğ‘¡ , wâ€ (12.5.1) Wecanincreasethecomputationalefficiencyofthisoperationbyapplyingittoaminibatch ofobservationsatatime.
Thatis, wereplacethegradientgğ‘¡ overasingleobservationby oneoverasmallbatch 1 gğ‘¡ =ğœ• wj B j ğ‘“â€xğ‘– , wâ€ (12.5.2) ğ‘¡ ğ‘–2Bğ‘¡ Letâ€™sseewhatthisdoestothestatisticalpropertiesofgğ‘¡: sincebothxğ‘¡andalsoallelements oftheminibatch B ğ‘¡ aredrawnuniformlyatrandomfromthetrainingset, theexpectationof thegradientremainsunchanged.
Thevariance, ontheotherhand, isreducedsignificantly.
Since the minibatch gradient is composed of ğ‘ d = ef j B ğ‘¡ j independent gradients which are beingaveraged, itsstandarddeviationisreducedbyafactorofğ‘ 2 1.
This, byitself, isagood thing, sinceitmeansthattheupdatesaremorereliablyalignedwiththefullgradient.
Naivelythiswouldindicatethatchoosingalargeminibatch B ğ‘¡ wouldbeuniversallydesir- able.
Alas, aftersomepoint, theadditionalreductioninstandarddeviationisminimalwhen comparedtothelinearincreaseincomputationalcost.
Inpracticewepickaminibatchthat islargeenoughtooffergoodcomputationalefficiencywhilestillfittingintothememoryof a GPU.
Toillustratethesavingsletâ€™shavealookatsomecode.
Initweperformthesame matrix-matrixmultiplication, butthistimebrokenupintoâ€œminibatchesâ€of64columnsat atime.
504 Optimization Algorithms timer.
start() for j in range(0, 256, 64): A[:, j: j+64] = torch.
mm(B, C[:, j: j+64]) timer.
stop() print(f'performance in Gigaflops: block {0.03 / timer.
times[3]:.3f}') performance in Gigaflops: block 37.640 As we can see, the computation on the minibatch is essentially as efficient as on the full matrix.
Awordofcautionisinorder.
In Section8.5weusedatypeofregularizationthat washeavilydependentontheamountofvarianceinaminibatch.
Asweincreasethelatter, thevariancedecreasesandwithitthebenefitofthenoise-injectionduetobatchnormal- ization.
See e.
g., Ioffe (2017) for details on how to rescale and compute the appropriate terms.
12.5.3 Readingthe Dataset Letâ€™shavealookathowminibatchesareefficientlygeneratedfromdata.
Inthefollowing 172 we use a dataset developed by NASA to test the wing noise from different aircraft172 to compare these optimization algorithms.
For convenience we only use the first 1,500 examples.
Thedataiswhitenedforpreprocessing, i.
e., weremovethemeanandrescalethe varianceto1percoordinate.
#@save d2l.
DATA_HUB['airfoil'] = (d2l.
DATA_URL + 'airfoil_self_noise.
dat', '76e5be1548fd8222e5074cf0faae75edff8cf93f') #@save def get_data_ch11(batch_size=10, n=1500): data = np.
genfromtxt(d2l.
download('airfoil'), dtype=np.
float32, delimiter='\t') data = torch.
from_numpy((data - data.
mean(axis=0)) / data.
std(axis=0)) data_iter = d2l.
load_array((data[: n, :-1], data[: n, -1]), batch_size, is_train=True) return data_iter, data.
shape[1]-1 12.5.4 Implementationfrom Scratch Recalltheminibatchstochasticgradientdescentimplementationfrom Section3.4.
Inthe followingweprovideaslightlymoregeneralimplementation.
Forconvenienceithasthe same call signature as the other optimization algorithms introduced later in this chapter.
Specifically, we add the status input states and place the hyperparameter in dictionary hyperparams.
Inaddition, wewillaveragethelossofeachminibatchexampleinthetrain- ingfunction, sothegradientintheoptimizationalgorithmdoesnotneedtobedividedby thebatchsize.
505 Minibatch Stochastic Gradient Descent def sgd(params, states, hyperparams): for p in params: p.
data.
sub_(hyperparams['lr'] * p.
grad) p.
grad.
data.
zero_() Next, weimplementagenerictrainingfunctiontofacilitatetheuseoftheotheroptimization algorithmsintroducedlaterinthischapter.
Itinitializesalinearregressionmodelandcan beusedtotrainthemodelwithminibatchstochasticgradientdescentandotheralgorithms introducedsubsequently.
#@save def train_ch11(trainer_fn, states, hyperparams, data_iter, feature_dim, num_epochs=2): # Initialization w = torch.
normal(mean=0.0, std=0.01, size=(feature_dim, 1), requires_grad=True) b = torch.
zeros((1), requires_grad=True) net, loss = lambda X: d2l.
linreg(X, w, b), d2l.
squared_loss # Train animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[0, num_epochs], ylim=[0.22, 0.35]) n, timer = 0, d2l.
Timer() for _ in range(num_epochs): for X, y in data_iter: l = loss(net(X), y).
mean() l.
backward() trainer_fn([w, b], states, hyperparams) n += X.
shape[0] if n % 200 == 0: timer.
stop() animator.
add(n/X.
shape[0]/len(data_iter), (d2l.
evaluate_loss(net, data_iter, loss),)) timer.
start() print(f'loss: {animator.
Y[0][-1]:.3f}, {timer.
sum()/num_epochs:.3f} sec/ â†©! epoch') return timer.
cumsum(), animator.
Y[0] Letâ€™sseehowoptimizationproceedsforbatchgradientdescent.
Thiscanbeachievedby settingtheminibatchsizeto1500(i.
e., tothetotalnumberofexamples).
Asaresultthe modelparametersareupdatedonlyonceperepoch.
Thereislittleprogress.
Infact, after6 stepsprogressstalls.
def train_sgd(lr, batch_size, num_epochs=2): data_iter, feature_dim = get_data_ch11(batch_size) return train_ch11( sgd, None, {'lr': lr}, data_iter, feature_dim, num_epochs) gd_res = train_sgd(1, 1500, 10) loss: 0.247, 0.020 sec/epoch 506 Optimization Algorithms When the batch size equals 1, we use stochastic gradient descent for optimization.
For simplicityofimplementationwepickedaconstant(albeitsmall)learningrate.
Instochastic gradientdescent, themodelparametersareupdatedwheneveranexampleisprocessed.
In ourcasethisamountsto1500updatesperepoch.
Aswecansee, thedeclineinthevalueof theobjectivefunctionslowsdownafteroneepoch.
Althoughboththeproceduresprocessed 1500 examples within one epoch, stochastic gradient descent consumes more time than gradient descent in our experiment.
This is because stochastic gradient descent updated theparametersmorefrequentlyandsinceitislessefficienttoprocesssingleobservations oneatatime.
sgd_res = train_sgd(0.005, 1) loss: 0.245, 0.685 sec/epoch Finally, whenthebatchsizeequals100, weuseminibatchstochasticgradientdescentfor optimization.
The time required per epoch is shorter than the time needed for stochastic gradientdescentandthetimeforbatchgradientdescent.
mini1_res = train_sgd(.4, 100) loss: 0.246, 0.025 sec/epoch Reducingthebatchsizeto10, thetimeforeachepochincreasesbecausetheworkloadfor eachbatchislessefficienttoexecute.
507 Minibatch Stochastic Gradient Descent mini2_res = train_sgd(.05, 10) loss: 0.246, 0.090 sec/epoch Nowwecancomparethetimevs.
lossforthepreviousfourexperiments.
Ascanbeseen, although stochastic gradient descent converges faster than GD in terms of number of ex- amplesprocessed, itusesmoretimetoreachthesamelossthan GDbecausecomputingthe gradientexamplebyexampleisnotasefficient.
Minibatchstochasticgradientdescentis abletotrade-offconvergencespeedandcomputationefficiency.
Aminibatchsizeof10is moreefficientthanstochasticgradientdescent; aminibatchsizeof100evenoutperforms GDintermsofruntime.
d2l.
set_figsize([6, 3]) d2l.
plot(*list(map(list, zip(gd_res, sgd_res, mini1_res, mini2_res))), 'time (sec)', 'loss', xlim=[1e-2, 10], legend=['gd', 'sgd', 'batch size=100', 'batch size=10']) d2l.
plt.
gca().
set_xscale('log') 12.5.5 Concise Implementation In Gluon, wecanusethe Trainerclasstocalloptimizationalgorithms.
Thisisusedtoim- plementagenerictrainingfunction.
Wewillusethisthroughoutthecurrentchapter.
508 Optimization Algorithms #@save def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4): # Initialization net = nn.
Sequential(nn.
Linear(5, 1)) def init_weights(module): if type(module) == nn.
Linear: net.
apply(init_weights) optimizer = trainer_fn(net.
parameters(), **hyperparams) loss = nn.
MSELoss(reduction='none') animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[0, num_epochs], ylim=[0.22, 0.35]) n, timer = 0, d2l.
Timer() for _ in range(num_epochs): for X, y in data_iter: optimizer.
zero_grad() out = net(X) y = y.
reshape(out.
shape) l = loss(out, y) l.
mean().
backward() optimizer.
step() n += X.
shape[0] if n % 200 == 0: timer.
stop() # `MSELoss` computes squared error without the 1/2 factor animator.
add(n/X.
shape[0]/len(data_iter), (d2l.
evaluate_loss(net, data_iter, loss) / 2,)) timer.
start() print(f'loss: {animator.
Y[0][-1]:.3f}, {timer.
sum()/num_epochs:.3f} sec/ â†©! epoch') Using Gluontorepeatthelastexperimentshowsidenticalbehavior.
data_iter, _ = get_data_ch11(10) trainer = torch.
optim.
SGD train_concise_ch11(trainer, {'lr': 0.01}, data_iter) 509 Minibatch Stochastic Gradient Descent loss: 0.243, 0.096 sec/epoch 12.5.6 Summary Vectorizationmakescodemoreefficientduetoreducedoverheadarisingfromthedeep learning framework and due to better memory locality and caching on CPUs and GPUs.
Thereisatrade-offbetweenstatisticalefficiencyarisingfromstochasticgradientdescent andcomputationalefficiencyarisingfromprocessinglargebatchesofdataatatime.
Minibatchstochasticgradientdescentoffersthebestofbothworlds: computationaland statisticalefficiency.
Inminibatchstochasticgradientdescentweprocessbatchesofdataobtainedbyarandom permutation of the training data (i.
e., each observation is processed only once per epoch, albeitinrandomorder).
Itisadvisabletodecaythelearningratesduringtraining.
Ingeneral, minibatchstochasticgradientdescentisfasterthanstochasticgradientdescent and gradient descent for convergence to a smaller risk, when measured in terms of clocktime.
12.5.7 Exercises 1.
Modifythebatchsizeandlearningrateandobservetherateofdeclineforthevalueof theobjectivefunctionandthetimeconsumedineachepoch.
2.
Readthe MXNetdocumentationandusethe Trainerclassset_learning_ratefunc- tiontoreducethelearningrateoftheminibatchstochasticgradientdescentto1/10of itspreviousvalueaftereachepoch.
3.
Compareminibatchstochasticgradientdescentwithavariantthatactuallysampleswith replacementfromthetrainingset.
Whathappens? 4.
Anevilgeniereplicatesyourdatasetwithouttellingyou(i.
e., eachobservationoccurs twiceandyourdatasetgrowstotwiceitsoriginalsize, butnobodytoldyou).
Howdoes 510 Optimization Algorithms the behavior of stochastic gradient descent, minibatch stochastic gradient descent and thatofgradientdescentchange? Discussions173.
173 12.6 Momentum In Section12.4wereviewedwhathappenswhenperformingstochasticgradientdescent, i.
e., whenperformingoptimizationwhereonlyanoisyvariantofthegradientisavailable.
Inparticular, wenoticedthatfornoisygradientsweneedtobeextracautiouswhenitcomes tochoosingthelearningrateinthefaceofnoise.
Ifwedecreaseittoorapidly, convergence stalls.
Ifwearetoolenient, wefailtoconvergetoagoodenoughsolutionsincenoisekeeps ondrivingusawayfromoptimality.
12.6.1 Basics Inthissection, wewillexploremoreeffectiveoptimizationalgorithms, especiallyforcer- taintypesofoptimizationproblemsthatarecommoninpractice.
Leaky Averages Theprevioussectionsawusdiscussingminibatch SGDasameansforacceleratingcom- putation.
It also had the nice side-effect that averaging gradients reduced the amount of variance.
Theminibatchstochasticgradientdescentcanbecalculatedby: 1 1 gğ‘¡,ğ‘¡ 1 =ğœ• wj B j ğ‘“â€xğ‘– , wğ‘¡ 1 â€ = j B j hğ‘–,ğ‘¡ 1 .
(12.6.1) ğ‘¡ ğ‘¡ ğ‘–2Bğ‘¡ ğ‘–2Bğ‘¡ Tokeepthenotationsimple, hereweusedhğ‘–,ğ‘¡ 1 = ğœ• w ğ‘“â€xğ‘– , wğ‘¡ 1 â€ asthestochasticgra- dientdescentforsampleğ‘– usingtheweightsupdatedattimeğ‘¡ 1.
Itwouldbeniceifwe couldbenefitfromtheeffectofvariancereductionevenbeyondaveraginggradientsona minibatch.
Oneoptiontoaccomplishthistaskistoreplacethegradientcomputationbya â€œleakyaverageâ€: vğ‘¡ = ğ›½vğ‘¡ 1 â€šgğ‘¡,ğ‘¡ 1 (12.6.2) forsomeğ›½ 2 â€0,1â€.
Thiseffectivelyreplacestheinstantaneousgradientbyonethatisbeen averagedovermultiplepast gradients.
v iscalledvelocity.
Itaccumulatespastgradients similartohowaheavyballrollingdowntheobjectivefunctionlandscapeintegratesover pastforces.
Toseewhatishappeninginmoredetailletâ€™sexpandvğ‘¡ recursivelyinto ğ‘¡ 1 ğœ=0 Largeğ›½amountstoalong-rangeaverage, whereassmallğ›½amountstoonlyaslightcorrec- tionrelativetoagradientmethod.
Thenewgradientreplacementnolongerpointsintothe 511 Momentum directionofsteepestdescentonaparticularinstanceanylongerbutratherinthedirection of a weightedaverage of pastgradients.
This allowsus to realize mostof the benefits of averagingoverabatchwithoutthecostofactuallycomputingthegradientsonit.
Wewill revisitthisaveragingprocedureinmoredetaillater.
Theabovereasoningformedthebasisforwhatisnowknownasacceleratedgradientmeth- ods, suchasgradientswithmomentum.
Theyenjoytheadditionalbenefitofbeingmuch moreeffectiveincaseswheretheoptimizationproblemisill-conditioned(i.
e., wherethere are some directions where progress is much slower than in others, resembling a narrow canyon).
Furthermore, theyallowustoaverageoversubsequentgradientstoobtainmore stabledirectionsofdescent.
Indeed, theaspectofaccelerationevenfornoise-freeconvex problemsisoneofthekeyreasonswhymomentumworksandwhyitworkssowell.
Asonewouldexpect, duetoitsefficacymomentumisawell-studiedsubjectinoptimization fordeeplearningandbeyond.
Seee.
g., thebeautifulexpositoryarticle174 by Goh(2017) 174 foranin-depthanalysisandinteractiveanimation.
Itwasproposedby Polyak(1964).
Nes- terov (2018) has a detailed theoretical discussion in the context of convex optimization.
Momentumindeeplearninghasbeenknowntobebeneficialforalongtime.
Seee.
g., the discussionby Sutskeveretal.
(2013)fordetails.
An Ill-conditioned Problem To get a better understanding of the geometric properties of the momentum method we revisitgradientdescent, albeitwithasignificantlylesspleasantobjectivefunction.
Recall thatin Section12.3weused ğ‘“â€xâ€ =ğ‘¥2â€š2ğ‘¥2, i.
e., amoderatelydistortedellipsoidobjective.
1 2 Wedistortthisfunctionfurtherbystretchingitoutintheğ‘¥ directionvia 1 ğ‘“â€xâ€ =0.1ğ‘¥2â€š2ğ‘¥2.
(12.6.4) 1 2 Asbefore ğ‘“ hasitsminimumatâ€0,0â€.
Thisfunctionisveryflatinthedirectionofğ‘¥ .
Letâ€™s 1 seewhathappenswhenweperformgradientdescentasbeforeonthisnewfunction.
We pickalearningrateof0.4.
%matplotlib inline import torch from d2l import torch as d2l eta = 0.4 def f_2d(x1, x2): return 0.1 * x1 ** 2 + 2 * x2 ** 2 def gd_2d(x1, x2, s1, s2): return (x1 - eta * 0.2 * x1, x2 - eta * 4 * x2, 0, 0) d2l.
show_trace_2d(f_2d, d2l.
train_2d(gd_2d)) epoch 20, x1: -0.943467, x2: -0.000073 By construction, the gradient in the ğ‘¥ direction is much higher and changes much more 2 512 Optimization Algorithms rapidly than in the horizontal ğ‘¥ direction.
Thus we are stuck between two undesirable 1 choices: if we pick a small learning rate we ensure that the solution does not diverge in theğ‘¥ directionbutwearesaddledwithslowconvergenceintheğ‘¥ direction.
Conversely, 2 1 with a large learning rate we progress rapidly in the ğ‘¥ direction but diverge in ğ‘¥ .
The 1 2 example below illustrateswhat happens even after a slight increase in learning rate from 0.4to0.6.
Convergenceintheğ‘¥ directionimprovesbuttheoverallsolutionqualityismuch 1 worse.
eta = 0.6 d2l.
show_trace_2d(f_2d, d2l.
train_2d(gd_2d)) epoch 20, x1: -0.387814, x2: -1673.365109 The Momentum Method Themomentummethodallowsustosolvethegradientdescentproblemdescribedabove.
Lookingattheoptimizationtraceabovewemightintuitthataveraginggradientsoverthe pastwouldworkwell.
Afterall, intheğ‘¥ directionthiswillaggregatewell-alignedgradi- 1 ents, thusincreasingthedistancewecoverwitheverystep.
Conversely, intheğ‘¥ direction 2 where gradients oscillate, an aggregate gradient will reduce step size due to oscillations thatcanceleachotherout.
Usingvğ‘¡ insteadofthegradientgğ‘¡ yieldsthefollowingupdate equations: vğ‘¡ ğ›½vğ‘¡ 1 â€šgğ‘¡,ğ‘¡ 1 , (12.6.5) xğ‘¡ xğ‘¡ 1 ğœ‚ ğ‘¡vğ‘¡ .
513 Momentum Note that for ğ›½ = 0 we recover regular gradient descent.
Before delving deeper into the mathematical properties letâ€™s have a quick look at how the algorithm behaves in prac- tice.
def momentum_2d(x1, x2, v1, v2): v1 = beta * v1 + 0.2 * x1 v2 = beta * v2 + 4 * x2 return x1 - eta * v1, x2 - eta * v2, v1, v2 eta, beta = 0.6, 0.5 d2l.
show_trace_2d(f_2d, d2l.
train_2d(momentum_2d)) epoch 20, x1: 0.007188, x2: 0.002553 Aswecansee, evenwiththesamelearningratethatweusedbefore, momentumstillcon- vergeswell.
Letâ€™sseewhathappenswhenwedecreasethemomentumparameter.
Halving ittoğ›½=0.25leadstoatrajectorythatbarelyconvergesatall.
Nonetheless, itisalotbetter thanwithoutmomentum(whenthesolutiondiverges).
eta, beta = 0.6, 0.25 d2l.
show_trace_2d(f_2d, d2l.
train_2d(momentum_2d)) epoch 20, x1: -0.126340, x2: -0.186632 Note that we can combine momentum with stochastic gradient descent and in particular, minibatchstochasticgradientdescent.
Theonlychangeisthatinthatcasewereplacethe 514 Optimization Algorithms gradients gğ‘¡,ğ‘¡ 1 with gğ‘¡.
Last, for convenience we initialize v 0 = 0 at time ğ‘¡ = 0.
Letâ€™s lookatwhatleakyaveragingactuallydoestotheupdates.
Effective Sample Weight Ë Ë Recallthatvğ‘¡ = ğ‘¡ ğœ = 1 0 ğ›½ğœgğ‘¡ ğœ,ğ‘¡ ğœ 1 .
Inthelimitthetermsaddupto 1 ğœ=0 ğ›½ğœ = 1 1 ğ›½ .
In other words, rather than taking a step of size ğœ‚ in gradient descent or stochastic gradient ğœ‚ descentwetakeastepofsize whileatthesametime, dealingwithapotentiallymuch 1 ğ›½ betterbehaveddescentdirection.
Thesearetwobenefitsinone.
Toillustratehowweighting behavesfordifferentchoicesof ğ›½considerthediagrambelow.
d2l.
set_figsize() betas = [0.95, 0.9, 0.6, 0] for beta in betas: x = torch.
arange(40).
detach().
numpy() d2l.
plt.
plot(x, beta ** x, label=f'beta = {beta:.2f}') d2l.
plt.
xlabel('time') d2l.
plt.
legend(); 12.6.2 Practical Experiments Letâ€™sseehowmomentumworksinpractice, i.
e., whenusedwithinthecontextofaproper optimizer.
Forthisweneedasomewhatmorescalableimplementation.
Implementationfrom Scratch Compared with (minibatch) stochastic gradient descent the momentum method needs to maintainasetofauxiliaryvariables, i.
e., velocity.
Ithasthesameshapeasthegradients (and variables of the optimization problem).
In the implementation below we call these variablesstates.
def init_momentum_states(feature_dim): v_w = torch.
zeros((feature_dim, 1)) v_b = torch.
zeros(1) return (v_w, v_b) 515 Momentum def sgd_momentum(params, states, hyperparams): for p, v in zip(params, states): with torch.
no_grad(): v[:] = hyperparams['momentum'] * v + p.
grad p[:] -= hyperparams['lr'] * v p.
grad.
data.
zero_() Letâ€™sseehowthisworksinpractice.
def train_momentum(lr, momentum, num_epochs=2): d2l.
train_ch11(sgd_momentum, init_momentum_states(feature_dim), {'lr': lr, 'momentum': momentum}, data_iter, feature_dim, num_epochs) data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) train_momentum(0.02, 0.5) loss: 0.245, 0.153 sec/epoch Whenweincreasethemomentumhyperparametermomentumto0.9, itamountstoasignif- icantlylargereffectivesamplesizeof 1 = 10.
Wereducethelearningrateslightlyto 1 0.9 0.01tokeepmattersundercontrol.
train_momentum(0.01, 0.9) loss: 0.248, 0.109 sec/epoch Reducingthelearningratefurtheraddressesanyissueofnon-smoothoptimizationprob- lems.
Settingitto0.005yieldsgoodconvergenceproperties.
train_momentum(0.005, 0.9) loss: 0.243, 0.107 sec/epoch 516 Optimization Algorithms Concise Implementation There is very little to do in Gluon since the standard sgd solver already had momentum builtin.
Settingmatchingparametersyieldsaverysimilartrajectory.
trainer = torch.
optim.
SGD d2l.
train_concise_ch11(trainer, {'lr': 0.005, 'momentum': 0.9}, data_iter) loss: 0.250, 0.108 sec/epoch 12.6.3 Theoretical Analysis Sofarthe2Dexampleof ğ‘“â€ğ‘¥â€ =0.1ğ‘¥2â€š2ğ‘¥2seemedrathercontrived.
Wewillnowseethat 1 2 thisisactuallyquiterepresentativeofthetypesofproblemonemightencounter, atleastin thecaseofminimizingconvexquadraticobjectivefunctions.
517 Momentum Quadratic Convex Functions Considerthefunction 1 â„â€xâ€ = x > Qxâ€šx > câ€šğ‘.
(12.6.6) 2 Thisisageneralquadraticfunction.
Forpositivedefinitematrices Q 0, i.
e., formatrices with positive eigenvalues this has a minimizer at x = Q 1c with minimum value ğ‘ 1c>Q 1c.
Hencewecanrewriteâ„as 2 1 1 â„â€xâ€ = â€x Q 1câ€> Qâ€x Q 1câ€â€šğ‘ c > Q 1c.
(12.6.7) 2 2 The gradient is given by ğœ• â„â€xâ€ = Qâ€x Q 1câ€.
That is, it is given by the distance x betweenxandtheminimizer, multipliedby Q.
Consequentlyalsothevelocityisalinear combinationofterms Qâ€xğ‘¡ Q 1câ€.
Since Qispositivedefiniteitcanbedecomposedintoitseigensystemvia Q=O>ğš²Ofor anorthogonal(rotation)matrix Oandadiagonalmatrixğš²ofpositiveeigenvalues.
This allowsustoperformachangeofvariablesfromxtoz d = ef Oâ€x Q 1câ€ toobtainamuch simplifiedexpression: 1 â„â€zâ€ = z >ğš²zâ€šğ‘0.
(12.6.8) 2 Here ğ‘0 = ğ‘ 1c>Q 1c.
Since Oisonlyanorthogonalmatrixthisdoesnotperturbthe 2 gradientsinameaningfulway.
Expressedintermsofzgradientdescentbecomes zğ‘¡ =zğ‘¡ 1 ğš²zğ‘¡ 1 = â€I ğš²â€zğ‘¡ 1 .
(12.6.9) Theimportantfactinthisexpressionisthatgradientdescentdoesnotmixbetweendifferent eigenspaces.
That is, when expressed in terms of the eigensystem of Q the optimization problemproceedsinacoordinate-wisemanner.
Thisalsoholdsfor vğ‘¡ = ğ›½vğ‘¡ 1 â€šğš²zğ‘¡ 1 zğ‘¡ =zğ‘¡ 1 ğœ‚â€ğ›½vğ‘¡ 1 â€šğš²zğ‘¡ 1 â€ (12.6.10) = â€I ğœ‚ğš²â€zğ‘¡ 1 ğœ‚ğ›½vğ‘¡ 1 .
In doing this we just proved the following theorem: gradient descent with and without momentumforaconvexquadraticfunctiondecomposesintocoordinate-wiseoptimization inthedirectionoftheeigenvectorsofthequadraticmatrix.
Scalar Functions Giventheaboveresultletâ€™sseewhathappenswhenweminimizethefunction ğ‘“â€ğ‘¥â€ = ğœ†ğ‘¥2.
2 Forgradientdescentwehave ğ‘¥ ğ‘¡â€š1 =ğ‘¥ ğ‘¡ ğœ‚ğœ†ğ‘¥ ğ‘¡ = â€1 ğœ‚ğœ†â€ğ‘¥ ğ‘¡ .
(12.6.11) Wheneverj1 ğœ‚ğœ†j <1thisoptimizationconvergesatanexponentialratesinceafterğ‘¡steps wehaveğ‘¥ ğ‘¡ = â€1 ğœ‚ğœ†â€ğ‘¡ğ‘¥ 0 .
Thisshowshowtherateofconvergenceimprovesinitiallyas 518 Optimization Algorithms weincreasethelearningrateğœ‚untilğœ‚ğœ† =1.
Beyondthatthingsdivergeandforğœ‚ğœ† >2the optimizationproblemdiverges.
lambdas = [0.1, 1, 10, 19] eta = 0.1 d2l.
set_figsize((6, 4)) for lam in lambdas: t = torch.
arange(20).
detach().
numpy() d2l.
plt.
plot(t, (1 - eta * lam) ** t, label=f'lambda = {lam:.2f}') d2l.
plt.
xlabel('time') d2l.
plt.
legend(); Toanalyzeconvergenceinthecaseofmomentumwebeginbyrewritingtheupdateequa- tionsintermsoftwoscalars: oneforğ‘¥andoneforvelocityğ‘£.
Thisyields: ğ‘£ ğ›½ ğœ† ğ‘£ ğ‘£ ğ‘¡â€š1 = ğ‘¡ =Râ€ğ›½,ğœ‚,ğœ†â€ ğ‘¡ .
(12.6.12) ğ‘¥ ğ‘¡â€š1 ğœ‚ğ›½ â€1 ğœ‚ğœ†â€ ğ‘¥ ğ‘¡ ğ‘¥ ğ‘¡ We used R to denote the 2 2 governing convergence behavior.
Afterğ‘¡ steps the initial choice Â»ğ‘£ ,ğ‘¥ â€¦ becomes Râ€ğ›½,ğœ‚,ğœ†â€ğ‘¡Â»ğ‘£ ,ğ‘¥ â€¦.
Hence, it is up to the eigenvalues of R to 0 0 0 0 determine the speed of convergence.
See the Distill post175 of Goh (2017) for a great 175 animation and Flammarion and Bach (2015) for a detailed analysis.
One can show that 0 < ğœ‚ğœ† < 2â€š2ğ›½ velocityconverges.
Thisis alargerrangeoffeasibleparameterswhen comparedto0 < ğœ‚ğœ† < 2forgradientdescent.
Italsosuggeststhatingenerallargevalues of ğ›½aredesirable.
Furtherdetailsrequireafairamountoftechnicaldetailandwesuggest thattheinterestedreaderconsulttheoriginalpublications.
12.6.4 Summary Momentumreplacesgradientswithaleakyaverageoverpastgradients.
Thisaccelerates convergencesignificantly.
Itisdesirableforbothnoise-freegradientdescentand(noisy)stochasticgradientdescent.
Momentum prevents stalling of the optimization process that is much more likely to occurforstochasticgradientdescent.
519 Adagrad Theeffectivenumberofgradientsisgivenby 1 duetoexponentiateddownweighting 1 ğ›½ ofpastdata.
Inthecaseofconvexquadraticproblemsthiscanbeanalyzedexplicitlyindetail.
Implementation is quite straightforward but it requires us to store an additional state vector(velocityv).
12.6.5 Exercises 1.
Useothercombinationsofmomentumhyperparametersandlearningratesandobserve andanalyzethedifferentexperimentalresults.
2.
Tryoutgradientdescentandmomentumforaquadraticproblemwhereyouhavemulti- Ë fortheinitializationğ‘¥ ğ‘– =1.
3.
Deriveminimumvalueandminimizerforâ„â€xâ€ = 1x>Qxâ€šx>câ€šğ‘.
2 4.
What changes when we perform stochastic gradient descent with momentum? What happenswhenweuseminibatchstochasticgradientdescentwithmomentum? Experi- mentwiththeparameters? 176 Discussions176.
12.7 Adagrad Letâ€™sbeginbyconsideringlearningproblemswithfeaturesthatoccurinfrequently.
12.7.1 Sparse Featuresand Learning Rates Imagine that we are training a language model.
To get good accuracy we typically want todecreasethelearningrateaswekeepontraining, usuallyatarateof Oâ€ğ‘¡ 1 2 â€ orslower.
Nowconsideramodeltrainingonsparsefeatures, i.
e., featuresthatoccuronlyinfrequently.
Thisiscommonfornaturallanguage, e.
g., itisalotlesslikelythatwewillseetheword preconditioningthanlearning.
However, itisalsocommoninotherareassuchascomputa- tionaladvertisingandpersonalizedcollaborativefiltering.
Afterall, therearemanythings thatareofinterestonlyforasmallnumberofpeople.
Parametersassociatedwithinfrequentfeaturesonlyreceivemeaningfulupdateswhenever these features occur.
Given a decreasing learning rate we might end up in a situation wheretheparametersforcommonfeaturesconvergeratherquicklytotheiroptimalvalues, whereasforinfrequentfeatureswearestillshortofobservingthemsufficientlyfrequently before their optimal values can be determined.
In other words, the learning rate either decreasestooslowlyforfrequentfeaturesortooquicklyforinfrequentones.
520 Optimization Algorithms Apossiblehacktoredressthisissuewouldbetocountthenumberoftimesweseeapar- ticular feature and to use this as a clock for adjusting learning rates.
That is, rather than choosing a learning rate of the form ğœ‚ = p ğœ‚ 0 we could use ğœ‚ ğ‘– = p ğœ‚ 0 .
Here ğ‘ â€ğ‘–,ğ‘¡â€ ğ‘¡â€šğ‘ ğ‘ â€ğ‘–,ğ‘¡â€â€šğ‘ countsthenumberofnonzerosforfeatureğ‘–thatwehaveobserveduptotimeğ‘¡.
Thisisac- tuallyquiteeasytoimplementatnomeaningfuloverhead.
However, itfailswheneverwe donotquitehavesparsitybutratherjustdatawherethegradientsareoftenverysmalland onlyrarelylarge.
Afterall, itisunclearwhereonewoulddrawthelinebetweensomething thatqualifiesasanobservedfeatureornot.
Adagradby Duchietal.
(2011)addressesthisbyreplacingtherathercrudecounterğ‘ â€ğ‘–,ğ‘¡â€ by an aggregate of the squares of previously observed gradients.
In particular, it uses ğ‘ â€ğ‘–,ğ‘¡â€š1â€ = ğ‘ â€ğ‘–,ğ‘¡â€â€šâ€ğœ• ğ‘– ğ‘“â€xâ€â€2asameanstoadjustthelearningrate.
Thishastwobenefits: first, wenolongerneedtodecidejustwhenagradientislargeenough.
Second, itscales automaticallywiththemagnitudeofthegradients.
Coordinatesthatroutinelycorrespond to large gradients are scaled down significantly, whereas others with small gradients re- ceiveamuchmoregentletreatment.
Inpracticethisleadstoaveryeffectiveoptimization procedureforcomputationaladvertisingandrelatedproblems.
Butthishidessomeofthe additionalbenefitsinherentin Adagradthatarebestunderstoodinthecontextofprecondi- tioning.
12.7.2 Preconditioning Convex optimization problems are good for analyzing the characteristics of algorithms.
Afterall, formostnonconvexproblemsitisdifficulttoderivemeaningfultheoreticalguar- antees, butintuitionandinsightoftencarryover.
Letâ€™slookattheproblemofminimizing ğ‘“â€xâ€ = 1x>Qxâ€šc>xâ€šğ‘.
2 Aswesawin Section12.6, itispossibletorewritethisproblemintermsofitseigendecom- position Q=U>ğš²Utoarriveatamuchsimplifiedproblemwhereeachcoordinatecanbe solvedindividually: 1 ğ‘“â€xâ€ = ğ‘“Â¯â€xÂ¯â€ = xÂ¯ >ğš²xÂ¯ â€šcÂ¯ > xÂ¯ â€šğ‘.
(12.7.1) 2 HereweusedxÂ¯ = UxandconsequentlycÂ¯ = Uc.
Themodifiedproblemhasasitsmin- imizerxÂ¯ = ğš² 1cÂ¯ andminimumvalue 1cÂ¯ >ğš² 1cÂ¯ â€šğ‘.
Thisismucheasiertocompute 2 sinceğš²isadiagonalmatrixcontainingtheeigenvaluesof Q.
Ifweperturbcslightlywewouldhopetofindonlyslightchangesintheminimizerof ğ‘“.
Unfortunatelythisisnotthecase.
Whileslightchangesincleadtoequallyslightchanges in cÂ¯, this is not the case for the minimizer of ğ‘“ (and of ğ‘“Â¯ respectively).
Whenever the eigenvalues ğš² ğ‘– are large we will see only small changes in ğ‘¥Â¯ğ‘– and in the minimum of ğ‘“Â¯.
Conversely, forsmallğš² ğ‘– changesinğ‘¥Â¯ğ‘– canbedramatic.
Theratiobetweenthelargestand thesmallesteigenvalueiscalledtheconditionnumberofanoptimizationproblem.
ğš² ğœ… = 1.
(12.7.2) ğš² ğ‘‘ Iftheconditionnumberğœ…islarge, itisdifficulttosolvetheoptimizationproblemaccurately.
Weneedtoensurethatwearecarefulingettingalargedynamicrangeofvaluesright.
Our 521 Adagrad analysisleadstoanobvious, albeitsomewhatnaivequestion: couldnâ€™twesimplyâ€œfixâ€the problembydistortingthespacesuchthatalleigenvaluesare1.
Intheorythisisquiteeasy: weonlyneedtheeigenvaluesandeigenvectorsof Qtorescaletheproblemfromxtoone inz d = efğš² 2 1 Ux.
Inthenewcoordinatesystemx>Qxcouldbesimplifiedtokzk2.
Alas, this is a rather impractical suggestion.
Computing eigenvalues and eigenvectors is in general muchmoreexpensivethansolvingtheactualproblem.
While computing eigenvalues exactly might be expensive, guessing them and computing themevensomewhatapproximatelymayalreadybealotbetterthannotdoinganythingat all.
Inparticular, wecouldusethediagonalentriesof Qandrescaleitaccordingly.
Thisis muchcheaperthancomputingeigenvalues.
QËœ =diag 1 2 â€Qâ€Qdiag 2 1â€Qâ€.
(12.7.3) p Inthiscasewehave QËœ ğ‘–ğ‘— =Qğ‘–ğ‘— Qğ‘–ğ‘–Qğ‘—ğ‘— andspecifically QËœ ğ‘–ğ‘– =1forallğ‘–.
Inmostcases this simplifies the condition number considerably.
For instance, the cases we discussed previously, this would entirely eliminate the problem at hand since the problem is axis aligned.
Unfortunatelywefaceyetanotherproblem: indeeplearningwetypicallydonotevenhave accesstothesecondderivativeoftheobjectivefunction: forx2Rğ‘‘ thesecondderivative evenonaminibatchmayrequire Oâ€ğ‘‘2â€spaceandworktocompute, thusmakingitpracti- callyinfeasible.
Theingeniousideaof Adagradistouseaproxyforthatelusivediagonal ofthe Hessianthatisbothrelativelycheaptocomputeandeffectiveâ€”themagnitudeofthe gradientitself.
Inordertoseewhythisworks, letâ€™slookat ğ‘“Â¯â€xÂ¯â€.
Wehavethat ğœ• ğ‘“Â¯â€xÂ¯â€ =ğš²xÂ¯ â€šcÂ¯ =ğš²â€xÂ¯ xÂ¯ â€, (12.7.4) xÂ¯ 0 wherexÂ¯ istheminimizerof ğ‘“Â¯.
Hencethemagnitudeofthegradientdependsbothonğš² 0 andthedistancefromoptimality.
IfxÂ¯ xÂ¯ didnotchange, thiswouldbeallthatisneeded.
0 Afterall, inthiscasethemagnitudeofthegradient ğœ• ğ‘“Â¯â€xÂ¯â€ suffices.
Since Ada Gradisa xÂ¯ stochasticgradientdescentalgorithm, wewillseegradientswithnonzerovarianceevenat optimality.
Asaresultwecansafelyusethevarianceofthegradientsasacheapproxyfor thescaleofthe Hessian.
Athoroughanalysisisbeyondthescopeofthissection(itwould beseveralpages).
Wereferthereaderto(Duchietal.,2011)fordetails.
12.7.3 The Algorithm Letâ€™sformalizethediscussionfromabove.
Weusethevariablesğ‘¡ toaccumulatepastgra- dientvarianceasfollows.
gğ‘¡ =ğœ• w ğ‘™â€ğ‘¦ ğ‘¡ , ğ‘“â€xğ‘¡ , wâ€â€, sğ‘¡ =sğ‘¡ 1 â€šg ğ‘¡ 2, (12.7.5) ğœ‚ wğ‘¡ =wğ‘¡ 1 p sğ‘¡ â€šğœ– gğ‘¡ .
522 Optimization Algorithms Heretheoperationareappliedcoordinatewise.
Thatis, v2hasentriesğ‘£2.
Likewise p1 has ğ‘– ğ‘£ entries p1 ğ‘£ğ‘– andu vhasentriesğ‘¢ ğ‘– ğ‘£ ğ‘–.
Asbeforeğœ‚isthelearningrateandğœ– isanadditive constantthatensuresthatwedonotdivideby0.
Last, weinitializes =0.
0 Justlikeinthecaseofmomentumweneedtokeeptrackofanauxiliaryvariable, inthis casetoallowforanindividuallearningratepercoordinate.
Thisdoesnotincreasethecost of Adagradsignificantlyrelativeto SGD, simplysincethemaincostistypicallytocompute ğ‘™â€ğ‘¦ ğ‘¡ , ğ‘“â€xğ‘¡ , wâ€â€anditsderivative.
Notethataccumulatingsquaredgradientsinsğ‘¡ meansthatsğ‘¡ growsessentiallyatlinearrate (somewhat slower than linearly in practice, since the gradients initially diminish).
This leads to an Oâ€ğ‘¡ 1 2 â€ learning rate, albeit adjusted on a per coordinate basis.
For convex problemsthisisperfectlyadequate.
Indeeplearning, though, wemightwanttodecrease thelearningraterathermoreslowly.
Thisledtoanumberof Adagradvariantsthatwewill discussinthesubsequentchapters.
Fornowletâ€™sseehowitbehavesinaquadraticconvex problem.
Weusethesameproblemasbefore: ğ‘“â€xâ€ =0.1ğ‘¥2â€š2ğ‘¥2.
(12.7.6) 1 2 Wearegoingtoimplement Adagradusingthesamelearningratepreviously, i.
e.,ğœ‚ =0.4.
Aswecansee, theiterativetrajectoryoftheindependentvariableissmoother.
However, duetothecumulativeeffectofğ’” ğ‘¡, thelearningratecontinuouslydecays, sotheindependent variabledoesnotmoveasmuchduringlaterstagesofiteration.
%matplotlib inline import math import torch from d2l import torch as d2l def adagrad_2d(x1, x2, s1, s2): eps = 1e-6 g1, g2 = 0.2 * x1, 4 * x2 s1 += g1 ** 2 s2 += g2 ** 2 x1 -= eta / math.
sqrt(s1 + eps) * g1 x2 -= eta / math.
sqrt(s2 + eps) * g2 return x1, x2, s1, s2 def f_2d(x1, x2): return 0.1 * x1 ** 2 + 2 * x2 ** 2 eta = 0.4 d2l.
show_trace_2d(f_2d, d2l.
train_2d(adagrad_2d)) epoch 20, x1: -2.382563, x2: -0.158591 Asweincreasethelearningrateto2weseemuchbetterbehavior.
Thisalreadyindicates thatthedecreaseinlearningratemightberatheraggressive, eveninthenoise-freecaseand weneedtoensurethatparametersconvergeappropriately.
523 Adagrad eta = 2 d2l.
show_trace_2d(f_2d, d2l.
train_2d(adagrad_2d)) epoch 20, x1: -0.002295, x2: -0.000000 12.7.4 Implementationfrom Scratch Just like the momentum method, Adagrad needs to maintain a state variable of the same shapeastheparameters.
def init_adagrad_states(feature_dim): s_w = torch.
zeros((feature_dim, 1)) s_b = torch.
zeros(1) return (s_w, s_b) def adagrad(params, states, hyperparams): eps = 1e-6 for p, s in zip(params, states): with torch.
no_grad(): s[:] += torch.
square(p.
grad) p[:] -= hyperparams['lr'] * p.
grad / torch.
sqrt(s + eps) p.
grad.
data.
zero_() Compared to the experiment in Section 12.5 we use a larger learning rate to train the model.
524 Optimization Algorithms data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) d2l.
train_ch11(adagrad, init_adagrad_states(feature_dim), {'lr': 0.1}, data_iter, feature_dim); loss: 0.243, 0.162 sec/epoch 12.7.5 Concise Implementation Using the Trainer instance of the algorithm adagrad, we can invoke the Adagrad algo- rithmin Gluon.
trainer = torch.
optim.
Adagrad d2l.
train_concise_ch11(trainer, {'lr': 0.1}, data_iter) loss: 0.242, 0.129 sec/epoch 12.7.6 Summary Adagraddecreasesthelearningratedynamicallyonaper-coordinatebasis.
It uses the magnitude of the gradient as a means of adjusting how quickly progress is achieved-coordinateswithlargegradientsarecompensatedwithasmallerlearning rate.
525 RMSProp Computingtheexactsecondderivativeistypicallyinfeasibleindeeplearningproblems duetomemoryandcomputationalconstraints.
Thegradientcanbeausefulproxy.
Iftheoptimizationproblemhasaratherunevenstructure Adagradcanhelpmitigatethe distortion.
Adagradisparticularlyeffectiveforsparsefeatureswherethelearningrateneedstode- creasemoreslowlyforinfrequentlyoccurringterms.
Ondeeplearningproblems Adagradcansometimesbetooaggressiveinreducinglearn- ingrates.
Wewilldiscussstrategiesformitigatingthisinthecontextof Section12.10.
12.7.7 Exercises 1.
Provethatforanorthogonalmatrix Uandavectorcthefollowingholds: kc ffik = 2 k Uc Uffik .
Whydoesthismeanthatthemagnitudeofperturbationsdoesnotchange 2 afteranorthogonalchangeofvariables? 2.
Tryout Adagradfor ğ‘“â€xâ€ =0.1ğ‘¥2â€š2ğ‘¥2andalsofortheobjectivefunctionwasrotated 1 2 by45degrees, i.
e., ğ‘“â€xâ€ =0.1â€ğ‘¥ â€šğ‘¥ â€2â€š2â€ğ‘¥ ğ‘¥ â€2.
Doesitbehavedifferently? 1 2 1 2 177 3.
Prove Gerschgorinâ€™sc Ë ircletheorem177 whichstatesthateigenvaluesğœ† ğ‘– ofamatrix M satisfyjğœ† ğ‘– Mğ‘—ğ‘— j ğ‘˜â‰ ğ‘— j Mğ‘—ğ‘˜ jforatleastonechoiceof ğ‘—.
4.
What does Gerschgorinâ€™s theorem tell us about the eigenvalues of the diagonally pre- conditionedmatrixdiag 1 2 â€Mâ€Mdiag 1 2 â€Mâ€? 5.
Tryout Adagradforaproperdeepnetwork, suchas Section7.6whenappliedto Fashion- MNIST.
6.
Howwouldyouneedtomodify Adagradtoachievealessaggressivedecayinlearning rate? 178 Discussions178.
12.8 RMSProp One of the key issues in Section 12.7 is that the learning rate decreases at a predefined scheduleofeffectively Oâ€ğ‘¡ 2 1â€.
Whilethisisgenerallyappropriateforconvexproblems, itmightnotbeidealfornonconvexones, suchasthoseencounteredindeeplearning.
Yet, thecoordinate-wiseadaptivityof Adagradishighlydesirableasapreconditioner.
Tielemanand Hinton(2012)proposedthe RMSPropalgorithmasasimplefixtodecouple rateschedulingfromcoordinate-adaptivelearningrates.
Theissueisthat Adagradaccu- mulates the squares of the gradient gğ‘¡ into a state vector sğ‘¡ = sğ‘¡ 1 â€šg ğ‘¡ 2.
As a result sğ‘¡ keeps on growing without bound due to the lack of normalization, essentially linearly as thealgorithmconverges.
526 Optimization Algorithms One way of fixing this problem would be to use sğ‘¡ ğ‘¡.
For reasonable distributions of gğ‘¡ this will converge.
Unfortunately it might take a very long time until the limit behavior startstomattersincetheprocedureremembersthefulltrajectoryofvalues.
Analternative is to use a leaky average in the same way we used in the momentum method, i.
e., sğ‘¡ ğ›¾sğ‘¡ 1 â€š â€1 ğ›¾â€g ğ‘¡ 2 for some parameter ğ›¾ > 0.
Keeping all other parts unchanged yields RMSProp.
12.8.1 The Algorithm Letâ€™swriteouttheequationsindetail.
sğ‘¡ ğ›¾sğ‘¡ 1 â€šâ€1 ğ›¾â€g ğ‘¡ 2, ğœ‚ (12.8.1) xğ‘¡ xğ‘¡ 1 p sğ‘¡ â€šğœ– gğ‘¡ .
Theconstantğœ– >0istypicallysetto10 6toensurethatwedonotsufferfromdivisionby zerooroverlylargestepsizes.
Giventhisexpansionwearenowfreetocontrolthelearning rate ğœ‚ independently of the scaling that is applied on a per-coordinate basis.
In terms of leaky averages we can apply the same reasoning as previously applied in the case of the momentummethod.
Expandingthedefinitionofsğ‘¡ yields sğ‘¡ = â€1 ğ›¾â€g ğ‘¡ 2â€šğ›¾sğ‘¡ 1 (12.8.2) = â€1 ğ›¾â€ g ğ‘¡ 2â€šğ›¾g ğ‘¡ 2 1 â€šğ›¾2gğ‘¡ 2 â€š..., .
1 ğ›¾ normalizedto1withahalf-lifetimeofanobservationofğ›¾ 1.
Letâ€™svisualizetheweights forthepast40timestepsforvariouschoicesofğ›¾.
import math import torch from d2l import torch as d2l d2l.
set_figsize() gammas = [0.95, 0.9, 0.8, 0.7] for gamma in gammas: x = torch.
arange(40).
detach().
numpy() d2l.
plt.
plot(x, (1-gamma) * gamma ** x, label=f'gamma = {gamma:.2f}') d2l.
plt.
xlabel('time'); 12.8.2 Implementationfrom Scratch As before we use the quadratic function ğ‘“â€xâ€ = 0.1ğ‘¥2 â€š2ğ‘¥2 to observe the trajectory of 1 2 RMSProp.
Recall that in Section 12.7, when we used Adagrad with a learning rate of 0.4, the variables moved only very slowly in the later stages of the algorithm since the learningratedecreasedtooquickly.
Sinceğœ‚ iscontrolledseparatelythisdoesnothappen with RMSProp.
527 RMSProp def rmsprop_2d(x1, x2, s1, s2): g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6 s1 = gamma * s1 + (1 - gamma) * g1 ** 2 s2 = gamma * s2 + (1 - gamma) * g2 ** 2 x1 -= eta / math.
sqrt(s1 + eps) * g1 x2 -= eta / math.
sqrt(s2 + eps) * g2 return x1, x2, s1, s2 def f_2d(x1, x2): return 0.1 * x1 ** 2 + 2 * x2 ** 2 eta, gamma = 0.4, 0.9 d2l.
show_trace_2d(f_2d, d2l.
train_2d(rmsprop_2d)) epoch 20, x1: -0.010599, x2: 0.000000 Next, weimplement RMSProp to be used in a deep network.
This is equallystraightfor- ward.
def init_rmsprop_states(feature_dim): s_w = torch.
zeros((feature_dim, 1)) s_b = torch.
zeros(1) return (s_w, s_b) def rmsprop(params, states, hyperparams): gamma, eps = hyperparams['gamma'], 1e-6 (continuesonnextpage) 528 Optimization Algorithms (continuedfrompreviouspage) for p, s in zip(params, states): with torch.
no_grad(): s[:] = gamma * s + (1 - gamma) * torch.
square(p.
grad) p[:] -= hyperparams['lr'] * p.
grad / torch.
sqrt(s + eps) p.
grad.
data.
zero_() Wesettheinitiallearningrateto0.01andtheweightingtermğ›¾to0.9.
Thatis, saggregates onaverageoverthepast1 â€1 ğ›¾â€ =10observationsofthesquaregradient.
data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) d2l.
train_ch11(rmsprop, init_rmsprop_states(feature_dim), {'lr': 0.01, 'gamma': 0.9}, data_iter, feature_dim); loss: 0.245, 0.245 sec/epoch 12.8.3 Concise Implementation Since RMSPropisaratherpopularalgorithmitisalsoavailableinthe Trainerinstance.
Allweneedtodoisinstantiateitusinganalgorithmnamedrmsprop, assigning ğ›¾ tothe parametergamma1.
trainer = torch.
optim.
RMSprop d2l.
train_concise_ch11(trainer, {'lr': 0.01, 'alpha': 0.9}, data_iter) loss: 0.246, 0.129 sec/epoch 12.8.4 Summary RMSProp is very similar to Adagrad insofar as both use the square of the gradient to scalecoefficients.
RMSProp shares with momentum the leaky averaging.
However, RMSProp uses the techniquetoadjustthecoefficient-wisepreconditioner.
529 Adadelta Thelearningrateneedstobescheduledbytheexperimenterinpractice.
Thecoefficientğ›¾ determineshowlongthehistoryiswhenadjustingtheper-coordinate scale.
12.8.5 Exercises 1.
Whathappensexperimentallyifwesetğ›¾ =1? Why? 2.
Rotatetheoptimizationproblemtominimize ğ‘“â€xâ€ =0.1â€ğ‘¥ â€šğ‘¥ â€2â€š2â€ğ‘¥ ğ‘¥ â€2.
What 1 2 1 2 happenstotheconvergence? 3.
Tryoutwhathappensto RMSProponarealmachinelearningproblem, suchastraining on Fashion-MNIST.
Experimentwithdifferentchoicesforadjustingthelearningrate.
4.
Wouldyouwanttoadjustğ›¾ asoptimizationprogresses? Howsensitiveis RMSPropto this? 179 Discussions179.
12.9 Adadelta Adadelta is yet another variant of Ada Grad (Section 12.7).
The main difference lies in thefactthatitdecreasestheamountbywhichthelearningrateisadaptivetocoordinates.
Moreover, traditionallyitreferredtoasnothavingalearningratesinceitusestheamountof changeitselfascalibrationforfuturechange.
Thealgorithmwasproposedin Zeiler(2012).
Itisfairlystraightforward, giventhediscussionofpreviousalgorithmssofar.
12.9.1 The Algorithm Inanutshell, Adadeltausestwostatevariables, sğ‘¡ tostorealeakyaverageofthesecond momentofthegradientandÎ”xğ‘¡tostorealeakyaverageofthesecondmomentofthechange ofparametersinthemodelitself.
Notethatweusetheoriginalnotationandnamingofthe authors for compatibility with other publications and implementations (there is no other 530 Optimization Algorithms realreasonwhyoneshouldusedifferent Greekvariablestoindicateaparameterserving thesamepurposeinmomentum, Adagrad, RMSProp, and Adadelta).
Herearethetechnicaldetailsof Adadelta.
GiventheparameterdujourisğœŒ, weobtainthe followingleakyupdatessimilarlyto Section12.8: sğ‘¡ = ğœŒsğ‘¡ 1 â€šâ€1 ğœŒâ€g ğ‘¡ 2.
(12.9.1) The difference to Section 12.8 is that we perform updates with the rescaled gradient g0 , ğ‘¡ i.
e., xğ‘¡ =xğ‘¡ 1 g ğ‘¡ 0.
(12.9.2) Sowhatistherescaledgradientg0 ? Wecancalculateitasfollows: ğ‘¡ p g ğ‘¡ 0 = Î” p x s ğ‘¡ ğ‘¡ â€š 1 ğœ– â€šğœ– gğ‘¡ , (12.9.3) whereÎ”xğ‘¡ 1 istheleakyaverageofthesquaredrescaledgradientsg ğ‘¡ 0 .
WeinitializeÎ”x 0 tobe0andupdateitateachstepwithg0 , i.
e., ğ‘¡ Î”xğ‘¡ = ğœŒÎ”xğ‘¡ 1 â€šâ€1 ğœŒâ€g ğ‘¡ 02, (12.9.4) andğœ– (asmallvaluesuchas10 5)isaddedtomaintainnumericalstability.
12.9.2 Implementation Adadeltaneedstomaintaintwostatevariablesforeachvariable, sğ‘¡ andÎ”xğ‘¡.
Thisyields thefollowingimplementation.
%matplotlib inline import torch from d2l import torch as d2l def init_adadelta_states(feature_dim): s_w, s_b = torch.
zeros((feature_dim, 1)), torch.
zeros(1) delta_w, delta_b = torch.
zeros((feature_dim, 1)), torch.
zeros(1) return ((s_w, delta_w), (s_b, delta_b)) def adadelta(params, states, hyperparams): rho, eps = hyperparams['rho'], 1e-5 for p, (s, delta) in zip(params, states): with torch.
no_grad(): # In-place updates via [:] s[:] = rho * s + (1 - rho) * torch.
square(p.
grad) g = (torch.
sqrt(delta + eps) / torch.
sqrt(s + eps)) * p.
grad p[:] -= g delta[:] = rho * delta + (1 - rho) * g * g p.
grad.
data.
zero_() Choosing ğœŒ = 0.9amountstoahalf-lifetimeof10foreachparameterupdate.
Thistends toworkquitewell.
Wegetthefollowingbehavior.
531 Adadelta data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) d2l.
train_ch11(adadelta, init_adadelta_states(feature_dim), {'rho': 0.9}, data_iter, feature_dim); loss: 0.245, 0.160 sec/epoch Foraconciseimplementationwesimplyusethe Adadeltaalgorithmfromhigh-level APIs.
Thisyieldsthefollowingone-linerforamuchmorecompactinvocation.
trainer = torch.
optim.
Adadelta d2l.
train_concise_ch11(trainer, {'rho': 0.9}, data_iter) loss: 0.243, 0.119 sec/epoch 12.9.3 Summary Adadeltahasnolearningrateparameter.
Instead, itusestherateofchangeintheparam- etersitselftoadaptthelearningrate.
Adadelta requires two state variables to store the second moments of gradient and the changeinparameters.
Adadeltausesleakyaveragestokeeparunningestimateoftheappropriatestatistics.
532 Optimization Algorithms 12.9.4 Exercises 1.
Adjustthevalueof ğœŒ.
Whathappens? 2.
Showhowtoimplementthealgorithmwithouttheuseofg0 .
Whymightthisbeagood ğ‘¡ idea? 3.
Is Adadeltareallylearningratefree? Couldyoufindoptimizationproblemsthatbreak Adadelta? 4.
Compare Adadeltato Adagradand RMSproptodiscusstheirconvergencebehavior.
180 Discussions180.
12.10 Adam In the discussions leading up to this section we encountered a number of techniques for efficientoptimization.
Letâ€™srecapthemindetailhere: We saw that Section 12.4 is more effective than Gradient Descent when solving opti- mizationproblems, e.
g., duetoitsinherentresiliencetoredundantdata.
We saw that Section 12.5 affords significant additional efficiency arising from vector- ization, usinglargersetsofobservationsinoneminibatch.
Thisisthekeytoefficient multi-machine, multi-GPUandoverallparallelprocessing.
Section12.6addedamechanismforaggregatingahistoryofpastgradientstoaccelerate convergence.
Section12.7usedper-coordinatescalingtoallowforacomputationallyefficientprecon- ditioner.
Section12.8decoupledper-coordinatescalingfromalearningrateadjustment.
Adam (Kingma and Ba, 2014) combines all these techniques into one efficient learning algorithm.
Asexpected, thisisanalgorithmthathasbecomeratherpopularasoneofthe morerobustandeffectiveoptimizationalgorithmstouseindeeplearning.
Itisnotwithout issues, though.
Inparticular,(Reddietal.,2019)showthattherearesituationswhere Adam candivergeduetopoorvariancecontrol.
Inafollow-upwork Zaheeretal.
(2018)proposed ahotfixto Adam, called Yogiwhichaddressestheseissues.
Moreonthislater.
Fornow letâ€™sreviewthe Adamalgorithm.
12.10.1 The Algorithm Oneofthekeycomponentsof Adamisthatitusesexponentialweightedmovingaverages (alsoknownasleakyaveraging)toobtainanestimateofboththemomentumandalsothe 533 Adam secondmomentofthegradient.
Thatis, itusesthestatevariables vğ‘¡ ğ›½ 1 vğ‘¡ 1 â€šâ€1 ğ›½ 1 â€gğ‘¡ , (12.10.1) sğ‘¡ ğ›½ 2 sğ‘¡ 1 â€šâ€1 ğ›½ 2 â€g ğ‘¡ 2.
Here ğ›½ and ğ›½ are nonnegative weighting parameters.
Common choices for them are 1 2 ğ›½ =0.9and ğ›½ =0.999.
Thatis, thevarianceestimatemovesmuchmoreslowlythanthe 1 2 momentumterm.
Notethatifweinitializev =s =0wehaveasignificantamountofbias 0 0 Ë initiallytowardssmallervalues.
Thiscanbeaddressedbyusingthefactthat ğ‘¡ 1ğ›½ğ‘– = 1 ğ›½ğ‘¡ ğ‘–=0 1 ğ›½ tore-normalizeterms.
Correspondinglythenormalizedstatevariablesaregivenby vË†ğ‘¡ = 1 vğ‘¡ ğ›½ğ‘¡ andsË†ğ‘¡ = 1 sğ‘¡ ğ›½ğ‘¡ .
(12.10.2) 1 2 Armed with the proper estimates we can now write out the update equations.
First, we rescalethegradientinamannerverymuchakintothatof RMSProptoobtain g ğ‘¡ 0 = p s ğœ‚ Ë†ğ‘¡ vË† â€š ğ‘¡ ğœ– .
(12.10.3) Unlike RMSPropourupdateusesthemomentumvË†ğ‘¡ ratherthanthegradientitself.
More- over, thereisaslightcosmeticdifferenceastherescalinghappensusing p 1 insteadof sË†ğ‘¡â€šğœ– p 1 .
Theformerworksarguablyslightlybetterinpractice, hencethedeviationfrom RM- sË†ğ‘¡â€šğœ– SProp.
Typically we pick ğœ– = 10 6 for a good trade-off between numerical stability and fidelity.
Nowwehaveallthepiecesinplacetocomputeupdates.
Thisisslightlyanticlimacticand wehaveasimpleupdateoftheform xğ‘¡ xğ‘¡ 1 g ğ‘¡ 0.
(12.10.4) Reviewing the design of Adam its inspiration is clear.
Momentum and scale are clearly visible in the state variables.
Their rather peculiar definition forces us to debias terms (thiscouldbefixedbyaslightlydifferentinitializationandupdatecondition).
Second, the combination of both terms is pretty straightforward, given RMSProp.
Last, the explicit learningrateğœ‚allowsustocontrolthesteplengthtoaddressissuesofconvergence.
12.10.2 Implementation Implementing Adamfromscratchisnotverydaunting.
Forconveniencewestorethetime stepcounterğ‘¡ inthehyperparamsdictionary.
Beyondthatallisstraightforward.
%matplotlib inline import torch from d2l import torch as d2l def init_adam_states(feature_dim): v_w, v_b = torch.
zeros((feature_dim, 1)), torch.
zeros(1) s_w, s_b = torch.
zeros((feature_dim, 1)), torch.
zeros(1) return ((v_w, s_w), (v_b, s_b)) (continuesonnextpage) 534 Optimization Algorithms (continuedfrompreviouspage) def adam(params, states, hyperparams): beta1, beta2, eps = 0.9, 0.999, 1e-6 for p, (v, s) in zip(params, states): with torch.
no_grad(): v[:] = beta1 * v + (1 - beta1) * p.
grad s[:] = beta2 * s + (1 - beta2) * torch.
square(p.
grad) v_bias_corr = v / (1 - beta1 ** hyperparams['t']) s_bias_corr = s / (1 - beta2 ** hyperparams['t']) p[:] -= hyperparams['lr'] * v_bias_corr / (torch.
sqrt(s_bias_corr) + eps) p.
grad.
data.
zero_() hyperparams['t'] += 1 Wearereadytouse Adamtotrainthemodel.
Weusealearningrateofğœ‚ =0.01.
data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) d2l.
train_ch11(adam, init_adam_states(feature_dim), {'lr': 0.01, 't': 1}, data_iter, feature_dim); loss: 0.243, 0.193 sec/epoch Amoreconciseimplementationisstraightforwardsinceadamisoneofthealgorithmspro- vided as part of the Gluon trainer optimization library.
Hence we only need to pass configurationparametersforanimplementationin Gluon.
trainer = torch.
optim.
Adam d2l.
train_concise_ch11(trainer, {'lr': 0.01}, data_iter) loss: 0.243, 0.152 sec/epoch 12.10.3 Yogi Oneoftheproblemsof Adamisthatitcanfailtoconvergeeveninconvexsettingswhenthe secondmomentestimateinsğ‘¡ blowsup.
Asafix Zaheeretal.
(2018)proposedarefined 535 Adam update (and initialization) for sğ‘¡.
To understand whatâ€™s going on, letâ€™s rewrite the Adam updateasfollows: sğ‘¡ sğ‘¡ 1 â€šâ€1 ğ›½ 2 â€ g ğ‘¡ 2 sğ‘¡ 1 .
(12.10.5) Wheneverg ğ‘¡ 2hashighvarianceorupdatesaresparse, sğ‘¡mightforgetpastvaluestooquickly.
Apossiblefixforthisistoreplaceg ğ‘¡ 2 sğ‘¡ 1 byg ğ‘¡ 2 sgnâ€g ğ‘¡ 2 sğ‘¡ 1 â€.
Nowthemagnitudeofthe updatenolongerdependsontheamountofdeviation.
Thisyieldsthe Yogiupdates sğ‘¡ sğ‘¡ 1 â€šâ€1 ğ›½ 2 â€g ğ‘¡ 2 sgnâ€g ğ‘¡ 2 sğ‘¡ 1 â€.
(12.10.6) Theauthorsfurthermoreadvisetoinitializethemomentumonalargerinitialbatchrather thanjustinitialpointwiseestimate.
Weomitthedetailssincetheyarenotmaterialtothe discussionandsinceevenwithoutthisconvergenceremainsprettygood.
def yogi(params, states, hyperparams): beta1, beta2, eps = 0.9, 0.999, 1e-3 for p, (v, s) in zip(params, states): with torch.
no_grad(): v[:] = beta1 * v + (1 - beta1) * p.
grad s[:] = s + (1 - beta2) * torch.
sign( torch.
square(p.
grad) - s) * torch.
square(p.
grad) v_bias_corr = v / (1 - beta1 ** hyperparams['t']) s_bias_corr = s / (1 - beta2 ** hyperparams['t']) p[:] -= hyperparams['lr'] * v_bias_corr / (torch.
sqrt(s_bias_corr) + eps) p.
grad.
data.
zero_() hyperparams['t'] += 1 data_iter, feature_dim = d2l.
get_data_ch11(batch_size=10) d2l.
train_ch11(yogi, init_adam_states(feature_dim), {'lr': 0.01, 't': 1}, data_iter, feature_dim); loss: 0.243, 0.165 sec/epoch 12.10.4 Summary Adam combines features of many optimization algorithms into a fairly robust update rule.
536 Optimization Algorithms Createdonthebasisof RMSProp, Adamalsouses EWMAontheminibatchstochastic gradient.
Adamusesbiascorrectiontoadjustforaslowstartupwhenestimatingmomentumand asecondmoment.
Forgradientswithsignificantvariancewemayencounterissueswithconvergence.
They canbeamendedbyusinglargerminibatchesorbyswitchingtoanimprovedestimate forsğ‘¡.
Yogiofferssuchanalternative.
12.10.5 Exercises 1.
Adjustthelearningrateandobserveandanalyzetheexperimentalresults.
2.
Canyourewritemomentumandsecondmomentupdatessuchthatitdoesnotrequire biascorrection? 3.
Whydoyouneedtoreducethelearningrateğœ‚asweconverge? 4.
Trytoconstructacaseforwhich Adamdivergesand Yogiconverges? 181 Discussions181.
12.11 Learning Rate Scheduling Sofarweprimarilyfocusedonoptimizationalgorithmsforhowtoupdatetheweightvectors ratherthanontherateatwhichtheyarebeingupdated.
Nonetheless, adjustingthelearning rate is often just as important as the actual algorithm.
There are a number of aspects to consider: Mostobviouslythemagnitudeofthelearningratematters.
Ifitistoolarge, optimization diverges, if it is too small, it takes too long to train or weend up with a suboptimal result.
Wesawpreviouslythattheconditionnumberoftheproblemmatters(seee.
g., Section12.6fordetails).
Intuitivelyitistheratiooftheamountofchangeintheleast sensitivedirectionvs.
themostsensitiveone.
537 Learning Rate Scheduling Secondly, therateofdecayisjustasimportant.
Ifthelearningrateremainslargewemay simplyendupbouncingaroundtheminimumandthusnotreachoptimality.
Section 12.5discussedthisinsomedetailandweanalyzedperformanceguaranteesin Section 12.4.
Inshort, wewanttheratetodecay, butprobablymoreslowlythan Oâ€ğ‘¡ 1 2 â€which wouldbeagoodchoiceforconvexproblems.
Anotheraspectthatisequallyimportantisinitialization.
Thispertainsbothtohowthe parametersaresetinitially(review Section5.4fordetails)andalsohowtheyevolve initially.
Thisgoesunderthemonikerofwarmup, i.
e., howrapidlywestartmoving towardsthesolutioninitially.
Largestepsinthebeginningmightnotbebeneficial, in particularsincetheinitialsetofparametersisrandom.
Theinitialupdatedirections mightbequitemeaningless, too.
Lastly, there are a number of optimization variants that perform cyclical learning rate adjustment.
This is beyond the scope of the current chapter.
We recommend the readertoreviewdetailsin Izmailovetal.
(2018), e.
g., howtoobtainbettersolutions byaveragingoveranentirepathofparameters.
Giventhefactthatthereisalotofdetailneededtomanagelearningrates, mostdeeplearn- ingframeworkshavetoolstodealwiththisautomatically.
Inthecurrentchapterwewill reviewtheeffectsthatdifferentscheduleshaveonaccuracyandalsoshowhowthiscanbe managedefficientlyviaalearningratescheduler.
12.11.1 Toy Problem Webeginwithatoyproblemthatischeapenoughtocomputeeasily, yetsufficientlynon- trivialtoillustratesomeofthekeyaspects.
Forthatwepickaslightlymodernizedversion of Le Net(reluinsteadof sigmoidactivation, Max Poolingratherthan Average Pooling), asappliedto Fashion-MNIST.
Moreover, wehybridizethenetworkforperformance.
Since mostofthecodeisstandardwejustintroducethebasicswithoutfurtherdetaileddiscussion.
See Chapter7forarefresherasneeded.
%matplotlib inline import math import torch from torch import nn from torch.
optim import lr_scheduler from d2l import torch as d2l def net_fn(): model = nn.
Sequential( nn.
Conv2d(1, 6, kernel_size=5, padding=2), nn.
Re LU(), nn.
Max Pool2d(kernel_size=2, stride=2), nn.
Conv2d(6, 16, kernel_size=5), nn.
Re LU(), nn.
Max Pool2d(kernel_size=2, stride=2), nn.
Flatten(), nn.
Linear(16 * 5 * 5, 120), nn.
Re LU(), nn.
Linear(120, 84), nn.
Re LU(), nn.
Linear(84, 10)) (continuesonnextpage) 538 Optimization Algorithms (continuedfrompreviouspage) return model loss = nn.
Cross Entropy Loss() device = d2l.
try_gpu() batch_size = 256 train_iter, test_iter = d2l.
load_data_fashion_mnist(batch_size=batch_size) # The code is almost identical to `d2l.
train_ch6` defined in the # lenet section of chapter convolutional neural networks def train(net, train_iter, test_iter, num_epochs, loss, trainer, device, scheduler=None): net.
to(device) animator = d2l.
Animator(xlabel='epoch', xlim=[0, num_epochs], legend=['train loss', 'train acc', 'test acc']) for epoch in range(num_epochs): metric = d2l.
Accumulator(3) # train_loss, train_acc, num_examples for i, (X, y) in enumerate(train_iter): net.
train() trainer.
zero_grad() X, y = X.
to(device), y.
to(device) y_hat = net(X) l = loss(y_hat, y) l.
backward() trainer.
step() with torch.
no_grad(): metric.
add(l * X.
shape[0], d2l.
accuracy(y_hat, y), X.
shape[0]) train_loss = metric[0] / metric[2] train_acc = metric[1] / metric[2] if (i + 1) % 50 == 0: animator.
add(epoch + i / len(train_iter), (train_loss, train_acc, None)) test_acc = d2l.
evaluate_accuracy_gpu(net, test_iter) animator.
add(epoch+1, (None, None, test_acc)) if scheduler: if scheduler.__module__ == lr_scheduler.__name__: # Using Py Torch In-Built scheduler scheduler.
step() else: # Using custom defined scheduler for param_group in trainer.
param_groups: param_group['lr'] = scheduler(epoch) print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, ' f'test acc {test_acc:.3f}') Letâ€™shavealookatwhathappensifweinvokethisalgorithmwithdefaultsettings, suchas alearningrateof0.3andtrainfor30iterations.
Notehowthetrainingaccuracykeepson increasingwhileprogressintermsoftestaccuracystallsbeyondapoint.
Thegapbetween bothcurvesindicatesoverfitting.
539 Learning Rate Scheduling lr, num_epochs = 0.3, 30 net = net_fn() trainer = torch.
optim.
SGD(net.
parameters(), lr=lr) train(net, train_iter, test_iter, num_epochs, loss, trainer, device) train loss 0.145, train acc 0.944, test acc 0.877 12.11.2 Schedulers One way of adjusting the learning rate is to set it explicitly at each step.
This is conve- nientlyachievedbytheset_learning_ratemethod.
Wecouldadjustitdownwardafter everyepoch(orevenaftereveryminibatch), e.
g., inadynamicmannerinresponsetohow optimizationisprogressing.
lr = 0.1 trainer.
param_groups[0]["lr"] = lr print(f'learning rate is now {trainer.
param_groups[0]["lr"]:.2f}') learning rate is now 0.10 Moregenerallywewanttodefineascheduler.
Wheninvokedwiththenumberofupdates itreturnstheappropriatevalueofthelearningrate.
Letâ€™sdefineasimpleonethatsetsthe learningratetoğœ‚ =ğœ‚ 0 â€ğ‘¡â€š1â€ 1 2.
class Square Root Scheduler: def __init__(self, lr=0.1): self.
lr = lr def __call__(self, num_update): return self.
lr * pow(num_update + 1.0, -0.5) Letâ€™splotitsbehavioroverarangeofvalues.
scheduler = Square Root Scheduler(lr=0.1) d2l.
plot(torch.
arange(num_epochs), [scheduler(t) for t in range(num_epochs)]) 540 Optimization Algorithms Now letâ€™s see how this plays out for training on Fashion-MNIST.
We simply provide the schedulerasanadditionalargumenttothetrainingalgorithm.
net = net_fn() trainer = torch.
optim.
SGD(net.
parameters(), lr) train(net, train_iter, test_iter, num_epochs, loss, trainer, device, scheduler) train loss 0.273, train acc 0.900, test acc 0.886 Thisworkedquiteabitbetterthanpreviously.
Twothingsstandout: thecurvewasrather moresmooththanpreviously.
Secondly, therewaslessoverfitting.
Unfortunatelyitisnota well-resolvedquestionastowhycertainstrategiesleadtolessoverfittingintheory.
There issomeargumentthatasmallerstepsizewillleadtoparametersthatareclosertozeroand thussimpler.
However, thisdoesnotexplainthephenomenonentirelysincewedonotreally stopearlybutsimplyreducethelearningrategently.
12.11.3 Policies Whilewecannotpossiblycovertheentirevarietyoflearningrateschedulers, weattempt togiveabriefoverviewofpopularpoliciesbelow.
Commonchoicesarepolynomialdecay andpiecewiseconstantschedules.
Beyondthat, cosinelearningratescheduleshavebeen foundtoworkwellempiricallyonsomeproblems.
Lastly, onsomeproblemsitisbeneficial towarmuptheoptimizerpriortousinglargelearningrates.
541 Learning Rate Scheduling Factor Scheduler Onealternativetoapolynomialdecaywouldbeamultiplicativeone, thatisğœ‚ ğ‘¡â€š1 ğœ‚ ğ‘¡ ğ›¼ forğ›¼ 2 â€0,1â€.
Topreventthelearningratefromdecayingbeyondareasonablelowerbound theupdateequationisoftenmodifiedtoğœ‚ ğ‘¡â€š1 maxâ€ğœ‚ min ,ğœ‚ ğ‘¡ ğ›¼â€.
class Factor Scheduler: def __init__(self, factor=1, stop_factor_lr=1e-7, base_lr=0.1): self.
factor = factor self.
stop_factor_lr = stop_factor_lr self.
base_lr = base_lr def __call__(self, num_update): self.
base_lr = max(self.
stop_factor_lr, self.
base_lr * self.
factor) return self.
base_lr scheduler = Factor Scheduler(factor=0.9, stop_factor_lr=1e-2, base_lr=2.0) d2l.
plot(torch.
arange(50), [scheduler(t) for t in range(50)]) Thiscanalsobeaccomplishedbyabuilt-inschedulerin MXNetviathelr_scheduler.
Factor Schedulerobject.
Ittakesafewmoreparameters, suchaswarmupperiod, warmup mode(linearorconstant), themaximumnumberofdesiredupdates, etc.; Goingforward wewillusethebuilt-inschedulersasappropriateandonlyexplaintheirfunctionalityhere.
Asillustrated, itisfairlystraightforwardtobuildyourownschedulerifneeded.
Multi Factor Scheduler Acommonstrategyfortrainingdeepnetworksistokeepthelearningratepiecewisecon- stant and to decrease it by a given amount every so often.
That is, given a set of times whentodecreasetherate, suchasğ‘  = f5,10,20gdecreaseğœ‚ ğ‘¡â€š1 ğœ‚ ğ‘¡ ğ›¼wheneverğ‘¡ 2 ğ‘ .
Assumingthatthevaluesarehalvedateachstepwecanimplementthisasfollows.
net = net_fn() trainer = torch.
optim.
SGD(net.
parameters(), lr=0.5) scheduler = lr_scheduler.
Multi Step LR(trainer, milestones=[15, 30], gamma=0.5) def get_lr(trainer, scheduler): lr = scheduler.
get_last_lr()[0] trainer.
step() (continuesonnextpage) 542 Optimization Algorithms (continuedfrompreviouspage) scheduler.
step() return lr d2l.
plot(torch.
arange(num_epochs), [get_lr(trainer, scheduler) for t in range(num_epochs)]) The intuition behind this piecewise constant learning rate schedule is that one lets opti- mizationproceeduntilastationarypointhasbeenreachedintermsofthedistributionof weight vectors.
Then (and only then) do we decrease the rate such as to obtain a higher qualityproxytoagoodlocalminimum.
Theexamplebelowshowshowthiscanproduce everslightlybettersolutions.
train(net, train_iter, test_iter, num_epochs, loss, trainer, device, scheduler) train loss 0.194, train acc 0.927, test acc 0.869 Cosine Scheduler Aratherperplexingheuristicwasproposedby Loshchilovand Hutter(2016).
Itrelieson theobservationthatwemightnotwanttodecreasethelearningratetoodrasticallyinthe beginningandmoreover, thatwemightwanttoâ€œrefineâ€thesolutionintheendusingavery small learning rate.
This results in a cosine-like schedule with the following functional 543 Learning Rate Scheduling formforlearningratesintherangeğ‘¡ 2 Â»0,ğ‘‡â€¦.
ğœ‚ ğœ‚ ğœ‚ ğ‘¡ =ğœ‚ ğ‘‡ â€š 0 ğ‘‡ â€1â€šcosâ€ğœ‹ğ‘¡ ğ‘‡â€â€ (12.11.1) 2 Hereğœ‚ 0 istheinitiallearningrate,ğœ‚ ğ‘‡ isthetargetrateattimeğ‘‡.
Furthermore, forğ‘¡ > ğ‘‡ wesimplypinthevaluetoğœ‚ ğ‘‡ withoutincreasingitagain.
Inthefollowingexample, weset themaxupdatestepğ‘‡ =20.
class Cosine Scheduler: def __init__(self, max_update, base_lr=0.01, final_lr=0, warmup_steps=0, warmup_begin_lr=0): self.
base_lr_orig = base_lr self.
max_update = max_update self.
final_lr = final_lr self.
warmup_steps = warmup_steps self.
warmup_begin_lr = warmup_begin_lr self.
max_steps = self.
max_update - self.
warmup_steps def get_warmup_lr(self, epoch): increase = (self.
base_lr_orig - self.
warmup_begin_lr) \ * float(epoch) / float(self.
warmup_steps) return self.
warmup_begin_lr + increase def __call__(self, epoch): if epoch < self.
warmup_steps: return self.
get_warmup_lr(epoch) if epoch <= self.
max_update: self.
base_lr = self.
final_lr + ( self.
base_lr_orig - self.
final_lr) * (1 + math.
cos( math.
pi * (epoch - self.
warmup_steps) / self.
max_steps)) / 2 return self.
base_lr scheduler = Cosine Scheduler(max_update=20, base_lr=0.3, final_lr=0.01) d2l.
plot(torch.
arange(num_epochs), [scheduler(t) for t in range(num_epochs)]) Inthecontextofcomputervisionthisschedulecanleadtoimprovedresults.
Note, though, thatsuchimprovementsarenotguaranteed(ascanbeseenbelow).
net = net_fn() trainer = torch.
optim.
SGD(net.
parameters(), lr=0.3) train(net, train_iter, test_iter, num_epochs, loss, trainer, device, scheduler) 544 Optimization Algorithms train loss 0.159, train acc 0.942, test acc 0.904 Warmup Insomecasesinitializingtheparametersisnotsufficienttoguaranteeagoodsolution.
This is particularly a problem for some advanced network designs that may lead to unstable optimization problems.
We could address this by choosing a sufficiently small learning ratetopreventdivergenceinthebeginning.
Unfortunatelythismeansthatprogressisslow.
Conversely, alargelearningrateinitiallyleadstodivergence.
Arathersimplefixforthisdilemmaistouseawarmupperiodduringwhichthelearningrate increasestoitsinitialmaximumandtocooldowntherateuntiltheendoftheoptimization process.
Forsimplicityonetypicallyusesalinearincreaseforthispurpose.
Thisleadsto ascheduleoftheformindicatedbelow.
scheduler = Cosine Scheduler(20, warmup_steps=5, base_lr=0.3, final_lr=0.01) d2l.
plot(torch.
arange(num_epochs), [scheduler(t) for t in range(num_epochs)]) Notethatthenetworkconvergesbetterinitially(inparticularobservetheperformancedur- ingthefirst5epochs).
net = net_fn() trainer = torch.
optim.
SGD(net.
parameters(), lr=0.3) train(net, train_iter, test_iter, num_epochs, loss, trainer, device, scheduler) 545 Learning Rate Scheduling train loss 0.181, train acc 0.934, test acc 0.901 Warmupcanbeappliedtoanyscheduler(notjustcosine).
Foramoredetaileddiscussion oflearningrateschedulesandmanymoreexperimentsseealso(Gotmareetal.,2018).
In particular they find that a warmup phase limits the amount of divergence of parameters in very deep networks.
This makes intuitively sense since we would expect significant divergence due to random initialization in those parts of the network that take the most timetomakeprogressinthebeginning.
12.11.4 Summary Decreasing the learning rate during training can lead to improved accuracy and (most perplexingly)reducedoverfittingofthemodel.
Apiecewisedecreaseofthelearningratewheneverprogresshasplateauediseffective inpractice.
Essentiallythisensuresthatweconvergeefficientlytoasuitablesolution andonlythenreducetheinherentvarianceoftheparametersbyreducingthelearning rate.
Cosineschedulersarepopularforsomecomputervisionproblems.
Seee.
g., Gluon CV 182 182 fordetailsofsuchascheduler.
Awarmupperiodbeforeoptimizationcanpreventdivergence.
Optimizationservesmultiplepurposesindeeplearning.
Besidesminimizingthetraining objective, different choices of optimization algorithms and learning rate scheduling can lead to rather different amounts of generalization and overfitting on the test set (forthesameamountoftrainingerror).
12.11.5 Exercises 1.
Experimentwiththeoptimizationbehaviorforagivenfixedlearningrate.
Whatisthe bestmodelyoucanobtainthisway? 2.
Howdoesconvergencechangeifyouchangetheexponentofthedecreaseinthelearning rate? Use Poly Schedulerforyourconvenienceintheexperiments.
546 Optimization Algorithms 3.
Applythecosineschedulertolargecomputervisionproblems, e.
g., training Image Net.
Howdoesitaffectperformancerelativetootherschedulers? 4.
Howlongshouldwarmuplast? 5.
Canyouconnectoptimizationandsampling? Startbyusingresultsfrom Wellingand Teh(2011)on Stochastic Gradient Langevin Dynamics.
Discussions183.
183 13 Computational Performance In deep learning, datasets and models are usually large, which involves heavy computa- tion.
Therefore, computationalperformancemattersalot.
Thischapterwillfocusonthe majorfactorsthataffectcomputationalperformance: imperativeprogramming, symbolic programming, asynchronouscomputing, automaticparallelism, andmulti-GPUcomputa- tion.
By studying this chapter, you may further improve computational performance of thosemodelsimplementedinthepreviouschapters, forexample, byreducingtrainingtime withoutaffectingaccuracy.
13.1 Compilers and Interpreters Sofar, thisbookhasfocusedonimperativeprogramming, whichmakesuseofstatements suchasprint,+, andiftochangeaprogramâ€™sstate.
Considerthefollowingexampleofa simpleimperativeprogram.
def add(a, b): return a + b def fancy_func(a, b, c, d): e = add(a, b) f = add(c, d) g = add(e, f) return g print(fancy_func(1, 2, 3, 4)) 10 Python is an interpreted language.
When evaluating the above fancy_func function it performstheoperationsmakingupthefunctionâ€™sbodyinsequence.
Thatis, itwillevaluate e = add(a, b)andstoretheresultsasvariablee, therebychangingtheprogramâ€™sstate.
Thenexttwostatementsf = add(c, d)andg = add(e, f)willbeexecutedsimilarly, performingadditionsandstoringtheresultsasvariables.
.1.1illustratestheflowof data.
547 548 Computational Performance t .1.1 Dataflowinanimperativeprogram.
Althoughimperativeprogrammingisconvenient, itmaybeinefficient.
Ontheonehand, eveniftheaddfunctionisrepeatedlycalledthroughoutfancy_func, Pythonwillexecute thethreefunctioncallsindividually.
Iftheseareexecuted, say, ona GPU(orevenonmul- tiple GPUs), theoverheadarisingfromthe Pythoninterpretercanbecomeoverwhelming.
Moreover, it will need to save the variable values of e and f until all the statements in fancy_funchavebeenexecuted.
Thisisbecausewedonotknowwhetherthevariablese andfwillbeusedbyotherpartsoftheprogramafterthestatementse = add(a, b)and f = add(c, d)areexecuted.
13.1.1 Symbolic Programming Considerthealternative, symbolicprogramming, wherecomputationisusuallyperformed onlyoncetheprocesshasbeenfullydefined.
Thisstrategyisusedbymultipledeeplearning frameworks, including Theanoand Tensor Flow(thelatterhasacquiredimperativeexten- sions).
Itusuallyinvolvesthefollowingsteps: 1.
Definetheoperationstobeexecuted.
2.
Compiletheoperationsintoanexecutableprogram.
3.
Providetherequiredinputsandcallthecompiledprogramforexecution.
Thisallowsforasignificantamountofoptimization.
First, wecanskipthe Pythoninter- preterinmanycases, thusremovingaperformancebottleneckthatcanbecomesignificant onmultiplefast GPUspaired witha single Python threadon a CPU.
Second, acompiler might optimize and rewrite the above code into print((1 + 2) + (3 + 4)) or even print(10).
Thisispossiblesinceacompilergetstoseethefullcodebeforeturningitinto machineinstructions.
Forinstance, itcanreleasememory(orneverallocateit)whenevera variableisnolongerneeded.
Oritcantransformthecodeentirelyintoanequivalentpiece.
To get a better idea, consider the following simulation of imperative programming (it is Pythonafterall)below.
def add_(): return ''' def add(a, b): return a + b ''' def fancy_func_(): return ''' (continuesonnextpage) 549 Compilersand Interpreters (continuedfrompreviouspage) def fancy_func(a, b, c, d): e = add(a, b) f = add(c, d) g = add(e, f) return g ''' def evoke_(): return add_() + fancy_func_() + 'print(fancy_func(1, 2, 3, 4))' prog = evoke_() print(prog) y = compile(prog, '', 'exec') exec(y) def add(a, b): return a + b def fancy_func(a, b, c, d): e = add(a, b) f = add(c, d) g = add(e, f) return g print(fancy_func(1, 2, 3, 4)) 10 Thedifferencesbetweenimperative(interpreted)programmingandsymbolicprogramming areasfollows: Imperative programming is easier.
When imperative programming is used in Python, themajorityofthecodeisstraightforwardandeasytowrite.
Itisalsoeasiertode- bugimperativeprogrammingcode.
Thisisbecauseitiseasiertoobtainandprintall relevantintermediatevariablevalues, oruse Pythonâ€™sbuilt-indebuggingtools.
Symbolic programming is more efficient and easier to port.
Symbolic programming makesiteasiertooptimizethecodeduringcompilation, whilealsohavingtheability toporttheprogramintoaformatindependentof Python.
Thisallowstheprogramto beruninanon-Pythonenvironment, thusavoidinganypotentialperformanceissues relatedtothe Pythoninterpreter.
13.1.2 Hybrid Programming Historicallymostdeeplearningframeworkschoosebetweenanimperativeorasymbolic approach.
Forexample, Theano, Tensor Flow(inspiredbytheformer), Keras, and CNTK formulatemodelssymbolically.
Conversely, Chainerand Py Torchtakeanimperativeap- proach.
Animperativemodewasaddedto Tensor Flow2.0and Kerasinlaterrevisions.
Asmentionedabove, Py Torchisbasedonimperativeprogrammingandusesdynamiccom- putationgraphs.
Inanefforttoleveragetheportabilityandefficiencyofsymbolicprogram- ming, developersconsideredwhetheritwouldbepossibletocombinethebenefitsofboth 550 Computational Performance programming paradigms.
This led to a torchscript that lets users develop and debug us- ingpureimperativeprogramming, whilehavingtheabilitytoconvertmostprogramsinto symbolicprogramstoberunwhenproduct-levelcomputingperformanceanddeployment arerequired.
13.1.3 Hybridizingthe Sequential Class Theeasiestwaytogetafeelforhowhybridizationworksistoconsiderdeepnetworkswith multiplelayers.
Conventionallythe Pythoninterpreterwillneedtoexecutethecodeforall layerstogenerateaninstructionthatcanthenbeforwardedtoa CPUora GPU.
Forasingle (fast)computingdevicethisdoesnotcauseanymajorissues.
Ontheotherhand, ifweuse anadvanced8-GPUserversuchasan AWSP3dn.24xlargeinstance Pythonwillstruggleto keepall GPUsbusy.
Thesingle-threaded Pythoninterpreterbecomesthebottleneckhere.
Letâ€™sseehowwecanaddressthisforsignificantpartsofthecodebyreplacing Sequential with Hybrid Sequential.
Webeginbydefiningasimple MLP.
import torch from torch import nn from d2l import torch as d2l # Factory for networks def get_net(): net = nn.
Sequential(nn.
Linear(512, 256), nn.
Re LU(), nn.
Linear(256, 128), nn.
Re LU(), nn.
Linear(128, 2)) return net x = torch.
randn(size=(1, 512)) net = get_net() net(x) tensor([[-0.1602, 0.0003]], grad_fn=<Addmm Backward0>) Byconvertingthemodelusingtorch.
jit.
scriptfunction, weareabletocompileandop- timizethecomputationinthe MLP.
Themodelâ€™scomputationresultremainsunchanged.
net = torch.
jit.
script(net) net(x) tensor([[-0.1602, 0.0003]], grad_fn=<Addmm Backward0>) Thisseemsalmosttoogoodtobetrue: writethesamecodeasbeforeandsimplyconvert themodelusingtorch.
jit.
script.
Oncethishappensthenetworkisoptimized(wewill benchmarktheperformancebelow).
551 Compilersand Interpreters Accelerationby Hybridization Todemonstratetheperformanceimprovementgainedbycompilationwecomparethetime neededtoevaluatenet(x)beforeandafterhybridization.
Letâ€™sdefineaclasstomeasure this time first.
It will come handy throughout the chapter as we set out to measure (and improve)performance.
#@save class Benchmark: """For measuring running time.""" def __init__(self, description='Done'): self.
description = description def __enter__(self): self.
timer = d2l.
Timer() return self def __exit__(self, *args): print(f'{self.
description}: {self.
timer.
stop():.4f} sec') Nowwecaninvokethenetworktwice, oncewithandoncewithouttorchscript.
net = get_net() with Benchmark('Without torchscript'): for i in range(1000): net(x) net = torch.
jit.
script(net) with Benchmark('With torchscript'): for i in range(1000): net(x) Without torchscript: 2.1447 sec With torchscript: 4.0545 sec As is observed in the above results, after an nn.
Sequential instance is scripted using thetorch.
jit.
scriptfunction, computingperformanceisimprovedthroughtheuseof symbolicprogramming.
Serialization Oneofthebenefitsofcompilingthemodelsisthatwecanserialize(save)themodeland itsparameterstodisk.
Thisallowsustostoreamodelinamannerthatisindependentof thefront-endlanguageofchoice.
Thisallowsustodeploytrainedmodelstootherdevices andeasilyuseotherfront-endprogramminglanguages.
Atthesametimethecodeisoften fasterthanwhatcanbeachievedinimperativeprogramming.
Letâ€™sseethesavefunction inaction.
net.
save('my_mlp') ! ls -lh my_mlp* 552 Computational Performance -rw-r--r-- 1 ci ci 651K Aug 18 19:32 my_mlp 13.1.4 Summary Imperativeprogrammingmakesiteasytodesignnewmodelssinceitispossibletowrite code with control flow and the ability to use a large amount of the Python software ecosystem.
Symbolicprogrammingrequiresthatwespecifytheprogramandcompileitbeforeexe- cutingit.
Thebenefitisimprovedperformance.
13.1.5 Exercises 1.
Review the models that interest you in the previous chapters.
Can you improve their computationalperformancebyreimplementingthem? Discussions184.
184 13.2 Asynchronous Computation Todayâ€™s computers are highly parallel systems, consisting of multiple CPU cores (often multiplethreadspercore), multipleprocessingelementsper GPU, andoftenmultiple GPUs perdevice.
Inshort, wecanprocessmanydifferentthingsatthesametime, oftenondiffer- entdevices.
Unfortunately Pythonisnotagreatwayofwritingparallelandasynchronous code, atleastnotwithoutsomeextrahelp.
Afterall, Pythonissingle-threadedandthisis unlikely to change in the future.
Deep learning frameworks such as MXNet and Tensor- Flowadoptanasynchronousprogrammingmodeltoimproveperformance, while Py Torch uses Pythonâ€™sownschedulerleadingtoadifferentperformancetrade-off.
For Py Torch, by default, GPUoperationsareasynchronous.
Whenyoucallafunctionthatusesthe GPU, the operations are enqueued to the particular device, but not necessarily executed until later.
Thisallowsustoexecutemorecomputationsinparallel, includingoperationsonthe CPU orother GPUs.
Hence, understanding how asynchronous programming works helps us to develop more efficient programs, by proactively reducing computational requirements and mutual de- pendencies.
This allows us to reduce memory overhead and increase processor utiliza- tion.
import os import subprocess import numpy import torch from torch import nn from d2l import torch as d2l 553 Asynchronous Computation 13.2.1 Asynchronyvia Backend Forawarmupconsiderthefollowingtoyproblem: wewanttogeneratearandommatrix andmultiplyit.
Letâ€™sdothatbothin Num Pyandin Py Torchtensortoseethedifference.
Notethat Py Torchtensorisdefinedona GPU.
# Warmup for GPU computation device = d2l.
try_gpu() a = torch.
randn(size=(1000, 1000), device=device) b = torch.
mm(a, a) with d2l.
Benchmark('numpy'): for _ in range(10): a = numpy.
random.
normal(size=(1000, 1000)) b = numpy.
dot(a, a) with d2l.
Benchmark('torch'): for _ in range(10): a = torch.
randn(size=(1000, 1000), device=device) b = torch.
mm(a, a) numpy: 1.4693 sec torch: 0.0022 sec Thebenchmarkoutputvia Py Torchisordersofmagnitudefaster.
Num Pydotproductisex- ecutedonthe CPUprocessorwhile Py Torchmatrixmultiplicationisexecutedon GPUand hencethelatterisexpectedtobemuchfaster.
Butthehugetimedifferencesuggestssome- thing else must be going on.
By default, GPU operations are asynchronous in Py Torch.
Forcing Py Torchtofinishallcomputationpriortoreturningshowswhathappenedprevi- ously: computationisbeingexecutedbythebackendwhilethefrontendreturnscontrolto Python.
with d2l.
Benchmark(): for _ in range(10): a = torch.
randn(size=(1000, 1000), device=device) b = torch.
mm(a, a) torch.
cuda.
synchronize(device) Done: 0.0058 sec Broadly speaking, Py Torch has a frontend for direct interaction with the users, e.
g., via Python, as well as a backend used by the system to perform the computation.
As shown in .2.1, users can write Py Torch programs in various frontend languages, such as Pythonand C++.
Regardlessofthefrontendprogramminglanguageused, theexecutionof Py Torchprograms occurs primarilyin the backendof C++ implementations.
Operations issuedbythefrontendlanguagearepassedontothebackendforexecution.
Thebackend managesitsownthreadsthatcontinuouslycollectandexecutequeuedtasks.
Notethatfor thistoworkthebackendmustbeabletokeeptrackofthedependenciesbetweenvarious 554 Computational Performance steps in the computational graph.
Hence, it is not possible to parallelize operations that dependoneachother.
t .2.1 Programminglanguagefrontendsanddeeplearningframeworkbackends.
Letâ€™slookatanothertoyexampletounderstandthedependencygraphabitbetter.
x = torch.
ones((1, 2), device=device) y = torch.
ones((1, 2), device=device) z = x * y + 2 z tensor([[3., 3.]], device='cuda:0') t .2.2 Thebackendtracksdependenciesbetweenvariousstepsinthecomputationalgraph.
The code snippet above is also illustrated in .2.2.
Whenever the Python frontend threadexecutesoneofthefirstthreestatements, itsimplyreturnsthetasktothebackend queue.
When the last statementâ€™s results need to be printed, the Python frontend thread willwaitforthe C++backendthreadtofinishcomputingtheresultofthevariablez.
One benefit of this design is that the Python frontend thread does not need to perform actual computations.
Thus, thereislittleimpactontheprogramâ€™soverallperformance, regardless 13.2.2 Barriersand Blockers 13.2.3 Improving Computation 555 Automatic Parallelism t .2.3 Interactionsofthefrontendandbackend.
13.2.4 Summary Deeplearningframeworksmaydecouplethe Pythonfrontendfromanexecutionback- end.
Thisallowsforfastasynchronousinsertionofcommandsintothebackendand associatedparallelism.
Asynchronyleadstoaratherresponsivefrontend.
However, usecautionnottooverfill thetaskqueuesinceitmayleadtoexcessivememoryconsumption.
Itisrecommended tosynchronizeforeachminibatchtokeepfrontendandbackendapproximatelysyn- chronized.
Chipvendorsoffersophisticatedperformanceanalysistoolstoobtainamuchmorefine- grainedinsightintotheefficiencyofdeeplearning.
13.2.5 Exercises 1.
Onthe CPU, benchmarkthesamematrixmultiplicationoperationsinthissection.
Can youstillobserveasynchronyviathebackend? 185 Discussions185.
13.3 Automatic Parallelism Deep learning frameworks(e.
g., MXNetand Py Torch) automaticallyconstruct computa- tionalgraphsatthebackend.
Usingacomputationalgraph, thesystemisawareofallthe dependencies, andcanselectivelyexecutemultiplenon-interdependenttasksinparallelto dently.
Consequentlythesystemcanchoosetoexecutetheminparallel.
Typically, asingleoperatorwilluseallthecomputationalresourcesonall CPUsoronasin- gle GPU.
Forexample, thedotoperatorwilluseallcores(andthreads)onall CPUs, evenif therearemultiple CPUprocessorsonasinglemachine.
Thesameappliestoasingle GPU.
Henceparallelizationisnotquitesousefulforsingle-devicecomputers.
Withmultiplede- vicesthingsmattermore.
Whileparallelizationistypicallymostrelevantbetweenmultiple GPUs, addingthelocal CPUwillincreaseperformanceslightly.
Forexample, see Hadjiset 556 Computational Performance al.
(2016)thatfocusesontrainingcomputervisionmodelscombininga GPUanda CPU.
Withtheconvenienceofanautomaticallyparallelizingframeworkwecanaccomplishthe samegoalinafewlinesof Pythoncode.
Morebroadly, ourdiscussionofautomaticparallel computation focuses on parallel computation using both CPUs and GPUs, as well as the parallelizationofcomputationandcommunication.
Notethatweneedatleasttwo GPUstoruntheexperimentsinthissection.
import torch from d2l import torch as d2l 13.3.1 Parallel Computationon GPUs Letâ€™s start by defining a reference workload to test: the run function below performs 10 matrix-matrix multiplications on the device of our choice using data allocated into two variables: x_gpu1andx_gpu2.
devices = d2l.
try_all_gpus() def run(x): return [x.
mm(x) for _ in range(50)] x_gpu1 = torch.
rand(size=(4000, 4000), device=devices[0]) x_gpu2 = torch.
rand(size=(4000, 4000), device=devices[1]) Nowweapplythefunctiontothedata.
Toensurethatcachingdoesnotplayaroleinthe resultswewarmupthedevicesbyperformingasinglepassoneitherofthempriortomea- suring.
torch.
cuda.
synchronize()waitsforallkernelsinallstreamsona CUDAdevice tocomplete.
Ittakesinadeviceargument, thedeviceforwhichweneedtosynchronize.
It uses the current device, given by current_device(), if the device argument is None (default).
run(x_gpu1) run(x_gpu2) # Warm-up all devices torch.
cuda.
synchronize(devices[0]) torch.
cuda.
synchronize(devices[1]) with d2l.
Benchmark('GPU1 time'): run(x_gpu1) torch.
cuda.
synchronize(devices[0]) with d2l.
Benchmark('GPU2 time'): run(x_gpu2) torch.
cuda.
synchronize(devices[1]) GPU1 time: 0.4660 sec GPU2 time: 0.4510 sec Ifweremovethesynchronizestatementbetweenbothtasksthesystemisfreetoparallelize computationonbothdevicesautomatically.
557 Automatic Parallelism with d2l.
Benchmark('GPU1 & GPU2'): run(x_gpu1) run(x_gpu2) torch.
cuda.
synchronize() GPU1 & GPU2: 0.4659 sec Intheabovecasethetotalexecutiontimeislessthanthesumofitsparts, sincethedeep learningframeworkautomaticallyschedulescomputationonboth GPUdeviceswithoutthe needforsophisticatedcodeonbehalfoftheuser.
13.3.2 Parallel Computationand Communication Inmanycasesweneedtomovedatabetweendifferentdevices, saybetweenthe CPUand GPU, orbetweendifferent GPUs.
Forinstance, thisoccurswhenwewanttoperformdis- tributedoptimizationwhereweneedtoaggregatethegradientsovermultipleaccelerator cards.
Letâ€™ssimulatethisbycomputingonthe GPUandthencopyingtheresultsbackto the CPU.
def copy_to_cpu(x, non_blocking=False): return [y.
to('cpu', non_blocking=non_blocking) for y in x] with d2l.
Benchmark('Run on GPU1'): y = run(x_gpu1) torch.
cuda.
synchronize() with d2l.
Benchmark('Copy to CPU'): y_cpu = copy_to_cpu(y) torch.
cuda.
synchronize() Run on GPU1: 0.4656 sec Copy to CPU: 2.3125 sec Thisissomewhatinefficient.
Notethatwecouldalreadystartcopyingpartsofytothe CPU whiletheremainderofthelistisstillbeingcomputed.
Thissituationoccurs, e.
g., whenwe computethe(backprop)gradientonaminibatch.
Thegradientsofsomeoftheparameters willbeavailableearlierthanthatofothers.
Henceitworkstoouradvantagetostartusing PCI-Expressbusbandwidthwhilethe GPUisstillrunning.
In Py Torch, severalfunctions suchasto()andcopy_()admitanexplicitnon_blockingargument, whichletsthecaller bypasssynchronizationwhenitisunnecessary.
Settingnon_blocking=Trueallowsusto simulatethisscenario.
with d2l.
Benchmark('Run on GPU1 and copy to CPU'): y = run(x_gpu1) y_cpu = copy_to_cpu(y, True) torch.
cuda.
synchronize() 558 Computational Performance Run on GPU1 and copy to CPU: 1.6907 sec Thetotaltimerequiredforbothoperationsis(asexpected)lessthanthesumoftheirparts.
Notethatthistaskisdifferentfromparallelcomputationasitusesadifferentresource: the busbetweenthe CPUand GPUs.
Infact, wecouldcomputeonbothdevicesandcommuni- cate, allatthesametime.
Asnotedabove, thereisadependencybetweencomputationand communication: y[i]mustbecomputedbeforeitcanbecopiedtothe CPU.
Fortunately, thesystemcancopyy[i-1]whilecomputingy[i]toreducethetotalrunningtime.
We conclude with an illustration of the computational graph and its dependencies for a simpletwo-layer MLPwhentrainingona CPUandtwo GPUs, asdepictedin.3.1.
It wouldbequitepainfultoscheduletheparallelprogramresultingfromthismanually.
Thisis whereitisadvantageoustohaveagraph-basedcomputingbackendforoptimization.
t .3.1 Thecomputationalgraphanditsdependenciesofatwo-layer MLPona CPUandtwo GPUs.
13.3.3 Summary Modernsystemshaveavarietyofdevices, suchasmultiple GPUsand CPUs.
Theycan beusedinparallel, asynchronously.
Modern systems also have a variety of resources for communication, such as PCI Ex- press, storage(typicallysolid-statedrivesorvianetworks), andnetworkbandwidth.
Theycanbeusedinparallelforpeakefficiency.
Thebackendcanimproveperformancethroughautomaticparallelcomputationandcom- munication.
559 Hardware 13.3.4 Exercises 1.
Eight operations were performed in the run function defined in this section.
There are no dependencies between them.
Design an experiment to see if the deep learning frameworkwillautomaticallyexecutetheminparallel.
2.
When the workload of an individual operator is sufficiently small, parallelization can helpevenonasingle CPUor GPU.
Designanexperimenttoverifythis.
3.
Designanexperimentthatusesparallelcomputationon CPUs, GPUs, andcommunica- tionbetweenbothdevices.
4.
Useadebuggersuchas NVIDIAâ€™s Nsight186 toverifythatyourcodeisefficient.
186 5.
Designing computation tasks that include more complex data dependencies, and run experimentstoseeifyoucanobtainthecorrectresultswhileimprovingperformance.
187 Discussions187.
13.4 Hardware Buildingsystemswithgreatperformancerequiresagoodunderstandingofthealgorithms and models to capture the statistical aspects of the problem.
At the same time it is also indispensable to have at least a modicum of knowledge of the underlyinghardware.
The currentsectionisnosubstituteforapropercourseonhardwareandsystemdesign.
Instead, itmightserveasastartingpointforunderstandingwhysomealgorithmsaremoreefficient thanothersandhowtoachievegoodthroughput.
Agooddesigncaneasilymakeadiffer- enceofanorderofmagnitudeand, inturn, thiscanmakethedifferencebetweenbeingable totrainanetwork(e.
g., inaweek)andnotatall(in3months, thusmissingthedeadline).
We will start by looking at computers.
Then we will zoom in to look more carefully at CPUsand GPUs.
Lastlywezoomouttoreviewhowmultiplecomputersareconnectedin aservercenterorinthecloud.
t .4.1 Latency Numbersthateveryprogrammershouldknow.
560 Computational Performance Impatientreadersmaybeabletogetbywith.4.1.
Itistakenfrom Colin Scottâ€™sinter- activepost188thatgivesagoodoverviewoftheprogressoverthepastdecade.
Theoriginal 188 numbersaredueto Jeff Deanâ€™s Stanfordtalkfrom2010189.
Thediscussionbelowexplains someoftherationaleforthesenumbersandhowtheycanguideusindesigningalgorithms.
Thediscussionbelowisveryhighlevelandcursory.
Itisclearlynosubstituteforaproper coursebutratherjustmeanttoprovideenoughinformationforastatisticalmodelertomake 189 suitabledesigndecisions.
Foranin-depthoverviewofcomputerarchitecturewereferthe readerto(Hennessyand Patterson,2011)orarecentcourseonthesubject, suchastheone by Arste Asanovic190.
190 13.4.1 Computers Most deep learning researchers and practitioners have access to a computer with a fair amountofmemory, computation, someformofanacceleratorsuchasa GPU, ormultiples thereof.
Acomputerconsistsofthefollowingkeycomponents: Aprocessor(alsoreferredtoasa CPU)thatisabletoexecutetheprogramswegiveit(in additiontorunninganoperatingsystemandmanyotherthings), typicallyconsisting of8ormorecores.
Memory(RAM)tostoreandretrievetheresultsfromcomputation, suchasweightvec- torsandactivations, andtrainingdata.
An Ethernetnetworkconnection(sometimesmultiple)withspeedsrangingfrom1GB/s to100GB/s.
Onhighendserversmoreadvancedinterconnectscanbefound.
Ahighspeedexpansionbus(PCIe)toconnectthesystemtooneormore GPUs.
Servers have up to 8 accelerators, often connected in an advanced topology, while desktop systems have 1 or 2, depending on the budget of the user and the size of the power supply.
Durablestorage, suchasamagneticharddiskdrive, asolidstatedrive, inmanycases connected using the PCIe bus.
It provides efficient transfer of training data to the systemandstorageofintermediatecheckpointsasneeded.
t .4.2 Connectivityofcomponentsofacomputer.
As.4.2indicates, mostcomponents(network, GPU, andstorage)areconnectedto the CPUacrossthe PCIebus.
Itconsistsofmultiplelanesthataredirectlyattachedtothe CPU.
Forinstance AMDâ€™s Threadripper3has64PCIe4.0lanes, eachofwhichiscapable 16Gbit/sdatatransferinbothdirections.
Thememoryisdirectlyattachedtothe CPUwith atotalbandwidthofupto100GB/s.
Whenweruncodeonacomputerweneedtoshuffledatatotheprocessors(CPUsor GPUs), 561 Hardware performcomputation, andthenmovetheresultsofftheprocessorbackto RAManddurable storage.
Hence, in order to get good performance we need to make sure that this works seamlesslywithoutanyoneofthesystemsbecomingamajorbottleneck.
Forinstance, if wecannotloadimagesquicklyenoughtheprocessorwillnothaveanyworktodo.
Likewise, ifwecannotmovematricesquicklyenoughtothe CPU(or GPU), itsprocessingelements willstarve.
Finally, ifwewanttosynchronizemultiplecomputersacrossthenetwork, the lattershouldnotslowdowncomputation.
Oneoptionistointerleavecommunicationand computation.
Letâ€™shavealookatthevariouscomponentsinmoredetail.
13.4.2 Memory At its most basic memory is used to store data that needs to be readily accessible.
At present CPURAMistypicallyofthe DDR4191 variety, offering20â€“25GB/sbandwidth 191 permodule.
Eachmodulehasa64-bit-widebus.
Typicallypairsofmemorymodulesare used to allow for multiple channels.
CPUs have between 2 and 4 memory channels, i.
e., theyhavebetween40GB/sand100GB/speakmemorybandwidth.
Oftentherearetwo banksperchannel.
Forinstance AMDâ€™s Zen3Threadripperhas8slots.
While these numbers are impressive, indeed, they only tell part of the story.
When we want to read a portion from memory we first need to tell the memory module where the information can be found.
That is, we first need to send the address to RAM.
Once this is accomplished we can choose to read just a single 64 bit record or a long sequence of records.
Thelatteriscalledburstread.
Inanutshell, sendinganaddresstomemoryand setting up the transfer takes approximately 100 ns (details depend on the specific timing coefficients of the memory chips used), every subsequent transfer takes only 0.2 ns.
In short, the first read is 500 times as expensive as subsequent ones! Note that we could performupto10,000,000randomreadspersecond.
Thissuggeststhatweavoidrandom memoryaccessasfaraspossibleanduseburstreads(andwrites)instead.
Matters are a bit more complex when we take into account that we have multiple banks.
Each bank can read memory largely independently.
This means two things.
On the one hand, theeffectivenumberofrandomreadsisupto4timeshigher, providedthattheyare spread evenly across memory.
It also means that it is still a bad idea to perform random readssinceburstreadsare4timesfaster, too.
Ontheotherhand, duetomemoryalignment to64bitboundariesitisagoodideatoalignanydatastructureswiththesameboundaries.
Compilersdothisprettymuchautomatically192whentheappropriateflagsareset.
Curious 192 readersareencouragedtoreviewalectureon DRAMssuchastheoneby Zeshan Chishti 193.
GPUmemoryissubjecttoevenhigherbandwidthrequirementssincetheyhavemanymore 193 processingelementsthan CPUs.
Byandlargetherearetwooptionstoaddressthem.
The first is to make the memory bus significantly wider.
For instance, NVIDIAâ€™s RTX 2080 Ti has a 352-bit-wide bus.
This allows for much more information to be transferred at the same time.
Second, GPUs use specific high-performance memory.
Consumer-grade 194 devices, suchas NVIDIAâ€™s RTXand Titanseriestypicallyuse GDDR6194 chipswithover 500GB/saggregatebandwidth.
Analternativeistouse HBM(highbandwidthmemory) modules.
Theyuseaverydifferentinterfaceandconnectdirectlywith GPUsonadedicated 562 Computational Performance siliconwafer.
Thismakesthemveryexpensiveandtheiruseistypicallylimitedtohigh-end serverchips, suchasthe NVIDIAVolta V100seriesofaccelerators.
Quiteunsurprisingly, GPUmemoryisgenerallymuchsmallerthan CPUmemoryduetothehighercostofthe former.
Forourpurposes, byandlargetheirperformancecharacteristicsaresimilar, justa lotfaster.
Wecansafelyignorethedetailsforthepurposeofthisbook.
Theyonlymatter whentuning GPUkernelsforhighthroughput.
13.4.3 Storage Wesawthatsomeofthekeycharacteristicsof RAMarebandwidthandlatency.
Thesame istrueforstoragedevices, justthatthedifferencescanbeevenmoreextreme.
Hard Disk Drives Harddiskdrives(HDDs)havebeeninuseforoverhalfacentury.
Inanutshelltheycontain anumberofspinningplatterswithheadsthatcanbepositionedtoreadorwriteatanygiven track.
High-end disks hold up to 16 TB on 9 platters.
One of the key benefits of HDDs is that they are relatively inexpensive.
One of their many downsides are their typically catastrophicfailuremodesandtheirrelativelyhighreadlatency.
Tounderstandthelatter, considerthefactthat HDDsspinataround7,200RPM(revolutions perminute).
Iftheyweremuchfastertheywouldshatterduetothecentrifugalforceexerted on the platters.
This has a major downside when it comes to accessing a specific sector on the disk: we need to wait until the platter has rotated in position (we can move the headsbutnotacceleratetheactualdisks).
Henceitcantakeover8msuntiltherequested data is available.
A common way this is expressed is to say that HDDs can operate at approximately100IOPs(input/outputoperationspersecond).
Thisnumberhasessentially remainedunchangedforthepasttwodecades.
Worsestill, itisequallydifficulttoincrease bandwidth(itisintheorderof100â€“200MB/s).
Afterall, eachheadreadsatrackofbits, hencethebitrateonlyscaleswiththesquarerootoftheinformationdensity.
Asaresult, HDDsarequicklybecomingrelegatedtoarchivalstorageandlow-gradestorageforvery largedatasets.
Solid State Drives Solidstatedrives(SSDs)useflashmemorytostoreinformationpersistently.
Thisallows formuchfasteraccesstostoredrecords.
Modern SSDscanoperateat100,000to500,000 IOPs, i.
e., up to 3 orders of magnitude faster than HDDs.
Furthermore, their bandwidth canreach1â€“3GB/s, i.
e., oneorderofmagnitudefasterthan HDDs.
Theseimprovements soundalmosttoogoodtobetrue.
Indeed, theycomewiththefollowingcaveats, duetothe way SSDsaredesigned.
SSDsstoreinformationinblocks(256KBorlarger).
Theycanonlybewrittenasawhole, whichtakessignificanttime.
Consequentlybit-wiserandomwriteson SSDhavevery poorperformance.
Likewise, writingdataingeneraltakessignificanttimesincethe blockhastoberead, erasedandthenrewrittenwithnewinformation.
Bynow SSD 563 Hardware controllers and firmware have developed algorithms to mitigate this.
Nonetheless, writes can be much slower, in particular for QLC (quad level cell) SSDs.
The key forimprovedperformanceistomaintainaqueueofoperations, topreferreadsandto writeinlargeblocksifpossible.
Thememorycellsin SSDswearoutrelativelyquickly(oftenalreadyafterafewthousand writes).
Wear-levelprotectionalgorithmsareabletospreadthedegradationovermany cells.
That said, it is not recommended to use SSDs for swapping files or for large aggregationsoflog-files.
Lastly, themassiveincreaseinbandwidthhasforcedcomputerdesignerstoattach SSDs directly to the PCIe bus.
The drives capable of handling this, referred to as NVMe (Non Volatile Memoryenhanced), canuseupto4PCIelanes.
Thisamountstoupto 8GB/son PCIe4.0.
Cloud Storage Cloud storage provides a configurable range of performance.
That is, the assignment of storage to virtual machines is dynamic, both in terms of quantity and in terms of speed, as chosen by users.
We recommend that users increase the provisioned number of IOPs wheneverlatencyistoohigh, e.
g., duringtrainingwithmanysmallrecords.
13.4.4 CPUs Central processing units (CPUs) are the centerpiece of any computer.
They consist of a numberofkeycomponents: processorcoresthatareabletoexecutemachinecode, abus connectingthem(thespecifictopologydifferssignificantlybetweenprocessormodels, gen- erations, andvendors), andcachestoallowforhigherbandwidthandlowerlatencymemory accessthanwhatispossiblebyreadsfrommainmemory.
Lastly, almostallmodern CPUs containvectorprocessingunitstoaidwithhighperformancelinearalgebraandconvolu- tions, astheyarecommoninmediaprocessingandmachinelearning.
t .4.3 Intel Skylakeconsumerquad-core CPU.
.4.3depictsan Intel Skylakeconsumer-gradequad-core CPU.
Ithasanintegrated 564 Computational Performance GPU, caches, andaringbusconnectingthefourcores.
Peripherals, suchas Ethernet, Wi Fi, Bluetooth, SSD controller, and USB, are either part of the chipset or directly attached (PCIe)tothe CPU.
Microarchitecture Each of the processor cores consists of a rather sophisticated set of components.
While detailsdifferbetweengenerationsandvendors, thebasicfunctionalityisprettymuchstan- dard.
Thefront-endloadsinstructionsandtriestopredictwhichpathwillbetaken(e.
g., forcontrolflow).
Instructionsarethendecodedfromassemblycodetomicroinstructions.
Assemblycodeisoftennotthelowestlevelcodethataprocessorexecutes.
Instead, com- plexinstructionsmaybedecodedintoasetofmorelowerleveloperations.
Thesearethen processedbytheactualexecutioncore.
Oftenthelatteriscapableofperformingmanyop- erationssimultaneously.
Forinstance, the ARMCortex A77coreof.4.4isableto performupto8operationssimultaneously.
t .4.4 ARMCortex A77Microarchitecture.
Thismeansthatefficientprogramsmightbeabletoperformmorethanoneinstructionper clockcycle, providedthattheycanbecarriedoutindependently.
Notallunitsarecreated equal.
Some specialize in integer instructions whereas others are optimized for floating pointperformance.
Toincreasethroughput, theprocessormightalsofollowmultiplecode pathssimultaneouslyinabranchinginstructionandthendiscardtheresultsofthebranches nottaken.
Thisiswhybranchpredictionunitsmatter(onthefront-end)suchthatonlythe mostpromisingpathsarepursued.
Vectorization Deeplearningisextremelycompute-hungry.
Hence, tomake CPUssuitableformachine learning, one needs to perform manyoperations in one clockcycle.
This is achievedvia vectorunits.
Theyhavedifferentnames: on ARMtheyarecalled NEON, onx86they(a 195 recentgeneration)arereferredtoas AVX2195 units.
Acommonaspectisthattheyareable to perform SIMD (single instruction multiple data) operations.
.4.5 shows how 8 shortintegerscanbeaddedinoneclockcycleon ARM.
565 Hardware t .4.5 128bit NEONvectorization.
Dependingonarchitecturechoices, suchregistersareupto512bitslong, allowingforthe combination of up to 64 pairs of numbers.
For instance, we might be multiplying two numbersandaddingthemtoathird, whichisalsoknownasafusedmultiply-add.
Intelâ€™s Open Vino196 uses these to achieve respectable throughput for deep learning on server- 196 grade CPUs.
Note, though, thatthisnumberisentirelydwarfedbywhat GPUsarecapable ofachieving.
Forinstance, NVIDIAâ€™s RTX2080Tihas4,352CUDAcores, eachofwhich iscapableofprocessingsuchanoperationatanytime.
Cache Considerthefollowingsituation: wehaveamodest CPUcorewith4coresasdepictedin .4.3above, runningat2GHzfrequency.
Moreover, letâ€™sassumethatwehavean IPC (instructionsperclock)countof1andthattheunitshave AVX2with256-bitwidthenabled.
Letâ€™sfurthermoreassumethatatleastoneoftheregistersusedfor AVX2operationsneeds toberetrievedfrommemory.
Thismeansthatthe CPUconsumes4 256bit=128bytes of data per clock cycle.
Unless we are able to transfer 2 109 128 = 256 109 bytes totheprocessorpersecondtheprocessingelementsaregoingtostarve.
Unfortunatelythe memoryinterfaceofsuchachiponlysupports20â€“40GB/sdatatransfer, i.
e., oneorderof magnitudeless.
Thefixistoavoidloadingnewdatafrommemoryasfaraspossibleand rathertocacheitlocallyonthe CPU.
Thisiswherecachescomeinhandy.
Commonlythe followingnamesorconceptsareused: Registersarestrictlyspeakingnotpartofthecache.
Theyhelpstageinstructions.
That said, CPUregistersarememorylocationsthata CPUcanaccessatclockspeedwith- outanydelaypenalty.
CPUshavetensofregisters.
Itisuptothecompiler(orpro- grammer)touseregistersefficiently.
Forinstancethe Cprogramminglanguagehasa registerkeyword.
L1 caches are the first line of defense against high memory bandwidth requirements.
L1 caches are tiny (typical sizes might be 32â€“64 KB) and often split into data and instructionscaches.
Whendataisfoundinthe L1cache, accessisveryfast.
Ifthey cannotbefoundthere, thesearchprogressesdownthecachehierarchy.
L2cachesarethenextstop.
Dependingonarchitecturedesignandprocessorsizethey mightbeexclusive.
Theymightbeaccessibleonlybyagivencoreorsharedamong multiplecores.
L2cachesarelarger(typically256â€“512KBpercore)andslowerthan 566 Computational Performance L1.
Furthermore, toaccesssomethingin L2wefirstneedtochecktorealizethatthe dataisnotin L1, whichaddsasmallamountofextralatency.
L3cachesaresharedamongmultiplecoresandcanbequitelarge.
AMDâ€™s Epyc3server CPUshaveawhopping256MBofcachespreadacrossmultiplechiplets.
Moretypical numbersareinthe4â€“8MBrange.
Predictingwhichmemoryelementswillbeneedednextisoneofthekeyoptimizationpa- rametersinchipdesign.
Forinstance, itisadvisabletotraversememoryinaforwarddirec- tionsincemostcachingalgorithmswilltrytoreadaheadratherthanbackwards.
Likewise, keepingmemoryaccesspatternslocalisagoodwayofimprovingperformance.
Adding caches is a double-edge sword.
On the one hand they ensure that the processor cores do not starve of data.
At the same time they increase chip size, using up area that otherwisecouldhavebeenspentonincreasingprocessingpower.
Moreover, cachemisses A memory location is cached on processor 0 when a thread on processor 1 requests the data.
Toobtain it, processor 0 needs to stopwhat it is doing, write the information back tomainmemoryandthenletprocessor1readitfrommemory.
Duringthisoperationboth processorswait.
Quitepotentiallysuchcoderunsmoreslowlyonmultipleprocessorswhen comparedwithanefficientsingle-processorimplementation.
Thisisonemorereasonfor whythereisapracticallimittocachesizes(besidestheirphysicalsize).
t .4.6 Falsesharing(imagecourtesyof Intel).
13.4.5 GPUsandother Accelerators Itisnotanexaggerationtoclaimthatdeeplearningwouldnothavebeensuccessfulwithout GPUs.
Bythesametoken, itisquitereasonabletoarguethat GPUmanufacturersâ€™fortunes have increased significantly due to deep learning.
This co-evolution of hardware and al- gorithms has led to a situation where for better or worse deep learning is the preferable statisticalmodelingparadigm.
Henceitpaystounderstandthespecificbenefitsthat GPUs andrelatedacceleratorssuchasthe TPU(Jouppietal.,2017).
Ofnoteisadistinctionthatisoftenmadeinpractice: acceleratorsareoptimizedeitherfor training or inference.
For the latter we only need to compute the forward propagation in anetwork.
Nostorageofintermediatedataisneededforbackpropagation.
Moreover, we maynotneedveryprecisecomputation(FP16or INT8typicallysuffice).
Ontheotherhand, 567 Hardware duringtrainingallintermediateresultsneedstoragetocomputegradients.
Moreover, ac- cumulatinggradientsrequireshigherprecisiontoavoidnumericalunderflow(oroverflow).
This means that FP16 (or mixed precision with FP32) is the minimum requirement.
All of this necessitates faster and larger memory (HBM2 vs.
GDDR6) and more processing power.
Forinstance, NVIDIAâ€™s Turing197 T4GPUsareoptimizedforinferencewhereas 197 the V100GPUsarepreferablefortraining.
Recallvectorizationasillustratedin .4.5.
Addingvectorunitstoaprocessorcore allowedustoincreasethroughputsignificantly.
Forexample, intheexamplein.4.5 wewereabletoperform16operationssimultaneously.
First, whatifweaddedoperations thatoptimizednotjustoperationsbetweenvectorsbutalsobetweenmatrices? Thisstrategy led to tensor cores (to be covered shortly).
Second, what if we added many more cores? In a nutshell, these two strategies summarize the design decisions in GPUs.
.4.7 givesanoverviewofabasicprocessingblock.
Itcontains16integerand16floatingpoint units.
In addition to that, two tensor cores accelerate a narrow subset of additional op- erations relevant for deep learning.
Each streaming multiprocessor consists of four such blocks.
t .4.7 NVIDIATuringprocessingblock(imagecourtesyof NVIDIA).
Next, 12 streaming multiprocessors are grouped into graphics processing clusters which makeupthehigh-end TU102processors.
Amplememorychannelsandan L2cachecom- suchadeviceisthatindividualblockscanbeaddedorremovedasneededtoallowformore compactchipsandtodealwithyieldissues(faultymodulesmightnotbeactivated).
Fortu- natelyprogrammingsuchdevicesiswellhiddenfromthecasualdeeplearningresearcher beneathlayersof CUDAandframeworkcode.
Inparticular, morethanoneoftheprograms might well be executed simultaneously on the GPU, provided that there are available re- sources.
Nonethelessitpaystobeawareofthelimitationsofthedevicestoavoidpicking modelsthatdonotfitintodevicememory.
Alastaspectthatisworthmentioninginmoredetailaretensorcores.
Theyareanexample ofarecenttrendofaddingmoreoptimizedcircuitsthatarespecificallyeffectivefordeep learning.
Forinstance, the TPUaddedasystolicarray(Kung,1988)forfastmatrixmultipli- 568 Computational Performance t .4.8 NVIDIATuringarchitecture(imagecourtesyof NVIDIA) cation.
Therethedesignwastosupportaverysmallnumber(oneforthefirstgenerationof TPUs)oflargeoperations.
Tensorcoresareattheotherend.
Theyareoptimizedforsmall operations involving between 4 4 and 16 16 matrices, depending on their numerical t .4.9 NVIDIAtensorcoresin Turing(imagecourtesyof NVIDIA).
Obviouslywhenoptimizingforcomputationweendupmakingcertaincompromises.
One 198 ofthemisthat GPUsarenotverygoodathandlinginterruptsandsparsedata.
Whilethere arenotableexceptions, suchas Gunrock198(Wangetal.,2016), theaccesspatternofsparse matricesandvectorsdonotgowellwiththehighbandwidthburstreadoperationswhere 569 Hardware GPUsexcel.
Matchingbothgoalsisanareaofactiveresearch.
Seee.
g., DGL199, alibrary 199 tunedfordeeplearningongraphs.
13.4.6 Networksand Buses Whenever a single device is insufficient for optimization we need to transfer data to and fromittosynchronizeprocessing.
Thisiswherenetworksandbusescomeinhandy.
We haveanumberofdesignparameters: bandwidth, cost, distance, andflexibility.
Ononeend wehave Wi Fithathasaprettygoodrange, isveryeasytouse(nowires, afterall), cheapbut itofferscomparativelymediocrebandwidthandlatency.
Nomachinelearningresearcher withintheirrightmindwoulduseittobuildaclusterofservers.
Inwhatfollowswefocus oninterconnectsthataresuitablefordeeplearning.
PCIe is a dedicated bus for very high bandwidth point-to-point connections (up to 32 GB/son PCIe 4.0 in a 16-lane slot)per lane.
Latency is in the orderof single-digit microseconds(5Î¼s).
PCIelinksareprecious.
Processorsonlyhavealimitednumber of them: AMDâ€™s EPYC 3 has 128 lanes, Intelâ€™s Xeon has up to 48 lanes per chip; ondesktop-grade CPUsthenumbersare20(Ryzen9)and16(Corei9)respectively.
Since GPUshavetypically16lanes, thislimitsthenumberof GPUsthatcanconnect tothe CPUatfullbandwidth.
Afterall, theyneedtosharethelinkswithotherhigh bandwidthperipheralssuchasstorageand Ethernet.
Justlikewith RAMaccess, large bulktransfersarepreferableduetoreducedpacketoverhead.
Ethernetisthemostcommonlyusedwayofconnectingcomputers.
Whileitissignifi- cantlyslowerthan PCIe, itisverycheapandresilienttoinstallandcoversmuchlonger distances.
Typicalbandwidthforlow-gradeserversis1GBit/s.
Higher-enddevices 200 (e.
g., C5instances200 inthecloud)offerbetween10and100GBit/sbandwidth.
As in all previous cases data transmission has significant overheads.
Note that we al- mostneveruseraw Ethernetdirectlybutratheraprotocolthatisexecutedontopof thephysicalinterconnect(suchas UDPor TCP/IP).
Thisaddsfurtheroverhead.
Like PCIe, Ethernetisdesignedtoconnecttwodevices, e.
g., acomputerandaswitch.
201 Switchesallowustoconnectmultipledevicesinamannerwhereanypairofthemcan carryouta(typicallyfullbandwidth)point-to-pointconnectionsimultaneously.
For instance, Ethernet switches might connect 40 servers at high cross-sectional band- width.
Notethatswitchesarenotuniquetotraditionalcomputernetworks.
Even PCIe 202 lanescanbeswitched201.
Thisoccurs, e.
g., toconnectalargenumberof GPUstoa hostprocessor, asisthecaseforthe P2instances202.
NVLinkisanalternativeto PCIewhenitcomestoveryhighbandwidthinterconnects.
203 Itoffersupto300Gbit/sdatatransferrateperlink.
Server GPUs(Volta V100)have sixlinkswhereasconsumer-grade GPUs(RTX2080Ti)haveonlyonelink, operating atareduced100Gbit/srate.
Werecommendtouse NCCL203 toachievehighdata transferbetween GPUs.
204 13.4.7 More Latency Numbers 570 Computational Performance Thesummaryin Table13.4.1and Table13.4.2arefrom Eliot Eshelman204 whomaintains anupdatedversionofthenumbersasa Git Hubgist205.
205 Table 13.4.1: Common Latency Numbers.
Action Time Notes L1cachereference/hit 1.5ns 4cycles Floating-pointadd/mult/FMA 1.5ns 4cycles L2cachereference/hit 5ns 12~17cycles Branchmispredict 6ns 15~20cycles L3cachehit(unsharedcache) 16ns 42cycles L3cachehit(sharedinanothercore) 25ns 65cycles Mutexlock/unlock 25ns L3cachehit(modifiedinanothercore) 29ns 75cycles L3cachehit(onaremote CPUsocket) 40ns 100~300cycles(40~116ns) QPIhoptoaanother CPU(perhop) 40ns 64MBmemoryref.
(local CPU) 46ns Tiny Mem Benchon Broadwell E5-2690v4 64MBmemoryref.
(remote CPU) 70ns Tiny Mem Benchon Broadwell E5-2690v4 256MBmemoryref.
(local CPU) 75ns Tiny Mem Benchon Broadwell E5-2690v4 Intel Optanerandomwrite 94ns UCSDNon-Volatile Systems Lab 256MBmemoryref.
(remote CPU) 120ns Tiny Mem Benchon Broadwell E5-2690v4 Intel Optanerandomread 305ns UCSDNon-Volatile Systems Lab Send4KBover100Gbps HPCfabric 1Î¼s MVAPICH2over Intel Omni-Path Compress1KBwith Google Snappy 3Î¼s Send4KBover10Gbpsethernet 10Î¼s Write4KBrandomlyto NVMe SSD 30Î¼s DCP3608NVMe SSD(QOS99%is500Î¼s) Transfer1MBto/from NVLink GPU 30Î¼s ~33GB/son NVIDIA40GBNVLink Transfer1MBto/from PCI-EGPU 80Î¼s ~12GB/son PCIe3.0x16link Read4KBrandomlyfrom NVMe SSD 120Î¼s DCP3608NVMe SSD(QOS99%) Read1MBsequentiallyfrom NVMe SSD 208Î¼s ~4.8GB/s DCP3608NVMe SSD Write4KBrandomlyto SATASSD 500Î¼s DCS3510SATASSD(QOS99.9%) Read4KBrandomlyfrom SATASSD 500Î¼s DCS3510SATASSD(QOS99.9%) Roundtripwithinsamedatacenter 500Î¼s One-waypingis~250Î¼s Read1MBsequentiallyfrom SATASSD 2ms ~550MB/s DCS3510SATASSD Read1MBsequentiallyfromdisk 5ms ~200MB/sserver HDD Random Disk Access(seek+rotation) 10ms Sendpacket CA->Netherlands->CA 150ms Table 13.4.2: Latency Numbers for NVIDIA Tesla GPUs.
571 Hardware Action Time Notes GPUShared Memoryaccess 30ns 30~90 cycles (bank conflicts add la- tency) GPUGlobal Memoryaccess 200 200~800cycles ns Launch CUDAkernelon GPU 10Î¼s Host CPUinstructs GPUtostartkernel Transfer 1MB to/from NVLink 30Î¼s ~33GB/son NVIDIA40GBNVLink GPU Transfer1MBto/from PCI-EGPU 80Î¼s ~12GB/son PCI-Expressx16link 13.4.8 Summary Deviceshaveoverheadsforoperations.
Henceitisimportanttoaimforasmallnumber oflargetransfersratherthanmanysmallones.
Thisappliesto RAM, SSDs, networks and GPUs.
Vectorizationiskeyforperformance.
Makesureyouareawareofthespecificabilities ofyouraccelerator.
E.
g., some Intel Xeon CPUsareparticularlygoodfor INT8op- erations, NVIDIAVolta GPUsexcelat FP16matrix-matrixoperationsand NVIDIA Turingshinesat FP16, INT8, and INT4operations.
Numericaloverflowduetosmalldatatypescanbeaproblemduringtraining(andtoa lesserextentduringinference).
Aliasingcansignificantlydegradeperformance.
Forinstance, memoryalignmenton64 bit CPUsshouldbedonewithrespectto64bitboundaries.
On GPUsitisagoodidea tokeepconvolutionsizesaligned, e.
g., totensorcores.
Matchyouralgorithmstothehardware(e.
g., memoryfootprint, andbandwidth).
Great speedup(ordersofmagnitude)canbeachievedwhenfittingtheparametersintocaches.
Werecommendthatyousketchouttheperformanceofanovelalgorithmonpaperbefore verifying the experimental results.
Discrepancies ofan order-of-magnitudeormore arereasonsforconcern.
Useprofilerstodebugperformancebottlenecks.
Trainingandinferencehardwarehavedifferentsweetspotsintermsofpriceandperfor- mance.
13.4.9 Exercises 1.
Write Ccodetotestwhetherthereisanydifferenceinspeedbetweenaccessingmemory aligned or misaligned relative to the external memory interface.
Hint: be careful of cachingeffects.
2.
Test the difference in speed between accessing memory in sequence or with a given stride.
572 Computational Performance 3.
Howcouldyoumeasurethecachesizesona CPU? 4.
Howwouldyoulayoutdataacrossmultiplememorychannelsformaximumbandwidth? Howwouldyoulayitoutifyouhadmanysmallthreads? 5.
Anenterprise-class HDDisspinningat10,000rpm.
Whatistheabsolutelyminimum time an HDD needs to spend worst case before it can read data (you can assume that headsmovealmostinstantaneously)? Whyare2.5â€HDDsbecomingpopularforcom- mercialservers(relativeto3.5â€and5.25â€drives)? 6.
Assumethatan HDDmanufacturerincreasesthestoragedensityfrom1Tbitpersquare inchto5Tbitpersquareinch.
Howmuchinformationcanyoustoreonaringona2.5â€ HDD? Isthereadifferencebetweentheinnerandoutertracks? 7.
Goingfrom8bitto16bitdatatypesincreasestheamountofsiliconapproximatelyby four times.
Why? Why might NVIDIA have added INT4 operations to their Turing GPUs? 8.
How much faster is it to read forward through memory vs.
reading backwards? Does thisnumberdifferbetweendifferentcomputersand CPUvendors? Why? Write Ccode andexperimentwithit.
9.
Canyoumeasurethecachesizeofyourdisk? Whatisitforatypical HDD? Do SSDs needacache? 10.
Measurethepacketoverheadwhensendingmessagesacrossthe Ethernet.
Lookupthe differencebetween UDPand TCP/IPconnections.
11.
Directmemoryaccessallowsdevicesotherthanthe CPUtowrite(andread)directlyto (from)memory.
Whyisthisagoodidea? 12.
Lookattheperformancenumbersforthe Turing T4GPU.
Whydoestheperformance â€œonlyâ€doubleasyougofrom FP16to INT8and INT4? 13.
Whatistheshortesttimeitshouldtakeforapacketonaroundtripbetween San Fran- ciscoand Amsterdam? Hint: youcanassumethatthedistanceis10,000km.
206 Discussions206.
13.5 Training on Multiple GPUs Sofarwediscussedhowtotrainmodelsefficientlyon CPUsand GPUs.
Weevenshowed how deep learning frameworks allow one to parallelize computation and communication automatically between them in Section 13.3.
We also showed in Section 6.7 how to list alltheavailable GPUsonacomputerusingthenvidia-smicommand.
Whatwedidnot discussishowtoactuallyparallelizedeeplearningtraining.
Instead, weimpliedinpass- ingthatonewouldsomehowsplitthedataacrossmultipledevicesandmakeitwork.
The 573 Trainingon Multiple GPUs presentsectionfillsinthedetailsandshowshowtotrainanetworkinparallelwhenstarting fromscratch.
Detailsonhowtotakeadvantageoffunctionalityinhigh-level APIsisrele- gatedto Section13.6.
Weassumethatyouarefamiliarwithminibatchstochasticgradient descentalgorithmssuchastheonesdescribedin Section12.5.
13.5.1 Splittingthe Problem Letâ€™sstartwithasimplecomputervisionproblemandaslightlyarchaicnetwork, e.
g., with multiplelayersofconvolutions, pooling, andpossiblyafewfullyconnectedlayersinthe end.
That is, letâ€™s start with a network that looks quite similar to Le Net (Le Cun et al., 1998) or Alex Net (Krizhevsky et al., 2012).
Given multiple GPUs (2 if it is a desktop server,4onan AWSg4dn.12xlargeinstance,8onap3.16xlarge, or16onap2.16xlarge), wewanttopartitiontraininginamannerastoachievegoodspeedupwhilesimultaneously benefittingfromsimpleandreproducibledesignchoices.
Multiple GPUs, afterall, increase bothmemoryandcomputationability.
Inanutshell, wehavethefollowingchoices, given aminibatchoftrainingdatathatwewanttoclassify.
First, we could partition the network across multiple GPUs.
That is, each GPU takes as inputthedataflowingintoaparticularlayer, processesdataacrossanumberofsubsequent layersandthensendsthedatatothenext GPU.
Thisallowsustoprocessdatawithlarger networkswhencomparedwithwhatasingle GPUcouldhandle.
Besides, memoryfootprint per GPUcanbewellcontrolled(itisafractionofthetotalnetworkfootprint).
However, theinterfacebetweenlayers(andthus GPUs)requirestightsynchronization.
This can be tricky, in particular if the computational workloads are not properly matched be- tween layers.
The problem is exacerbated for large numbers of GPUs.
The interface be- tweenlayersalsorequireslargeamountsofdatatransfer, suchasactivationsandgradients.
Thismayoverwhelmthebandwidthofthe GPUbuses.
Moreover, compute-intensive, yet sequentialoperationsarenontrivialtopartition.
Seee.
g., Mirhoseinietal.
(2017)forabest effortinthisregard.
Itremainsadifficultproblemanditisunclearwhetheritispossible to achievegood (linear) scaling on nontrivial problems.
Wedo not recommend it unless there is excellent framework or operating system support for chaining together multiple GPUs.
Second, wecouldsplittheworklayerwise.
Forinstance, ratherthancomputing64channels onasingle GPUwecouldsplituptheproblemacross4GPUs, eachofwhichgeneratesdata for16channels.
Likewise, forafullyconnectedlayerwecouldsplitthenumberofoutput strategywasusedtodealwith GPUsthathadaverysmallmemoryfootprint(2GBatthe time).
Thisallowsforgoodscalingintermsofcomputation, providedthatthenumberof channels(orunits)isnottoosmall.
Besides, multiple GPUscanprocessincreasinglylarger networkssincetheavailablememoryscaleslinearly.
However, weneedaverylargenumberofsynchronizationorbarrieroperationssinceeach layer depends on the results from all the other layers.
Moreover, the amount of data that needstobetransferredispotentiallyevenlargerthanwhendistributinglayersacross GPUs.
Thus, wedonotrecommendthisapproachduetoitsbandwidthcostandcomplexity.
574 Computational Performance t .5.1 Modelparallelismintheoriginal Alex Netdesignduetolimited GPUmemory.
Last, wecouldpartitiondataacrossmultiple GPUs.
Thiswayall GPUsperformthesame typeofwork, albeitondifferentobservations.
Gradientsareaggregatedacross GPUsafter eachminibatchoftrainingdata.
Thisisthesimplestapproachanditcanbeappliedinany situation.
Weonlyneedtosynchronizeaftereachminibatch.
Thatsaid, itishighlydesirable to start exchanging gradients parameters already while others are still being computed.
Moreover, largernumbersof GPUsleadtolargerminibatchsizes, thusincreasingtraining efficiency.
However, addingmore GPUsdoesnotallowustotrainlargermodels.
t .5.2 Parallelizationonmultiple GPUs.
Fromlefttoright: originalproblem, network partitioning, layerwisepartitioning, dataparallelism.
A comparison of different ways of parallelization on multiple GPUs is depicted in .5.2.
By and large, data parallelism is the most convenient way to proceed, provided thatwehaveaccessto GPUswithsufficientlylargememory.
Seealso(Lietal.,2014)for a detailed description of partitioning for distributed training.
GPU memory used to be a problemintheearlydaysofdeeplearning.
Bynowthisissuehasbeenresolvedforallbut themostunusualcases.
Wefocusondataparallelisminwhatfollows.
13.5.2 Data Parallelism Assumethatthereareğ‘˜GPUsonamachine.
Giventhemodeltobetrained, each GPUwill maintainacompletesetofmodelparametersindependentlythoughparametervaluesacross 575 Trainingon Multiple GPUs the GPUs are identical and synchronized.
As an example, .5.3 illustrates training withdataparallelismwhenğ‘˜ =2.
t .5.3 Calculationofminibatchstochasticgradientdescentusingdataparallelismontwo GPUs.
Ingeneral, thetrainingproceedsasfollows: Inanyiterationoftraining, givenarandomminibatch, wesplittheexamplesinthebatch intoğ‘˜ portionsanddistributethemevenlyacrossthe GPUs.
Each GPUcalculateslossandgradientofthemodelparametersbasedontheminibatch subsetitwasassigned.
Thelocalgradientsofeachoftheğ‘˜GPUsareaggregatedtoobtainthecurrentminibatch stochasticgradient.
Theaggregategradientisre-distributedtoeach GPU.
Each GPUusesthisminibatchstochasticgradienttoupdatethecompletesetofmodel parametersthatitmaintains.
Notethatinpracticeweincreasetheminibatchsizeğ‘˜-foldwhentrainingonğ‘˜ GPUssuch thateach GPUhasthesameamountofworktodoasifweweretrainingonasingle GPU only.
Ona16-GPUserverthiscanincreasetheminibatchsizeconsiderablyandwemay havetoincreasethelearningrateaccordingly.
Alsonotethatbatchnormalizationin Section 8.5 needs to be adjusted, e.
g., by keeping a separate batch normalization coefficient per GPU.
Inwhatfollowswewilluseatoynetworktoillustratemulti-GPUtraining.
%matplotlib inline import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 13.5.3 AToy Network Weuse Le Netasintroducedin Section7.6(withslightmodifications).
Wedefineitfrom scratchtoillustrateparameterexchangeandsynchronizationindetail.
576 Computational Performance # Initialize model parameters scale = 0.01 W1 = torch.
randn(size=(20, 1, 3, 3)) * scale b1 = torch.
zeros(20) W2 = torch.
randn(size=(50, 20, 5, 5)) * scale b2 = torch.
zeros(50) W3 = torch.
randn(size=(800, 128)) * scale b3 = torch.
zeros(128) W4 = torch.
randn(size=(128, 10)) * scale b4 = torch.
zeros(10) params = [W1, b1, W2, b2, W3, b3, W4, b4] # Define the model def lenet(X, params): h1_conv = F.
conv2d(input=X, weight=params[0], bias=params[1]) h1_activation = F.
relu(h1_conv) h1 = F.
avg_pool2d(input=h1_activation, kernel_size=(2, 2), stride=(2, 2)) h2_conv = F.
conv2d(input=h1, weight=params[2], bias=params[3]) h2_activation = F.
relu(h2_conv) h2 = F.
avg_pool2d(input=h2_activation, kernel_size=(2, 2), stride=(2, 2)) h2 = h2.
reshape(h2.
shape[0], -1) h3_linear = torch.
mm(h2, params[4]) + params[5] h3 = F.
relu(h3_linear) y_hat = torch.
mm(h3, params[6]) + params[7] return y_hat # Cross-entropy loss function loss = nn.
Cross Entropy Loss(reduction='none') 13.5.4 Data Synchronization For efficient multi-GPU training we need two basic operations.
First we need to have the ability to distribute a list of parameters to multiple devices and to attach gradients (get_params).
Without parameters it is impossible to evaluate the network on a GPU.
Second, we need the ability to sum parameters across multiple devices, i.
e., we need an allreducefunction.
def get_params(params, device): new_params = [p.
to(device) for p in params] for p in new_params: p.
requires_grad_() return new_params Letâ€™stryitoutbycopyingthemodelparameterstoone GPU.
new_params = get_params(params, d2l.
try_gpu(0)) print('b1 weight:', new_params[1]) print('b1 grad:', new_params[1].
grad) (continuesonnextpage) 577 Trainingon Multiple GPUs (continuedfrompreviouspage) device='cuda:0', requires_grad=True) b1 grad: None Sincewedidnotperformanycomputationyet, thegradientwithregardtothebiasparam- eterisstillzero.
Nowletâ€™sassumethatwehaveavectordistributedacrossmultiple GPUs.
Thefollowingallreducefunctionaddsupallvectorsandbroadcaststheresultbacktoall GPUs.
Notethatforthistoworkweneedtocopythedatatothedeviceaccumulatingthe results.
def allreduce(data): for i in range(1, len(data)): data[0][:] += data[i].
to(data[0].
device) for i in range(1, len(data)): data[i][:] = data[0].
to(data[i].
device) Letâ€™stestthisbycreatingvectorswithdifferentvaluesondifferentdevicesandaggregate them.
data = [torch.
ones((1, 2), device=d2l.
try_gpu(i)) * (i + 1) for i in range(2)] print('before allreduce:\n', data[0], '\n', data[1]) allreduce(data) print('after allreduce:\n', data[0], '\n', data[1]) before allreduce: tensor([[1., 1.]], device='cuda:0') tensor([[2., 2.]], device='cuda:1') after allreduce: tensor([[3., 3.]], device='cuda:0') tensor([[3., 3.]], device='cuda:1') 13.5.5 Distributing Data Weneedasimpleutilityfunctiontodistributeaminibatchevenlyacrossmultiple GPUs.
Forinstance, ontwo GPUswewouldliketohavehalfofthedatatobecopiedtoeitherof the GPUs.
Sinceitismoreconvenientandmoreconcise, weusethebuilt-infunctionfrom thedeeplearningframeworktotryitoutona4 5matrix.
data = torch.
arange(20).
reshape(4, 5) devices = [torch.
device('cuda:0'), torch.
device('cuda:1')] split = nn.
parallel.
scatter(data, devices) print('input :', data) print('load into', devices) print('output:', split) 578 Computational Performance input : tensor([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) load into [device(type='cuda', index=0), device(type='cuda', index=1)] output: (tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], device='cuda:0'), tensor([[10, 11, 12, 13, 14], [15, 16, 17, 18, 19]], device='cuda:1')) Forlaterreusewedefineasplit_batchfunctionthatsplitsbothdataandlabels.
#@save def split_batch(X, y, devices): """Split `X` and `y` into multiple devices.""" assert X.
shape[0] == y.
shape[0] return (nn.
parallel.
scatter(X, devices), nn.
parallel.
scatter(y, devices)) 13.5.6 Training Nowwecanimplementmulti-GPUtrainingonasingleminibatch.
Itsimplementationis primarilybasedonthedataparallelismapproachdescribedinthissection.
Wewillusethe auxiliaryfunctionswejustdiscussed, allreduceandsplit_and_load, tosynchronizethe dataamongmultiple GPUs.
Notethatwedonotneedtowriteanyspecificcodetoachieve parallelism.
Sincethecomputationalgraphdoesnothaveanydependenciesacrossdevices withinaminibatch, itisexecutedinparallelautomatically.
def train_batch(X, y, device_params, devices, lr): X_shards, y_shards = split_batch(X, y, devices) # Loss is calculated separately on each GPU ls = [loss(lenet(X_shard, device_W), y_shard).
sum() for X_shard, y_shard, device_W in zip( X_shards, y_shards, device_params)] for l in ls: # Backpropagation is performed separately on each GPU l.
backward() # Sum all gradients from each GPU and broadcast them to all GPUs with torch.
no_grad(): for i in range(len(device_params[0])): allreduce([device_params[c][i].
grad for c in range(len(devices))]) # The model parameters are updated separately on each GPU for param in device_params: d2l.
sgd(param, lr, X.
shape[0]) # Here, we use a full-size batch Now, wecandefinethetrainingfunction.
Itisslightlydifferentfromtheonesusedinthe previouschapters: weneedtoallocatethe GPUsandcopyallthemodelparameterstoall the devices.
Obviously each batch is processed using the train_batch function to deal withmultiple GPUs.
Forconvenience(andconcisenessofcode)wecomputetheaccuracy onasingle GPU, thoughthisisineï¬€icientsincetheother GPUsareidle.
579 Trainingon Multiple GPUs def train(num_gpus, batch_size, lr): train_iter, test_iter = d2l.
load_data_fashion_mnist(batch_size) devices = [d2l.
try_gpu(i) for i in range(num_gpus)] # Copy model parameters to `num_gpus` GPUs device_params = [get_params(params, d) for d in devices] num_epochs = 10 animator = d2l.
Animator('epoch', 'test acc', xlim=[1, num_epochs]) timer = d2l.
Timer() for epoch in range(num_epochs): timer.
start() for X, y in train_iter: # Perform multi-GPU training for a single minibatch train_batch(X, y, device_params, devices, lr) torch.
cuda.
synchronize() timer.
stop() # Evaluate the model on GPU 0 animator.
add(epoch + 1, (d2l.
evaluate_accuracy_gpu( lambda x: lenet(x, device_params[0]), test_iter, devices[0]),)) print(f'test acc: {animator.
Y[0][-1]:.2f}, {timer.
avg():.1f} sec/epoch ' f'on {str(devices)}') Letâ€™s see how well this works on a single GPU.
We first use a batch size of 256 and a learningrateof0.2.
train(num_gpus=1, batch_size=256, lr=0.2) test acc: 0.83, 3.0 sec/epoch on [device(type='cuda', index=0)] Bykeepingthebatchsizeandlearningrateunchangedandincreasingthenumberof GPUs to2, wecanseethatthetestaccuracyroughlystaysthesamecomparedwiththeprevious experiment.
Intermsoftheoptimizationalgorithms, theyareidentical.
Unfortunatelythere isnomeaningfulspeeduptobegainedhere: themodelissimplytoosmall; moreoverwe only have a small dataset, where our slightly unsophisticated approach to implementing multi-GPU training suffered from significant Python overhead.
We will encounter more complexmodelsandmoresophisticatedwaysofparallelizationgoingforward.
Letâ€™ssee whathappensnonethelessfor Fashion-MNIST.
580 Computational Performance train(num_gpus=2, batch_size=256, lr=0.2) test acc: 0.84, 2.8 sec/epoch on [device(type='cuda', index=0), device(type= â†©!'cuda', index=1)] 13.5.7 Summary Therearemultiplewaystosplitdeepnetworktrainingovermultiple GPUs.
Wecould splitthembetweenlayers, acrosslayers, oracrossdata.
Theformertworequiretightly choreographeddatatransfers.
Dataparallelismisthesimpleststrategy.
Data parallel training is straightforward.
However, it increases the effective minibatch sizetobeefficient.
In data parallelism, data is split across multiple GPUs, where each GPU executes its ownforwardandbackwardoperationandsubsequentlygradientsareaggregatedand resultsarebroadcastbacktothe GPUs.
Wemayuseslightlyincreasedlearningratesforlargerminibatches.
13.5.8 Exercises 1.
Whentrainingonğ‘˜ GPUs, changetheminibatchsizefromğ‘toğ‘˜ ğ‘, i.
e., scaleitupby thenumberof GPUs.
2.
Compare accuracy for different learning rates.
How does it scale with the number of GPUs? 3.
Implementamoreefficientallreducefunctionthataggregatesdifferentparameterson different GPUs? Whyisitmoreefficient? 207 4.
Implementmulti-GPUtestaccuracycomputation.
Discussions207.
581 Concise Implementationfor Multiple GPUs 13.6 Concise Implementation for Multiple GPUs Implementingparallelismfromscratchforeverynewmodelisnofun.
Moreover, thereis significantbenefitinoptimizingsynchronizationtoolsforhighperformance.
Inthefollow- ingwewillshowhowtodothisusinghigh-level APIsofdeeplearningframeworks.
The mathematicsandthealgorithmsarethesameasin Section13.5.
Quiteunsurprisinglyyou willneedatleasttwo GPUstoruncodeofthissection.
import torch from torch import nn from d2l import torch as d2l 13.6.1 AToy Network Letâ€™s use a slightly more meaningful network than Le Net from Section 13.5 that is still sufficientlyeasyandquicktotrain.
Wepicka Res Net-18variant(Heetal.,2016).
Since theinputimagesaretinywemodifyitslightly.
Inparticular, thedifferencefrom Section8.6 isthatweuseasmallerconvolutionkernel, stride, andpaddingatthebeginning.
Moreover, weremovethemax-poolinglayer.
#@save def resnet18(num_classes, in_channels=1): """A slightly modified Res Net-18 model.""" def resnet_block(in_channels, out_channels, num_residuals, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.
append(d2l.
Residual(out_channels, use_1x1conv=True, strides=2)) else: blk.
append(d2l.
Residual(out_channels)) return nn.
Sequential(*blk) # This model uses a smaller convolution kernel, stride, and padding and # removes the max-pooling layer net = nn.
Sequential( nn.
Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1), nn.
Batch Norm2d(64), nn.
Re LU()) net.
add_module("resnet_block1", resnet_block(64, 64, 2, first_block=True)) net.
add_module("resnet_block2", resnet_block(64, 128, 2)) net.
add_module("resnet_block3", resnet_block(128, 256, 2)) net.
add_module("resnet_block4", resnet_block(256, 512, 2)) net.
add_module("global_avg_pool", nn.
Adaptive Avg Pool2d((1,1))) net.
add_module("fc", nn.
Sequential(nn.
Flatten(), nn.
Linear(512, num_classes))) return net 582 Computational Performance 13.6.2 Network Initialization We will initialize the network inside the training loop.
For a refresher on initialization methodssee Section5.4.
net = resnet18(10) # Get a list of GPUs devices = d2l.
try_all_gpus() # We will initialize the network inside the training loop 13.6.3 Training As before, the training code needs to perform several basic functions for efficient paral- lelism: Networkparametersneedtobeinitializedacrossalldevices.
Whileiteratingoverthedatasetminibatchesaretobedividedacrossalldevices.
Wecomputethelossanditsgradientinparallelacrossdevices.
Gradientsareaggregatedandparametersareupdatedaccordingly.
Intheendwecomputetheaccuracy(againinparallel)toreportthefinalperformanceof thenetwork.
Thetrainingroutineisquitesimilartoimplementationsinpreviouschapters, exceptthatweneedtosplitandaggregatedata.
def train(net, num_gpus, batch_size, lr): train_iter, test_iter = d2l.
load_data_fashion_mnist(batch_size) devices = [d2l.
try_gpu(i) for i in range(num_gpus)] def init_weights(module): if type(module) in [nn.
Linear, nn.
Conv2d]: nn.
init.
normal_(module.
weight, std=0.01) net.
apply(init_weights) # Set the model on multiple GPUs net = nn.
Data Parallel(net, device_ids=devices) trainer = torch.
optim.
SGD(net.
parameters(), lr) loss = nn.
Cross Entropy Loss() timer, num_epochs = d2l.
Timer(), 10 animator = d2l.
Animator('epoch', 'test acc', xlim=[1, num_epochs]) for epoch in range(num_epochs): net.
train() timer.
start() for X, y in train_iter: trainer.
zero_grad() X, y = X.
to(devices[0]), y.
to(devices[0]) l = loss(net(X), y) l.
backward() trainer.
step() timer.
stop() animator.
add(epoch + 1, (d2l.
evaluate_accuracy_gpu(net, test_iter),)) print(f'test acc: {animator.
Y[0][-1]:.2f}, {timer.
avg():.1f} sec/epoch ' f'on {str(devices)}') 583 Concise Implementationfor Multiple GPUs Letâ€™s see how this works in practice.
As a warm-up we train the network on a single GPU.
train(net, num_gpus=1, batch_size=256, lr=0.1) test acc: 0.91, 12.2 sec/epoch on [device(type='cuda', index=0)] Next we use 2 GPUs for training.
Compared with Le Net evaluated in Section 13.5, the model for Res Net-18 is considerably more complex.
This is where parallelization shows itsadvantage.
Thetimeforcomputationismeaningfullylargerthanthetimeforsynchro- nizingparameters.
Thisimprovesscalabilitysincetheoverheadforparallelizationisless relevant.
train(net, num_gpus=2, batch_size=512, lr=0.2) test acc: 0.73, 7.5 sec/epoch on [device(type='cuda', index=0), device(type= â†©!'cuda', index=1)] 13.6.4 Summary Dataisautomaticallyevaluatedonthedeviceswherethedatacanbefound.
Takecaretoinitializethenetworksoneachdevicebeforetryingtoaccesstheparameters onthatdevice.
Otherwiseyouwillencounteranerror.
Theoptimizationalgorithmsautomaticallyaggregateovermultiple GPUs.
584 Computational Performance 13.6.5 Exercises 1.
Thissectionuses Res Net-18.
Trydifferentepochs, batchsizes, andlearningrates.
Use more GPUsforcomputation.
Whathappensifyoutrythiswith16GPUs(e.
g., onan AWSp2.16xlargeinstance)? 2.
Sometimes, different devices provide different computing power.
We could use the GPUsandthe CPUatthesametime.
Howshouldwedividethework? Isitworththe effort? Why? Whynot? Discussions208.
208 13.7 Parameter Servers Aswemovefromasingle GPUtomultiple GPUsandthentomultipleserverscontaining multiple GPUs, possibly all spread out across multiple racks and network switches, our algorithmsfordistributedandparalleltrainingneedtobecomemuchmoresophisticated.
Details matter since different interconnects have very different bandwidth (e.
g., NVLink canofferupto100GB/sacross6linksinanappropriatesetting, PCIe4.0(16-lane)offers 32GB/s, whileevenhighspeed100Gb EEthernetonlyamountsto10GB/s).
Atthesame timeitisunreasonabletoexpectthatastatisticalmodelerbeanexpertinnetworkingand systems.
Thecoreideaoftheparameterserverwasintroducedin Smolaand Narayanamurthy(2010) in the context of distributed latent variable models.
A description of the push and pull semantics then followed in Ahmed et al.
(2012) and a description of the system and an open source library followed in Li et al.
(2014).
In the following we will motivate the componentsneededforefficiency.
13.7.1 Data-Parallel Training Letâ€™s review the data parallel training approach to distributed training.
We will use this to the exclusion of all others in this section since it is significantly simpler to implement inpractice.
Therearevirtuallynousecases(besidesdeeplearningongraphs)whereany other strategy for parallelism is preferred since GPUs have plenty of memory nowadays.
Thekeyaspectinitisthattheaggregationofgradientsoccursononesingle GPU(GPU0) beforetheupdatedparametersarerebroadcasttoall GPUs.
Inretrospect, thedecisiontoaggregateon GPU0seemsratherad-hoc.
Afterall, wemight just as well aggregate on the CPU.
In fact, we could even decide to aggregate some of the parameters on one GPU and some others on another.
Provided that the optimization algorithmsupportsthis, thereisnorealreasonforwhywecouldnot.
Forinstance, ifwe have four parameter vectors with associated gradients g ,..., g we could aggregate the 1 4 gradientsonone GPUforeachgğ‘– (ğ‘– =1,...,4).
585 Parameter Servers t .7.1 Left: single GPUtraining.
Right: avariantofmulti-GPUtraining: (1)wecomputeloss andgradient,(2)allgradientsareaggregatedonone GPU,(3)parameterupdatehappens andtheparametersarere-distributedtoall GPUs.
Thisreasoningseemsarbitraryandfrivolous.
Afterall, themathematicsisthesamethrough- out.
However, wearedealingwithrealphysicalhardwarewheredifferentbuseshavediffer- entbandwidthasdiscussedin Section13.4.
Considerareal4-way GPUserverasdescribed Moretypicalnumbersareinthe1â€“10Gb Erangewithaneffectivebandwidthof100MB/s to1GB/s.
Sincethe CPUshavetoofew PCIelanestoconnecttoall GPUsdirectly(e.
g., consumer-grade Intel CPUshave24lanes)weneedamultiplexer209.
Thebandwidthfrom 209 the CPUona16x Gen3linkis16GB/s.
Thisisalsothespeedatwhicheachofthe GPUs isconnectedtotheswitch.
Thismeansthatitismoreeffectivetocommunicatebetween thedevices.
t .7.2 A4-way GPUserver.
586 Computational Performance For the sake of the argument letâ€™s assume that the gradients are of 160 MB.
In this case it takes 30 ms to send the gradients from all 3 remaining GPUs to the fourth one (each transfertakes10ms=160MB/16GB/s).
Addinganother30mstotransmittheweight vectorsbackwearriveatatotalof60ms.
Ifwesendalldatatothe CPUweincurapenalty of40mssinceeachofthefour GPUsneedstosendthedatatothe CPU, yieldingatotal of80ms.
Lastlyassumethatweareabletosplitthegradientsinto4partsof40MBeach.
Nowwecanaggregateeachofthepartsonadifferent GPUsimultaneouslysincethe PCIe switchoffersafull-bandwidthoperationbetweenalllinks.
Insteadof30msthistakes7.5 ms, yieldingatotalof15msforasynchronizationoperation.
Inshort, dependingonhow we synchronize parameters the same operation can take anywhere from 15 ms to 80 ms.
.7.3depictsthedifferentstrategiesforexchangingparameters.
t .7.3 Parametersynchronizationstrategies.
Notethatwehaveyetanothertoolatourdisposalwhenitcomestoimprovingperformance: inadeepnetworkittakessometimetocomputeallgradientsfromthetoptothebottom.
Wecanbeginsynchronizinggradientsforsomeparametergroupsevenwhilewearestill busycomputingthemforothers.
Seee.
g., Sergeevand Del Balso(2018)fordetailsonhow todothisin Horovod210.
210 13.7.2 Ring Synchronization Whenitcomestosynchronizationonmoderndeeplearninghardwareweoftenencounter significantlybespokenetworkconnectivity.
Forinstance, the AWSp3.16xlargeand NVIDIA DGX-2instancessharetheconnectivitystructureof.7.4.
Each GPUconnectstoa host CPUviaa PCIelinkwhichoperatesatbestat16GB/s.
Additionallyeach GPUalso has 6 NVLink connections, each of which is capable of transferring 300 Gbit/s bidirec- tionally.
This amounts to around 18 GB/s per link per direction.
In short, the aggregate NVLinkbandwidthissignificantlyhigherthanthe PCIebandwidth.
Thequestionishow touseitmostefficiently.
Itturnsoutthattheoptimalsynchronizationstrategyistodecomposethenetworkintotwo thatthenetworkcanbedecomposedintoonering(1-2-3-4-5-6-7-8-1)withdouble NVLink bandwidthandintoone(1-4-6-3-5-8-2-7-1)withregularbandwidth.
Designinganefficient synchronizationprotocolinthiscaseisnontrivial.
Considerthefollowingthoughtexperiment: givenaringofğ‘›computingnodes(or GPUs) 587 Parameter Servers t .7.4 NVLinkconnectivityon8V100GPUservers(imagecourtesyof NVIDIA).
t .7.5 Decompositionofthe NVLinknetworkintotworings.
we can send gradients from the first to the second node.
There it is added to the local gradientandsentontothethirdnode, andsoon.
Afterğ‘› 1stepstheaggregategradient canbefoundinthelast-visitednode.
Thatis, thetimetoaggregategradientsgrowslinearly with the number of nodes.
But if we do this the algorithm is quite inefficient.
After all, atanytimethereisonlyoneofthenodescommunicating.
Whatifwebrokethegradients intoğ‘›chunksandstartedsynchronizingchunkğ‘–startingatnodeğ‘–? Sinceeachchunkisof size1 ğ‘›thetotaltimeisnow â€ğ‘› 1â€ ğ‘› 1.
Inotherwords, thetimespenttoaggregate 588 Computational Performance gradients does not grow as we increase the size of the ring.
This is quite an astonishing t .7.6 Ringsynchronizationacross4nodes.
Eachnodestartstransmittingpartsofgradientsto itsleftneighboruntiltheassembledgradientcanbefoundinitsrightneighbor.
If we use the same example of synchronizing 160 MB across 8 V100 GPUs we arrive at approximately 2 160MB â€3 18GB/sâ€ 6ms.
This is better than using the PCIe bus, even though we are now using 8 GPUs.
Note that in practice these numbers are a bitworse, sincedeeplearningframeworksoftenfailtoassemblecommunicationintolarge bursttransfers.
Note that there is a common misconception that ring synchronization is fundamentally differentfromothersynchronizationalgorithms.
Theonlydifferenceisthatthesynchro- nizationpathissomewhatmoreelaboratewhencomparedwithasimpletree.
13.7.3 Multi-Machine Training Distributedtrainingonmultiplemachinesaddsafurtherchallenge: weneedtocommuni- catewithserversthatareonlyconnectedacrossacomparativelylowerbandwidthfabricthat canbeoveranorderofmagnitudeslowerinsomecases.
Synchronizationacrossdevicesis tricky.
Afterall, differentmachinesrunningtrainingcodewillhavesubtlydifferentspeed.
Henceweneedtosynchronizethemifwewanttousesynchronousdistributedoptimization.
.7.7illustrateshowdistributedparalleltrainingoccurs.
1.
A (different) batch of data is read on each machine, split across multiple GPUs and transferred to GPU memory.
There predictions and gradients are computed on each GPUbatchseparately.
2.
Thegradientsfromalllocal GPUsareaggregatedonone GPU(orpartsofitareaggre- gatedoverdifferent GPUs).
589 Parameter Servers 3.
Thegradientsaresenttothe CPUs.
4.
The CPUs send the gradients to a central parameter server which aggregates all the gradients.
5.
Theaggregategradientsarethenusedtoupdatetheparametersandtheupdatedparam- etersarebroadcastbacktotheindividual CPUs.
6.
Theinformationissenttoone(ormultiple)GPUs.
7.
Theupdatedparametersarespreadacrossall GPUs.
t .7.7 Multi-machinemulti-GPUdistributedparalleltraining.
Each of these operations seems rather straightforward.
And, indeed, they can be carried out efficiently within a single machine.
Once we look at multiple machines, though, we canseethatthecentralparameterserverbecomesthebottleneck.
Afterall, thebandwidth per server is limited, hence for ğ‘š workers the time it takes to send all gradients to the server is Oâ€ğ‘šâ€.
We can break through this barrier by increasing the number of servers to ğ‘›.
At this point each server only needs to store Oâ€1 ğ‘›â€ of the parameters, hence the totaltimeforupdatesandoptimizationbecomes Oâ€ğ‘š ğ‘›â€.
Matchingbothnumbersyields constantscalingregardlessofhowmanyworkerswearedealingwith.
Inpracticeweusethe samemachinesbothasworkersandasservers.
.7.8illustratesthedesign(seealso (Lietal., 2014)fordetails).
Inparticular, ensuringthatmultiplemachinesworkwithout unreasonabledelaysisnontrivial.
13.7.4 Keyâ€“Value Stores Implementingthestepsrequiredfordistributedmulti-GPUtraininginpracticeisnontrivial.
This is why it pays to use a common abstraction, namely that of a keyâ€“value store with redefinedupdatesemantics.
590 Computational Performance t .7.8 Top: asingleparameterserverisabottlenecksinceitsbandwidthisfinite.
Bottom: multipleparameterserversstorepartsoftheparameterswithaggregatebandwidth.
Acrossmanyworkersandmany GPUsthecomputationforgradientğ‘–canbedefinedas gğ‘– = gğ‘–ğ‘—ğ‘˜ , (13.7.1) ğ‘˜2workersğ‘—2GPUs wheregğ‘–ğ‘—ğ‘˜ispartofgradientğ‘–spliton GPU ğ‘—ofworkerğ‘˜.
Thekeyaspectinthisoperation isthatitisacommutativereduction, thatis, itturnsmanyvectorsintooneandtheorderin whichtheoperationisapplieddoesnotmatter.
Thisisgreatforourpurposessincewedo not(needto)havefinegrainedcontroloverwhenwhichgradientisreceived.
Besides, note thatthisoperationisindependentamongdifferentğ‘–.
Thisallowsustodefinethefollowingtwooperations: push, whichaccumulatesgradients, and pull, which retrieves aggregate gradients.
Since we have many different sets of gra- dients(afterall, wehavemanylayers), weneedtoindexthegradientswithakeyğ‘–.
This similarity to keyâ€“value stores, such as the one introduced in Dynamo (De Candia et al., 2007)isnotbycoincidence.
They, too, satisfymanysimilarcharacteristics, inparticular whenitcomestodistributingtheparametersacrossmultipleservers.
Thepushandpulloperationsforkey-valuestoresaredescribedasfollows: push(key, value) sends a particular gradient (the value) from a worker to a common storage.
Therethevalueisaggregated, e.
g., bysummingitup.
pull(key, value)retrievesanaggregatevaluefromcommonstorage, e.
g., aftercombining thegradientsfromallworkers.
Byhidingallthecomplexityaboutsynchronizationbehindasimplepushandpulloperation 591 Parameter Servers wecandecoupletheconcernsofstatisticalmodelerswhowanttobeabletoexpressopti- mizationinsimpletermsandthesystemengineerswhoneedtodealwiththecomplexity inherentindistributedsynchronization.
13.7.5 Summary Synchronizationneedstobehighlyadaptivetospecificnetworkinfrastructureandcon- nectivitywithinaserver.
Thiscanmakeasignificantdifferencetothetimeittakesto synchronize.
Ring-synchronizationcanbeoptimalforp3and DGX-2servers.
Forotherspossiblynot somuch.
A hierarchical synchronization strategy works well when adding multiple parameter serversforincreasedbandwidth.
13.7.6 Exercises 1.
Canyouincreasetheringsynchronizationevenfurther? Hint: youcansendmessages inbothdirections.
2.
Is it possible to allow asynchronous communication (while computation is still ongo- ing)? Howdoesitaffectperformance? 3.
Whatifwelostaserverduringalong-runningcomputation? Howcanwedesignafault tolerancemechanismtoavoidrestartingthecomputationfully? Discussions211.
211 14 Computer Vision Whetheritismedicaldiagnosis, self-drivingvehicles, cameramonitoring, orsmartfilters, manyapplicationsinthefieldofcomputervisionarecloselyrelatedtoourcurrentandfu- turelives.
Inrecentyears, deeplearninghasbeenthetransformativepowerforadvancing theperformanceofcomputervisionsystems.
Itcanbesaidthatthemostadvancedcom- putervisionapplicationsarealmostinseparablefromdeeplearning.
Inviewofthis, this chapterwillfocusonthefieldofcomputervision, andinvestigatemethodsandapplications thathaverecentlybeeninfluentialinacademiaandindustry.
In Chapter 7 and Chapter 8, we studied various convolutional neural networks that are commonlyusedincomputervision, andappliedthemtosimpleimageclassificationtasks.
At the beginning of this chapter, we will describe two methods that may improve model generalization, namelyimageaugmentationandfine-tuning, andapplythemtoimageclas- sification.
Since deep neural networks can effectively represent images in multiple lev- els, suchlayerwiserepresentationshavebeensuccessfullyusedinvariouscomputervision taskssuchasobjectdetection, semanticsegmentation, andstyletransfer.
Followingthekey ideaofleveraginglayerwiserepresentationsincomputervision, wewillbeginwithmajor componentsandtechniquesforobjectdetection.
Next, wewillshowhowtousefullycon- volutionalnetworksforsemanticsegmentationofimages.
Thenwewillexplainhowtouse styletransfertechniquestogenerateimageslikethecoverofthisbook.
Intheend, wecon- cludethischapterbyapplyingthematerialsofthischapterandseveralpreviouschapters ontwopopularcomputervisionbenchmarkdatasets.
14.1 Image Augmentation In Section8.1, wementionedthatlargedatasetsareaprerequisiteforthesuccessofdeep neuralnetworksinvariousapplications.
Imageaugmentationgeneratessimilarbutdistinct trainingexamplesafteraseriesofrandomchangestothetrainingimages, therebyexpand- ingthesizeofthetrainingset.
Alternatively, imageaugmentationcanbemotivatedbythe factthatrandomtweaksoftrainingexamplesallowmodelstorelylessoncertainattributes, therebyimprovingtheirgeneralizationability.
Forexample, wecancropanimageindif- ferent ways to make the object of interest appear in different positions, thereby reducing thedependenceofamodelonthepositionoftheobject.
Wecanalsoadjustfactorssuchas brightnessandcolortoreduceamodelâ€™ssensitivitytocolor.
Itisprobablytruethatimage 592 593 Image Augmentation augmentationwasindispensableforthesuccessof Alex Netatthattime.
Inthissectionwe willdiscussthiswidelyusedtechniqueincomputervision.
%matplotlib inline import torch import torchvision from torch import nn from d2l import torch as d2l 14.1.1 Common Image Augmentation Methods In our investigation of common image augmentation methods, we will use the following 400 500imageanexample.
d2l.
set_figsize() d2l.
plt.
imshow(img); Mostimageaugmentationmethodshaveacertaindegreeofrandomness.
Tomakeiteasier for us to observe the effect of image augmentation, next we define an auxiliary function apply.
Thisfunctionrunstheimageaugmentationmethodaugmultipletimesontheinput imageimgandshowsalltheresults.
def apply(img, aug, num_rows=2, num_cols=4, scale=1.5): Y = [aug(img) for _ in range(num_rows * num_cols)] d2l.
show_images(Y, num_rows, num_cols, scale=scale) Flippingand Cropping Flippingtheimageleftandrightusuallydoesnotchangethecategoryoftheobject.
Thisis oneoftheearliestandmostwidelyusedmethodsofimageaugmentation.
Next, weusethe transformsmoduletocreatethe Random Horizontal Flipinstance, whichflipsanimage leftandrightwitha50%chance.
apply(img, torchvision.
transforms.
Random Horizontal Flip()) Flipping up and down is not as common as flipping left and right.
But at least for this 594 Computer Vision exampleimage, flippingupanddowndoesnothinderrecognition.
Next, wecreatea Ran- dom Vertical Flipinstancetoflipanimageupanddownwitha50%chance.
apply(img, torchvision.
transforms.
Random Vertical Flip()) Intheexampleimageweused, thecatisinthemiddleoftheimage, butthismaynotbethe caseingeneral.
In Section7.5, weexplainedthatthepoolinglayercanreducethesensitivity ofaconvolutionallayertothetargetposition.
Inaddition, wecanalsorandomlycropthe imagetomakeobjectsappearindifferentpositionsintheimageatdifferentscales, which canalsoreducethesensitivityofamodeltothetargetposition.
Inthecodebelow, werandomlycropanareawithanareaof10% 100%oftheoriginal areaeachtime, andtheratioofwidthtoheightofthisareaisrandomlyselectedfrom0.5 2.
Then, thewidthandheightoftheregionarebothscaledto200pixels.
Unlessotherwise specified, therandomnumberbetweenğ‘andğ‘inthissectionreferstoacontinuousvalue obtainedbyrandomanduniformsamplingfromtheinterval Â»ğ‘,ğ‘â€¦.
shape_aug = torchvision.
transforms.
Random Resized Crop( (200, 200), scale=(0.1, 1), ratio=(0.5, 2)) apply(img, shape_aug) Changing Colors Anotheraugmentationmethodischangingcolors.
Wecanchangefouraspectsoftheimage color: brightness, contrast, saturation, andhue.
Intheexamplebelow, werandomlychange the brightness of the image to a value between 50% (1 0.5) and 150% (1â€š0.5) of the originalimage.
595 Image Augmentation apply(img, torchvision.
transforms.
Color Jitter( brightness=0.5, contrast=0, saturation=0, hue=0)) Similarly, wecanrandomlychangethehueoftheimage.
apply(img, torchvision.
transforms.
Color Jitter( brightness=0, contrast=0, saturation=0, hue=0.5)) We can also create a Random Color Jitter instance and set how to randomly change the brightness, contrast, saturation, andhueoftheimageatthesametime.
color_aug = torchvision.
transforms.
Color Jitter( brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5) apply(img, color_aug) 596 Computer Vision Combining Multiple Image Augmentation Methods Inpractice, wewillcombinemultipleimageaugmentationmethods.
Forexample, wecan combinethedifferentimageaugmentationmethodsdefinedaboveandapplythemtoeach imageviaa Composeinstance.
augs = torchvision.
transforms.
Compose([ torchvision.
transforms.
Random Horizontal Flip(), color_aug, shape_aug]) apply(img, augs) 14.1.2 Trainingwith Image Augmentation Letâ€™strainamodelwithimageaugmentation.
Hereweusethe CIFAR-10datasetinstead ofthe Fashion-MNISTdatasetthatweusedbefore.
Thisisbecausethepositionandsize of the objects in the Fashion-MNIST dataset have been normalized, while the color and sizeoftheobjectsinthe CIFAR-10datasethavemoresignificantdifferences.
Thefirst32 trainingimagesinthe CIFAR-10datasetareshownbelow.
all_images = torchvision.
datasets.
CIFAR10(train=True, root="../data", download=True) d2l.
show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8); â†©! cifar-10-python.
tar.
gz 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 170498071/170498071 [00:04<00:00, 37716809.52it/s] In order to obtain definitive results during prediction, we usually only apply image aug- 597 Image Augmentation mentation to training examples, and do not use image augmentation with random opera- tionsduringprediction.
Hereweonlyusethesimplestrandomleft-rightflippingmethod.
Inaddition, weusea To Tensorinstancetoconvertaminibatchofimagesintotheformat requiredbythedeeplearningframework, i.
e.,32-bitfloatingpointnumbersbetween0and 1withtheshapeof(batchsize, numberofchannels, height, width).
train_augs = torchvision.
transforms.
Compose([ torchvision.
transforms.
Random Horizontal Flip(), torchvision.
transforms.
To Tensor()]) test_augs = torchvision.
transforms.
Compose([ torchvision.
transforms.
To Tensor()]) Next, we define an auxiliary function to facilitate reading the image and applying image augmentation.
Thetransformargumentprovidedby Py Torchâ€™sdatasetappliesaugmen- tationtotransformtheimages.
Foradetailedintroductionto Data Loader, pleasereferto Section4.2.
def load_cifar10(is_train, augs, batch_size): dataset = torchvision.
datasets.
CIFAR10(root="../data", train=is_train, transform=augs, download=True) dataloader = torch.
utils.
data.
Data Loader(dataset, batch_size=batch_size, shuffle=is_train, num_workers=d2l.
get_dataloader_workers()) return dataloader Multi-GPUTraining Wetrainthe Res Net-18modelfrom Section8.6onthe CIFAR-10dataset.
Recallthein- troductiontomulti-GPUtrainingin Section13.6.
Inthefollowing, wedefineafunctionto trainandevaluatethemodelusingmultiple GPUs.
#@save def train_batch_ch13(net, X, y, loss, trainer, devices): """Train for a minibatch with multiple GPUs (defined in Chapter 13).""" if isinstance(X, list): # Required for BERT fine-tuning (to be covered later) X = [x.
to(devices[0]) for x in X] (continuesonnextpage) 598 Computer Vision (continuedfrompreviouspage) else: X = X.
to(devices[0]) y = y.
to(devices[0]) net.
train() trainer.
zero_grad() pred = net(X) l = loss(pred, y) l.
sum().
backward() trainer.
step() train_loss_sum = l.
sum() train_acc_sum = d2l.
accuracy(pred, y) return train_loss_sum, train_acc_sum #@save def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices=d2l.
try_all_gpus()): """Train a model with multiple GPUs (defined in Chapter 13).""" timer, num_batches = d2l.
Timer(), len(train_iter) animator = d2l.
Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1], legend=['train loss', 'train acc', 'test acc']) net = nn.
Data Parallel(net, device_ids=devices).
to(devices[0]) for epoch in range(num_epochs): # Sum of training loss, sum of training accuracy, no.
of examples, # no.
of predictions metric = d2l.
Accumulator(4) for i, (features, labels) in enumerate(train_iter): timer.
start() l, acc = train_batch_ch13( net, features, labels, loss, trainer, devices) metric.
add(l, acc, labels.
shape[0], labels.
numel()) timer.
stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.
add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[3], None)) test_acc = d2l.
evaluate_accuracy_gpu(net, test_iter) animator.
add(epoch + 1, (None, None, test_acc)) print(f'loss {metric[0] / metric[2]:.3f}, train acc ' f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}') print(f'{metric[2] * num_epochs / timer.
sum():.1f} examples/sec on ' f'{str(devices)}') Now we can define the train_with_data_aug function to train the model with image augmentation.
Thisfunctiongetsallavailable GPUs, uses Adamastheoptimizationalgo- rithm, appliesimageaugmentationtothetrainingdataset, andfinallycallsthetrain_ch13 functionjustdefinedtotrainandevaluatethemodel.
batch_size, devices, net = 256, d2l.
try_all_gpus(), d2l.
resnet18(10, 3) net.
apply(d2l.
init_cnn) def train_with_data_aug(train_augs, test_augs, net, lr=0.001): train_iter = load_cifar10(True, train_augs, batch_size) (continuesonnextpage) 599 Image Augmentation (continuedfrompreviouspage) test_iter = load_cifar10(False, test_augs, batch_size) loss = nn.
Cross Entropy Loss(reduction="none") trainer = torch.
optim.
Adam(net.
parameters(), lr=lr) net(next(iter(train_iter))[0]) train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices) Letâ€™strainthemodelusingimageaugmentationbasedonrandomleft-rightflipping.
train_with_data_aug(train_augs, test_augs, net) loss 0.215, train acc 0.925, test acc 0.810 4728.8 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] 14.1.3 Summary Imageaugmentationgeneratesrandomimagesbasedonexistingtrainingdatatoimprove thegeneralizationabilityofmodels.
Inordertoobtaindefinitiveresultsduringprediction, weusuallyonlyapplyimageaug- mentationtotrainingexamples, anddonotuseimageaugmentationwithrandomop- erationsduringprediction.
Deeplearningframeworksprovidemanydifferentimageaugmentationmethods, which canbeappliedsimultaneously.
14.1.4 Exercises 1.
Trainthemodelwithoutusingimageaugmentation: train_with_data_aug(test_augs, test_augs).
Comparetrainingandtestingaccuracywhenusingandnotusingimage augmentation.
Canthiscomparativeexperimentsupporttheargumentthatimageaug- mentationcanmitigateoverfitting? Why? 2.
Combinemultipledifferentimageaugmentationmethodsinmodeltrainingonthe CIFAR- 10dataset.
Doesitimprovetestaccuracy? 600 Computer Vision 3.
Refertotheonlinedocumentationofthedeeplearningframework.
Whatotherimage augmentationmethodsdoesitalsoprovide? Discussions212.
212 14.2 Fine-Tuning In earlier chapters, we discussed how to train models on the Fashion-MNIST training datasetwithonly60000images.
Wealsodescribed Image Net, themostwidelyusedlarge- scaleimagedatasetinacademia, whichhasmorethan10millionimagesand1000objects.
However, the size of the dataset that we usually encounter is between those of the two datasets.
Supposethatwewanttorecognizedifferenttypesofchairsfromimages, andthenrecom- mendpurchaselinkstousers.
Onepossiblemethodistofirstidentify100commonchairs, take 1000 images of different angles for each chair, and then train a classification model onthecollectedimagedataset.
Althoughthischairdatasetmaybelargerthanthe Fashion- MNIST dataset, the number of examples is still less than one-tenth of that in Image Net.
Thismayleadtooverfittingofcomplicatedmodelsthataresuitablefor Image Netonthis chairdataset.
Besides, duetothelimitedamountoftrainingexamples, theaccuracyofthe trainedmodelmaynotmeetpracticalrequirements.
Inordertoaddresstheaboveproblems, anobvioussolutionistocollectmoredata.
How- ever, collectingandlabelingdatacantakealotoftimeandmoney.
Forexample, inorder to collect the Image Net dataset, researchers have spent millions of dollars from research funding.
Althoughthecurrentdatacollectioncosthasbeensignificantlyreduced, thiscost stillcannotbeignored.
Anothersolutionistoapplytransferlearningtotransfertheknowledgelearnedfromthe sourcedatasettothetargetdataset.
Forexample, althoughmostoftheimagesinthe Ima- ge Netdatasethavenothingtodowithchairs, themodeltrainedonthisdatasetmayextract more general image features, which can help identify edges, textures, shapes, and object composition.
Thesesimilarfeaturesmayalsobeeffectiveforrecognizingchairs.
14.2.1 Steps Inthissection, wewillintroduceacommontechniqueintransferlearning: fine-tuning.
As shownin.2.1, fine-tuningconsistsofthefollowingfoursteps: Image Netdataset).
2.
Create a new neural network model, i.
e., the target model.
This copies all model de- signsandtheirparametersonthesourcemodelexcepttheoutputlayer.
Weassumethat thesemodelparameterscontaintheknowledgelearnedfromthesourcedatasetandthis 601 Fine-Tuning knowledgewillalsobeapplicabletothetargetdataset.
Wealsoassumethattheoutput layerofthesourcemodeliscloselyrelatedtothelabelsofthesourcedataset; thusitis notusedinthetargetmodel.
3.
Add an output layer to the target model, whose number of outputs is the number of categoriesinthetargetdataset.
Thenrandomlyinitializethemodelparametersofthis layer.
4.
Train the target model on the target dataset, such as a chair dataset.
The output layer willbetrainedfromscratch, whiletheparametersofalltheotherlayersarefine-tuned basedontheparametersofthesourcemodel.
t .2.1 Finetuning.
Whentargetdatasetsaremuchsmallerthansourcedatasets, fine-tuninghelpstoimprove modelsâ€™generalizationability.
14.2.2 Hot Dog Recognition Letâ€™sdemonstratefine-tuningviaaconcretecase: hotdogrecognition.
Wewillfine-tune a Res Net model on a small dataset, which was pretrained on the Image Net dataset.
This smalldatasetconsistsofthousandsofimageswithandwithouthotdogs.
Wewillusethe fine-tunedmodeltorecognizehotdogsfromimages.
%matplotlib inline import os import torch import torchvision from torch import nn from d2l import torch as d2l Readingthe Dataset Thehotdogdatasetweusewastakenfromonlineimages.
Thisdatasetconsistsof1400 positive-classimagescontaininghotdogs, andasmanynegative-classimagescontaining other foods.
1000 images of both classes are used for training and the rest are for test- ing.
602 Computer Vision Afterunzippingthedownloadeddataset, weobtaintwofoldershotdog/trainandhotdog/ test.
Both folders have hotdog and not-hotdog subfolders, either of which contains imagesofthecorrespondingclass.
#@save d2l.
DATA_HUB['hotdog'] = (d2l.
DATA_URL + 'hotdog.
zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5') data_dir = d2l.
download_extract('hotdog') â†©! com/hotdog.
zip...
Wecreatetwoinstancestoreadalltheimagefilesinthetrainingandtestingdatasets, re- spectively.
train_imgs = torchvision.
datasets.
Image Folder(os.
path.
join(data_dir, 'train')) test_imgs = torchvision.
datasets.
Image Folder(os.
path.
join(data_dir, 'test')) Thefirst8positiveexamplesandthelast8negativeimagesareshownbelow.
Asyoucan see, theimagesvaryinsizeandaspectratio.
hotdogs = [train_imgs[i][0] for i in range(8)] not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)] d2l.
show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4); Duringtraining, wefirstcroparandomareaofrandomsizeandrandomaspectratiofrom theimage, andthenscalethisareatoa224 224inputimage.
Duringtesting, wescaleboth theheightandwidthofanimageto256pixels, andthencropacentral224 224areaas input.
Inaddition, forthethree RGB(red, green, andblue)colorchannelswestandardize theirvalueschannelbychannel.
Concretely, themeanvalueofachannelissubtractedfrom eachvalueofthatchannelandthentheresultisdividedbythestandarddeviationofthat channel.
# Specify the means and standard deviations of the three RGB channels to # standardize each channel normalize = torchvision.
transforms.
Normalize( (continuesonnextpage) 603 Fine-Tuning (continuedfrompreviouspage) train_augs = torchvision.
transforms.
Compose([ torchvision.
transforms.
Random Resized Crop(224), torchvision.
transforms.
Random Horizontal Flip(), torchvision.
transforms.
To Tensor(), normalize]) test_augs = torchvision.
transforms.
Compose([ torchvision.
transforms.
Resize([256, 256]), torchvision.
transforms.
Center Crop(224), torchvision.
transforms.
To Tensor(), normalize]) Definingand Initializingthe Model We use Res Net-18, which was pretrained on the Image Net dataset, as the source model.
Here, wespecify pretrained=True toautomaticallydownloadthe pretrainedmodelpa- rameters.
Ifthismodelisusedforthefirsttime, Internetconnectionisrequiredfordown- load.
pretrained_net = torchvision.
models.
resnet18(pretrained=True) The pretrained source model instance contains a number of feature layers and an output layerfc.
Themainpurposeofthisdivisionistofacilitatethefine-tuningofmodelparam- etersofalllayersbuttheoutputlayer.
Themembervariablefcofsourcemodelisgiven below.
pretrained_net.
fc Linear(in_features=512, out_features=1000, bias=True) Asafullyconnectedlayer, ittransforms Res Netâ€™sfinalglobalaveragepoolingoutputsinto 1000 class outputs of the Image Net dataset.
We then construct a new neural network as thetargetmodel.
Itisdefinedinthesamewayasthepretrainedsourcemodelexceptthat itsnumberofoutputsinthefinallayerissettothenumberofclassesinthetargetdataset (ratherthan1000).
In the code below, the model parameters before the output layer of the target model in- stancefinetune_netareinitializedtomodelparametersofthecorrespondinglayersfrom the source model.
Since these model parameters were obtained via pretraining on Ima- ge Net, theyareeffective.
Therefore, wecanonlyuseasmalllearningratetofine-tunesuch pretrainedparameters.
Incontrast, modelparametersintheoutputlayerarerandomlyini- tializedandgenerallyrequirealargerlearningratetobelearnedfromscratch.
Lettingthe baselearningratebeğœ‚, alearningrateof10ğœ‚willbeusedtoiteratethemodelparameters intheoutputlayer.
604 Computer Vision finetune_net = torchvision.
models.
resnet18(pretrained=True) finetune_net.
fc = nn.
Linear(finetune_net.
fc.
in_features, 2) nn.
init.
xavier_uniform_(finetune_net.
fc.
weight); Fine-Tuningthe Model First, wedefineatrainingfunctiontrain_fine_tuningthatusesfine-tuningsoitcanbe calledmultipletimes.
# If `param_group=True`, the model parameters in the output layer will be # updated using a learning rate ten times greater def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True): os.
path.
join(data_dir, 'train'), transform=train_augs), batch_size=batch_size, shuffle=True) os.
path.
join(data_dir, 'test'), transform=test_augs), batch_size=batch_size) devices = d2l.
try_all_gpus() loss = nn.
Cross Entropy Loss(reduction="none") if param_group: params_1x = [param for name, param in net.
named_parameters() if name not in ["fc.
weight", "fc.
bias"]] trainer = torch.
optim.
SGD([{'params': params_1x}, {'params': net.
fc.
parameters(), 'lr': learning_rate * 10}], lr=learning_rate, weight_decay=0.001) else: trainer = torch.
optim.
SGD(net.
parameters(), lr=learning_rate, weight_decay=0.001) d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) We set the base learning rate to a small value in order to fine-tune the model parameters obtained via pretraining.
Based on the previous settings, we will train the output layer parametersofthetargetmodelfromscratchusingalearningratetentimesgreater.
train_fine_tuning(finetune_net, 5e-5) loss 0.242, train acc 0.909, test acc 0.940 1062.4 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Forcomparison, wedefineanidenticalmodel, butinitializeallofitsmodelparametersto randomvalues.
Sincetheentiremodelneedstobetrainedfromscratch, wecanusealarger learningrate.
605 Fine-Tuning scratch_net = torchvision.
models.
resnet18() scratch_net.
fc = nn.
Linear(scratch_net.
fc.
in_features, 2) train_fine_tuning(scratch_net, 5e-4, param_group=False) loss 0.352, train acc 0.846, test acc 0.850 1525.4 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Aswecansee, thefine-tunedmodeltendstoperformbetterforthesameepochbecauseits initialparametervaluesaremoreeffective.
14.2.3 Summary Transferlearningtransfersknowledgelearnedfromthesourcedatasettothetargetdataset.
Fine-tuningisacommontechniquefortransferlearning.
Thetargetmodelcopiesallmodeldesignswiththeirparametersfromthesourcemodel excepttheoutputlayer, andfine-tunestheseparametersbasedonthetargetdataset.
In contrast, theoutputlayerofthetargetmodelneedstobetrainedfromscratch.
Generally, fine-tuningparametersusesasmallerlearningrate, whiletrainingtheoutput layerfromscratchcanusealargerlearningrate.
14.2.4 Exercises 606 Computer Vision 1.
Keep increasing the learning rate of finetune_net.
How does the accuracy of the modelchange? 2.
Furtheradjusthyperparametersoffinetune_netandscratch_netinthecomparative experiment.
Dotheystilldifferinaccuracy? 3.
Settheparametersbeforetheoutputlayeroffinetune_nettothoseofthesourcemodel anddonotupdatethemduringtraining.
Howdoestheaccuracyofthemodelchange? Youcanusethefollowingcode.
for param in finetune_net.
parameters(): param.
requires_grad = False 4.
In fact, there is a â€œhotdogâ€ class in the Image Net dataset.
Its corresponding weight parameter in the output layer can be obtained via the following code.
How can we leveragethisweightparameter? weight = pretrained_net.
fc.
weight hotdog_w = torch.
split(weight.
data, 1, dim=0)[934] hotdog_w.
shape torch.
Size([1, 512]) 213 Discussions213.
14.3 Object Detection and Bounding Boxes Inearliersections(e.
g., Section8.1â€“Section8.4), weintroducedvariousmodelsforimage classification.
Inimageclassificationtasks, weassumethatthereisonlyonemajorobject intheimageandweonlyfocusonhowtorecognizeitscategory.
However, thereareoften multipleobjectsintheimageofinterest.
Wenotonlywanttoknowtheircategories, but also their specific positions in the image.
In computer vision, we refer to such tasks as objectdetection(orobjectrecognition).
Objectdetectionhasbeenwidelyappliedinmanyfields.
Forexample, self-drivingneedsto plantravelingroutesbydetectingthepositionsofvehicles, pedestrians, roads, andobstacles inthecapturedvideoimages.
Besides, robotsmayusethistechniquetodetectandlocalize objectsofinterestthroughoutitsnavigationofanenvironment.
Moreover, securitysystems mayneedtodetectabnormalobjects, suchasintrudersorbombs.
Inthenextfewsections, wewillintroduceseveraldeeplearningmethodsforobjectdetec- tion.
Wewillbeginwithanintroductiontopositions(orlocations)ofobjects.
607 Object Detectionand Bounding Boxes %matplotlib inline import torch from d2l import torch as d2l Wewillloadthesampleimagetobeusedinthissection.
Wecanseethatthereisadog ontheleftsideoftheimageandacatontheright.
Theyarethetwomajorobjectsinthis image.
d2l.
set_figsize() d2l.
plt.
imshow(img); 14.3.1 Bounding Boxes In object detection, we usually use a bounding box to describe the spatial location of an object.
Theboundingboxisrectangular, whichisdeterminedbytheğ‘¥ and ğ‘¦ coordinates oftheupper-leftcorneroftherectangleandthesuchcoordinatesofthelower-rightcorner.
Anothercommonlyusedboundingboxrepresentationisthe â€ğ‘¥,ğ‘¦â€-axiscoordinatesofthe boundingboxcenter, andthewidthandheightofthebox.
Herewedefinefunctionstoconvertbetweenthesetworepresentations: box_corner_to_center converts from the two-corner representation to the center-width-height presentation, and box_center_to_cornerviceversa.
Theinputargumentboxesshouldbeatwo-dimensional tensorofshape(ğ‘›,4), whereğ‘›isthenumberofboundingboxes.
#@save def box_corner_to_center(boxes): """Convert from (upper-left, lower-right) to (center, width, height).""" x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] cx = (x1 + x2) / 2 cy = (y1 + y2) / 2 w = x2 - x1 h = y2 - y1 boxes = torch.
stack((cx, cy, w, h), axis=-1) return boxes #@save def box_center_to_corner(boxes): (continuesonnextpage) 608 Computer Vision (continuedfrompreviouspage) """Convert from (center, width, height) to (upper-left, lower-right).""" cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] x1 = cx - 0.5 * w y1 = cy - 0.5 * h x2 = cx + 0.5 * w y2 = cy + 0.5 * h boxes = torch.
stack((x1, y1, x2, y2), axis=-1) return boxes We will define the bounding boxes of the dog and the cat in the image based on the co- ordinate information.
The origin of the coordinates in the image is the upper-left corner of the image, and to the right and down are the positive directions of the ğ‘¥ and ğ‘¦ axes, respectively.
# Here `bbox` is the abbreviation for bounding box Wecanverifythecorrectnessofthetwoboundingboxconversionfunctionsbyconverting twice.
boxes = torch.
tensor((dog_bbox, cat_bbox)) box_center_to_corner(box_corner_to_center(boxes)) == boxes tensor([[True, True, True, True], [True, True, True, True]]) Letâ€™sdrawtheboundingboxesintheimagetocheckiftheyareaccurate.
Beforedrawing, we will define a helper function bbox_to_rect.
It represents the bounding box in the boundingboxformatofthematplotlibpackage.
#@save def bbox_to_rect(bbox, color): """Convert bounding box to matplotlib format.""" # Convert the bounding box (upper-left x, upper-left y, lower-right x, # lower-right y) format to the matplotlib format: ((upper-left x, # upper-left y), width, height) return d2l.
plt.
Rectangle( xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1], fill=False, edgecolor=color, linewidth=2) Afteraddingtheboundingboxesontheimage, wecanseethatthemainoutlineofthetwo objectsarebasicallyinsidethetwoboxes.
fig = d2l.
plt.
imshow(img) fig.
axes.
add_patch(bbox_to_rect(dog_bbox, 'blue')) fig.
axes.
add_patch(bbox_to_rect(cat_bbox, 'red')); 609 Anchor Boxes 14.3.2 Summary Objectdetectionnotonlyrecognizesalltheobjectsofinterestintheimage, butalsotheir positions.
Thepositionisgenerallyrepresentedbyarectangularboundingbox.
Wecanconvertbetweentwocommonlyusedboundingboxrepresentations.
14.3.3 Exercises 1.
Findanotherimageandtrytolabelaboundingboxthatcontainstheobject.
Compare labelingboundingboxesandcategories: whichusuallytakeslonger? 2.
Whyistheinnermostdimensionoftheinputargumentboxesofbox_corner_to_center andbox_center_to_corneralways4? 214 Discussions214.
14.4 Anchor Boxes Objectdetectionalgorithmsusuallysamplealargenumberofregionsintheinputimage, determinewhethertheseregionscontainobjectsofinterest, andadjusttheboundariesof theregionssoastopredicttheground-truthboundingboxesoftheobjectsmoreaccurately.
Differentmodelsmayadoptdifferentregionsamplingschemes.
Hereweintroduceoneof suchmethods: itgeneratesmultipleboundingboxeswithvaryingscalesandaspectratios centeredoneachpixel.
Theseboundingboxesarecalledanchorboxes.
Wewilldesignan objectdetectionmodelbasedonanchorboxesin Section14.7.
First, letâ€™smodifytheprintingaccuracyjustformoreconciseoutputs.
%matplotlib inline import torch from d2l import torch as d2l torch.
set_printoptions(2) # Simplify printing accuracy 610 Computer Vision 14.4.1 Generating Multiple Anchor Boxes Supposethattheinputimagehasaheightofâ„andwidthofğ‘¤.
Wegenerateanchorboxes withdifferentshapescenteredoneachpixeloftheimage.
Letthescalebeğ‘  2 â€0,1â€¦andthe aspectratio(ratioofwidthtoheight)isğ‘Ÿ >0.
Thenthewidthandheightoftheanchorbox p p areğ‘¤ğ‘  ğ‘Ÿ and â„ğ‘  ğ‘Ÿ, respectively.
Notethatwhenthecenterpositionisgiven, ananchor boxwithknownwidthandheightisdetermined.
Togeneratemultipleanchorboxeswithdifferentshapes, letâ€™ssetaseriesofscalesğ‘  1 ,...,ğ‘  ğ‘› andaseriesofaspectratiosğ‘Ÿ 1 ,...,ğ‘Ÿ ğ‘š.
Whenusingallthecombinationsofthesescales andaspectratioswitheachpixelasthecenter, theinputimagewillhaveatotalofğ‘¤â„ğ‘›ğ‘š anchorboxes.
Althoughtheseanchorboxesmaycoveralltheground-truthboundingboxes, the computational complexity is easily too high.
In practice, we can only consider those combinationscontainingğ‘  orğ‘Ÿ : 1 1 Thatistosay, thenumberofanchorboxescenteredonthesamepixelisğ‘›â€šğ‘š 1.
Forthe entireinputimage, wewillgenerateatotalofğ‘¤â„â€ğ‘›â€šğ‘š 1â€anchorboxes.
The above method of generating anchor boxes is implemented in the following multi- box_priorfunction.
Wespecifytheinputimage, alistofscales, andalistofaspectratios, thenthisfunctionwillreturnalltheanchorboxes.
#@save def multibox_prior(data, sizes, ratios): """Generate anchor boxes with different shapes centered on each pixel.""" in_height, in_width = data.
shape[-2:] device, num_sizes, num_ratios = data.
device, len(sizes), len(ratios) boxes_per_pixel = (num_sizes + num_ratios - 1) size_tensor = torch.
tensor(sizes, device=device) ratio_tensor = torch.
tensor(ratios, device=device) # Offsets are required to move the anchor to the center of a pixel.
Since # a pixel has height=1 and width=1, we choose to offset our centers by 0.5 offset_h, offset_w = 0.5, 0.5 steps_h = 1.0 / in_height # Scaled steps in y axis steps_w = 1.0 / in_width # Scaled steps in x axis # Generate all center points for the anchor boxes center_h = (torch.
arange(in_height, device=device) + offset_h) * steps_h center_w = (torch.
arange(in_width, device=device) + offset_w) * steps_w shift_y, shift_x = torch.
meshgrid(center_h, center_w, indexing='ij') shift_y, shift_x = shift_y.
reshape(-1), shift_x.
reshape(-1) # Generate `boxes_per_pixel` number of heights and widths that are later # used to create anchor box corner coordinates (xmin, xmax, ymin, ymax) w = torch.
cat((size_tensor * torch.
sqrt(ratio_tensor[0]), sizes[0] * torch.
sqrt(ratio_tensor[1:])))\ * in_height / in_width # Handle rectangular inputs h = torch.
cat((size_tensor / torch.
sqrt(ratio_tensor[0]), sizes[0] / torch.
sqrt(ratio_tensor[1:]))) # Divide by 2 to get half height and half width anchor_manipulations = torch.
stack((-w, -h, w, h)).
T.
repeat( (continuesonnextpage) 611 Anchor Boxes (continuedfrompreviouspage) in_height * in_width, 1) / 2 # Each center point will have `boxes_per_pixel` number of anchor boxes, so # generate a grid of all anchor box centers with `boxes_per_pixel` repeats out_grid = torch.
stack([shift_x, shift_y, shift_x, shift_y], dim=1).
repeat_interleave(boxes_per_pixel, dim=0) output = out_grid + anchor_manipulations return output.
unsqueeze(0) Wecanseethattheshapeofthereturnedanchorboxvariable Yis(batchsize, numberof anchorboxes,4).
h, w = img.
shape[:2] print(h, w) X = torch.
rand(size=(1, 3, h, w)) # Construct input data Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5]) Y.
shape 561 728 torch.
Size([1, 2042040, 4]) Afterchangingtheshapeoftheanchorboxvariable Yto(imageheight, imagewidth, num- ber of anchor boxes centered on the same pixel, 4), we can obtain all the anchor boxes centeredonaspecifiedpixelposition.
Inthefollowing, weaccessthefirstanchorboxcen- teredon(250,250).
Ithasfourelements: theâ€ğ‘¥,ğ‘¦â€-axiscoordinatesattheupper-leftcorner andtheâ€ğ‘¥,ğ‘¦â€-axiscoordinatesatthelower-rightcorneroftheanchorbox.
Thecoordinate valuesofbothaxesaredividedbythewidthandheightoftheimage, respectively.
boxes = Y.
reshape(h, w, 5, 4) boxes[250, 250, 0, :] tensor([0.06, 0.07, 0.63, 0.82]) In order to show all the anchor boxes centered on one pixel in the image, we define the followingshow_bboxesfunctiontodrawmultipleboundingboxesontheimage.
#@save def show_bboxes(axes, bboxes, labels=None, colors=None): """Show bounding boxes.""" def make_list(obj, default_values=None): if obj is None: obj = default_values (continuesonnextpage) 612 Computer Vision (continuedfrompreviouspage) elif not isinstance(obj, (list, tuple)): obj = [obj] return obj labels = make_list(labels) colors = make_list(colors, ['b', 'g', 'r', 'm', 'c']) for i, bbox in enumerate(bboxes): color = colors[i % len(colors)] rect = d2l.
bbox_to_rect(bbox.
detach().
numpy(), color) axes.
add_patch(rect) if labels and len(labels) > i: text_color = 'k' if color == 'w' else 'w' axes.
text(rect.
xy[0], rect.
xy[1], labels[i], va='center', ha='center', fontsize=9, color=text_color, bbox=dict(facecolor=color, lw=0)) Aswejustsaw, thecoordinatevaluesoftheğ‘¥ and ğ‘¦ axesinthevariableboxeshavebeen dividedbythewidthandheightoftheimage, respectively.
Whendrawinganchorboxes, we need to restore their original coordinate values; thus, we define variable bbox_scale below.
Now, wecandrawalltheanchorboxescenteredon(250,250)intheimage.
Asyou cansee, theblueanchorboxwithascaleof0.75andanaspectratioof1wellsurrounds thedogintheimage.
d2l.
set_figsize() bbox_scale = torch.
tensor((w, h, w, h)) fig = d2l.
plt.
imshow(img) show_bboxes(fig.
axes, boxes[250, 250, :, :] * bbox_scale, ['s=0.75, r=1', 's=0.5, r=1', 's=0.25, r=1', 's=0.75, r=2', 's=0.75, r=0.5']) 14.4.2 Intersectionover Union(Io U) Wejustmentionedthatananchorboxâ€œwellâ€surroundsthedogintheimage.
Iftheground- truthboundingboxoftheobjectisknown, howcanâ€œwellâ€herebequantified? Intuitively, wecanmeasurethesimilaritybetweentheanchorboxandtheground-truthboundingbox.
Weknowthatthe Jaccardindexcanmeasurethesimilaritybetweentwosets.
Givensets A and B, their Jaccard index is the size of their intersection divided by the size of their 613 Anchor Boxes union: j A\Bj ğ½â€A, Bâ€ = .
(14.4.2) j A[Bj Infact, wecanconsiderthepixelareaofanyboundingboxasasetofpixels.
Inthisway, wecanmeasurethesimilarityofthetwoboundingboxesbythe Jaccardindexoftheirpixel sets.
For two bounding boxes, we usually refer their Jaccard index as intersection over union (Io U), which is the ratio of their intersection area to their union area, as shown in .4.1.
Therangeofan Io Uisbetween0and1: 0meansthattwoboundingboxesdo notoverlapatall, while1indicatesthatthetwoboundingboxesareequal.
t .4.1 Io Uistheratiooftheintersectionareatotheunionareaoftwoboundingboxes.
Fortheremainderofthissection, wewilluse Io Utomeasurethesimilaritybetweenanchor boxes and ground-truth bounding boxes, and between different anchor boxes.
Given two lists of anchor or bounding boxes, the following box_iou computes their pairwise Io U acrossthesetwolists.
#@save def box_iou(boxes1, boxes2): """Compute pairwise Io U across two lists of anchor or bounding boxes.""" box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])) # Shape of `boxes1`, `boxes2`, `areas1`, `areas2`: (no.
of boxes1, 4), # (no.
of boxes2, 4), (no.
of boxes1,), (no.
of boxes2,) areas1 = box_area(boxes1) areas2 = box_area(boxes2) # Shape of `inter_upperlefts`, `inter_lowerrights`, `inters`: (no.
of # boxes1, no.
of boxes2, 2) inter_upperlefts = torch.
max(boxes1[:, None, :2], boxes2[:, :2]) inter_lowerrights = torch.
min(boxes1[:, None, 2:], boxes2[:, 2:]) inters = (inter_lowerrights - inter_upperlefts).
clamp(min=0) # Shape of `inter_areas` and `union_areas`: (no.
of boxes1, no.
of boxes2) inter_areas = inters[:, :, 0] * inters[:, :, 1] union_areas = areas1[:, None] + areas2 - inter_areas return inter_areas / union_areas 14.4.3 Labeling Anchor Boxesin Training Data Inatrainingdataset, weconsidereachanchorboxasatrainingexample.
Inordertotrain anobjectdetectionmodel, weneedclassandoffsetlabelsforeachanchorbox, wherethe formeristheclassoftheobjectrelevanttotheanchorboxandthelatteristheoffsetofthe ground-truthboundingboxrelativetotheanchorbox.
Duringtheprediction, foreachim- agewegeneratemultipleanchorboxes, predictclassesandoffsetsforalltheanchorboxes, 614 Computer Vision adjust their positions according to the predicted offsets to obtain the predicted bounding boxes, and finally only output those predicted bounding boxes that satisfy certain crite- ria.
Asweknow, anobjectdetectiontrainingsetcomeswithlabelsforlocationsofground-truth boundingboxesandclassesoftheirsurroundedobjects.
Tolabelanygeneratedanchorbox, werefertothelabeledlocationandclassofitsassignedground-truthboundingboxthatis closesttotheanchorbox.
Inthefollowing, wedescribeanalgorithmforassigningclosest ground-truthboundingboxestoanchorboxes.
Assigning Ground-Truth Bounding Boxesto Anchor Boxes Givenanimage, supposethattheanchorboxesare ğ´ 1 ,ğ´ 2 ,...,ğ´ ğ‘›ğ‘ andtheground-truth boundingboxesare ğµ 1 ,ğµ 2 ,...,ğµ ğ‘›ğ‘ , whereğ‘› ğ‘ ğ‘› ğ‘.
Letâ€™sdefineamatrix X 2 Rğ‘›ğ‘ ğ‘›ğ‘, whoseelementğ‘¥ ğ‘–ğ‘— intheğ‘–th rowand ğ‘—th columnisthe Io Uoftheanchorbox ğ´ ğ‘– andthe ground-truthboundingboxğµ ğ‘—.
Thealgorithmconsistsofthefollowingsteps: 1.
Findthelargestelementinmatrix Xanddenoteitsrowandcolumnindicesasğ‘– and 1 ğ‘— 1 , respectively.
Thentheground-truthboundingboxğµ ğ‘— 1 isassignedtotheanchorbox ğ´ ğ‘– .
This is quite intuitive because ğ´ ğ‘– and ğµ ğ‘— are the closest among all the pairs of 1 1 1 anchorboxesandground-truthboundingboxes.
Afterthefirstassignment, discardall theelementsintheğ‘– throwandthe ğ‘— thcolumninmatrix X.
1 1 2.
Findthelargestoftheremainingelementsinmatrix Xanddenoteitsrowandcolumn indicesasğ‘– 2 and ğ‘— 2 , respectively.
Weassignground-truthboundingbox ğµ ğ‘— 2 toanchor box ğ´ ğ‘– 2 anddiscardalltheelementsintheğ‘– 2 throwandthe ğ‘— 2 thcolumninmatrix X.
3.
Atthispoint, elementsintworowsandtwocolumnsinmatrix Xhavebeendiscarded.
Weproceeduntilallelementsinğ‘› ğ‘ columnsinmatrix Xarediscarded.
Atthistime, wehaveassignedaground-truthboundingboxtoeachofğ‘› ğ‘ anchorboxes.
4.
Only traverse through the remaining ğ‘› ğ‘ ğ‘› ğ‘ anchor boxes.
For example, given any anchor box ğ´ ğ‘–, find the ground-truth bounding box ğµ ğ‘— with the largest Io U with ğ´ ğ‘– throughouttheğ‘–th rowofmatrix X, andassignğµ ğ‘— to ğ´ ğ‘– onlyifthis Io Uisgreaterthan apredefinedthreshold.
Letâ€™sillustratetheabovealgorithmusingaconcreteexample.
Asshownin.4.2(left), assumingthatthemaximumvalueinmatrix Xisğ‘¥ , weassigntheground-truthbounding 23 boxğµ totheanchorboxğ´ .
Then, wediscardalltheelementsinrow2andcolumn3ofthe 3 2 matrix, findthelargestğ‘¥ intheremainingelements(shadedarea), andassigntheground- 71 truthboundingboxğµ totheanchorboxğ´ .
Next, asshownin.4.2(middle), discard 1 7 alltheelementsinrow7andcolumn1ofthematrix, findthelargestğ‘¥ intheremaining 54 elements (shaded area), and assign the ground-truth bounding box ğµ to the anchor box 4 ğ´ .
Finally, asshownin.4.2(right), discardalltheelementsinrow5andcolumn4 5 ofthematrix, findthelargestğ‘¥ intheremainingelements(shadedarea), andassignthe 92 ground-truthboundingbox ğµ totheanchorbox ğ´ .
Afterthat, weonlyneedtotraverse 2 9 through the remaining anchor boxes ğ´ ,ğ´ ,ğ´ ,ğ´ ,ğ´ and determine whether to assign 1 3 4 6 8 themground-truthboundingboxesaccordingtothethreshold.
615 Anchor Boxes t .4.2 Assigningground-truthboundingboxestoanchorboxes.
Thisalgorithmisimplementedinthefollowingassign_anchor_to_bboxfunction.
#@save def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5): """Assign closest ground-truth bounding boxes to anchor boxes.""" num_anchors, num_gt_boxes = anchors.
shape[0], ground_truth.
shape[0] # Element x_ij in the i-th row and j-th column is the Io U of the anchor # box i and the ground-truth bounding box j jaccard = box_iou(anchors, ground_truth) # Initialize the tensor to hold the assigned ground-truth bounding box for # each anchor anchors_bbox_map = torch.
full((num_anchors,), -1, dtype=torch.
long, device=device) # Assign ground-truth bounding boxes according to the threshold max_ious, indices = torch.
max(jaccard, dim=1) anc_i = torch.
nonzero(max_ious >= iou_threshold).
reshape(-1) box_j = indices[max_ious >= iou_threshold] anchors_bbox_map[anc_i] = box_j col_discard = torch.
full((num_anchors,), -1) row_discard = torch.
full((num_gt_boxes,), -1) for _ in range(num_gt_boxes): max_idx = torch.
argmax(jaccard) # Find the largest Io U box_idx = (max_idx % num_gt_boxes).
long() anc_idx = (max_idx / num_gt_boxes).
long() anchors_bbox_map[anc_idx] = box_idx jaccard[:, box_idx] = col_discard jaccard[anc_idx, :] = row_discard return anchors_bbox_map Labeling Classesand Offsets Now we can label the class and offset for each anchor box.
Suppose that an anchor box ğ´ is assigned a ground-truth bounding box ğµ.
On the one hand, the class of the anchor box ğ´willbelabeledasthatof ğµ.
Ontheotherhand, theoffsetoftheanchorbox ğ´will be labeled according to the relative position between the central coordinates of ğµ and ğ´ togetherwiththerelativesizebetweenthesetwoboxes.
Givenvaryingpositionsandsizes 616 Computer Vision of different boxes in the dataset, we can apply transformations to those relative positions andsizesthatmayleadtomoreuniformlydistributedoffsetsthatareeasiertofit.
Herewe describeacommontransformation.
Giventhecentralcoordinatesof ğ´and ğµas â€ğ‘¥ ğ‘ ,ğ‘¦ ğ‘ â€ and â€ğ‘¥ ğ‘ ,ğ‘¦ ğ‘ â€, theirwidthsasğ‘¤ ğ‘ andğ‘¤ ğ‘, andtheirheightsas â„ ğ‘ and â„ ğ‘, respectively.
We maylabeltheoffsetof ğ´as ! ğ‘¥ğ‘ ğ‘¤ ğ‘ ğ‘¥ğ‘ ğœ‡ ğ‘¥ , ğ‘¦ğ‘ â„ ğ‘ ğ‘¦ğ‘ ğœ‡ ğ‘¦ , log ğ‘¤ ğ‘¤ğ‘ ğ‘ ğœ‡ ğ‘¤ , log â„ â„ğ‘ ğ‘ ğœ‡ â„ , (14.4.3) ğœ ğœ ğœ ğœ ğ‘¥ ğ‘¦ ğ‘¤ â„ where default values of the constants are ğœ‡ ğ‘¥ = ğœ‡ ğ‘¦ = ğœ‡ ğ‘¤ = ğœ‡ â„ = 0,ğœ ğ‘¥ = ğœ ğ‘¦ = 0.1, and ğœ ğ‘¤ = ğœ â„ = 0.2.
This transformation is implemented below in the offset_boxes function.
#@save def offset_boxes(anchors, assigned_bb, eps=1e-6): """Transform for anchor box offsets.""" c_anc = d2l.
box_corner_to_center(anchors) c_assigned_bb = d2l.
box_corner_to_center(assigned_bb) offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:] offset_wh = 5 * torch.
log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:]) offset = torch.
cat([offset_xy, offset_wh], axis=1) return offset If an anchor box is not assigned a ground-truth bounding box, we just label the class of the anchor box as â€œbackgroundâ€.
Anchor boxes whose classes are background are often referred to as negative anchor boxes, and the rest are called positive anchor boxes.
We implementthefollowingmultibox_targetfunctiontolabelclassesandoffsetsforanchor boxes(theanchorsargument)usingground-truthboundingboxes(thelabelsargument).
Thisfunctionsetsthebackgroundclasstozeroandincrementstheintegerindexofanew classbyone.
#@save def multibox_target(anchors, labels): """Label anchor boxes using ground-truth bounding boxes.""" batch_size, anchors = labels.
shape[0], anchors.
squeeze(0) batch_offset, batch_mask, batch_class_labels = [], [], [] device, num_anchors = anchors.
device, anchors.
shape[0] for i in range(batch_size): label = labels[i, :, :] anchors_bbox_map = assign_anchor_to_bbox( label[:, 1:], anchors, device) bbox_mask = ((anchors_bbox_map >= 0).
float().
unsqueeze(-1)).
repeat( 1, 4) # Initialize class labels and assigned bounding box coordinates with # zeros class_labels = torch.
zeros(num_anchors, dtype=torch.
long, device=device) assigned_bb = torch.
zeros((num_anchors, 4), dtype=torch.
float32, device=device) # Label classes of anchor boxes using their assigned ground-truth # bounding boxes.
If an anchor box is not assigned any, we label its (continuesonnextpage) 617 Anchor Boxes (continuedfrompreviouspage) # class as background (the value remains zero) indices_true = torch.
nonzero(anchors_bbox_map >= 0) bb_idx = anchors_bbox_map[indices_true] class_labels[indices_true] = label[bb_idx, 0].
long() + 1 assigned_bb[indices_true] = label[bb_idx, 1:] # Offset transformation offset = offset_boxes(anchors, assigned_bb) * bbox_mask batch_offset.
append(offset.
reshape(-1)) batch_mask.
append(bbox_mask.
reshape(-1)) batch_class_labels.
append(class_labels) bbox_offset = torch.
stack(batch_offset) bbox_mask = torch.
stack(batch_mask) class_labels = torch.
stack(batch_class_labels) return (bbox_offset, bbox_mask, class_labels) An Example Letâ€™sillustrateanchorboxlabelingviaaconcreteexample.
Wedefineground-truthbound- ing boxes for the dog and cat in the loaded image, where the first element is the class (0 for dog and 1 for cat) and the remaining four elements are the â€ğ‘¥,ğ‘¦â€-axis coordinates at theupper-leftcornerandthelower-rightcorner(rangeisbetween0and1).
Wealsocon- structfiveanchorboxestobelabeledusingthecoordinatesoftheupper-leftcornerandthe lower-rightcorner: ğ´ ,...,ğ´ (theindexstartsfrom0).
Thenweplottheseground-truth 0 4 boundingboxesandanchorboxesintheimage.
[1, 0.55, 0.2, 0.9, 0.88]]) [0.57, 0.3, 0.92, 0.9]]) fig = d2l.
plt.
imshow(img) show_bboxes(fig.
axes, ground_truth[:, 1:] * bbox_scale, ['dog', 'cat'], 'k') show_bboxes(fig.
axes, anchors * bbox_scale, ['0', '1', '2', '3', '4']); Using the multibox_target function defined above, we can label classes and offsets of theseanchorboxesbasedontheground-truthboundingboxesforthedogandcat.
Inthis example, indices of the background, dog, and cat classes are 0, 1, and 2, respectively.
618 Computer Vision Below we add an dimension for examples of anchor boxes and ground-truth bounding boxes.
labels = multibox_target(anchors.
unsqueeze(dim=0), ground_truth.
unsqueeze(dim=0)) Therearethreeitemsinthereturnedresult, allofwhichareinthetensorformat.
Thethird itemcontainsthelabeledclassesoftheinputanchorboxes.
Letâ€™sanalyzethereturnedclasslabelsbelowbasedonanchorboxandground-truthbound- ingboxpositionsintheimage.
First, amongallthepairsofanchorboxesandground-truth boundingboxes, the Io Uoftheanchorbox ğ´ andtheground-truthboundingboxofthe 4 catisthelargest.
Thus, theclassof ğ´ islabeledasthecat.
Takingoutpairscontaining 4 ğ´ ortheground-truthboundingboxofthecat, amongtherestthepairoftheanchorbox 4 ğ´ andtheground-truthboundingboxofthedoghasthelargest Io U.
Sotheclassof ğ´ is 1 1 labeledasthedog.
Next, weneedtotraversethroughtheremainingthreeunlabeledanchor boxes: ğ´ , ğ´ , and ğ´ .
For ğ´ , theclassoftheground-truthboundingboxwiththelargest 0 2 3 0 Io Uisthedog, butthe Io Uisbelowthepredefinedthreshold(0.5), sotheclassislabeled asbackground; for ğ´ , theclassoftheground-truthboundingboxwiththelargest Io Uis 2 thecatandthe Io Uexceedsthethreshold, sotheclassislabeledasthecat; forğ´ , theclass 3 oftheground-truthboundingboxwiththelargest Io Uisthecat, butthevalueisbelowthe threshold, sotheclassislabeledasbackground.
labels[2] tensor([[0, 1, 2, 0, 2]]) Thesecondreturneditemisamaskvariableoftheshape(batchsize, fourtimesthenumber ofanchorboxes).
Everyfourelementsinthemaskvariablecorrespondtothefouroffset valuesofeachanchorbox.
Sincewedonotcareaboutbackgrounddetection, offsetsofthis negativeclass shouldnot affectthe objectivefunction.
Through elementwisemultiplica- tions, zerosinthemaskvariablewillfilteroutnegativeclassoffsetsbeforecalculatingthe objectivefunction.
labels[1] â†©!, 1., 1.]]) The first returned item contains the four offset values labeled for each anchor box.
Note thattheoffsetsofnegative-classanchorboxesarelabeledaszeros.
labels[0] 619 Anchor Boxes 4.17e-06, 6.26e-01]]) 14.4.4 Predicting Bounding Boxeswith Non-Maximum Suppression Duringprediction, wegeneratemultipleanchorboxesfortheimageandpredictclassesand offsetsforeachofthem.
Apredictedboundingboxisthusobtainedaccordingtoananchor boxwithitspredictedoffset.
Belowweimplementtheoffset_inversefunctionthattakes in anchors and offset predictions as inputs and applies inverse offset transformations to returnthepredictedboundingboxcoordinates.
#@save def offset_inverse(anchors, offset_preds): """Predict bounding boxes based on anchor boxes with predicted offsets.""" anc = d2l.
box_corner_to_center(anchors) pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2] pred_bbox_wh = torch.
exp(offset_preds[:, 2:] / 5) * anc[:, 2:] pred_bbox = torch.
cat((pred_bbox_xy, pred_bbox_wh), axis=1) predicted_bbox = d2l.
box_center_to_corner(pred_bbox) return predicted_bbox Whentherearemanyanchorboxes, manysimilar(withsignificantoverlap)predictedbound- ingboxescanbepotentiallyoutputforsurroundingthesameobject.
Tosimplifytheoutput, we can merge similar predicted bounding boxes that belong to the same object by using non-maximumsuppression(NMS).
Hereishownon-maximumsuppressionworks.
Forapredictedboundingboxğµ, theobject detectionmodelcalculatesthepredictedlikelihoodforeachclass.
Denotingbyğ‘thelargest predictedlikelihood, theclasscorrespondingtothisprobabilityisthepredictedclassforğµ.
Specifically, werefertoğ‘astheconfidence(score)ofthepredictedboundingboxğµ.
Onthe sameimage, allthepredictednon-backgroundboundingboxesaresortedbyconfidencein descendingordertogeneratealistğ¿.
Thenwemanipulatethesortedlistğ¿inthefollowing steps: 1.
Selectthepredictedboundingboxğµ withthehighestconfidencefromğ¿asabasisand 1 removeallnon-basispredictedboundingboxeswhose Io Uwithğµ exceedsapredefined 1 thresholdğœ– fromğ¿.
Atthispoint,ğ¿ keepsthepredictedboundingboxwiththehighest confidence but drops others that are too similar to it.
In a nutshell, those with non- maximumconfidencescoresaresuppressed.
2.
Select the predicted bounding box ğµ with the second highest confidence from ğ¿ as 2 another basis and remove all non-basis predicted bounding boxes whose Io U with ğµ 2 exceedsğœ– fromğ¿.
3.
Repeattheaboveprocessuntilallthepredictedboundingboxesinğ¿havebeenusedas 620 Computer Vision abasis.
Atthistime, the Io Uofanypairofpredictedboundingboxesinğ¿isbelowthe thresholdğœ–; thus, nopairistoosimilarwitheachother.
4.
Outputallthepredictedboundingboxesinthelistğ¿.
Thefollowingnmsfunctionsortsconfidencescoresindescendingorderandreturnstheir indices.
#@save def nms(boxes, scores, iou_threshold): """Sort confidence scores of predicted bounding boxes.""" B = torch.
argsort(scores, dim=-1, descending=True) keep = [] # Indices of predicted bounding boxes that will be kept while B.
numel() > 0: i = B[0] keep.
append(i) if B.
numel() == 1: break iou = box_iou(boxes[i, :].
reshape(-1, 4), boxes[B[1:], :].
reshape(-1, 4)).
reshape(-1) inds = torch.
nonzero(iou <= iou_threshold).
reshape(-1) B = B[inds + 1] return torch.
tensor(keep, device=boxes.
device) Wedefinethefollowingmultibox_detectiontoapplynon-maximumsuppressiontopre- dicting bounding boxes.
Do not worry if you find the implementation a bit complicated: wewillshowhowitworkswithaconcreteexamplerightaftertheimplementation.
#@save def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5, pos_threshold=0.009999999): """Predict bounding boxes using non-maximum suppression.""" device, batch_size = cls_probs.
device, cls_probs.
shape[0] anchors = anchors.
squeeze(0) num_classes, num_anchors = cls_probs.
shape[1], cls_probs.
shape[2] out = [] for i in range(batch_size): cls_prob, offset_pred = cls_probs[i], offset_preds[i].
reshape(-1, 4) conf, class_id = torch.
max(cls_prob[1:], 0) predicted_bb = offset_inverse(anchors, offset_pred) keep = nms(predicted_bb, conf, nms_threshold) # Find all non-`keep` indices and set the class to background all_idx = torch.
arange(num_anchors, dtype=torch.
long, device=device) combined = torch.
cat((keep, all_idx)) uniques, counts = combined.
unique(return_counts=True) non_keep = uniques[counts == 1] all_id_sorted = torch.
cat((keep, non_keep)) class_id[non_keep] = -1 class_id = class_id[all_id_sorted] conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted] # Here `pos_threshold` is a threshold for positive (non-background) # predictions below_min_idx = (conf < pos_threshold) class_id[below_min_idx] = -1 conf[below_min_idx] = 1 - conf[below_min_idx] (continuesonnextpage) 621 Anchor Boxes (continuedfrompreviouspage) pred_info = torch.
cat((class_id.
unsqueeze(1), conf.
unsqueeze(1), predicted_bb), dim=1) out.
append(pred_info) return torch.
stack(out) Nowletâ€™sapplytheaboveimplementationstoaconcreteexamplewithfouranchorboxes.
For simplicity, we assume that the predicted offsets are all zeros.
This means that the predicted bounding boxes are anchor boxes.
For each class among the background, dog, andcat, wealsodefineitspredictedlikelihood.
offset_preds = torch.
tensor([0] * anchors.
numel()) cls_probs = torch.
tensor([[0] * 4, # Predicted background likelihood [0.9, 0.8, 0.7, 0.1], # Predicted dog likelihood [0.1, 0.2, 0.3, 0.9]]) # Predicted cat likelihood Wecanplotthesepredictedboundingboxeswiththeirconfidenceontheimage.
fig = d2l.
plt.
imshow(img) show_bboxes(fig.
axes, anchors * bbox_scale, ['dog=0.9', 'dog=0.8', 'dog=0.7', 'cat=0.9']) Nowwecaninvokethemultibox_detectionfunctiontoperformnon-maximumsuppres- sion, wherethethresholdissetto0.5.
Notethatweaddadimensionforexamplesinthe tensorinput.
We can see that the shape of the returned result is (batch size, number of anchor boxes, 6).
Thesixelementsintheinnermostdimensiongivestheoutputinformationforthesame predictedboundingbox.
Thefirstelementisthepredictedclassindex, whichstartsfrom 0(0isdogand1iscat).
Thevalue-1indicatesbackgroundorremovalinnon-maximum suppression.
The second element is the confidence of the predicted bounding box.
The remaining four elements are the â€ğ‘¥,ğ‘¦â€-axis coordinates of the upper-left corner and the lower-right corner of the predicted bounding box, respectively (range is between 0 and 1).
622 Computer Vision output = multibox_detection(cls_probs.
unsqueeze(dim=0), offset_preds.
unsqueeze(dim=0), anchors.
unsqueeze(dim=0), nms_threshold=0.5) output Afterremovingthosepredictedboundingboxesofclass-1, wecanoutputthefinalpredicted boundingboxkeptbynon-maximumsuppression.
fig = d2l.
plt.
imshow(img) for i in output[0].
detach().
numpy(): if i[0] == -1: continue label = ('dog=', 'cat=')[int(i[0])] + str(i[1]) show_bboxes(fig.
axes, [torch.
tensor(i[2:]) * bbox_scale], label) In practice, we can remove predicted bounding boxes with lower confidence even before performing non-maximum suppression, thereby reducing computation in this algorithm.
Wemayalsopost-processtheoutputofnon-maximumsuppression, forexample, byonly keepingresultswithhigherconfidenceinthefinaloutput.
14.4.5 Summary Wegenerateanchorboxeswithdifferentshapescenteredoneachpixeloftheimage.
Intersectionoverunion(Io U), alsoknownas Jaccardindex, measuresthesimilarityof twoboundingboxes.
Itistheratiooftheirintersectionareatotheirunionarea.
In a training set, we need two types of labels for each anchor box.
One is the class of the object relevant to the anchor box and the other is the offset of the ground-truth boundingboxrelativetotheanchorbox.
Duringprediction, wecanusenon-maximumsuppression(NMS)toremovesimilarpre- dictedboundingboxes, therebysimplifyingtheoutput.
623 Multiscale Object Detection 14.4.6 Exercises 1.
Change values of sizes and ratios in the multibox_prior function.
What are the changestothegeneratedanchorboxes? 2.
Constructandvisualizetwoboundingboxeswithan Io Uof0.5.
Howdotheyoverlap witheachother? change? 4.
Non-maximum suppression is a greedy algorithm that suppresses predicted bounding boxes by removing them.
Is it possible that some of these removed ones are actually useful? Howcanthisalgorithmbemodifiedtosuppresssoftly? Youmayreferto Soft- NMS(Bodlaetal.,2017).
5.
Ratherthanbeinghand-crafted, cannon-maximumsuppressionbelearned? Discussions215.
215 14.5 Multiscale Object Detection In Section 14.4, we generated multiple anchor boxes centered on each pixel of an input image.
Essentiallytheseanchorboxesrepresentsamplesofdifferentregionsoftheimage.
However, wemayendupwithtoomanyanchorboxestocomputeiftheyaregeneratedfor everypixel.
Thinkofa561 728inputimage.
Iffiveanchorboxeswithvaryingshapes aregeneratedforeachpixelastheircenter, overtwomillionanchorboxes(561 728 5) needtobelabeledandpredictedontheimage.
14.5.1 Multiscale Anchor Boxes Youmayrealizethatitisnotdifficulttoreduceanchorboxesonanimage.
Forinstance, we canjustuniformlysampleasmallportionofpixelsfromtheinputimagetogenerateanchor boxescenteredonthem.
Inaddition, atdifferentscaleswecangeneratedifferentnumbers ofanchorboxesofdifferentsizes.
Intuitively, smallerobjectsaremorelikelytoappearon animagethanlargerones.
Asanexample,1 1,1 2, and2 2objectscanappearona 2 2imagein4,2, and1possibleways, respectively.
Therefore, whenusingsmalleranchor boxestodetectsmallerobjects, wecansamplemoreregions, whileforlargerobjectswe cansamplefewerregions.
To demonstrate how to generate anchor boxes at multiple scales, letâ€™s read an image.
Its heightandwidthare561and728pixels, respectively.
%matplotlib inline import torch (continuesonnextpage) 624 Computer Vision (continuedfrompreviouspage) from d2l import torch as d2l h, w = img.
shape[:2] h, w (561, 728) Recallthatin Section7.2wecallatwo-dimensionalarrayoutputofaconvolutionallayer afeaturemap.
Bydefiningthefeaturemapshape, wecandeterminecentersofuniformly sampledanchorboxesonanyimage.
Thedisplay_anchorsfunctionisdefinedbelow.
Wegenerateanchorboxes(anchors)on the feature map (fmap) with each unit (pixel) as the anchor box center.
Since the â€ğ‘¥,ğ‘¦â€- axiscoordinatevaluesintheanchorboxes(anchors)havebeendividedbythewidthand height of the feature map (fmap), these values are between 0 and 1, which indicate the relativepositionsofanchorboxesinthefeaturemap.
Sincecentersoftheanchorboxes(anchors)arespreadoverallunitsonthefeaturemap (fmap), these centers must be uniformly distributed on any input image in terms of their relativespatialpositions.
Moreconcretely, giventhewidthandheightofthefeaturemap fmap_w and fmap_h, respectively, the following function will uniformly sample pixels in fmap_hrowsandfmap_wcolumnsonanyinputimage.
Centeredontheseuniformlysam- pled pixels, anchor boxes of scale s (assuming the length of the list s is 1) and different aspectratios(ratios)willbegenerated.
def display_anchors(fmap_w, fmap_h, s): d2l.
set_figsize() # Values on the first two dimensions do not affect the output fmap = torch.
zeros((1, 10, fmap_h, fmap_w)) anchors = d2l.
multibox_prior(fmap, sizes=s, ratios=[1, 2, 0.5]) bbox_scale = torch.
tensor((w, h, w, h)) d2l.
show_bboxes(d2l.
plt.
imshow(img).
axes, anchors[0] * bbox_scale) First, letâ€™s consider detection of small objects.
In order to make it easier to distinguish when displayed, the anchor boxes with different centers here do not overlap: the anchor boxscaleissetto0.15andtheheightandwidthofthefeaturemaparesetto4.
Wecansee thatthecentersoftheanchorboxesin4rowsand4columnsontheimageareuniformly distributed.
display_anchors(fmap_w=4, fmap_h=4, s=[0.15]) Wemoveontoreducetheheightandwidthofthefeaturemapbyhalfanduselargeranchor boxestodetectlargerobjects.
Whenthescaleissetto0.4, someanchorboxeswilloverlap witheachother.
625 Multiscale Object Detection display_anchors(fmap_w=2, fmap_h=2, s=[0.4]) Finally, wefurtherreducetheheightandwidthofthefeaturemapbyhalfandincreasethe anchorboxscaleto0.8.
Nowthecenteroftheanchorboxisthecenteroftheimage.
display_anchors(fmap_w=1, fmap_h=1, s=[0.8]) 14.5.2 Multiscale Detection Since we have generated multiscale anchor boxes, we will use them to detect objects of various sizes at different scales.
In the following we introduce a CNN-based multiscale objectdetectionmethodthatwewillimplementin Section14.7.
Atsomescale, saythatwehaveğ‘featuremapsofshapeâ„ ğ‘¤.
Usingthemethodin Section 14.5.1, wegenerate â„ğ‘¤ setsofanchorboxes, whereeachsethasğ‘ anchorboxeswiththe samecenter.
Forexample, atthefirstscaleintheexperimentsin Section14.5.1, giventen 626 Computer Vision (numberofchannels)4 4featuremaps, wegenerated16setsofanchorboxes, whereeach set contains 3 anchor boxes with the same center.
Next, each anchor box is labeled with theclassandoffsetbasedonground-truthboundingboxes.
Atthecurrentscale, theobject detectionmodelneedstopredicttheclassesandoffsetsofâ„ğ‘¤ setsofanchorboxesonthe inputimage, wheredifferentsetshavedifferentcenters.
Assumethattheğ‘featuremapsherearetheintermediateoutputsobtainedbythe CNNfor- wardpropagationbasedontheinputimage.
Sincethereare â„ğ‘¤ differentspatialpositions on each feature map, the same spatial position can be thought of as having ğ‘ units.
Ac- cordingtothedefinitionofreceptivefieldin Section7.2, theseğ‘ unitsatthesamespatial positionofthefeaturemapshavethesamereceptivefieldontheinputimage: theyrepre- senttheinputimageinformationinthesamereceptivefield.
Therefore, wecantransform theğ‘unitsofthefeaturemapsatthesamespatialpositionintotheclassesandoffsetsofthe ğ‘anchorboxesgeneratedusingthisspatialposition.
Inessence, weusetheinformationof theinputimageinacertainreceptivefieldtopredicttheclassesandoffsetsoftheanchor boxesthatareclosetothatreceptivefieldontheinputimage.
When the feature maps at different layers have varying-size receptive fields on the input image, theycanbeusedtodetectobjectsofdifferentsizes.
Forexample, wecandesigna neuralnetworkwhereunitsoffeaturemapsthatareclosertotheoutputlayerhavewider receptivefields, sotheycandetectlargerobjectsfromtheinputimage.
Inanutshell, wecanleveragelayerwiserepresentationsofimagesatmultiplelevelsbydeep neural networks for multiscale object detection.
We will show how this works through a concreteexamplein Section14.7.
14.5.3 Summary At multiple scales, we can generate anchor boxes with different sizes to detect objects withdifferentsizes.
Bydefiningtheshapeoffeaturemaps, wecandeterminecentersofuniformlysampled anchorboxesonanyimage.
Weusetheinformationoftheinputimageinacertainreceptivefieldtopredicttheclasses andoffsetsoftheanchorboxesthatareclosetothatreceptivefieldontheinputimage.
Throughdeeplearning, wecanleverageitslayerwiserepresentationsofimagesatmul- tiplelevelsformultiscaleobjectdetection.
14.5.4 Exercises 1.
According to our discussions in Section 8.1, deep neural networks learn hierarchical featureswithincreasinglevelsofabstractionforimages.
Inmultiscaleobjectdetection, dofeaturemapsatdifferentscalescorrespondtodifferentlevelsofabstraction? Whyor whynot? 2.
Atthefirstscale(fmap_w=4, fmap_h=4)intheexperimentsin Section14.5.1, generate uniformlydistributedanchorboxesthatmayoverlap.
627 The Object Detection Dataset 3.
Given a feature map variable with shape 1 ğ‘ â„ ğ‘¤, where ğ‘, â„, and ğ‘¤ are the numberofchannels, height, andwidthofthefeaturemaps, respectively.
Howcanyou transformthisvariableintotheclassesandoffsetsofanchorboxes? Whatistheshape oftheoutput? Discussions216.
216 14.6 The Object Detection Dataset Thereisnosmalldatasetsuchas MNISTand Fashion-MNISTinthefieldofobjectdetec- tion.
Inordertoquicklydemonstrateobjectdetectionmodels, wecollectedandlabeleda small dataset.
First, we took photos of free bananas from our office and generated 1000 bananaimageswithdifferentrotationsandsizes.
Thenweplacedeachbananaimageata random position on some background image.
In the end, we labeled bounding boxes for thosebananasontheimages.
14.6.1 Downloadingthe Dataset The banana detection dataset with all the image and csv label files can be downloaded directlyfromthe Internet.
%matplotlib inline import os import pandas as pd import torch import torchvision from d2l import torch as d2l #@save d2l.
DATA_HUB['banana-detection'] = ( d2l.
DATA_URL + 'banana-detection.
zip', '5de26c8fce5ccdea9f91267273464dc968d20d72') 14.6.2 Readingthe Dataset We are going to read the banana detection dataset in the read_data_bananas function below.
The dataset includes a csv file for object class labels and ground-truth bounding boxcoordinatesattheupper-leftandlower-rightcorners.
#@save def read_data_bananas(is_train=True): """Read the banana detection dataset images and labels.""" data_dir = d2l.
download_extract('banana-detection') csv_fname = os.
path.
join(data_dir, 'bananas_train' if is_train (continuesonnextpage) 628 Computer Vision (continuedfrompreviouspage) else 'bananas_val', 'label.
csv') csv_data = pd.
read_csv(csv_fname) csv_data = csv_data.
set_index('img_name') images, targets = [], [] for img_name, target in csv_data.
iterrows(): images.
append(torchvision.
io.
read_image( os.
path.
join(data_dir, 'bananas_train' if is_train else 'bananas_val', 'images', f'{img_name}'))) # Here `target` contains (class, upper-left x, upper-left y, # lower-right x, lower-right y), where all the images have the same # banana class (index 0) targets.
append(list(target)) return images, torch.
tensor(targets).
unsqueeze(1) / 256 By using the read_data_bananas function to read imagesand labels, the following Ba- nanas Datasetclasswillallowustocreateacustomized Datasetinstanceforloadingthe bananadetectiondataset.
#@save class Bananas Dataset(torch.
utils.
data.
Dataset): """A customized dataset to load the banana detection dataset.""" def __init__(self, is_train): self.
features, self.
labels = read_data_bananas(is_train) print('read ' + str(len(self.
features)) + (f' training examples' if is_train else f' validation examples')) def __getitem__(self, idx): return (self.
features[idx].
float(), self.
labels[idx]) def __len__(self): return len(self.
features) Finally, we define the load_data_bananas function to return two data iterator instances forboththetrainingandtestsets.
Forthetestdataset, thereisnoneedtoreaditinrandom order.
#@save def load_data_bananas(batch_size): """Load the banana detection dataset.""" train_iter = torch.
utils.
data.
Data Loader(Bananas Dataset(is_train=True), batch_size, shuffle=True) val_iter = torch.
utils.
data.
Data Loader(Bananas Dataset(is_train=False), batch_size) return train_iter, val_iter Letâ€™s read a minibatch and print the shapes of both images and labels in this minibatch.
Theshapeoftheimageminibatch,(batchsize, numberofchannels, height, width), looks familiar: itisthesameasinourearlierimageclassificationtasks.
Theshapeofthelabel minibatchis(batchsize,ğ‘š,5), whereğ‘š isthelargestpossiblenumberofboundingboxes thatanyimagehasinthedataset.
629 The Object Detection Dataset Althoughcomputationinminibatchesismoreefficient, itrequiresthatalltheimageexam- ples contain the same number of bounding boxes to form a minibatch via concatenation.
Ingeneral, imagesmayhaveavaryingnumberofboundingboxes; thus, imageswithfewer thanğ‘šboundingboxeswillbepaddedwithillegalboundingboxesuntilğ‘šisreached.
Then thelabelofeachboundingboxisrepresentedbyanarrayoflength5.
Thefirstelementin thearrayistheclassoftheobjectintheboundingbox, where-1indicatesanillegalbound- ing box for padding.
The remaining four elements of the array are the (ğ‘¥, ğ‘¦)-coordinate valuesoftheupper-leftcornerandthelower-rightcorneroftheboundingbox(therange isbetween0and1).
Forthebananadataset, sincethereisonlyoneboundingboxoneach image, wehaveğ‘š =1.
batch_size, edge_size = 32, 256 train_iter, _ = load_data_bananas(batch_size) batch = next(iter(train_iter)) batch[0].
shape, batch[1].
shape read 1000 training examples read 100 validation examples (torch.
Size([32, 3, 256, 256]), torch.
Size([32, 1, 5])) 14.6.3 Demonstration Letâ€™sdemonstratetenimageswiththeirlabeledground-truthboundingboxes.
Wecansee thattherotations, sizes, andpositionsofbananasvaryacrossalltheseimages.
Ofcourse, thisisjustasimpleartificialdataset.
Inpractice, real-worlddatasetsareusuallymuchmore complicated.
imgs = (batch[0][:10].
permute(0, 2, 3, 1)) / 255 axes = d2l.
show_images(imgs, 2, 5, scale=2) for ax, label in zip(axes, batch[1][:10]): d2l.
show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w']) 14.6.4 Summary Thebananadetectiondatasetwecollectedcanbeusedtodemonstrateobjectdetection models.
Thedataloadingforobjectdetectionissimilartothatforimageclassification.
However, inobjectdetectionthelabelsalsocontaininformationofground-truthboundingboxes, whichismissinginimageclassification.
14.6.5 Exercises 630 Computer Vision 1.
Demonstrate other images with ground-truth bounding boxes in the banana detection dataset.
Howdotheydifferwithrespecttoboundingboxesandobjects? 2.
Saythatwewanttoapplydataaugmentation, suchasrandomcropping, toobjectdetec- tion.
Howcanitbedifferentfromthatinimageclassification? Hint: whatifacropped imageonlycontainsasmallportionofanobject? Discussions217.
217 14.7 Single Shot Multibox Detection In Section 14.3â€“Section 14.6, we introduced bounding boxes, anchor boxes, multiscale objectdetection, andthedatasetforobjectdetection.
Nowwearereadytousesuchback- ground knowledge to design an object detection model: single shot multibox detection (SSD) (Liu et al., 2016).
This model is simple, fast, and widely used.
Although this is just one of vast amounts of object detection models, some of the design principles and implementationdetailsinthissectionarealsoapplicabletoothermodels.
14.7.1 Model .7.1 provides an overview of the design of single-shot multibox detection.
This modelmainlyconsistsofabasenetworkfollowedbyseveralmultiscalefeaturemapblocks.
Thebasenetworkisforextractingfeaturesfromtheinputimage, soitcanuseadeep CNN.
Forexample, theoriginalsingle-shotmultiboxdetectionpaperadoptsa VGGnetworktrun- catedbeforetheclassificationlayer(Liuetal.,2016), while Res Nethasalsobeencommonly used.
Throughourdesignwecanmakethebasenetworkoutputlargerfeaturemapssoas togeneratemoreanchorboxesfordetectingsmallerobjects.
Subsequently, eachmultiscale featuremapblockreduces(e.
g., byhalf)theheightandwidthofthefeaturemapsfromthe previousblock, andenableseachunitofthefeaturemapstoincreaseitsreceptivefieldon theinputimage.
631 Single Shot Multibox Detection Recallthedesignofmultiscaleobjectdetectionthroughlayerwiserepresentationsofimages bydeepneuralnetworksin Section14.5.
Sincemultiscalefeaturemapsclosertothetopof .7.1aresmallerbuthavelargerreceptivefields, theyaresuitablefordetectingfewer butlargerobjects.
In a nutshell, via its base network and several multiscale feature map blocks, single-shot multibox detection generates a varying number of anchor boxes with different sizes, and detects varying-size objects by predicting classes and offsets of these anchor boxes (thus theboundingboxes); thus, thisisamultiscaleobjectdetectionmodel.
t .7.1 Asamultiscaleobjectdetectionmodel, single-shotmultiboxdetectionmainlyconsistsof abasenetworkfollowedbyseveralmultiscalefeaturemapblocks.
In the following, we will describe the implementation details of different blocks in .7.1.
Tobegin with, wediscuss howto implementthe class and bounding boxpredic- tion.
Class Prediction Layer Letthenumberofobjectclassesbeğ‘.
Thenanchorboxeshaveğ‘â€š1classes, whereclass0is background.
Atsomescale, supposethattheheightandwidthoffeaturemapsareâ„andğ‘¤, respectively.
Whenğ‘anchorboxesaregeneratedwitheachspatialpositionofthesefeature mapsastheircenter, atotalof â„ğ‘¤ğ‘ anchorboxesneedtobeclassified.
Thisoftenmakes classification with fully connected layers infeasible due to likely heavy parametrization costs.
Recall how we used channels of convolutional layers to predict classes in Section 8.3.
Single-shot multibox detection uses the same technique to reduce model complex- ity.
Specifically, the class prediction layer uses a convolutional layer without altering width orheightoffeaturemaps.
Inthisway, therecanbeaone-to-onecorrespondencebetween outputsandinputsatthesamespatialdimensions(widthandheight)offeaturemaps.
More concretely, channelsoftheoutputfeaturemapsatanyspatialposition(ğ‘¥,ğ‘¦)representclass predictionsforalltheanchorboxescenteredon(ğ‘¥,ğ‘¦)oftheinputfeaturemaps.
Toproduce validpredictions, theremustbeğ‘â€ğ‘â€š1â€outputchannels, whereforthesamespatialposition 632 Computer Vision theoutputchannelwithindexğ‘–â€ğ‘â€š1â€â€šğ‘—representsthepredictionoftheclass ğ‘—(0 ğ‘— ğ‘) fortheanchorboxğ‘–(0 ğ‘– < ğ‘).
Belowwedefinesuchaclasspredictionlayer, specifyingğ‘andğ‘viaargumentsnum_anchors andnum_classes, respectively.
Thislayerusesa3 3convolutionallayerwithapadding of1.
Thewidthandheightoftheinputandoutputofthisconvolutionallayerremainun- changed.
%matplotlib inline import torch import torchvision from torch import nn from torch.
nn import functional as F from d2l import torch as d2l def cls_predictor(num_inputs, num_anchors, num_classes): return nn.
Conv2d(num_inputs, num_anchors * (num_classes + 1), kernel_size=3, padding=1) Bounding Box Prediction Layer The design of the bounding box prediction layer is similar to that of the class prediction layer.
Theonlydifferenceliesinthenumberofoutputsforeachanchorbox: hereweneed topredictfouroffsetsratherthanğ‘â€š1classes.
def bbox_predictor(num_inputs, num_anchors): return nn.
Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1) Concatenating Predictionsfor Multiple Scales Aswementioned, single-shotmultiboxdetectionusesmultiscalefeaturemapstogenerate anchorboxesandpredicttheirclassesandoffsets.
Atdifferentscales, theshapesoffeature mapsorthenumbersofanchorboxescenteredonthesameunitmayvary.
Therefore, shapes ofthepredictionoutputsatdifferentscalesmayvary.
Inthefollowingexample, weconstructfeaturemapsattwodifferentscales, Y1and Y2, for thesameminibatch, wheretheheightandwidthof Y2arehalfofthoseof Y1.
Letâ€™stake classpredictionasanexample.
Supposethat5and3anchorboxesaregeneratedforevery unit in Y1 and Y2, respectively.
Suppose further that the number of object classes is 10.
For feature maps Y1 and Y2 the numbers of channels in the class prediction outputs are 5 â€10â€š1â€ =55and3 â€10â€š1â€ =33, respectively, whereeitheroutputshapeis(batch size, numberofchannels, height, width).
def forward(x, block): return block(x) (continuesonnextpage) 633 Single Shot Multibox Detection (continuedfrompreviouspage) Y1 = forward(torch.
zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10)) Y2 = forward(torch.
zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10)) Y1.
shape, Y2.
shape (torch.
Size([2, 55, 20, 20]), torch.
Size([2, 33, 10, 10])) As we can see, except for the batch size dimension, the other three dimensions all have differentsizes.
Toconcatenatethesetwopredictionoutputsformoreefficientcomputation, wewilltransformthesetensorsintoamoreconsistentformat.
Notethatthechanneldimensionholdsthepredictionsforanchorboxeswiththesamecenter.
Wefirstmovethisdimensiontotheinnermost.
Sincethebatchsizeremainsthesamefor differentscales, wecantransformthepredictionoutputintoatwo-dimensionaltensorwith shape(batchsize, height width numberofchannels).
Thenwecanconcatenatesuch outputsatdifferentscalesalongdimension1.
def flatten_pred(pred): return torch.
flatten(pred.
permute(0, 2, 3, 1), start_dim=1) def concat_preds(preds): return torch.
cat([flatten_pred(p) for p in preds], dim=1) In this way, even though Y1 and Y2 have different sizes in channels, heights, and widths, we can still concatenate these two prediction outputs at two different scales for the same minibatch.
concat_preds([Y1, Y2]).
shape torch.
Size([2, 25300]) Downsampling Block Inordertodetectobjectsatmultiplescales, wedefinethefollowingdownsamplingblock down_sample_blkthathalvestheheightandwidthofinputfeaturemaps.
Infact, thisblock appliesthedesignof VGGblocksin Section8.2.1.
Moreconcretely, eachdownsampling blockconsistsoftwo3 3convolutionallayerswithpaddingof1followedbya2 2max- poolinglayerwithstrideof2.
Asweknow,3 3convolutionallayerswithpaddingof1do notchangetheshapeoffeaturemaps.
However, thesubsequent2 2max-poolingreduces theheightandwidthofinputfeaturemapsbyhalf.
Forbothinputandoutputfeaturemaps ofthisdownsamplingblock, because1 2â€šâ€3 1â€â€šâ€3 1â€ =6, eachunitintheoutput hasa6 6receptivefieldontheinput.
Therefore, thedownsamplingblockenlargesthe receptivefieldofeachunitinitsoutputfeaturemaps.
634 Computer Vision def down_sample_blk(in_channels, out_channels): blk = [] for _ in range(2): blk.
append(nn.
Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) blk.
append(nn.
Batch Norm2d(out_channels)) blk.
append(nn.
Re LU()) in_channels = out_channels blk.
append(nn.
Max Pool2d(2)) return nn.
Sequential(*blk) Inthefollowingexample, ourconstructeddownsamplingblockchangesthenumberofinput channelsandhalvestheheightandwidthoftheinputfeaturemaps.
forward(torch.
zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).
shape torch.
Size([2, 10, 10, 10]) Base Network Block Thebasenetworkblockisusedtoextractfeaturesfrominputimages.
Forsimplicity, we construct a small base network consisting of three downsampling blocks that double the numberofchannelsateachblock.
Givena256 256inputimage, thisbasenetworkblock outputs32 32featuremaps(256 23 =32).
def base_net(): blk = [] num_filters = [3, 16, 32, 64] for i in range(len(num_filters) - 1): blk.
append(down_sample_blk(num_filters[i], num_filters[i+1])) return nn.
Sequential(*blk) forward(torch.
zeros((2, 3, 256, 256)), base_net()).
shape torch.
Size([2, 64, 32, 32]) The Complete Model The complete single shot multibox detection model consists of five blocks.
The feature mapsproducedbyeachblockareusedforboth(i)generatinganchorboxesand(ii)predict- ingclassesandoffsetsoftheseanchorboxes.
Amongthesefiveblocks, thefirstoneisthe basenetworkblock, thesecondtothefourtharedownsamplingblocks, andthelastblock usesglobalmax-poolingtoreduceboththeheightandwidthto1.
Technically, thesecond tothefifthblocksareallthosemultiscalefeaturemapblocksin.7.1.
635 Single Shot Multibox Detection def get_blk(i): if i == 0: blk = base_net() elif i == 1: blk = down_sample_blk(64, 128) elif i == 4: blk = nn.
Adaptive Max Pool2d((1,1)) else: blk = down_sample_blk(128, 128) return blk Nowwedefinetheforwardpropagationforeachblock.
Differentfrominimageclassifica- tiontasks, outputshereinclude(i)CNNfeaturemaps Y,(ii)anchorboxesgeneratedusing Yatthecurrentscale, and(iii)classesandoffsetspredicted(basedon Y)fortheseanchor boxes.
def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor): Y = blk(X) anchors = d2l.
multibox_prior(Y, sizes=size, ratios=ratio) cls_preds = cls_predictor(Y) bbox_preds = bbox_predictor(Y) return (Y, anchors, cls_preds, bbox_preds) Recall that in .7.1 a multiscale feature map block that is closer to the top is for detectinglargerobjects; thus, itneedstogeneratelargeranchorboxes.
Intheaboveforward propagation, ateachmultiscalefeaturemapblockwepassinalistoftwoscalevaluesviathe sizesargumentoftheinvokedmultibox_priorfunction(describedin Section14.4).
In thefollowing, theintervalbetween0.2and1.05issplitevenlyintofivesectionstodetermine [0.88, 0.961]] ratios = [[1, 2, 0.5]] * 5 num_anchors = len(sizes[0]) + len(ratios[0]) - 1 Nowwecandefinethecompletemodel Tiny SSDasfollows.
class Tiny SSD(nn.
Module): def __init__(self, num_classes, **kwargs): super(Tiny SSD, self).__init__(**kwargs) self.
num_classes = num_classes idx_to_in_channels = [64, 128, 128, 128, 128] for i in range(5): # Equivalent to the assignment statement `self.
blk_i = get_blk(i)` setattr(self, f'blk_{i}', get_blk(i)) setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i], num_anchors, num_classes)) setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i], num_anchors)) (continuesonnextpage) 636 Computer Vision (continuedfrompreviouspage) def forward(self, X): anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5 for i in range(5): # Here `getattr(self, 'blk_%d' % i)` accesses `self.
blk_i` X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward( X, getattr(self, f'blk_{i}'), sizes[i], ratios[i], getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}')) anchors = torch.
cat(anchors, dim=1) cls_preds = concat_preds(cls_preds) cls_preds = cls_preds.
reshape( cls_preds.
shape[0], -1, self.
num_classes + 1) bbox_preds = concat_preds(bbox_preds) return anchors, cls_preds, bbox_preds Wecreateamodel instanceanduse ittoperform forwardpropagationon aminibatchof 256 256images X.
Asshownearlierinthissection, thefirstblockoutputs32 32featuremaps.
Recallthatthe secondtofourthdownsamplingblockshalvetheheightandwidthandthefifthblockuses globalpooling.
Since4anchorboxesaregeneratedforeachunitalongspatialdimensions offeaturemaps, atallthefivescalesatotalofâ€322â€š162â€š82â€š42â€š1â€ 4=5444anchor boxesaregeneratedforeachimage.
net = Tiny SSD(num_classes=1) X = torch.
zeros((32, 3, 256, 256)) anchors, cls_preds, bbox_preds = net(X) print('output anchors:', anchors.
shape) print('output class preds:', cls_preds.
shape) print('output bbox preds:', bbox_preds.
shape) output anchors: torch.
Size([1, 5444, 4]) output class preds: torch.
Size([32, 5444, 2]) output bbox preds: torch.
Size([32, 21776]) 14.7.2 Training Nowwewillexplainhowtotrainthesingleshotmultiboxdetectionmodelforobjectde- tection.
Readingthe Datasetand Initializingthe Model Tobeginwith, letâ€™sreadthebananadetectiondatasetdescribedin Section14.6.
batch_size = 32 train_iter, _ = d2l.
load_data_bananas(batch_size) 637 Single Shot Multibox Detection read 1000 training examples read 100 validation examples Thereisonlyoneclassinthebananadetectiondataset.
Afterdefiningthemodel, weneed toinitializeitsparametersanddefinetheoptimizationalgorithm.
device, net = d2l.
try_gpu(), Tiny SSD(num_classes=1) trainer = torch.
optim.
SGD(net.
parameters(), lr=0.2, weight_decay=5e-4) Defining Lossand Evaluation Functions Objectdetectionhastwotypesoflosses.
Thefirstlossconcernsclassesofanchorboxes: its computation can simply reuse the cross-entropy loss function that we used for image classification.
Thesecondlossconcernsoffsetsofpositive(non-background)anchorboxes: thisisaregressionproblem.
Forthisregressionproblem, however, herewedonotusethe squared loss described in Section 3.1.3.
Instead, we use the â„“ norm loss, the absolute 1 value of the difference between the prediction and the ground-truth.
The mask variable bbox_masksfiltersoutnegativeanchorboxesandillegal(padded)anchorboxesintheloss calculation.
Intheend, wesumuptheanchorboxclasslossandtheanchorboxoffsetloss toobtainthelossfunctionforthemodel.
cls_loss = nn.
Cross Entropy Loss(reduction='none') bbox_loss = nn.
L1Loss(reduction='none') def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks): batch_size, num_classes = cls_preds.
shape[0], cls_preds.
shape[2] cls = cls_loss(cls_preds.
reshape(-1, num_classes), cls_labels.
reshape(-1)).
reshape(batch_size, -1).
mean(dim=1) bbox = bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).
mean(dim=1) return cls + bbox We can use accuracy to evaluate the classification results.
Due to the used â„“ norm loss 1 fortheoffsets, weusethemeanabsoluteerror toevaluatethepredictedboundingboxes.
These prediction results are obtained from the generated anchor boxes and the predicted offsetsforthem.
def cls_eval(cls_preds, cls_labels): # Because the class prediction results are on the final dimension, # `argmax` needs to specify this dimension return float((cls_preds.
argmax(dim=-1).
type( cls_labels.
dtype) == cls_labels).
sum()) def bbox_eval(bbox_preds, bbox_labels, bbox_masks): return float((torch.
abs((bbox_labels - bbox_preds) * bbox_masks)).
sum()) 638 Computer Vision Trainingthe Model Whentrainingthemodel, weneedtogeneratemultiscaleanchorboxes(anchors)andpre- dicttheirclasses(cls_preds)andoffsets(bbox_preds)intheforwardpropagation.
Then we label the classes (cls_labels) and offsets (bbox_labels) of such generated anchor boxes based on the label information Y.
Finally, we calculate the loss function using the predictedandlabeledvaluesoftheclassesandoffsets.
Forconciseimplementations, eval- uationofthetestdatasetisomittedhere.
num_epochs, timer = 20, d2l.
Timer() animator = d2l.
Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['class error', 'bbox mae']) net = net.
to(device) for epoch in range(num_epochs): # Sum of training accuracy, no.
of examples in sum of training accuracy, # Sum of absolute error, no.
of examples in sum of absolute error metric = d2l.
Accumulator(4) net.
train() for features, target in train_iter: timer.
start() trainer.
zero_grad() X, Y = features.
to(device), target.
to(device) # Generate multiscale anchor boxes and predict their classes and # offsets anchors, cls_preds, bbox_preds = net(X) # Label the classes and offsets of these anchor boxes bbox_labels, bbox_masks, cls_labels = d2l.
multibox_target(anchors, Y) # Calculate the loss function using the predicted and labeled values # of the classes and offsets l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks) l.
mean().
backward() trainer.
step() metric.
add(cls_eval(cls_preds, cls_labels), cls_labels.
numel(), bbox_eval(bbox_preds, bbox_labels, bbox_masks), bbox_labels.
numel()) cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3] animator.
add(epoch + 1, (cls_err, bbox_mae)) print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}') print(f'{len(train_iter.
dataset) / timer.
stop():.1f} examples/sec on ' f'{str(device)}') class err 3.27e-03, bbox mae 3.08e-03 14.7.3 Prediction Duringprediction, thegoalistodetectalltheobjectsofinterestontheimage.
Belowwe readandresizeatestimage, convertingittoafour-dimensionaltensorthatisrequiredby convolutionallayers.
639 Single Shot Multibox Detection img = X.
squeeze(0).
permute(1, 2, 0).
long() Usingthemultibox_detectionfunctionbelow, thepredictedboundingboxesareobtained fromtheanchorboxesandtheirpredictedoffsets.
Thennon-maximumsuppressionisused toremovesimilarpredictedboundingboxes.
def predict(X): net.
eval() anchors, cls_preds, bbox_preds = net(X.
to(device)) cls_probs = F.
softmax(cls_preds, dim=2).
permute(0, 2, 1) output = d2l.
multibox_detection(cls_probs, bbox_preds, anchors) idx = [i for i, row in enumerate(output[0]) if row[0] != -1] return output[0, idx] output = predict(X) Finally, wedisplayallthepredictedboundingboxeswithconfidence0.9oraboveasout- put.
def display(img, output, threshold): d2l.
set_figsize((5, 5)) fig = d2l.
plt.
imshow(img) for row in output: score = float(row[1]) if score < threshold: continue h, w = img.
shape[:2] bbox = [row[2:6] * torch.
tensor((w, h, w, h), device=row.
device)] d2l.
show_bboxes(fig.
axes, bbox, '%.2f' % score, 'w') display(img, output.
cpu(), threshold=0.9) 14.7.4 Summary Singleshotmultiboxdetectionisamultiscaleobjectdetectionmodel.
Viaitsbasenet- workandseveralmultiscalefeaturemapblocks, single-shotmultiboxdetectiongen- eratesavaryingnumberofanchorboxeswithdifferentsizes, anddetectsvarying-size 640 Computer Vision objects by predicting classes and offsets of these anchor boxes (thus the bounding boxes).
Whentrainingthesingle-shotmultiboxdetectionmodel, thelossfunctioniscalculated basedonthepredictedandlabeledvaluesoftheanchorboxclassesandoffsets.
14.7.5 Exercises 1.
Canyouimprovethesingle-shotmultiboxdetectionbyimprovingthelossfunction? For example, replaceâ„“ normlosswithsmoothâ„“ normlossforthepredictedoffsets.
This 1 1 lossfunctionusesasquarefunctionaroundzeroforsmoothness, whichiscontrolledby thehyperparameterğœ: ( â€ğœğ‘¥â€2 2, ifjğ‘¥j <1 ğœ2 ğ‘“â€ğ‘¥â€ = (14.7.1) jğ‘¥j 0.5 ğœ2, otherwise Whenğœisverylarge, thislossissimilartotheâ„“ normloss.
Whenitsvalueissmaller, the 1 lossfunctionissmoother.
def smooth_l1(data, scalar): out = [] for i in data: if abs(i) < 1 / (scalar ** 2): out.
append(((scalar * i) ** 2) / 2) else: out.
append(abs(i) - 0.5 / (scalar ** 2)) return torch.
tensor(out) sigmas = [10, 1, 0.5] lines = ['-', '--', '-.'] x = torch.
arange(-2, 2, 0.1) d2l.
set_figsize() (continuesonnextpage) 641 Single Shot Multibox Detection (continuedfrompreviouspage) for l, s in zip(lines, sigmas): y = smooth_l1(x, scalar=s) d2l.
plt.
plot(x, y, l, label='sigma=%.1f' % s) d2l.
plt.
legend(); Besides, intheexperimentweusedcross-entropylossforclassprediction: denotingby ğ‘ ğ‘— thepredictedprobabilityfortheground-truthclass ğ‘—, thecross-entropylossis logğ‘ ğ‘—.
We canalsousethefocalloss(Linetal.,2017): givenhyperparametersğ›¾ > 0andğ›¼ > 0, this lossisdefinedas: ğ›¼â€1 ğ‘ ğ‘— â€ğ›¾ logğ‘ ğ‘— .
(14.7.2) Aswecansee, increasingğ›¾ caneffectivelyreducetherelativelossforwell-classifiedex- amples(e.
g., ğ‘ ğ‘— > 0.5)sothetrainingcanfocusmoreonthosedifficultexamplesthatare misclassified.
def focal_loss(gamma, x): return -(1 - x) ** gamma * torch.
log(x) x = torch.
arange(0.01, 1, 0.01) for l, gamma in zip(lines, [0, 1, 5]): y = d2l.
plt.
plot(x, focal_loss(gamma, x), l, label='gamma=%.1f' % gamma) d2l.
plt.
legend(); 2.
Due to space limitations, we have omitted some implementation details of the single shotmultiboxdetectionmodelinthissection.
Canyoufurtherimprovethemodelinthe followingaspects: 642 Computer Vision 1.
Whenanobjectismuchsmallercomparedwiththeimage, themodelcouldresize theinputimagebigger.
2.
Therearetypicallyavastnumberofnegativeanchorboxes.
Tomaketheclassdis- tributionmorebalanced, wecoulddownsamplenegativeanchorboxes.
3.
Inthelossfunction, assigndifferentweighthyperparameterstotheclasslossandthe offsetloss.
4.
Useothermethodstoevaluatetheobjectdetectionmodel, suchasthoseinthesingle shotmultiboxdetectionpaper(Liuetal.,2016).
Discussions218.
218 14.8 Region-based CNNs (R-CNNs) Besides single shot multibox detection described in Section 14.7, region-based CNNs or regionswith CNNfeatures(R-CNNs)arealsoamongmanypioneeringapproachesofap- plying deep learning to object detection (Girshick et al., 2014).
In this section, we will introducethe R-CNNanditsseriesofimprovements: thefast R-CNN(Girshick,2015), the faster R-CNN(Renetal., 2015), andthemask R-CNN(Heetal., 2017).
Duetolimited space, wewillonlyfocusonthedesignofthesemodels.
14.8.1 R-CNNs The R-CNNfirstextractsmany(e.
g.,2000)regionproposalsfromtheinputimage(e.
g., an- chorboxescanalsobeconsideredasregionproposals), labelingtheirclassesandbounding boxes(e.
g., offsets).
(Girshicketal.,2014) Then a CNN is used to perform forward propagation on each region proposal to extract its features.
Next, features of each region proposal are used for predicting the class and boundingboxofthisregionproposal.
t .8.1 The R-CNNmodel.
.8.1showsthe R-CNNmodel.
Moreconcretely, the R-CNNconsistsofthefollowing foursteps: 643 Region-based CNNs(R-CNNs) 1.
Performselectivesearchtoextractmultiplehigh-qualityregionproposalsontheinput image(Uijlingsetal., 2013).
Theseproposedregionsareusuallyselectedatmultiple scaleswithdifferentshapesandsizes.
Eachregionproposalwillbelabeledwithaclass andaground-truthboundingbox.
2.
Choose a pretrained CNN and truncate it before the output layer.
Resize each region proposaltotheinputsizerequiredbythenetwork, andoutputtheextractedfeaturesfor theregionproposalthroughforwardpropagation.
3.
Take the extracted features and labeled class of each region proposal as an example.
Trainmultiplesupportvectormachinestoclassifyobjects, whereeachsupportvector machineindividuallydetermineswhethertheexamplecontainsaspecificclass.
4.
Take the extracted features and labeled bounding box of each region proposal as an example.
Trainalinearregressionmodeltopredicttheground-truthboundingbox.
Althoughthe R-CNNmodelusespretrained CNNstoeffectivelyextractimagefeatures, it isslow.
Imaginethatweselectthousandsofregionproposalsfromasingleinputimage: this requires thousands of CNN forward propagations to perform object detection.
This massivecomputingloadmakesitinfeasibletowidelyuse R-CNNsinreal-worldapplica- tions.
14.8.2 Fast R-CNN Themainperformancebottleneckofan R-CNNliesintheindependent CNNforwardprop- agationforeachregionproposal, withoutsharingcomputation.
Sincetheseregionsusually have overlaps, independent feature extractions lead to much repeated computation.
One of the major improvements of the fast R-CNN from the R-CNN is that the CNN forward propagationisonlyperformedontheentireimage(Girshick,2015).
t .8.2 Thefast R-CNNmodel.
.8.2describesthefast R-CNNmodel.
Itsmajorcomputationsareasfollows: 1.
Comparedwiththe R-CNN, inthefast R-CNNtheinputofthe CNNforfeatureextrac- tionistheentireimage, ratherthanindividualregionproposals.
Moreover, this CNNis trainable.
Givenaninputimage, lettheshapeofthe CNNoutputbe1 ğ‘ â„ ğ‘¤ .
1 1 644 Computer Vision 2.
Supposethatselectivesearchgeneratesğ‘›regionproposals.
Theseregionproposals(of differentshapes)markregionsofinterest(ofdifferentshapes)onthe CNNoutput.
Then these regions of interest further extract features of the same shape (say height â„ and 2 widthğ‘¤ arespecified)inordertobeeasilyconcatenated.
Toachievethis, thefast R- 2 CNNintroducestheregionofinterest(Ro I)poolinglayer: the CNNoutputandregion proposalsareinputintothislayer, outputtingconcatenatedfeaturesofshapeğ‘› ğ‘ â„ 2 ğ‘¤ thatarefurtherextractedforalltheregionproposals.
2 3.
Using a fully connected layer, transform the concatenated features into an output of shapeğ‘› ğ‘‘, whereğ‘‘ dependsonthemodeldesign.
4.
Predicttheclassandboundingboxforeachoftheğ‘›regionproposals.
Moreconcretely, in class and bounding box prediction, transform the fully connected layer output into an output of shape ğ‘› ğ‘ (ğ‘ is the number of classes) and an output of shape ğ‘› 4, respectively.
Theclasspredictionusessoftmaxregression.
Theregionofinterestpoolinglayerproposedinthefast R-CNNisdifferentfromthepooling layerintroducedin Section7.5.
Inthepoolinglayer, weindirectlycontroltheoutputshape byspecifyingsizesofthepoolingwindow, padding, andstride.
Incontrast, wecandirectly specifytheoutputshapeintheregionofinterestpoolinglayer.
For example, letâ€™s specify the output height and width for each region as â„ and ğ‘¤ , re- 2 2 spectively.
For any region of interest window of shape â„ ğ‘¤, this window is divided intoa â„ ğ‘¤ gridofsubwindows, wheretheshapeofeachsubwindowisapproximately 2 2 â€â„ â„ â€ â€ğ‘¤ ğ‘¤ â€.
Inpractice, theheightandwidthofanysubwindowshallberoundedup, 2 2 andthelargestelementshallbeusedasoutputofthesubwindow.
Therefore, theregionof interestpoolinglayercanextractfeaturesofthesameshapeevenwhenregionsofinterest havedifferentshapes.
Asanillustrativeexample, in.8.3, theupper-left3 3regionofinterestisselected ona4 4input.
Forthisregionofinterest, weusea2 2regionofinterestpoolinglayerto obtaina2 2output.
Notethateachofthefourdividedsubwindowscontainselements0, 1,4, and5(5isthemaximum);2and6(6isthemaximum);8and9(9isthemaximum); and10.
t .8.3 A2 2regionofinterestpoolinglayer.
Below we demonstrate the computation of the region of interest pooling layer.
Suppose thatthe height andwidth of the CNN-extractedfeatures X areboth 4, andthere is onlya singlechannel.
import torch import torchvision (continuesonnextpage) 645 Region-based CNNs(R-CNNs) (continuedfrompreviouspage) X = torch.
arange(16.).
reshape(1, 1, 4, 4) X tensor([[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]]]) Letâ€™sfurthersupposethattheheightandwidthoftheinputimageareboth40pixelsand thatselectivesearchgeneratestworegionproposalsonthisimage.
Eachregionproposalis expressedasfiveelements: itsobjectclassfollowedbythe â€ğ‘¥,ğ‘¦â€-coordinatesofitsupper- leftandlower-rightcorners.
rois = torch.
Tensor([[0, 0, 0, 20, 20], [0, 0, 10, 30, 30]]) Because the height and width of X are 1 10 of the height and width of the input image, thecoordinatesofthetworegionproposalsaremultipliedby0.1accordingtothespecified spatial_scaleargument.
Thenthetworegionsofinterestaremarkedon Xas X[:, :, 0:3, 0:3]and X[:, :, 1:4, 0:4], respectively.
Finallyinthe2 2regionofinterest pooling, each region of interest is divided into a grid of sub-windows to further extract featuresofthesameshape2 2.
torchvision.
ops.
roi_pool(X, rois, output_size=(2, 2), spatial_scale=0.1) tensor([[[[ 5., 6.], [ 9., 10.]]], [[[ 9., 11.], [13., 15.]]]]) 14.8.3 Faster R-CNN To be more accurate in object detection, the fast R-CNN model usually has to generate a lot of region proposals in selective search.
To reduce region proposals without loss of accuracy, the faster R-CNN proposes to replace selective search with a region proposal network(Renetal.,2015).
.8.4showsthefaster R-CNNmodel.
Comparedwiththefast R-CNN, thefaster R- CNNonlychangestheregionproposalmethodfromselectivesearchtoaregionproposal network.
Therestofthemodelremainunchanged.
Theregionproposalnetworkworksin thefollowingsteps: 1.
Use a 3 3 convolutional layer with padding of 1 to transform the CNN output to a 646 Computer Vision t .8.4 Thefaster R-CNNmodel.
newoutputwithğ‘ channels.
Inthisway, eachunitalongthespatialdimensionsofthe CNN-extractedfeaturemapsgetsanewfeaturevectoroflengthğ‘.
2.
Centeredoneachpixelofthefeaturemaps, generatemultipleanchorboxesofdifferent scalesandaspectratiosandlabelthem.
3.
Using the length-ğ‘ feature vector at the center of each anchor box, predict the binary class(backgroundorobjects)andboundingboxforthisanchorbox.
4.
Considerthosepredictedboundingboxeswhosepredictedclassesareobjects.
Remove overlappedresultsusingnon-maximumsuppression.
Theremainingpredictedbounding boxesforobjectsaretheregionproposalsrequiredbytheregionofinterestpoolinglayer.
It is worth noting that, as part of the faster R-CNN model, the region proposal network isjointlytrainedwiththerestofthemodel.
Inotherwords, theobjectivefunctionofthe faster R-CNNincludesnotonlytheclassandboundingboxpredictioninobjectdetection, butalsothebinaryclassandboundingboxpredictionofanchorboxesintheregionproposal network.
Asaresultoftheend-to-endtraining, theregionproposalnetworklearnshowto generate high-quality region proposals, so as to stay accurate in object detection with a reducednumberofregionproposalsthatarelearnedfromdata.
14.8.4 Mask R-CNN In the training dataset, if pixel-level positions of object are also labeled on images, the mask R-CNN caneffectivelyleveragesuchdetailedlabelstofurtherimprovetheaccuracy ofobjectdetection(Heetal.,2017).
Asshownin.8.5, themask R-CNNismodifiedbasedonthefaster R-CNN.
Specif- ically, the mask R-CNN replaces the region of interest pooling layer with the region of interest(Ro I)alignment layer.
Thisregionofinterestalignmentlayerusesbilinearinter- polationtopreservethespatialinformationonthefeaturemaps, whichismoresuitablefor pixel-levelprediction.
Theoutputofthislayercontainsfeaturemapsofthesameshapefor all the regions of interest.
They are used to predict not only the class and bounding box foreachregionofinterest, butalsothepixel-levelpositionoftheobjectthroughanaddi- tionalfullyconvolutionalnetwork.
Moredetailsonusingafullyconvolutionalnetworkto 647 Region-based CNNs(R-CNNs) t .8.5 Themask R-CNNmodel.
predict pixel-level semantics of an image will be provided in subsequent sections of this chapter.
14.8.5 Summary The R-CNNextractsmanyregionproposalsfromtheinputimage, usesa CNNtoperform forward propagation on each region proposal to extract its features, then uses these featurestopredicttheclassandboundingboxofthisregionproposal.
Oneofthemajorimprovementsofthefast R-CNNfromthe R-CNNisthatthe CNNfor- wardpropagationisonlyperformedontheentireimage.
Italsointroducestheregion of interest pooling layer, so that features of the same shape can be further extracted forregionsofinterestthathavedifferentshapes.
The faster R-CNN replaces the selective search used in the fast R-CNN with a jointly trainedregionproposalnetwork, sothattheformercanstayaccurateinobjectdetec- tionwithareducednumberofregionproposals.
Based on the faster R-CNN, the mask R-CNN additionally introduces a fully convolu- tionalnetwork, soastoleveragepixel-levellabelstofurtherimprovetheaccuracyof objectdetection.
14.8.6 Exercises 1.
Canweframeobjectdetectionasasingleregressionproblem, suchaspredictingbound- ing boxes and class probabilities? You may refer to the design of the YOLO model (Redmonetal.,2016).
219 2.
Compare single shot multibox detection with the methods introduced in this section.
Whataretheirmajordifferences? Youmayreferto Figure2of Zhaoetal.
(2019).
Discussions219.
648 Computer Vision 14.9 Semantic Segmentation and the Dataset Whendiscussingobjectdetectiontasksin Section14.3â€“Section14.8, rectangularbound- ing boxes are used to label and predict objects in images.
This section will discuss the problemofsemanticsegmentation, whichfocusesonhowtodivideanimageintoregions belonging to different semantic classes.
Different from object detection, semantic seg- mentation recognizes and understands what are in images in pixel level: its labeling and predictionofsemanticregionsareinpixellevel.
.9.1showsthelabelsofthedog, cat, andbackgroundoftheimageinsemanticsegmentation.
Comparedwithinobjectde- tection, thepixel-levelborderslabeledinsemanticsegmentationareobviouslymorefine- grained.
t .9.1 Labelsofthedog, cat, andbackgroundoftheimageinsemanticsegmentation.
14.9.1 Image Segmentationand Instance Segmentation Therearealsotwoimportanttasksinthefieldofcomputervisionthataresimilartoseman- ticsegmentation, namelyimagesegmentationandinstancesegmentation.
Wewillbriefly distinguishthemfromsemanticsegmentationasfollows.
Imagesegmentationdividesanimageintoseveralconstituentregions.
Themethodsfor thistypeofproblemusuallymakeuseofthecorrelationbetweenpixelsintheimage.
It does not need label information about image pixels during training, and it cannot guaranteethatthesegmentedregionswillhavethesemanticsthatwehopetoobtain duringprediction.
Takingtheimagein.9.1asinput, imagesegmentationmay divide the dog into two regions: one covers the mouth and eyes which are mainly black, andtheothercoverstherestofthebodywhichismainlyyellow.
Instancesegmentationisalsocalledsimultaneousdetectionandsegmentation.
Itstudies howtorecognizethepixel-levelregionsofeachobjectinstanceinanimage.
Differ- entfromsemanticsegmentation, instancesegmentationneedstodistinguishnotonly semantics, but also different object instances.
For example, if there are two dogs in theimage, instancesegmentationneedstodistinguishwhichofthetwodogsapixel belongsto.
220 14.9.2 The Pascal VOC2012Semantic Segmentation Dataset On of the most important semantic segmentation dataset is Pascal VOC2012220.
In the 649 Semantic Segmentationandthe Dataset following, wewilltakealookatthisdataset.
%matplotlib inline import os import torch import torchvision from d2l import torch as d2l Thetarfileofthedatasetisabout2GB, soitmaytakeawhiletodownloadthefile.
The extracteddatasetislocatedat../data/VOCdevkit/VOC2012.
#@save d2l.
DATA_HUB['voc2012'] = (d2l.
DATA_URL + 'VOCtrainval_11-May-2012.
tar', '4e443f8a2eca6b1dac8a6c57641b67dd40621a49') voc_dir = d2l.
download_extract('voc2012', 'VOCdevkit/VOC2012') Downloading ../data/VOCtrainval_11-May-2012.
tar from http://d2l-data.
s3- After entering the path ../data/VOCdevkit/VOC2012, we can see the different compo- nents of the dataset.
The Image Sets/Segmentation path contains text files that specify trainingandtestsamples, whilethe JPEGImagesand Segmentation Classpathsstorethe input image and label for each example, respectively.
The label here is also in the im- age format, with the same size as its labeled input image.
Besides, pixels with the same color in any label image belong to the same semantic class.
The following defines the read_voc_imagesfunctiontoreadalltheinputimagesandlabelsintothememory.
#@save def read_voc_images(voc_dir, is_train=True): """Read all VOC feature and label images.""" txt_fname = os.
path.
join(voc_dir, 'Image Sets', 'Segmentation', 'train.
txt' if is_train else 'val.
txt') mode = torchvision.
io.
image.
Image Read Mode.
RGB with open(txt_fname, 'r') as f: images = f.
read().
split() features, labels = [], [] for i, fname in enumerate(images): voc_dir, 'JPEGImages', f'{fname}.
jpg'))) voc_dir, 'Segmentation Class' , f'{fname}.
png'), mode)) return features, labels train_features, train_labels = read_voc_images(voc_dir, True) Wedrawthefirstfiveinputimagesandtheirlabels.
Inthelabelimages, whiteandblackrep- resentbordersandbackground, respectively, whiletheothercolorscorrespondtodifferent classes.
650 Computer Vision n = 5 imgs = train_features[: n] + train_labels[: n] imgs = [img.
permute(1,2,0) for img in imgs] d2l.
show_images(imgs, 2, n); Next, weenumeratethe RGBcolorvaluesandclassnamesforallthelabelsinthisdataset.
#@save VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]] #@save VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor'] With the two constants defined above, we can conveniently find the class index for each pixelinalabel.
Wedefinethevoc_colormap2labelfunctiontobuildthemappingfrom theabove RGBcolorvaluestoclassindices, andthevoc_label_indicesfunctiontomap any RGBvaluestotheirclassindicesinthis Pascal VOC2012dataset.
#@save def voc_colormap2label(): """Build the mapping from RGB to class indices for VOC labels.""" colormap2label = torch.
zeros(256 ** 3, dtype=torch.
long) for i, colormap in enumerate(VOC_COLORMAP): colormap2label[ (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i return colormap2label #@save def voc_label_indices(colormap, colormap2label): """Map any RGB values in VOC labels to their class indices.""" colormap = colormap.
permute(1, 2, 0).
numpy().
astype('int32') (continuesonnextpage) 651 Semantic Segmentationandthe Dataset (continuedfrompreviouspage) idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256 + colormap[:, :, 2]) return colormap2label[idx] Forexample, inthefirstexampleimage, theclassindexforthefrontpartoftheairplaneis 1, whilethebackgroundindexis0.
y = voc_label_indices(train_labels[0], voc_colormap2label()) y[105:115, 130:140], VOC_CLASSES[1] (tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'aeroplane') Data Preprocessing Inpreviousexperimentssuchasin Section8.1â€“Section8.4, imagesarerescaledtofitthe modelâ€™srequiredinputshape.
However, insemanticsegmentation, doingsorequiresrescal- ingthepredictedpixelclassesbacktotheoriginalshapeoftheinputimage.
Suchrescaling maybeinaccurate, especiallyforsegmentedregionswithdifferentclasses.
Toavoidthis issue, wecroptheimagetoafixed shapeinsteadofrescaling.
Specifically, usingrandom croppingfromimageaugmentation, wecropthesameareaoftheinputimageandthela- bel.
#@save def voc_rand_crop(feature, label, height, width): """Randomly crop both feature and label images.""" rect = torchvision.
transforms.
Random Crop.
get_params( feature, (height, width)) feature = torchvision.
transforms.
functional.
crop(feature, *rect) label = torchvision.
transforms.
functional.
crop(label, *rect) return feature, label imgs = [] for _ in range(n): imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300) imgs = [img.
permute(1, 2, 0) for img in imgs] d2l.
show_images(imgs[::2] + imgs[1::2], 2, n); 652 Computer Vision Custom Semantic Segmentation Dataset Class Wedefineacustomsemanticsegmentationdatasetclass VOCSeg Datasetbyinheritingthe Datasetclassprovidedbyhigh-level APIs.
Byimplementingthe__getitem__function, wecanarbitrarilyaccesstheinputimageindexedasidxinthedatasetandtheclassindex of each pixel in this image.
Since some images in the dataset have a smaller size than the output size of random cropping, these examples are filtered out by a custom filter function.
In addition, we also define the normalize_image function to standardize the valuesofthethree RGBchannelsofinputimages.
#@save class VOCSeg Dataset(torch.
utils.
data.
Dataset): """A customized dataset to load the VOC dataset.""" def __init__(self, is_train, crop_size, voc_dir): self.
transform = torchvision.
transforms.
Normalize( self.
crop_size = crop_size features, labels = read_voc_images(voc_dir, is_train=is_train) self.
features = [self.
normalize_image(feature) for feature in self.
filter(features)] self.
labels = self.
filter(labels) self.
colormap2label = voc_colormap2label() print('read ' + str(len(self.
features)) + ' examples') def normalize_image(self, img): return self.
transform(img.
float() / 255) def filter(self, imgs): return [img for img in imgs if ( img.
shape[1] >= self.
crop_size[0] and img.
shape[2] >= self.
crop_size[1])] def __getitem__(self, idx): feature, label = voc_rand_crop(self.
features[idx], self.
labels[idx], *self.
crop_size) return (feature, voc_label_indices(label, self.
colormap2label)) def __len__(self): return len(self.
features) 653 Semantic Segmentationandthe Dataset Readingthe Dataset Weusethecustom VOCSeg Datasetclasstocreateinstancesofthetrainingsetandtestset, respectively.
Supposethatwespecifythattheoutputshapeofrandomlycroppedimagesis 320 480.
Belowwecanviewthenumberofexamplesthatareretainedinthetrainingset andtestset.
crop_size = (320, 480) voc_train = VOCSeg Dataset(True, crop_size, voc_dir) voc_test = VOCSeg Dataset(False, crop_size, voc_dir) read 1114 examples read 1078 examples Setting the batch size to 64, we define the data iterator for the training set.
Letâ€™s print theshapeofthefirstminibatch.
Differentfrominimageclassificationorobjectdetection, labelsherearethree-dimensionaltensors.
batch_size = 64 train_iter = torch.
utils.
data.
Data Loader(voc_train, batch_size, shuffle=True, drop_last=True, num_workers=d2l.
get_dataloader_workers()) for X, Y in train_iter: print(X.
shape) print(Y.
shape) break torch.
Size([64, 3, 320, 480]) torch.
Size([64, 320, 480]) Putting It All Together Finally, wedefinethefollowingload_data_vocfunctiontodownloadandreadthe Pascal VOC2012semanticsegmentationdataset.
Itreturnsdataiteratorsforboththetrainingand testdatasets.
#@save def load_data_voc(batch_size, crop_size): """Load the VOC semantic segmentation dataset.""" voc_dir = d2l.
download_extract('voc2012', os.
path.
join( 'VOCdevkit', 'VOC2012')) num_workers = d2l.
get_dataloader_workers() train_iter = torch.
utils.
data.
Data Loader( VOCSeg Dataset(True, crop_size, voc_dir), batch_size, shuffle=True, drop_last=True, num_workers=num_workers) test_iter = torch.
utils.
data.
Data Loader( VOCSeg Dataset(False, crop_size, voc_dir), batch_size, drop_last=True, num_workers=num_workers) return train_iter, test_iter 654 Computer Vision 14.9.3 Summary Semanticsegmentationrecognizesandunderstandswhatareinanimageinpixellevel bydividingtheimageintoregionsbelongingtodifferentsemanticclasses.
Oneofthemostimportantsemanticsegmentationdatasetis Pascal VOC2012.
Insemanticsegmentation, sincetheinputimageandlabelcorrespondone-to-oneonthe pixel, theinputimageisrandomlycroppedtoafixedshaperatherthanrescaled.
14.9.4 Exercises 1.
Howcansemanticsegmentationbeappliedinautonomousvehiclesandmedicalimage diagnostics? Canyouthinkofotherapplications? 2.
Recallthedescriptionsofdataaugmentationin Section14.1.
Whichoftheimageaug- mentation methods used in image classification would be infeasible to be applied in semanticsegmentation? 221 Discussions221.
14.10 Transposed Convolution The CNNlayerswehaveseensofar, suchasconvolutionallayers(Section7.2)andpool- inglayers(Section7.5), typicallyreduce(downsample)thespatialdimensions(heightand width) of the input, or keep them unchanged.
In semantic segmentation that classifies at pixel-level, it will be convenientif the spatial dimensions of the input and output are the same.
Forexample, thechanneldimensionatoneoutputpixelcanholdtheclassification resultsfortheinputpixelatthesamespatialposition.
To achieve this, especially after the spatial dimensions are reduced by CNN layers, we canuseanothertypeof CNNlayersthatcanincrease(upsample)thespatialdimensionsof intermediatefeaturemaps.
Inthissection, wewillintroducetransposedconvolution, which is also called fractionally-strided convolution (Dumoulin and Visin, 2016), for reversing downsamplingoperationsbytheconvolution.
import torch from torch import nn from d2l import torch as d2l 14.10.1 Basic Operation Ignoringchannelsfornow, letâ€™sbeginwiththebasictransposedconvolutionoperationwith strideof1andnopadding.
Supposethatwearegivenağ‘› â„ ğ‘› ğ‘¤ inputtensorandağ‘˜ â„ ğ‘˜ ğ‘¤ kernel.
Slidingthekernelwindowwithstrideof1forğ‘› ğ‘¤ timesineachrowandğ‘› â„ times 655 Transposed Convolution in each column yields a total of ğ‘› â„ ğ‘› ğ‘¤ intermediate results.
Each intermediate result is a â€ğ‘› â„ â€š ğ‘˜ â„ 1â€ â€ğ‘› ğ‘¤ â€š ğ‘˜ ğ‘¤ 1â€ tensor that are initialized as zeros.
To compute each intermediate tensor, each element in the input tensor is multiplied by the kernel so that theresulting ğ‘˜ â„ ğ‘˜ ğ‘¤ tensorreplacesaportionineachintermediatetensor.
Notethatthe positionofthereplacedportionineachintermediatetensorcorrespondstothepositionof theelementintheinputtensorusedforthecomputation.
Intheend, alltheintermediate resultsaresummedovertoproducetheoutput.
Asanexample,.10.1illustrateshowtransposedconvolutionwitha2 2kernelis computedfora2 2inputtensor.
t .10.1 Transposedconvolutionwitha2 2kernel.
Theshadedportionsareaportionofan intermediatetensoraswellastheinputandkerneltensorelementsusedforthe computation.
We can implement this basic transposed convolution operation trans_conv for a input matrix Xandakernelmatrix K.
def trans_conv(X, K): h, w = K.
shape Y = torch.
zeros((X.
shape[0] + h - 1, X.
shape[1] + w - 1)) for i in range(X.
shape[0]): for j in range(X.
shape[1]): Y[i: i + h, j: j + w] += X[i, j] * K return Y Incontrasttotheregularconvolution(in Section7.2)thatreducesinputelementsviathe kernel, thetransposedconvolutionbroadcastsinputelementsviathekernel, therebypro- ducinganoutputthatislargerthantheinput.
Wecanconstructtheinputtensor Xandthe kerneltensor Kfrom.10.1tovalidatetheoutputoftheaboveimplementationofthe basictwo-dimensionaltransposedconvolutionoperation.
trans_conv(X, K) tensor([[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]) 656 Computer Vision Alternatively, whentheinput Xandkernel Karebothfour-dimensionaltensors, wecanuse high-level APIstoobtainthesameresults.
X, K = X.
reshape(1, 1, 2, 2), K.
reshape(1, 1, 2, 2) tconv = nn.
Conv Transpose2d(1, 1, kernel_size=2, bias=False) tconv.
weight.
data = K tconv(X) tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=<Convolution Backward0>) 14.10.2 Padding, Strides, and Multiple Channels Differentfromintheregularconvolutionwherepaddingisappliedtoinput, itisappliedto outputinthetransposedconvolution.
Forexample, whenspecifyingthepaddingnumber on either side of the height and width as 1, the first and last rows and columns will be removedfromthetransposedconvolutionoutput.
tconv = nn.
Conv Transpose2d(1, 1, kernel_size=2, padding=1, bias=False) tconv.
weight.
data = K tconv(X) tensor([[[[4.]]]], grad_fn=<Convolution Backward0>) Inthetransposedconvolution, stridesarespecifiedforintermediateresults(thusoutput), not for input.
Using the same input and kernel tensors from .10.1, changing the stridefrom1to2increasesboththeheightandweightofintermediatetensors, hencethe outputtensorin.10.2.
Thefollowingcodesnippetcanvalidatethetransposedconvolutionoutputforstrideof2 in.10.2.
tconv = nn.
Conv Transpose2d(1, 1, kernel_size=2, stride=2, bias=False) tconv.
weight.
data = K tconv(X) tensor([[[[0., 0., 0., 1.], [0., 0., 2., 3.], [0., 2., 0., 3.], [4., 6., 6., 9.]]]], grad_fn=<Convolution Backward0>) Formultipleinputandoutputchannels, thetransposedconvolutionworksinthesameway astheregularconvolution.
Supposethattheinputhasğ‘ ğ‘– channels, andthatthetransposed convolutionassignsa ğ‘˜ â„ ğ‘˜ ğ‘¤ kerneltensortoeachinputchannel.
Whenmultipleoutput channelsarespecified, wewillhaveağ‘ ğ‘– ğ‘˜ â„ ğ‘˜ ğ‘¤ kernelforeachoutputchannel.
657 Transposed Convolution t .10.2 Transposedconvolutionwitha2 2kernelwithstrideof2.
Theshadedportionsarea portionofanintermediatetensoraswellastheinputandkerneltensorelementsusedfor thecomputation.
Asinall, ifwefeed Xintoaconvolutionallayer ğ‘“ tooutput Y = ğ‘“â€Xâ€ andcreateatrans- posedconvolutionallayerğ‘”withthesamehyperparametersas ğ‘“ exceptforthenumberof outputchannelsbeingthenumberofchannelsin X, thenğ‘”â€ğ‘Œâ€willhavethesameshapeas X.
Thiscanbeillustratedinthefollowingexample.
X = torch.
rand(size=(1, 10, 16, 16)) conv = nn.
Conv2d(10, 20, kernel_size=5, padding=2, stride=3) tconv = nn.
Conv Transpose2d(20, 10, kernel_size=5, padding=2, stride=3) tconv(conv(X)).
shape == X.
shape True 14.10.3 Connectionto Matrix Transposition Thetransposedconvolutionisnamedafterthematrixtransposition.
Toexplain, letâ€™sfirst seehowtoimplementconvolutionsusingmatrixmultiplications.
Intheexamplebelow, we definea3 3input Xanda2 2convolutionkernel K, andthenusethecorr2dfunction tocomputetheconvolutionoutput Y.
X = torch.
arange(9.0).
reshape(3, 3) Y = d2l.
corr2d(X, K) Y tensor([[27., 37.], [57., 67.]]) Next, werewritetheconvolutionkernel Kasasparseweightmatrix Wcontainingalotof 658 Computer Vision zeros.
Theshapeoftheweightmatrixis(4, 9), wherethenon-zeroelementscomefrom theconvolutionkernel K.
def kernel2matrix(K): k, W = torch.
zeros(5), torch.
zeros((4, 9)) k[:2], k[3:5] = K[0, :], K[1, :] W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k return W W = kernel2matrix(K) W Concatenatetheinput Xrowbyrowtogetavectoroflength9.
Thenthematrixmultiplica- tionof Wandthevectorized Xgivesavectoroflength4.
Afterreshapingit, wecanobtain thesameresult Yfromtheoriginalconvolutionoperationabove: wejustimplementedcon- volutionsusingmatrixmultiplications.
Y == torch.
matmul(W, X.
reshape(-1)).
reshape(2, 2) tensor([[True, True], [True, True]]) Likewise, wecanimplementtransposedconvolutionsusingmatrixmultiplications.
Inthe followingexample, wetakethe2 2output Yfromtheaboveregularconvolutionasinput to the transposed convolution.
To implement this operation by multiplying matrices, we onlyneedtotransposetheweightmatrix Wwiththenewshapeâ€9,4â€.
Z = trans_conv(Y, K) Z == torch.
matmul(W.
T, Y.
reshape(-1)).
reshape(3, 3) tensor([[True, True, True], [True, True, True], [True, True, True]]) Consider implementing the convolution by multiplying matrices.
Given an input vector x and a weight matrix W, the forward propagation function of the convolution can be implementedbymultiplyingitsinputwiththeweightmatrixandoutputtingavectory = Wx.
Sincebackpropagationfollowsthechainruleandr y = W> , thebackpropagation x functionoftheconvolutioncanbeimplementedbymultiplyingitsinputwiththetransposed weight matrix W> .
Therefore, the transposed convolutional layer can just exchange the forwardpropagationfunctionandthebackpropagationfunctionoftheconvolutionallayer: 659 Fully Convolutional Networks itsforwardpropagationandbackpropagationfunctionsmultiplytheirinputvectorwith W> and W, respectively.
14.10.4 Summary In contrast to the regular convolution that reduces input elements via the kernel, the transposed convolution broadcasts input elements via the kernel, thereby producing anoutputthatislargerthantheinput.
If we feed X into a convolutional layer ğ‘“ to output Y = ğ‘“â€Xâ€ and create a transposed convolutional layer ğ‘” with the same hyperparameters as ğ‘“ except for the number of outputchannelsbeingthenumberofchannelsin X, thenğ‘”â€ğ‘Œâ€willhavethesameshape as X.
Wecanimplementconvolutionsusingmatrixmultiplications.
Thetransposedconvolu- tionallayercanjustexchangetheforwardpropagationfunctionandthebackpropaga- tionfunctionoftheconvolutionallayer.
14.10.5 Exercises 1.
In Section14.10.3, theconvolutioninput Xandthetransposedconvolutionoutput Zhave thesameshape.
Dotheyhavethesamevalue? Why? 2.
Isitefficienttousematrixmultiplicationstoimplementconvolutions? Why? 222 Discussions222.
14.11 Fully Convolutional Networks As discussed in Section 14.9, semantic segmentation classifies images in pixel level.
A fullyconvolutionalnetwork(FCN)usesaconvolutionalneuralnetworktotransformimage pixels to pixel classes (Long et al., 2015).
Unlike the CNNs that we encountered earlier for image classification or object detection, a fully convolutional network transforms the height and width of intermediate feature maps back to those of the input image: this is achievedbythetransposedconvolutionallayerintroducedin Section14.10.
Asaresult, the classificationoutputandtheinputimagehaveaone-to-onecorrespondenceinpixellevel: thechanneldimensionatanyoutputpixelholdstheclassificationresultsfortheinputpixel atthesamespatialposition.
%matplotlib inline import torch import torchvision from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 660 Computer Vision 14.11.1 The Model Here we describe the basic design of the fully convolutional network model.
As shown in.11.1, thismodelfirstusesa CNNtoextractimagefeatures, thentransformsthe numberofchannelsintothenumberofclassesviaa1 1convolutionallayer, andfinally transforms the height and width of the feature maps to those of the input image via the transposedconvolutionintroducedin Section14.10.
Asaresult, themodeloutputhasthe sameheightandwidthastheinputimage, wheretheoutputchannelcontainsthepredicted classesfortheinputpixelatthesamespatialposition.
t .11.1 Fullyconvolutionalnetwork.
Below, we use a Res Net-18 model pretrained on the Image Net dataset to extract image features and denote the model instance as pretrained_net.
The last few layers of this model include a global average pooling layer and a fully connected layer: they are not neededinthefullyconvolutionalnetwork.
pretrained_net = torchvision.
models.
resnet18(pretrained=True) list(pretrained_net.
children())[-3:] Downloading: "https://download.
pytorch.
org/models/resnet18-f37072fd.
pth" to / â†©! home/ci/.
cache/torch/hub/checkpoints/resnet18-f37072fd.
pth 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 44.7M/44.7M [00:00<00:00, 56.3MB/s] [Sequential( (0): Basic Block( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1,â£ â†©!1), bias=False) (bn1): Batch Norm2d(512, eps=1e-05, momentum=0.1, affine=True, track_ â†©! running_stats=True) (relu): Re LU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,â£ â†©!1), bias=False) (bn2): Batch Norm2d(512, eps=1e-05, momentum=0.1, affine=True, track_ (continuesonnextpage) 661 Fully Convolutional Networks (continuedfrompreviouspage) â†©! running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): Batch Norm2d(512, eps=1e-05, momentum=0.1, affine=True, track_ â†©! running_stats=True) ) ) (1): Basic Block( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,â£ â†©!1), bias=False) (bn1): Batch Norm2d(512, eps=1e-05, momentum=0.1, affine=True, track_ â†©! running_stats=True) (relu): Re LU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,â£ â†©!1), bias=False) (bn2): Batch Norm2d(512, eps=1e-05, momentum=0.1, affine=True, track_ â†©! running_stats=True) ) ), Adaptive Avg Pool2d(output_size=(1, 1)), Linear(in_features=512, out_features=1000, bias=True)] Next, wecreatethefullyconvolutionalnetworkinstancenet.
Itcopiesallthepretrained layersinthe Res Net-18exceptforthefinalglobalaveragepoolinglayerandthefullycon- nectedlayerthatareclosesttotheoutput.
net = nn.
Sequential(*list(pretrained_net.
children())[:-2]) Givenaninputwithheightandwidthof320and480respectively, theforwardpropagation ofnetreducestheinputheightandwidthto1/32oftheoriginal, namely10and15.
X = torch.
rand(size=(1, 3, 320, 480)) net(X).
shape torch.
Size([1, 512, 10, 15]) Next, weusea1 1convolutionallayertotransformthenumberofoutputchannelsinto thenumberofclasses(21)ofthe Pascal VOC2012dataset.
Finally, weneedtoincreasethe height and width of the feature maps by 32 times to change them back to the height and widthoftheinputimage.
Recallhowtocalculatetheoutputshapeofaconvolutionallayer in Section7.3.
Sinceâ€320 64â€š16 2â€š32â€ 32=10andâ€480 64â€š16 2â€š32â€ 32=15, weconstructatransposedconvolutionallayerwithstrideof32, settingtheheightandwidth ofthekernelto64, thepaddingto16.
Ingeneral, wecanseethatforstrideğ‘ , paddingğ‘  2 (assuming ğ‘  2 is an integer), and the height and width of the kernel 2ğ‘ , the transposed convolutionwillincreasetheheightandwidthoftheinputbyğ‘ times.
662 Computer Vision num_classes = 21 net.
add_module('final_conv', nn.
Conv2d(512, num_classes, kernel_size=1)) net.
add_module('transpose_conv', nn.
Conv Transpose2d(num_classes, num_classes, kernel_size=64, padding=16, stride=32)) 14.11.2 Initializing Transposed Convolutional Layers Wealreadyknowthattransposedconvolutionallayerscanincreasetheheightandwidthof feature maps.
In image processing, we may need to scale up an image, i.
e., upsampling.
Bilinearinterpolationisoneofthecommonlyusedupsamplingtechniques.
Itisalsooften usedforinitializingtransposedconvolutionallayers.
Toexplainbilinearinterpolation, saythatgivenaninputimagewewanttocalculateeach pixel of the upsampled output image.
In order to calculate the pixel of the output image atcoordinateâ€ğ‘¥,ğ‘¦â€, firstmapâ€ğ‘¥,ğ‘¦â€tocoordinateâ€ğ‘¥0,ğ‘¦0â€ontheinputimage, forexample, accordingtotheratiooftheinputsizetotheoutputsize.
Notethatthemappedğ‘¥0 andğ‘¦0 are realnumbers.
Then, findthefourpixelsclosesttocoordinate â€ğ‘¥0,ğ‘¦0â€ ontheinputimage.
Finally, thepixeloftheoutputimageatcoordinate â€ğ‘¥,ğ‘¦â€ iscalculatedbasedonthesefour closestpixelsontheinputimageandtheirrelativedistancefromâ€ğ‘¥0,ğ‘¦0â€.
Upsamplingofbilinearinterpolationcanbeimplementedbythetransposedconvolutional layer with the kernel constructed by the following bilinear_kernel function.
Due to spacelimitations, weonlyprovidetheimplementationofthebilinear_kernelfunction belowwithoutdiscussionsonitsalgorithmdesign.
def bilinear_kernel(in_channels, out_channels, kernel_size): factor = (kernel_size + 1) // 2 if kernel_size % 2 == 1: center = factor - 1 else: center = factor - 0.5 og = (torch.
arange(kernel_size).
reshape(-1, 1), torch.
arange(kernel_size).
reshape(1, -1)) filt = (1 - torch.
abs(og[0] - center) / factor) * \ (1 - torch.
abs(og[1] - center) / factor) weight = torch.
zeros((in_channels, out_channels, kernel_size, kernel_size)) weight[range(in_channels), range(out_channels), :, :] = filt return weight Letâ€™sexperimentwithupsamplingofbilinearinterpolationthatisimplementedbyatrans- posedconvolutionallayer.
Weconstructatransposedconvolutionallayerthatdoublesthe heightandweight, andinitializeitskernelwiththebilinear_kernelfunction.
conv_trans = nn.
Conv Transpose2d(3, 3, kernel_size=4, padding=1, stride=2, bias=False) conv_trans.
weight.
data.
copy_(bilinear_kernel(3, 3, 4)); 663 Fully Convolutional Networks Read the image X and assign the upsampling output to Y.
In order to print the image, we needtoadjustthepositionofthechanneldimension.
X = img.
unsqueeze(0) Y = conv_trans(X) out_img = Y[0].
permute(1, 2, 0).
detach() Aswecansee, thetransposedconvolutionallayerincreasesboththeheightandwidthof the image by a factor of two.
Except for the different scales in coordinates, the image scaledupbybilinearinterpolationandtheoriginalimageprintedin Section14.3lookthe same.
d2l.
set_figsize() print('input image shape:', img.
permute(1, 2, 0).
shape) d2l.
plt.
imshow(img.
permute(1, 2, 0)); print('output image shape:', out_img.
shape) d2l.
plt.
imshow(out_img); input image shape: torch.
Size([561, 728, 3]) output image shape: torch.
Size([1122, 1456, 3]) Inafullyconvolutionalnetwork, weinitializethetransposedconvolutionallayerwithup- samplingofbilinearinterpolation.
Forthe1 1convolutionallayer, weuse Xavierinitial- ization.
W = bilinear_kernel(num_classes, num_classes, 64) net.
transpose_conv.
weight.
data.
copy_(W); 14.11.3 Readingthe Dataset Wereadthesemanticsegmentationdatasetasintroducedin Section14.9.
Theoutputimage shapeofrandomcroppingisspecifiedas320 480: boththeheightandwidtharedivisible by32.
batch_size, crop_size = 32, (320, 480) train_iter, test_iter = d2l.
load_data_voc(batch_size, crop_size) 664 Computer Vision read 1114 examples read 1078 examples 14.11.4 Training Nowwecantrainourconstructedfullyconvolutionalnetwork.
Thelossfunctionandac- curacy calculation here are not essentially different from those in image classification of earlierchapters.
Becauseweusetheoutputchannelofthetransposedconvolutionallayer topredicttheclassforeachpixel, thechanneldimensionisspecifiedinthelosscalculation.
Inaddition, theaccuracyiscalculatedbasedoncorrectnessofthepredictedclassforallthe pixels.
def loss(inputs, targets): return F.
cross_entropy(inputs, targets, reduction='none').
mean(1).
mean(1) num_epochs, lr, wd, devices = 5, 0.001, 1e-3, d2l.
try_all_gpus() trainer = torch.
optim.
SGD(net.
parameters(), lr=lr, weight_decay=wd) d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) loss 0.449, train acc 0.861, test acc 0.852 226.7 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] 14.11.5 Prediction Whenpredicting, weneedtostandardizetheinputimageineachchannelandtransformthe imageintothefour-dimensionalinputformatrequiredbythe CNN.
def predict(img): X = test_iter.
dataset.
normalize_image(img).
unsqueeze(0) pred = net(X.
to(devices[0])).
argmax(dim=1) return pred.
reshape(pred.
shape[1], pred.
shape[2]) Tovisualizethepredictedclassofeachpixel, wemapthepredictedclassbacktoitslabel colorinthedataset.
665 Fully Convolutional Networks def label2image(pred): colormap = torch.
tensor(d2l.
VOC_COLORMAP, device=devices[0]) X = pred.
long() return colormap[X, :] Imagesinthetestdatasetvaryinsizeandshape.
Sincethemodelusesatransposedcon- volutionallayerwithstrideof32, whentheheightorwidthofaninputimageisindivisible by32, theoutputheightorwidthofthe transposedconvolutionallayerwilldeviatefrom theshapeoftheinputimage.
Inordertoaddressthisissue, wecancropmultiplerectangu- larareaswithheightandwidththatareintegermultiplesof32intheimage, andperform forward propagation on the pixels in these areas separately.
Note that the union of these rectangularareasneedstocompletelycovertheinputimage.
Whenapixeliscoveredby multiple rectangular areas, the average of the transposed convolution outputs in separate areasforthissamepixelcanbeinputtothesoftmaxoperationtopredicttheclass.
Forsimplicity, weonlyreadafewlargertestimages, andcropa320 480areaforprediction startingfromtheupper-leftcornerofanimage.
Forthesetestimages, weprinttheircropped areas, predictionresults, andground-truthrowbyrow.
voc_dir = d2l.
download_extract('voc2012', 'VOCdevkit/VOC2012') test_images, test_labels = d2l.
read_voc_images(voc_dir, False) n, imgs = 4, [] for i in range(n): crop_rect = (0, 0, 320, 480) X = torchvision.
transforms.
functional.
crop(test_images[i], *crop_rect) pred = label2image(predict(X)) imgs += [X.
permute(1,2,0), pred.
cpu(), torchvision.
transforms.
functional.
crop( test_labels[i], *crop_rect).
permute(1,2,0)] d2l.
show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n, scale=2); 666 Computer Vision 14.11.6 Summary Thefullyconvolutionalnetworkfirstusesa CNNtoextractimagefeatures, thentrans- forms the number of channels into the number of classes via a 1 1 convolutional layer, andfinallytransformstheheightandwidthofthefeaturemapstothoseofthe inputimageviathetransposedconvolution.
In a fully convolutional network, we can use upsampling of bilinear interpolation to initializethetransposedconvolutionallayer.
14.11.7 Exercises 1.
Ifweuse Xavierinitializationforthetransposedconvolutionallayerintheexperiment, howdoestheresultchange? 2.
Canyoufurtherimprovetheaccuracyofthemodelbytuningthehyperparameters? 3.
Predicttheclassesofallpixelsintestimages.
4.
Theoriginalfullyconvolutionalnetworkpaperalsousesoutputsofsomeintermediate CNNlayers(Longetal.,2015).
Trytoimplementthisidea.
Discussions223.
223 14.12 Neural Style Transfer If you are a photography enthusiast, you may be familiar with the filter.
It can change thecolorstyleofphotossothatlandscapephotosbecomesharperorportraitphotoshave whitenedskins.
However, onefilterusuallyonlychangesoneaspectofthephoto.
Toapply anidealstyletoaphoto, youprobablyneedtotrymanydifferentfiltercombinations.
This processisascomplexastuningthehyperparametersofamodel.
Inthissection, wewillleveragelayerwiserepresentationsofa CNNtoautomaticallyapply thestyleofoneimagetoanotherimage, i.
e., styletransfer (Gatysetal.,2016).
Thistask needstwoinputimages: oneisthecontentimageandtheotheristhestyleimage.
Wewill useneuralnetworkstomodifythecontentimagetomakeitclosetothestyleimageinstyle.
Forexample, thecontentimagein.12.1isalandscapephototakenbyusin Mount Rainier National Parkinthesuburbsof Seattle, whilethestyleimageisanoilpaintingwith thetheme ofautumn oak trees.
Inthe output synthesizedimage, theoil brush strokesof thestyleimageareapplied, leadingtomorevividcolors, whilepreservingthemainshape oftheobjectsinthecontentimage.
14.12.1 Method .12.2 illustrates the CNN-based style transfer method with a simplified example.
First, weinitializethesynthesizedimage, forexample, intothecontentimage.
Thissyn- 667 Neural Style Transfer t .12.1 Givencontentandstyleimages, styletransferoutputsasynthesizedimage.
thesizedimageistheonlyvariablethatneedstobeupdatedduringthestyletransferprocess, i.
e., themodelparameterstobeupdatedduringtraining.
Thenwechooseapretrained CNN toextractimagefeaturesandfreezeitsmodelparametersduringtraining.
Thisdeep CNN usesmultiplelayerstoextracthierarchicalfeaturesforimages.
Wecanchoosetheoutput ofsomeoftheselayersascontentfeaturesorstylefeatures.
Take.12.2asanexam- ple.
Thepretrainedneuralnetworkherehas3convolutionallayers, wherethesecondlayer outputsthecontentfeatures, andthefirstandthirdlayersoutputthestylefeatures.
t .12.2 CNN-basedstyletransferprocess.
Solidlinesshowthedirectionofforwardpropagation anddottedlinesshowbackwardpropagation.
Next, wecalculatethelossfunctionofstyletransferthroughforwardpropagation(direc- tionofsolidarrows), andupdatethemodelparameters(thesynthesizedimageforoutput) throughbackpropagation(directionofdashedarrows).
Thelossfunctioncommonlyused instyletransferconsistsofthreeparts: (i)contentlossmakesthesynthesizedimageand thecontentimagecloseincontentfeatures;(ii)stylelossmakesthesynthesizedimageand style image close in style features; and (iii) total variation loss helps to reduce the noise in the synthesized image.
Finally, when the model training is over, we output the model parametersofthestyletransfertogeneratethefinalsynthesizedimage.
Inthefollowing, wewillexplainthetechnicaldetailsofstyletransferviaaconcreteexper- iment.
668 Computer Vision 14.12.2 Readingthe Contentand Style Images First, wereadthecontentandstyleimages.
Fromtheirprintedcoordinateaxes, wecantell thattheseimageshavedifferentsizes.
%matplotlib inline import torch import torchvision from torch import nn from d2l import torch as d2l d2l.
set_figsize() d2l.
plt.
imshow(content_img); d2l.
plt.
imshow(style_img); 14.12.3 Preprocessingand Postprocessing Below, we define two functions for preprocessing and postprocessing images.
The pre- process function standardizes each of the three RGB channels of the input image and transformstheresultsintothe CNNinputformat.
Thepostprocessfunctionrestoresthe pixelvaluesintheoutputimagetotheiroriginalvaluesbeforestandardization.
Sincethe imageprintingfunctionrequiresthateachpixelhasafloatingpointvaluefrom0to1, we replaceanyvaluesmallerthan0orgreaterthan1with0or1, respectively.
669 Neural Style Transfer rgb_mean = torch.
tensor([0.485, 0.456, 0.406]) rgb_std = torch.
tensor([0.229, 0.224, 0.225]) def preprocess(img, image_shape): transforms = torchvision.
transforms.
Compose([ torchvision.
transforms.
Resize(image_shape), torchvision.
transforms.
To Tensor(), torchvision.
transforms.
Normalize(mean=rgb_mean, std=rgb_std)]) return transforms(img).
unsqueeze(0) def postprocess(img): img = img[0].
to(rgb_std.
device) img = torch.
clamp(img.
permute(1, 2, 0) * rgb_std + rgb_mean, 0, 1) return torchvision.
transforms.
To PILImage()(img.
permute(2, 0, 1)) 14.12.4 Extracting Features We use the VGG-19 model pretrained on the Image Net dataset to extract image features (Gatysetal.,2016).
pretrained_net = torchvision.
models.
vgg19(pretrained=True) Downloading: "https://download.
pytorch.
org/models/vgg19-dcbb9e9d.
pth" to /home/ â†©! ci/.
cache/torch/hub/checkpoints/vgg19-dcbb9e9d.
pth 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 548M/548M [00:02<00:00, 213MB/s] In order to extract the content features and style features of the image, we can select the output of certain layers in the VGG network.
Generally speaking, the closer to the input layer, the easier to extract details of the image, and vice versa, the easier to extract the globalinformationoftheimage.
Inordertoavoidexcessivelyretainingthedetailsofthe contentimageinthesynthesizedimage, wechoosea VGGlayerthatisclosertotheoutput asthecontentlayertooutputthecontentfeaturesoftheimage.
Wealsoselecttheoutput ofdifferent VGGlayersforextractinglocalandglobalstylefeatures.
Theselayersarealso called style layers.
As mentioned in Section 8.2, the VGG network uses 5 convolutional blocks.
Intheexperiment, wechoosethelastconvolutionallayerofthefourthconvolutional blockasthecontentlayer, andthefirstconvolutionallayerofeachconvolutionalblockas thestylelayer.
Theindicesoftheselayerscanbeobtainedbyprintingthepretrained_net instance.
style_layers, content_layers = [0, 5, 10, 19, 28], [25] Whenextractingfeaturesusing VGGlayers, weonlyneedtouseallthosefromtheinput layer to the content layer or style layer that is closest to the output layer.
Letâ€™s construct anewnetworkinstancenet, whichonlyretainsallthe VGGlayerstobeusedforfeature extraction.
670 Computer Vision net = nn.
Sequential(*[pretrained_net.
features[i] for i in range(max(content_layers + style_layers) + 1)]) Given the input X, if we simply invoke the forward propagation net(X), we can only get theoutputofthelastlayer.
Sincewealsoneedtheoutputsofintermediatelayers, weneed toperformlayer-by-layercomputationandkeepthecontentandstylelayeroutputs.
def extract_features(X, content_layers, style_layers): contents = [] styles = [] for i in range(len(net)): X = net[i](X) if i in style_layers: styles.
append(X) if i in content_layers: contents.
append(X) return contents, styles Two functions are defined below: the get_contents function extracts content features fromthecontentimage, andtheget_stylesfunctionextractsstylefeaturesfromthestyle image.
Sincethereisnoneedtoupdatethemodelparametersofthepretrained VGGduring training, we can extract the content and the style features even before the training starts.
Sincethesynthesizedimageisasetofmodelparameterstobeupdatedforstyletransfer, wecanonlyextractthecontentandstylefeaturesofthesynthesizedimagebycallingthe extract_featuresfunctionduringtraining.
def get_contents(image_shape, device): content_X = preprocess(content_img, image_shape).
to(device) contents_Y, _ = extract_features(content_X, content_layers, style_layers) return content_X, contents_Y def get_styles(image_shape, device): style_X = preprocess(style_img, image_shape).
to(device) _, styles_Y = extract_features(style_X, content_layers, style_layers) return style_X, styles_Y 14.12.5 Definingthe Loss Function Nowwewilldescribethelossfunctionforstyletransfer.
Thelossfunctionconsistsofthe contentloss, styleloss, andtotalvariationloss.
Content Loss Similartothelossfunctioninlinearregression, thecontentlossmeasuresthedifferencein contentfeaturesbetweenthesynthesizedimageandthecontentimageviathesquaredloss function.
Thetwoinputsofthesquaredlossfunctionarebothoutputsofthecontentlayer computedbytheextract_featuresfunction.
671 Neural Style Transfer def content_loss(Y_hat, Y): # We detach the target content from the tree used to dynamically compute # the gradient: this is a stated value, not a variable.
Otherwise the loss # will throw an error.
return torch.
square(Y_hat - Y.
detach()).
mean() Style Loss Styleloss, similartocontentloss, alsousesthesquaredlossfunctiontomeasurethedif- ference in style between the synthesized image and the style image.
To express the style outputofanystylelayer, wefirstusetheextract_featuresfunctiontocomputethestyle layeroutput.
Supposethattheoutputhas1example,ğ‘channels, heightâ„, andwidthğ‘¤, we cantransformthisoutputintomatrix Xwithğ‘rowsandâ„ğ‘¤ columns.
Thismatrixcanbe thoughtofastheconcatenationofğ‘vectorsx 1 ,..., xğ‘, eachofwhichhasalengthofâ„ğ‘¤.
Here, vectorxğ‘– representsthestylefeatureofchannelğ‘–.
Inthe Grammatrixofthesevectors XX> 2 Rğ‘ ğ‘ , elementğ‘¥ ğ‘–ğ‘— inrowğ‘– andcolumn ğ‘— is thedotproductofvectorsxğ‘– andxğ‘—.
Itrepresentsthecorrelationofthestylefeaturesof channelsğ‘– and ğ‘—.
Weusethis Grammatrixtorepresentthestyleoutputofanystylelayer.
Notethatwhenthevalueofâ„ğ‘¤islarger, itlikelyleadstolargervaluesinthe Grammatrix.
Notealsothattheheightandwidthofthe Grammatrixareboththenumberofchannelsğ‘.
Toallowstylelossnottobeaffectedbythesevalues, thegramfunctionbelowdividesthe Grammatrixbythenumberofitselements, i.
e.,ğ‘â„ğ‘¤.
def gram(X): num_channels, n = X.
shape[1], X.
numel() // X.
shape[1] X = X.
reshape((num_channels, n)) return torch.
matmul(X, X.
T) / (num_channels * n) Obviously, thetwo Grammatrixinputsofthesquaredlossfunctionforstylelossarebased onthestylelayeroutputsforthesynthesizedimageandthestyleimage.
Itisassumedhere thatthe Grammatrixgram_Ybasedonthestyleimagehasbeenprecomputed.
def style_loss(Y_hat, gram_Y): return torch.
square(gram(Y_hat) - gram_Y.
detach()).
mean() Total Variation Loss Sometimes, thelearnedsynthesizedimagehasalotofhigh-frequencynoise, i.
e., particu- larlybrightordarkpixels.
Onecommonnoisereductionmethodistotalvariationdenois- ing.
Denotebyğ‘¥ ğ‘–,ğ‘— thepixelvalueatcoordinateâ€ğ‘–, ğ‘—â€.
Reducingtotalvariationloss ğ‘¥ ğ‘¥ â€š ğ‘¥ ğ‘¥ ğ‘–,ğ‘— ğ‘–â€š1,ğ‘— ğ‘–,ğ‘— ğ‘–,ğ‘—â€š1 (14.12.1) ğ‘–,ğ‘— makesvaluesofneighboringpixelsonthesynthesizedimagecloser.
672 Computer Vision def tv_loss(Y_hat): return 0.5 * (torch.
abs(Y_hat[:, :, 1:, :] - Y_hat[:, :, :-1, :]).
mean() + torch.
abs(Y_hat[:, :, :, 1:] - Y_hat[:, :, :, :-1]).
mean()) Loss Function Thelossfunctionofstyletransferistheweightedsumofcontentloss, styleloss, andtotal variationloss.
Byadjustingtheseweighthyperparameters, wecanbalanceamongcontent retention, styletransfer, andnoisereductiononthesynthesizedimage.
content_weight, style_weight, tv_weight = 1, 1e4, 10 def compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram): # Calculate the content, style, and total variance losses respectively contents_l = [content_loss(Y_hat, Y) * content_weight for Y_hat, Y in zip( contents_Y_hat, contents_Y)] styles_l = [style_loss(Y_hat, Y) * style_weight for Y_hat, Y in zip( styles_Y_hat, styles_Y_gram)] tv_l = tv_loss(X) * tv_weight # Add up all the losses l = sum(styles_l + contents_l + [tv_l]) return contents_l, styles_l, tv_l, l 14.12.6 Initializingthe Synthesized Image Instyletransfer, thesynthesizedimageistheonlyvariablethatneedstobeupdatedduring training.
Thus, wecandefineasimplemodel, Synthesized Image, andtreatthesynthe- sizedimageasthemodelparameters.
Inthismodel, forwardpropagationjustreturnsthe modelparameters.
class Synthesized Image(nn.
Module): def __init__(self, img_shape, **kwargs): super(Synthesized Image, self).__init__(**kwargs) self.
weight = nn.
Parameter(torch.
rand(*img_shape)) def forward(self): return self.
weight Next, wedefinetheget_initsfunction.
Thisfunctioncreatesasynthesizedimagemodel instanceandinitializesittotheimage X.
Grammatricesforthestyleimageatvariousstyle layers, styles_Y_gram, arecomputedpriortotraining.
def get_inits(X, device, lr, styles_Y): gen_img = Synthesized Image(X.
shape).
to(device) gen_img.
weight.
data.
copy_(X.
data) trainer = torch.
optim.
Adam(gen_img.
parameters(), lr=lr) styles_Y_gram = [gram(Y) for Y in styles_Y] return gen_img(), styles_Y_gram, trainer 673 Neural Style Transfer 14.12.7 Training When training the model for style transfer, we continuously extract content features and stylefeaturesofthesynthesizedimage, andcalculatethelossfunction.
Belowdefinesthe trainingloop.
def train(X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch): X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y) scheduler = torch.
optim.
lr_scheduler.
Step LR(trainer, lr_decay_epoch, 0.8) animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[10, num_epochs], legend=['content', 'style', 'TV'], ncols=2, figsize=(7, 2.5)) for epoch in range(num_epochs): trainer.
zero_grad() contents_Y_hat, styles_Y_hat = extract_features( X, content_layers, style_layers) contents_l, styles_l, tv_l, l = compute_loss( X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram) l.
backward() trainer.
step() scheduler.
step() if (epoch + 1) % 10 == 0: animator.
axes[1].
imshow(postprocess(X)) animator.
add(epoch + 1, [float(sum(contents_l)), float(sum(styles_l)), float(tv_l)]) return X Nowwestarttotrainthemodel.
Werescaletheheightandwidthofthecontentandstyle images to 300 by 450 pixels.
We use the content image to initialize the synthesized im- age.
device, image_shape = d2l.
try_gpu(), (300, 450) # PIL Image (h, w) net = net.
to(device) content_X, contents_Y = get_contents(image_shape, device) _, styles_Y = get_styles(image_shape, device) output = train(content_X, contents_Y, styles_Y, device, 0.3, 500, 50) Wecanseethatthesynthesizedimageretainsthesceneryandobjectsofthecontentimage, andtransfersthecolorofthestyleimageatthesametime.
Forexample, thesynthesized 674 Computer Vision imagehasblocksofcolorlikethoseinthestyleimage.
Someoftheseblocksevenhavethe subtletextureofbrushstrokes.
14.12.8 Summary Thelossfunctioncommonlyusedinstyletransferconsistsofthreeparts: (i)contentloss makesthesynthesizedimageandthecontentimagecloseincontentfeatures;(ii)style lossmakesthesynthesizedimageandstyleimagecloseinstylefeatures; and(iii)total variationlosshelpstoreducethenoiseinthesynthesizedimage.
Wecanuseapretrained CNNtoextractimagefeaturesandminimizethelossfunction tocontinuouslyupdatethesynthesizedimageasmodelparametersduringtraining.
Weuse Grammatricestorepresentthestyleoutputsfromthestylelayers.
14.12.9 Exercises 1.
Howdoestheoutputchangewhenyouselectdifferentcontentandstylelayers? 2.
Adjust the weight hyperparameters in the loss function.
Does the output retain more contentorhavelessnoise? 3.
Use different content and style images.
Can you create more interesting synthesized images? 4.
Canweapplystyletransferfortext? Hint: youmayrefertothesurveypaperby Huet al.
(2022).
224 Discussions224.
14.13 Image Classification (CIFAR-10) on Kaggle Sofar, wehavebeenusinghigh-level APIsofdeeplearningframeworkstodirectlyobtain imagedatasetsintensorformat.
However, customimagedatasetsoftencomeintheform ofimagefiles.
Inthissection, wewillstartfromrawimagefiles, andorganize, read, then transformthemintotensorformatstepbystep.
Weexperimentedwiththe CIFAR-10datasetin Section14.1, whichisanimportantdataset in computer vision.
In this section, we will apply the knowledge we learned in previous sections to practice the Kaggle competition of CIFAR-10 image classification.
The web addressofthecompetitionishttps://www.
kaggle.
com/c/cifar-10 .13.1showstheinformationonthecompetitionâ€™swebpage.
Inordertosubmitthe results, youneedtoregistera Kaggleaccount.
675 Image Classification(CIFAR-10)on Kaggle t .13.1 CIFAR-10imageclassificationcompetitionwebpageinformation.
Thecompetition datasetcanbeobtainedbyclickingtheâ€œDataâ€tab.
import collections import math import os import shutil import pandas as pd import torch import torchvision from torch import nn from d2l import torch as d2l 14.13.1 Obtainingand Organizingthe Dataset Thecompetitiondatasetisdividedintoatrainingsetandatestset, whichcontain50000 and300000images, respectively.
Inthetestset,10000imageswillbeusedforevaluation, whiletheremaining290000imageswillnotbeevaluated: theyareincludedjusttomake it hard to cheat with manually labeled results of the test set.
The images in this dataset areallpngcolor(RGBchannels)imagefiles, whoseheightandwidthareboth32pixels.
Theimagescoveratotalof10categories, namelyairplanes, cars, birds, cats, deer, dogs, frogs, horses, boats, andtrucks.
Theupper-leftcornerof.13.1showssomeimages ofairplanes, cars, andbirdsinthedataset.
Downloadingthe Dataset Afterlogginginto Kaggle, wecanclicktheâ€œDataâ€tabonthe CIFAR-10imageclassifi- cation competition webpage shown in .13.1 and download the dataset by clicking the â€œDownload Allâ€ button.
After unzipping the downloaded file in ../data, and un- zippingtrain.7zandtest.7zinsideit, youwillfindtheentiredatasetinthefollowing paths: ../data/cifar-10/train/[1-50000].
png ../data/cifar-10/test/[1-300000].
png 676 Computer Vision ../data/cifar-10/train Labels.
csv ../data/cifar-10/sample Submission.
csv wherethetrainandtestdirectoriescontainthetrainingandtestingimages, respectively, train Labels.
csvprovideslabelsforthetrainingimages, andsample_submission.
csv isasamplesubmissionfile.
Tomakeiteasiertogetstarted, weprovideasmall-scalesampleofthedatasetthatcontains thefirst1000trainingimagesand5randomtestingimages.
Tousethefulldatasetofthe Kagglecompetition, youneedtosetthefollowingdemovariableto False.
#@save d2l.
DATA_HUB['cifar10_tiny'] = (d2l.
DATA_URL + 'kaggle_cifar10_tiny.
zip', '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd') # If you use the full dataset downloaded for the Kaggle competition, set # `demo` to False demo = True if demo: data_dir = d2l.
download_extract('cifar10_tiny') else: data_dir = '../data/cifar-10/' Organizingthe Dataset We need to organize datasets to facilitate model training and testing.
Letâ€™s first read the labels from the csv file.
The following function returns a dictionary that maps the non- extensionpartofthefilenametoitslabel.
#@save def read_csv_labels(fname): """Read `fname` to return a filename to label dictionary.""" with open(fname, 'r') as f: # Skip the file header line (column name) lines = f.
readlines()[1:] tokens = [l.
rstrip().
split(',') for l in lines] return dict(((name, label) for name, label in tokens)) labels = read_csv_labels(os.
path.
join(data_dir, 'train Labels.
csv')) print('# training examples:', len(labels)) print('# classes:', len(set(labels.
values()))) # training examples: 1000 # classes: 10 677 Image Classification(CIFAR-10)on Kaggle Next, wedefinethereorg_train_validfunctiontosplitthevalidationsetoutoftheorig- inal training set.
The argument valid_ratio in this function is the ratio of the number of examples in the validation set to the number of examples in the original training set.
Moreconcretely, let ğ‘› bethenumberofimagesoftheclasswiththeleastexamples, and ğ‘Ÿ betheratio.
Thevalidationsetwillsplitoutmaxâ€bğ‘›ğ‘Ÿc,1â€ imagesforeachclass.
Letâ€™s use valid_ratio=0.1 as an example.
Since the original training set has 50000 images, therewillbe45000imagesusedfortraininginthepathtrain_valid_test/train, while theother5000imageswillbesplitoutasvalidationsetinthepathtrain_valid_test/ valid.
Afterorganizingthedataset, imagesofthesameclasswillbeplacedunderthesame folder.
#@save def copyfile(filename, target_dir): """Copy a file into a target directory.""" os.
makedirs(target_dir, exist_ok=True) shutil.
copy(filename, target_dir) #@save def reorg_train_valid(data_dir, labels, valid_ratio): """Split the validation set out of the original training set.""" # The number of examples of the class that has the fewest examples in the # training dataset n = collections.
Counter(labels.
values()).
most_common()[-1][1] # The number of examples per class for the validation set n_valid_per_label = max(1, math.
floor(n * valid_ratio)) label_count = {} for train_file in os.
listdir(os.
path.
join(data_dir, 'train')): label = labels[train_file.
split('.')[0]] fname = os.
path.
join(data_dir, 'train', train_file) copyfile(fname, os.
path.
join(data_dir, 'train_valid_test', 'train_valid', label)) if label not in label_count or label_count[label] < n_valid_per_label: copyfile(fname, os.
path.
join(data_dir, 'train_valid_test', 'valid', label)) label_count[label] = label_count.
get(label, 0) + 1 else: copyfile(fname, os.
path.
join(data_dir, 'train_valid_test', 'train', label)) return n_valid_per_label Thereorg_testfunctionbeloworganizesthetestingsetfordataloadingduringpredic- tion.
#@save def reorg_test(data_dir): """Organize the testing set for data loading during prediction.""" for test_file in os.
listdir(os.
path.
join(data_dir, 'test')): copyfile(os.
path.
join(data_dir, 'test', test_file), os.
path.
join(data_dir, 'train_valid_test', 'test', 'unknown')) 678 Computer Vision Finally, weuseafunctiontoinvoketheread_csv_labels, reorg_train_valid, andre- org_testfunctionsdefinedabove.
def reorg_cifar10_data(data_dir, valid_ratio): labels = read_csv_labels(os.
path.
join(data_dir, 'train Labels.
csv')) reorg_train_valid(data_dir, labels, valid_ratio) reorg_test(data_dir) Here we only set the batch size to 32 for the small-scale sample of the dataset.
When training and testing the complete dataset of the Kaggle competition, batch_size should be set to a larger integer, such as 128.
We split out 10% of the training examples as the validationsetfortuninghyperparameters.
batch_size = 32 if demo else 128 valid_ratio = 0.1 reorg_cifar10_data(data_dir, valid_ratio) 14.13.2 Image Augmentation Weuseimageaugmentationtoaddressoverfitting.
Forexample, imagescanbeflippedhor- izontallyatrandomduringtraining.
Wecanalsoperformstandardizationforthethree RGB channelsofcolorimages.
Belowlistssomeoftheseoperationsthatyoucantweak.
transform_train = torchvision.
transforms.
Compose([ # Scale the image up to a square of 40 pixels in both height and width torchvision.
transforms.
Resize(40), # Randomly crop a square image of 40 pixels in both height and width to # produce a small square of 0.64 to 1 times the area of the original # image, and then scale it to a square of 32 pixels in both height and # width torchvision.
transforms.
Random Resized Crop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)), torchvision.
transforms.
Random Horizontal Flip(), torchvision.
transforms.
To Tensor(), # Standardize each channel of the image [0.2023, 0.1994, 0.2010])]) Duringtesting, weonlyperformstandardizationonimagessoastoremoverandomnessin theevaluationresults.
transform_test = torchvision.
transforms.
Compose([ torchvision.
transforms.
To Tensor(), [0.2023, 0.1994, 0.2010])]) 14.13.3 Readingthe Dataset Next, wereadtheorganizeddatasetconsistingofrawimagefiles.
Eachexampleincludes animageandalabel.
679 Image Classification(CIFAR-10)on Kaggle train_ds, train_valid_ds = [torchvision.
datasets.
Image Folder( os.
path.
join(data_dir, 'train_valid_test', folder), transform=transform_train) for folder in ['train', 'train_valid']] valid_ds, test_ds = [torchvision.
datasets.
Image Folder( os.
path.
join(data_dir, 'train_valid_test', folder), transform=transform_test) for folder in ['valid', 'test']] Duringtraining, weneedtospecifyalltheimageaugmentationoperationsdefinedabove.
When the validation set is used for model evaluation during hyperparameter tuning, no randomness from image augmentation should be introduced.
Before final prediction, we trainthemodelonthecombinedtrainingsetandvalidationsettomakefulluseofallthe labeleddata.
train_iter, train_valid_iter = [torch.
utils.
data.
Data Loader( dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, train_valid_ds)] valid_iter = torch.
utils.
data.
Data Loader(valid_ds, batch_size, shuffle=False, drop_last=True) test_iter = torch.
utils.
data.
Data Loader(test_ds, batch_size, shuffle=False, drop_last=False) 14.13.4 Definingthe Model Wedefinethe Res Net-18modeldescribedin Section8.6.
def get_net(): num_classes = 10 net = d2l.
resnet18(num_classes, 3) return net loss = nn.
Cross Entropy Loss(reduction="none") 14.13.5 Definingthe Training Function Wewillselectmodelsandtunehyperparametersaccordingtothemodelâ€™sperformanceon thevalidationset.
Inthefollowing, wedefinethemodeltrainingfunctiontrain.
def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay): trainer = torch.
optim.
SGD(net.
parameters(), lr=lr, momentum=0.9, weight_decay=wd) scheduler = torch.
optim.
lr_scheduler.
Step LR(trainer, lr_period, lr_decay) num_batches, timer = len(train_iter), d2l.
Timer() legend = ['train loss', 'train acc'] if valid_iter is not None: legend.
append('valid acc') (continuesonnextpage) 680 Computer Vision (continuedfrompreviouspage) animator = d2l.
Animator(xlabel='epoch', xlim=[1, num_epochs], legend=legend) net = nn.
Data Parallel(net, device_ids=devices).
to(devices[0]) for epoch in range(num_epochs): net.
train() metric = d2l.
Accumulator(3) for i, (features, labels) in enumerate(train_iter): timer.
start() l, acc = d2l.
train_batch_ch13(net, features, labels, loss, trainer, devices) metric.
add(l, acc, labels.
shape[0]) timer.
stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.
add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[2], None)) if valid_iter is not None: valid_acc = d2l.
evaluate_accuracy_gpu(net, valid_iter) animator.
add(epoch + 1, (None, None, valid_acc)) scheduler.
step() measures = (f'train loss {metric[0] / metric[2]:.3f}, ' f'train acc {metric[1] / metric[2]:.3f}') if valid_iter is not None: measures += f', valid acc {valid_acc:.3f}' print(measures + f'\n{metric[2] * num_epochs / timer.
sum():.1f}' f' examples/sec on {str(devices)}') 14.13.6 Trainingand Validatingthe Model Now, wecantrainandvalidatethemodel.
Allthefollowinghyperparameterscanbetuned.
For example, we can increase the number of epochs.
When lr_period and lr_decay are set to 4 and 0.9, respectively, the learning rate of the optimization algorithm will be multiplied by 0.9 after every 4 epochs.
Just for ease of demonstration, we only train 20 epochshere.
devices, num_epochs, lr, wd = d2l.
try_all_gpus(), 20, 2e-4, 5e-4 lr_period, lr_decay, net = 4, 0.9, get_net() net(next(iter(train_iter))[0]) train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay) train loss 0.654, train acc 0.789, valid acc 0.438 958.1 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] 14.13.7 Classifyingthe Testing Setand Submitting Resultson Kaggle Afterobtainingapromisingmodelwithhyperparameters, weuseallthelabeleddata(in- cludingthevalidationset)toretrainthemodelandclassifythetestingset.
681 Image Classification(CIFAR-10)on Kaggle net, preds = get_net(), [] net(next(iter(train_valid_iter))[0]) train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period, lr_decay) for X, _ in test_iter: y_hat = net(X.
to(devices[0])) sorted_ids = list(range(1, len(test_ds) + 1)) sorted_ids.
sort(key=lambda x: str(x)) df = pd.
Data Frame({'id': sorted_ids, 'label': preds}) df['label'] = df['label'].
apply(lambda x: train_valid_ds.
classes[x]) df.
to_csv('submission.
csv', index=False) train loss 0.608, train acc 0.786 1040.8 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Theabovecodewillgenerateasubmission.
csvfile, whoseformatmeetstherequirement ofthe Kagglecompetition.
Themethodforsubmittingresultsto Kaggleissimilartothat in Section5.7.
14.13.8 Summary Wecanreaddatasetscontainingrawimagefilesafterorganizingthemintotherequired format.
682 Computer Vision Wecanuseconvolutionalneuralnetworksandimageaugmentationinanimageclassi- ficationcompetition.
14.13.9 Exercises 1.
Usethecomplete CIFAR-10datasetforthis Kagglecompetition.
Sethyperparameters asbatch_size = 128, num_epochs = 100, lr = 0.1, lr_period = 50, andlr_decay = 0.1.
Seewhataccuracyandrankingyoucanachieveinthiscompetition.
Canyou furtherimprovethem? 2.
Whataccuracycanyougetwhennotusingimageaugmentation? Discussions225.
225 14.14 Dog Breed Identification (Image Net Dogs) on Kaggle Inthissection, wewillpracticethedogbreedidentificationproblemon Kaggle.
Theweb addressofthiscompetitionishttps://www.
kaggle.
com/c/dog-breed-identification Inthiscompetition,120differentbreedsofdogswillberecognized.
Infact, thedatasetfor thiscompetitionisasubsetofthe Image Netdataset.
Unliketheimagesinthe CIFAR-10 datasetin Section14.13, theimagesinthe Image Netdatasetarebothhigherandwiderin Youneeda Kaggleaccounttosubmityourresults.
import os import torch import torchvision from torch import nn from d2l import torch as d2l 14.14.1 Obtainingand Organizingthe Dataset Thecompetitiondatasetisdividedintoatrainingsetandatestset, whichcontain10222 and10357JPEGimagesofthree RGB(color)channels, respectively.
Amongthetraining dataset, thereare120breedsofdogssuchas Labradors, Poodles, Dachshunds, Samoyeds, Huskies, Chihuahuas, and Yorkshire Terriers.
Downloadingthe Dataset After logging into Kaggle, you can click on the â€œDataâ€ tab on the competition webpage shown in .14.1 and download the dataset by clicking the â€œDownload Allâ€ button.
After unzipping the downloaded file in ../data, you will find the entire dataset in the followingpaths: 683 Dog Breed Identification(Image Net Dogs)on Kaggle t .14.1 Thedogbreedidentificationcompetitionwebsite.
Thecompetitiondatasetcanbe obtainedbyclickingtheâ€œDataâ€tab.
../data/dog-breed-identification/labels.
csv ../data/dog-breed-identification/sample_submission.
csv ../data/dog-breed-identification/train ../data/dog-breed-identification/test Youmayhavenoticedthattheabovestructureissimilartothatofthe CIFAR-10competition in Section14.13, wherefolderstrain/andtest/containtrainingandtestingdogimages, respectively, and labels.
csv contains the labels for the training images.
Similarly, to make it easier to get started, we provide a small sample of the dataset mentioned above: train_valid_test_tiny.
zip.
If you are going to use the full dataset for the Kaggle competition, youneedtochangethedemovariablebelowto False.
#@save d2l.
DATA_HUB['dog_tiny'] = (d2l.
DATA_URL + 'kaggle_dog_tiny.
zip', '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d') # If you use the full dataset downloaded for the Kaggle competition, change # the variable below to `False` demo = True if demo: data_dir = d2l.
download_extract('dog_tiny') (continuesonnextpage) 684 Computer Vision (continuedfrompreviouspage) else: data_dir = os.
path.
join('..', 'data', 'dog-breed-identification') Organizingthe Dataset Wecanorganizethedatasetsimilarlytowhatwedidin Section14.13, namelysplittingout avalidationsetfromtheoriginaltrainingset, andmovingimagesintosubfoldersgrouped bylabels.
Thereorg_dog_datafunctionbelowreadsthetrainingdatalabels, splitsoutthevalidation set, andorganizesthetrainingset.
def reorg_dog_data(data_dir, valid_ratio): labels = d2l.
read_csv_labels(os.
path.
join(data_dir, 'labels.
csv')) d2l.
reorg_train_valid(data_dir, labels, valid_ratio) d2l.
reorg_test(data_dir) batch_size = 32 if demo else 128 valid_ratio = 0.1 reorg_dog_data(data_dir, valid_ratio) 14.14.2 Image Augmentation Recall that this dog breed dataset is a subset of the Image Net dataset, whose images are largerthanthoseofthe CIFAR-10datasetin Section14.13.
Thefollowinglistsafewimage augmentationoperationsthatmightbeusefulforrelativelylargerimages.
transform_train = torchvision.
transforms.
Compose([ # Randomly crop the image to obtain an image with an area of 0.08 to 1 of # the original area and height-to-width ratio between 3/4 and 4/3.
Then, # scale the image to create a new 224 x 224 image torchvision.
transforms.
Random Resized Crop(224, scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0)), torchvision.
transforms.
Random Horizontal Flip(), # Randomly change the brightness, contrast, and saturation torchvision.
transforms.
Color Jitter(brightness=0.4, contrast=0.4, saturation=0.4), # Add random noise torchvision.
transforms.
To Tensor(), # Standardize each channel of the image [0.229, 0.224, 0.225])]) Duringprediction, weonlyuseimagepreprocessingoperationswithoutrandomness.
685 Dog Breed Identification(Image Net Dogs)on Kaggle transform_test = torchvision.
transforms.
Compose([ torchvision.
transforms.
Resize(256), # Crop a 224 x 224 square area from the center of the image torchvision.
transforms.
Center Crop(224), torchvision.
transforms.
To Tensor(), [0.229, 0.224, 0.225])]) 14.14.3 Readingthe Dataset Asin Section14.13, wecanreadtheorganizeddatasetconsistingofrawimagefiles.
train_ds, train_valid_ds = [torchvision.
datasets.
Image Folder( os.
path.
join(data_dir, 'train_valid_test', folder), transform=transform_train) for folder in ['train', 'train_valid']] valid_ds, test_ds = [torchvision.
datasets.
Image Folder( os.
path.
join(data_dir, 'train_valid_test', folder), transform=transform_test) for folder in ['valid', 'test']] Belowwecreatedataiteratorinstancesthesamewayasin Section14.13.
train_iter, train_valid_iter = [torch.
utils.
data.
Data Loader( dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, train_valid_ds)] valid_iter = torch.
utils.
data.
Data Loader(valid_ds, batch_size, shuffle=False, drop_last=True) test_iter = torch.
utils.
data.
Data Loader(test_ds, batch_size, shuffle=False, drop_last=False) 14.14.4 Fine-Tuninga Pretrained Model Again, thedatasetforthiscompetitionisasubsetofthe Image Netdataset.
Therefore, we can use the approach discussed in Section 14.2 to select a model pretrained on the full Image Net dataset and use it to extract imagefeatures to be fed into a customsmall-scale output network.
High-level APIs of deep learning frameworks provide a wide range of modelspretrainedonthe Image Netdataset.
Here, wechooseapretrained Res Net-34model, wherewesimplyreusetheinputofthismodelâ€™soutputlayer(i.
e., theextractedfeatures).
Thenwecanreplacetheoriginaloutputlayerwithasmallcustomoutputnetworkthatcan betrained, suchasstackingtwofullyconnectedlayers.
Differentfromtheexperimentin Section14.2, thefollowingdoesnotretrainthepretrainedmodelusedforfeatureextraction.
Thisreducestrainingtimeandmemoryforstoringgradients.
Recall that we standardized images using the means and standard deviations of the three RGBchannelsforthefull Image Netdataset.
Infact, thisisalsoconsistentwiththestan- dardizationoperationbythepretrainedmodelon Image Net.
686 Computer Vision def get_net(devices): finetune_net = nn.
Sequential() finetune_net.
features = torchvision.
models.
resnet34(pretrained=True) # Define a new output network (there are 120 output categories) finetune_net.
output_new = nn.
Sequential(nn.
Linear(1000, 256), nn.
Re LU(), nn.
Linear(256, 120)) # Move the model to devices finetune_net = finetune_net.
to(devices[0]) # Freeze parameters of feature layers for param in finetune_net.
features.
parameters(): param.
requires_grad = False return finetune_net Beforecalculatingtheloss, wefirstobtaintheinputofthepretrainedmodelâ€™soutputlayer, i.
e., the extracted feature.
Then we use this feature as input for our small custom output networktocalculatetheloss.
loss = nn.
Cross Entropy Loss(reduction='none') def evaluate_loss(data_iter, net, devices): l_sum, n = 0.0, 0 for features, labels in data_iter: features, labels = features.
to(devices[0]), labels.
to(devices[0]) outputs = net(features) l = loss(outputs, labels) l_sum += l.
sum() n += labels.
numel() return l_sum / n 14.14.5 Definingthe Training Function Wewillselectthemodelandtunehyperparametersaccordingtothemodelâ€™sperformance on the validation set.
The model training function train only iterates parameters of the smallcustomoutputnetwork.
def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay): # Only train the small custom output network net = nn.
Data Parallel(net, device_ids=devices).
to(devices[0]) trainer = torch.
optim.
SGD((param for param in net.
parameters() if param.
requires_grad), lr=lr, momentum=0.9, weight_decay=wd) scheduler = torch.
optim.
lr_scheduler.
Step LR(trainer, lr_period, lr_decay) num_batches, timer = len(train_iter), d2l.
Timer() legend = ['train loss'] if valid_iter is not None: legend.
append('valid loss') animator = d2l.
Animator(xlabel='epoch', xlim=[1, num_epochs], legend=legend) for epoch in range(num_epochs): metric = d2l.
Accumulator(2) (continuesonnextpage) 687 Dog Breed Identification(Image Net Dogs)on Kaggle (continuedfrompreviouspage) for i, (features, labels) in enumerate(train_iter): timer.
start() features, labels = features.
to(devices[0]), labels.
to(devices[0]) trainer.
zero_grad() output = net(features) l = loss(output, labels).
sum() l.
backward() trainer.
step() metric.
add(l, labels.
shape[0]) timer.
stop() if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.
add(epoch + (i + 1) / num_batches, (metric[0] / metric[1], None)) measures = f'train loss {metric[0] / metric[1]:.3f}' if valid_iter is not None: valid_loss = evaluate_loss(valid_iter, net, devices) animator.
add(epoch + 1, (None, valid_loss.
detach().
cpu())) scheduler.
step() if valid_iter is not None: measures += f', valid loss {valid_loss:.3f}' print(measures + f'\n{metric[1] * num_epochs / timer.
sum():.1f}' f' examples/sec on {str(devices)}') 14.14.6 Trainingand Validatingthe Model Nowwecantrainandvalidatethemodel.
Thefollowinghyperparametersarealltunable.
Forexample, thenumberofepochscanbeincreased.
Becauselr_periodandlr_decay are set to 2 and 0.9, respectively, the learning rate of the optimization algorithm will be multipliedby0.9afterevery2epochs.
devices, num_epochs, lr, wd = d2l.
try_all_gpus(), 10, 1e-4, 1e-4 lr_period, lr_decay, net = 2, 0.9, get_net(devices) train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay) train loss 1.240, valid loss 1.545 577.5 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] 688 Computer Vision 14.14.7 Classifyingthe Testing Setand Submitting Resultson Kaggle Similar to the final step in Section 14.13, in the end all the labeled data (including the validationset)areusedfortrainingthemodelandclassifyingthetestingset.
Wewilluse thetrainedcustomoutputnetworkforclassification.
net = get_net(devices) train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period, lr_decay) preds = [] for data, label in test_iter: output = torch.
nn.
functional.
softmax(net(data.
to(devices[0])), dim=1) preds.
extend(output.
cpu().
detach().
numpy()) ids = sorted(os.
listdir( os.
path.
join(data_dir, 'train_valid_test', 'test', 'unknown'))) with open('submission.
csv', 'w') as f: f.
write('id,' + ','.
join(train_valid_ds.
classes) + '\n') for i, output in zip(ids, preds): f.
write(i.
split('.')[0] + ',' + ','.
join( [str(num) for num in output]) + '\n') train loss 1.217 742.7 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Theabovecodewillgenerateasubmission.
csvfiletobesubmittedto Kaggleinthesame waydescribedin Section5.7.
14.14.8 Summary Imagesinthe Image Netdatasetarelarger(withvaryingdimensions)than CIFAR-10im- ages.
Wemaymodifyimageaugmentationoperationsfortasksonadifferentdataset.
Toclassifyasubsetofthe Image Netdataset, wecanleveragepre-trainedmodelsonthe full Image Net dataset to extract features and only train a custom small-scale output network.
Thiswillleadtolesscomputationaltimeandmemorycost.
14.14.9 Exercises 689 Dog Breed Identification(Image Net Dogs)on Kaggle 1.
Whenusingthefull Kagglecompetitiondataset, whatresultscanyouachievewhenyou increase batch_size (batch size) and num_epochs (number of epochs) while setting someotherhyperparametersaslr = 0.01, lr_period = 10, andlr_decay = 0.1? 2.
Doyougetbetterresultsifyouuseadeeperpretrainedmodel? Howdoyoutunehyper- parameters? Canyoufurtherimprovetheresults? Discussions226.
226 Natural Language Processing: Pretraining 15 Humansneedtocommunicate.
Outofthisbasicneedofthehumancondition, avastamount ofwrittentexthasbeengeneratedonaneverydaybasis.
Givenrichtextinsocialmedia, chatapps, emails, productreviews, newsarticles, researchpapers, andbooks, itbecomes vitaltoenablecomputerstounderstandthemtoofferassistanceormakedecisionsbased onhumanlanguages.
Natural language processing studies interactions between computers and humans using naturallanguages.
Inpractice, itisverycommontousenaturallanguageprocessingtech- niquestoprocessandanalyzetext(humannaturallanguage)data, suchaslanguagemodels in Section9.3andmachinetranslationmodelsin Section10.5.
Tounderstandtext, wecanbeginbylearningitsrepresentations.
Leveragingtheexisting text sequences from large corpora, self-supervised learning has been extensively used to pretraintextrepresentations, suchasbypredictingsomehiddenpartofthetextusingsome other part of their surrounding text.
In this way, models learn through supervision from massivetextdatawithoutexpensivelabelingefforts! Aswewillseeinthischapter, whentreatingeachwordorsubwordasanindividualtoken, the representation of each token can be pretrained using word2vec, Glo Ve, or subword embedding models on large corpora.
After pretraining, representation of each token can be a vector, however, it remains the same no matter what the context is.
For instance, the vector representation of â€œbankâ€ is the same in both â€œgo to the bank to deposit some moneyâ€ and â€œgo to the bank to sit downâ€.
Thus, many more recent pretraining models adaptrepresentationofthesametokentodifferentcontexts.
Amongthemis BERT, amuch deeperself-supervisedmodelbasedonthe Transformerencoder.
Inthischapter, wewill focusonhowtopretrainsuchrepresentationsfortext, ashighlightedin.1.
Forsightofthebigpicture,.1showsthatthepretrainedtextrepresentationscanbe fed to a variety of deep learning architectures for different downstream natural language processingapplications.
Wewillcoverthemin Chapter16.
690 691 Word Embedding(word2vec) t .1 Pretrainedtextrepresentationscanbefedtovariousdeeplearningarchitecturesfor differentdownstreamnaturallanguageprocessingapplications.
Thischapterfocuseson theupstreamtextrepresentationpretraining.
15.1 Word Embedding (word2vec) Natural language is a complex system used to express meanings.
In this system, words arethebasicunitofthemeaning.
Asthenameimplies, wordvectorsarevectorsusedto representwords, andcanalsobeconsideredasfeaturevectorsorrepresentationsofwords.
Thetechniqueofmappingwordstorealvectorsiscalledwordembedding.
Inrecentyears, wordembeddinghasgraduallybecomethebasicknowledgeofnaturallanguageprocess- ing.
15.1.1 One-Hot Vectors Area Bad Choice Weusedone-hotvectorstorepresentwords(charactersarewords)in Section9.5.
Suppose that the number of different words in the dictionary (the dictionary size) is ğ‘, and each word corresponds to a different integer (index) from 0 to ğ‘ 1.
To obtain the one-hot vectorrepresentationforanywordwithindexğ‘–, wecreatealength-ğ‘ vectorwithall0sand settheelementatpositionğ‘–to1.
Inthisway, eachwordisrepresentedasavectoroflength ğ‘, anditcanbeuseddirectlybyneuralnetworks.
Althoughone-hotwordvectorsareeasytoconstruct, theyareusuallynotagoodchoice.
A mainreasonisthatone-hotwordvectorscannotaccuratelyexpressthesimilaritybetween differentwords, suchasthecosinesimilaritythatweoftenuse.
Forvectorsx, y 2Rğ‘‘ , their cosinesimilarityisthecosineoftheanglebetweenthem: x>y 2 Â» 1,1â€¦.
(15.1.1) kxkkyk Sincethecosinesimilaritybetweenone-hotvectorsofanytwodifferentwordsis0, one-hot vectorscannotencodesimilaritiesamongwords.
227 15.1.2 Self-Supervisedword2vec The word2vec227 tool was proposed to address the above issue.
It maps each word to a 692 Natural Language Processing: Pretraining fixed-lengthvector, andthesevectorscanbetterexpressthesimilarityandanalogyrelation- ship among different words.
The word2vec tool contains two models, namely skip-gram (Mikolovetal.,2013)andcontinuousbagofwords(CBOW)(Mikolovetal.,2013).
For semanticallymeaningfulrepresentations, theirtrainingreliesonconditionalprobabilities thatcanbeviewedaspredictingsomewordsusingsomeoftheirsurroundingwordsincor- pora.
Sincesupervisioncomesfromthedatawithoutlabels, bothskip-gramandcontinuous bagofwordsareself-supervisedmodels.
Inthefollowing, wewillintroducethesetwomodelsandtheirtrainingmethods.
15.1.3 The Skip-Gram Model Theskip-grammodelassumesthatawordcanbeusedtogenerateitssurroundingwordsin atextsequence.
Takethetextsequenceâ€œtheâ€,â€œmanâ€,â€œlovesâ€,â€œhisâ€,â€œsonâ€asanexample.
Letâ€™schooseâ€œlovesâ€asthecenterwordandsetthecontextwindowsizeto2.
Asshownin .1.1, giventhecenterwordâ€œlovesâ€, theskip-grammodelconsiderstheconditional probabilityforgeneratingthecontextwords: â€œtheâ€,â€œmanâ€,â€œhisâ€, andâ€œsonâ€, whichareno morethan2wordsawayfromthecenterword: ğ‘ƒâ€â€theâ€,â€manâ€,â€hisâ€,â€sonâ€ j â€lovesâ€â€.
(15.1.2) Assume that the context words are independently generated given the center word (i.
e., conditionalindependence).
Inthiscase, theaboveconditionalprobabilitycanberewritten as ğ‘ƒâ€â€theâ€ j â€lovesâ€â€ ğ‘ƒâ€â€manâ€ j â€lovesâ€â€ ğ‘ƒâ€â€hisâ€ j â€lovesâ€â€ ğ‘ƒâ€â€sonâ€ j â€lovesâ€â€.
(15.1.3) t .1.1 Theskip-grammodelconsiderstheconditionalprobabilityofgeneratingthesurrounding contextwordsgivenacenterword.
Intheskip-grammodel, eachwordhastwo ğ‘‘-dimensional-vectorrepresentationsforcal- culatingconditionalprobabilities.
Moreconcretely, foranywordwithindexğ‘– inthedic- tionary, denotebyvğ‘– 2 Rğ‘‘ anduğ‘– 2 Rğ‘‘ itstwovectorswhenusedasacenterwordanda contextword, respectively.
Theconditionalprobabilityofgeneratinganycontextwordğ‘¤ ğ‘œ (withindexğ‘œ inthedictionary)giventhecenterwordğ‘¤ ğ‘ (withindexğ‘ inthedictionary) canbemodeledbyasoftmaxoperationonvectordotproducts: ğ‘ƒâ€ğ‘¤ ğ‘œ j ğ‘¤ ğ‘ â€ = Ë ğ‘–2 e V xp e â€ x u p > ğ‘œ â€ v u ğ‘ > ğ‘– â€ vğ‘ â€ , (15.1.4) 693 Word Embedding(word2vec) wherethevocabularyindexset V = f0,1,..., j Vj 1g.
Givenatextsequenceoflength ğ‘‡, where the word at time step ğ‘¡ is denoted as ğ‘¤â€ğ‘¡â€ .
Assume that context words are in- dependentlygeneratedgivenanycenterword.
Forcontextwindowsizeğ‘š, thelikelihood function of the skip-gram model is the probability of generating all context words given anycenterword: ğ‘‡ ğ‘ƒâ€ğ‘¤â€ğ‘¡â€šğ‘—â€ j ğ‘¤â€ğ‘¡â€â€, (15.1.5) ğ‘¡=1 ğ‘š ğ‘— ğ‘š, ğ‘—â‰ 0 whereanytimestepthatislessthan1orgreaterthanğ‘‡ canbeomitted.
Training The skip-gram model parameters are the center word vector and context word vector for eachwordinthevocabulary.
Intraining, welearnthemodelparametersbymaximizingthe likelihoodfunction(i.
e., maximumlikelihoodestimation).
Thisisequivalenttominimizing thefollowinglossfunction: ğ‘‡ logğ‘ƒâ€ğ‘¤â€ğ‘¡â€šğ‘—â€ j ğ‘¤â€ğ‘¡â€â€.
(15.1.6) ğ‘¡=1 ğ‘š ğ‘— ğ‘š, ğ‘—â‰ 0 Whenusingstochasticgradientdescenttominimizetheloss, ineachiterationwecanran- domly sample a shorter subsequence to calculate the (stochastic) gradient for this subse- quence to update the model parameters.
To calculate this (stochastic) gradient, we need to obtain the gradients of the log conditional probability with respect to the center word vectorand the contextwordvector.
In general, according to (15.1.4) thelog conditional probabilityinvolvinganypairofthecenterwordğ‘¤ ğ‘ andthecontextwordğ‘¤ ğ‘œ is ! logğ‘ƒâ€ğ‘¤ ğ‘œ j ğ‘¤ ğ‘ â€ =u > ğ‘œ vğ‘ log expâ€u > ğ‘– vğ‘ â€ .
(15.1.7) ğ‘–2V Throughdifferentiation, wecanobtainitsgradientwithrespecttothecenterwordvector vğ‘ as Ë ğœ•logğ‘ƒ ğœ• â€ v ğ‘¤ ğ‘ ğ‘œ j ğ‘¤ ğ‘ â€ =uğ‘œ Ë ğ‘—2 ğ‘–2 V V ex ex p p â€u â€u > ğ‘— > ğ‘– v v ğ‘ â€ ğ‘ u â€ ğ‘— ! expâ€u> ğ‘— vğ‘ â€ =uğ‘œ ğ‘—2V Ë ğ‘–2Vexpâ€u> ğ‘– vğ‘ â€ uğ‘— (15.1.8) =uğ‘œ ğ‘ƒâ€ğ‘¤ ğ‘— j ğ‘¤ ğ‘ â€uğ‘— .
ğ‘—2V Notethatthecalculationin(15.1.8)requirestheconditionalprobabilitiesofallwordsin thedictionarywithğ‘¤ ğ‘ asthecenterword.
Thegradientsfortheotherwordvectorscanbe obtainedinthesameway.
After training, for any word with index ğ‘– in the dictionary, we obtain both word vectors 694 Natural Language Processing: Pretraining vğ‘– (as the center word) and uğ‘– (as the context word).
In natural language processing ap- plications, thecenterwordvectorsoftheskip-grammodelaretypicallyusedastheword representations.
15.1.4 The Continuous Bagof Words(CBOW)Model Thecontinuousbagofwords(CBOW)modelissimilartotheskip-grammodel.
Themajor differencefromtheskip-grammodelisthatthecontinuousbagofwordsmodelassumesthat acenterwordisgeneratedbasedonitssurroundingcontextwordsinthetextsequence.
For example, inthesametextsequenceâ€œtheâ€,â€œmanâ€,â€œlovesâ€,â€œhisâ€, andâ€œsonâ€, withâ€œlovesâ€as thecenterwordandthecontextwindowsizebeing2, thecontinuousbagofwordsmodel considers the conditional probability of generating the center word â€œlovesâ€ based on the contextwordsâ€œtheâ€,â€œmanâ€,â€œhisâ€andâ€œsonâ€(asshownin.1.2), whichis ğ‘ƒâ€â€lovesâ€ j â€theâ€,â€manâ€,â€hisâ€,â€sonâ€â€.
(15.1.9) t .1.2 Thecontinuousbagofwordsmodelconsiderstheconditionalprobabilityofgenerating thecenterwordgivenitssurroundingcontextwords.
Sincetherearemultiplecontextwordsinthecontinuousbagofwordsmodel, thesecontext wordvectorsareaveragedinthecalculationoftheconditionalprobability.
Specifically, for any word with indexğ‘– in the dictionary, denote by vğ‘– 2 Rğ‘‘ and uğ‘– 2 Rğ‘‘ its two vectors whenusedasacontext wordandacenter word(meaningsareswitchedintheskip-gram model), respectively.
Theconditionalprobabilityofgeneratinganycenterwordğ‘¤ ğ‘ (with indexğ‘ inthedictionary)givenitssurroundingcontextwordsğ‘¤ ğ‘œ 1 ,...,ğ‘¤ ğ‘œ 2ğ‘š (withindex ğ‘œ 1 ,...,ğ‘œ 2ğ‘šinthedictionary)canbemodeledby canbesimplifiedas ğ‘ƒâ€ğ‘¤ ğ‘ j W ğ‘œ â€ = Ë ğ‘–2 e V xp ex u p > ğ‘ v u Â¯ğ‘œ > ğ‘– vÂ¯ğ‘œ .
(15.1.11) Givenatextsequenceoflengthğ‘‡, wherethewordattimestepğ‘¡ isdenotedas ğ‘¤â€ğ‘¡â€ .
For 695 Word Embedding(word2vec) context window size ğ‘š, the likelihood function of the continuous bag of words model is theprobabilityofgeneratingallcenterwordsgiventheircontextwords: ğ‘‡ ğ‘¡=1 Training Trainingcontinuousbagofwordsmodelsisalmostthesameastrainingskip-grammodels.
Themaximumlikelihoodestimationofthecontinuousbagofwordsmodelisequivalentto minimizingthefollowinglossfunction: ğ‘‡ ğ‘¡=1 Noticethat ! log ğ‘ƒâ€ğ‘¤ ğ‘ j W ğ‘œ â€ =u > ğ‘ vÂ¯ğ‘œ log exp u > ğ‘– vÂ¯ğ‘œ .
(15.1.14) ğ‘–2V Throughdifferentiation, wecanobtainitsgradientwithrespecttoanycontextwordvector vğ‘œğ‘– (ğ‘– =1,...,2ğ‘š)as ğœ•log ğ‘ƒ ğœ• â€ v ğ‘¤ ğ‘œ ğ‘ ğ‘– j W ğ‘œ â€ = 2 1 ğ‘š ' â€º Â« uğ‘ ğ‘— 2V Ë e ğ‘–2 x V pâ€ e u x > ğ‘— p vÂ¯ â€u ğ‘œ â€ > ğ‘– u vÂ¯ ğ‘— ğ‘œ â€ â€œ fi â€¹ = 2 1 ğ‘š ' â€º Â« uğ‘ ğ‘— 2V ğ‘ƒâ€ğ‘¤ ğ‘— j W ğ‘œ â€uğ‘— â€œ fi â€¹ .
(15.1.15) Thegradientsfortheotherwordvectorscanbeobtainedinthesameway.
Unliketheskip- grammodel, thecontinuousbagofwordsmodeltypicallyusescontextwordvectorsasthe wordrepresentations.
15.1.5 Summary Wordvectorsarevectorsusedtorepresentwords, andcanalsobeconsideredasfeature vectorsorrepresentationsofwords.
Thetechniqueofmappingwordstorealvectors iscalledwordembedding.
Theword2vectoolcontainsboththeskip-gramandcontinuousbagofwordsmodels.
Theskip-grammodelassumesthatawordcanbeusedtogenerateitssurroundingwords in a text sequence; while the continuous bag of words model assumes that a center wordisgeneratedbasedonitssurroundingcontextwords.
15.1.6 Exercises 1.
Whatisthecomputationalcomplexityforcalculatingeachgradient? Whatcouldbethe issueifthedictionarysizeishuge? 696 Natural Language Processing: Pretraining 2.
Somefixedphrasesin Englishconsistofmultiplewords, suchasâ€œnewyorkâ€.
Howto train their word vectors? Hint: see Section 4 in the word2vec paper (Mikolov et al., 2013).
3.
Letâ€™sreflectontheword2vecdesignbytakingtheskip-grammodelasanexample.
What istherelationshipbetweenthedotproductoftwowordvectorsintheskip-grammodel and the cosine similarity? For a pair of words with similar semantics, why may the cosinesimilarityoftheirwordvectors(trainedbytheskip-grammodel)behigh? Discussions228.
228 15.2 Approximate Training Recall our discussions in Section 15.1.
The main idea of the skip-gram model is using softmax operations to calculate the conditional probability of generating a context word ğ‘¤ ğ‘œ basedonthegivencenterwordğ‘¤ ğ‘ in(15.1.4), whosecorrespondinglogarithmicloss isgivenbytheoppositeof(15.1.7).
Due to the nature of the softmax operation, since a context word may be anyone in the dictionary V, the opposite of (15.1.7) contains the summation of items as many as the entire size of the vocabulary.
Consequently, the gradient calculation for the skip-gram modelin(15.1.8)andthatforthecontinuousbag-of-wordsmodelin(15.1.15)bothcontain thesummation.
Unfortunately, thecomputationalcostforsuchgradientsthatsumovera largedictionary(oftenwithhundredsofthousandsormillionsofwords)ishuge! Inordertoreducetheaforementionedcomputationalcomplexity, thissectionwillintroduce twoapproximatetrainingmethods: negativesamplingandhierarchicalsoftmax.
Duetothe similaritybetweentheskip-grammodelandthecontinuousbagofwordsmodel, wewill just take the skip-gram model as an example to describe these two approximate training methods.
15.2.1 Negative Sampling Negativesamplingmodifiestheoriginalobjectivefunction.
Giventhecontextwindowof acenterwordğ‘¤ ğ‘, thefactthatany(context)wordğ‘¤ ğ‘œ comesfromthiscontextwindowis consideredasaneventwiththeprobabilitymodeledby ğ‘ƒâ€ğ· =1 j ğ‘¤ ğ‘ ,ğ‘¤ ğ‘œ â€ =ğœâ€u > ğ‘œ vğ‘ â€, (15.2.1) whereğœusesthedefinitionofthesigmoidactivationfunction: 1 ğœâ€ğ‘¥â€ = .
(15.2.2) 1â€šexpâ€ ğ‘¥â€ Letâ€™sbeginbymaximizingthejointprobabilityofallsucheventsintextsequencestotrain wordembeddings.
Specifically, givenatextsequenceoflengthğ‘‡, denotebyğ‘¤â€ğ‘¡â€ theword 697 Approximate Training attimestepğ‘¡ andletthecontextwindowsizebeğ‘š, considermaximizingthejointproba- bility ğ‘‡ ğ‘ƒâ€ğ· =1 j ğ‘¤â€ğ‘¡â€,ğ‘¤â€ğ‘¡â€šğ‘—â€â€.
(15.2.3) ğ‘¡=1 ğ‘š ğ‘— ğ‘š, ğ‘—â‰ 0 However,(15.2.3)onlyconsidersthoseeventsthatinvolvepositiveexamples.
Asaresult, the joint probability in (15.2.3) is maximized to 1 only if all the word vectors are equal toinfinity.
Ofcourse, suchresultsaremeaningless.
Tomaketheobjectivefunctionmore meaningful, negativesamplingaddsnegativeexamplessampledfromapredefineddistri- bution.
Denote by ğ‘† the event that a context word ğ‘¤ ğ‘œ comes from the context window of a cen- terword ğ‘¤ ğ‘.
Forthiseventinvolving ğ‘¤ ğ‘œ, fromapredefineddistribution ğ‘ƒâ€ğ‘¤â€ sample ğ¾ noise words that are not from this context window.
Denote by ğ‘ ğ‘˜ the event that a noise wordğ‘¤ ğ‘˜ (ğ‘˜ =1,...,ğ¾)doesnotcomefromthecontextwindowofğ‘¤ ğ‘.
Assumethatthese eventsinvolvingboththepositiveexampleandnegativeexamplesğ‘†,ğ‘ 1 ,...,ğ‘ ğ¾ aremutu- allyindependent.
Negativesamplingrewritesthejointprobability(involvingonlypositive examples)in(15.2.3)as ğ‘‡ ğ‘ƒâ€ğ‘¤â€ğ‘¡â€šğ‘—â€ j ğ‘¤â€ğ‘¡â€â€, (15.2.4) ğ‘¡=1 ğ‘š ğ‘— ğ‘š, ğ‘—â‰ 0 wheretheconditionalprobabilityisapproximatedthrougheventsğ‘†,ğ‘ 1 ,...,ğ‘ ğ¾: ğ¾ ğ‘ƒâ€ğ‘¤â€ğ‘¡â€šğ‘—â€ j ğ‘¤â€ğ‘¡â€â€ = ğ‘ƒâ€ğ· =1 j ğ‘¤â€ğ‘¡â€,ğ‘¤â€ğ‘¡â€šğ‘—â€â€ ğ‘ƒâ€ğ· =0 j ğ‘¤â€ğ‘¡â€,ğ‘¤ ğ‘˜ â€.
(15.2.5) ğ‘˜=1,ğ‘¤ğ‘˜ ğ‘ƒâ€ğ‘¤â€ Denotebyğ‘– ğ‘¡ andâ„ ğ‘˜ theindicesofawordğ‘¤â€ğ‘¡â€ attimestepğ‘¡ofatextsequenceandanoise wordğ‘¤ ğ‘˜, respectively.
Thelogarithmiclosswithrespecttotheconditionalprobabilitiesin (15.2.5)is ğ¾ logğ‘ƒâ€ğ‘¤â€ğ‘¡â€šğ‘—â€ j ğ‘¤â€ğ‘¡â€â€ = logğ‘ƒâ€ğ· =1 j ğ‘¤â€ğ‘¡â€,ğ‘¤â€ğ‘¡â€šğ‘—â€â€ logğ‘ƒâ€ğ· =0 j ğ‘¤â€ğ‘¡â€,ğ‘¤ ğ‘˜ â€ ğ‘˜=1,ğ‘¤ğ‘˜ ğ‘ƒâ€ğ‘¤â€ ğ¾ = log ğœ u > ğ‘–ğ‘¡â€šğ‘— vğ‘–ğ‘¡ log 1 ğœ u > â„ğ‘˜ vğ‘–ğ‘¡ ğ‘˜=1,ğ‘¤ğ‘˜ ğ‘ƒâ€ğ‘¤â€ ğ¾ = log ğœ u > ğ‘–ğ‘¡â€šğ‘— vğ‘–ğ‘¡ logğœ u > â„ğ‘˜ vğ‘–ğ‘¡ .
ğ‘˜=1,ğ‘¤ğ‘˜ ğ‘ƒâ€ğ‘¤â€ (15.2.6) Wecanseethatnowthecomputationalcostforgradientsateachtrainingstephasnothing todowiththedictionarysize, butlinearlydependsonğ¾.
Whensettingthehyperparameter ğ¾toasmallervalue, thecomputationalcostforgradientsateachtrainingstepwithnegative samplingissmaller.
698 Natural Language Processing: Pretraining 15.2.2 Hierarchical Softmax Asanalternativeapproximatetrainingmethod, hierarchicalsoftmaxusesthebinarytree, a datastructureillustratedin.2.1, whereeachleafnodeofthetreerepresentsaword indictionary V.
t .2.1 Hierarchicalsoftmaxforapproximatetraining, whereeachleafnodeofthetreerepresents awordinthedictionary.
Denotebyğ¿â€ğ‘¤â€thenumberofnodes(includingbothends)onthepathfromtherootnode totheleafnoderepresentingwordğ‘¤inthebinarytree.
Letğ‘›â€ğ‘¤, ğ‘—â€bethe ğ‘—thnodeonthis path, withitscontextwordvectorbeinguğ‘›â€ğ‘¤,ğ‘—â€.
Forexample, ğ¿â€ğ‘¤ 3 â€ = 4in.2.1.
Hierarchicalsoftmaxapproximatestheconditionalprobabilityin(15.1.4)as ğ¿â€ ğ‘¤ğ‘œâ€ 1 ğ‘ƒâ€ğ‘¤ ğ‘œ j ğ‘¤ ğ‘ â€ = ğœ Â»Â»ğ‘›â€ğ‘¤ ğ‘œ , ğ‘— â€š1â€ =left Childâ€ğ‘›â€ğ‘¤ ğ‘œ , ğ‘—â€â€â€¦â€¦ u > ğ‘›â€ğ‘¤ğ‘œ,ğ‘—â€ vğ‘ , ğ‘—=1 (15.2.7) wherefunctionğœ isdefinedin(15.2.2), andleft Childâ€ğ‘›â€ istheleftchildnodeofnodeğ‘›: ifğ‘¥istrue, Â»Â»ğ‘¥â€¦â€¦ =1; otherwise Â»Â»ğ‘¥â€¦â€¦ = 1.
Toillustrate, letâ€™scalculatetheconditionalprobabilityofgeneratingwordğ‘¤ givenword 3 ğ‘¤ ğ‘ in.2.1.
Thisrequiresdotproductsbetweenthewordvectorvğ‘ ofğ‘¤ ğ‘ andnon- leafnodevectorsonthepath(thepathinboldin.2.1)fromtheroottoğ‘¤ , whichis 3 traversedleft, right, thenleft: ğ‘ƒâ€ğ‘¤ 3 j ğ‘¤ ğ‘ â€ =ğœâ€u > ğ‘›â€ğ‘¤ 3 ,1â€ vğ‘ â€ ğœâ€ u > ğ‘›â€ğ‘¤ 3 ,2â€ vğ‘ â€ ğœâ€u > ğ‘›â€ğ‘¤ 3 ,3â€ vğ‘ â€.
(15.2.8) Since ğœâ€ğ‘¥â€ â€šğœâ€ ğ‘¥â€ = 1, it holds that the conditional probabilities of generating all the wordsindictionary V basedonanywordğ‘¤ ğ‘ sumuptoone: ğ‘ƒâ€ğ‘¤ j ğ‘¤ ğ‘ â€ =1.
(15.2.9) ğ‘¤2V Fortunately, since ğ¿â€ğ‘¤ ğ‘œ â€ 1 is on the order of Oâ€log 2 j Vjâ€ due to the binary tree struc- ture, whenthedictionarysize V ishuge, thecomputationalcostforeachtrainingstepus- inghierarchicalsoftmaxissignificantlyreducedcomparedwiththatwithoutapproximate training.
699 The Datasetfor Pretraining Word Embeddings 15.2.3 Summary Negative sampling constructs the loss function by considering mutually independent eventsthatinvolvebothpositiveandnegativeexamples.
Thecomputationalcostfor trainingislinearlydependentonthenumberofnoisewordsateachstep.
Hierarchical softmax constructs the loss function using the path from the root node to theleafnodeinthebinarytree.
Thecomputationalcostfortrainingisdependenton thelogarithmofthedictionarysizeateachstep.
15.2.4 Exercises 1.
Howcanwesamplenoisewordsinnegativesampling? 2.
Verifythat(15.2.9)holds.
3.
Howtotrainthecontinuousbagofwordsmodelusingnegativesamplingandhierarchi- calsoftmax, respectively? 229 Discussions229.
15.3 The Dataset for Pretraining Word Embeddings Nowthatweknowthetechnicaldetailsoftheword2vecmodelsandapproximatetraining methods, letâ€™s walk through their implementations.
Specifically, we will take the skip- grammodelin Section15.1andnegativesamplingin Section15.2asanexample.
Inthis section, webeginwiththedatasetforpretrainingthewordembeddingmodel: theoriginal format of the data will be transformed into minibatches that can be iterated over during training.
import collections import math import os import random import torch from d2l import torch as d2l 15.3.1 Readingthe Dataset 230 Thedatasetthatweusehereis Penn Tree Bank(PTB)230.
Thiscorpusissampledfrom Wall Street Journalarticles, splitintotraining, validation, andtestsets.
Intheoriginalformat, eachlineofthetextfilerepresentsasentenceofwordsthatareseparatedbyspaces.
Here wetreateachwordasatoken.
700 Natural Language Processing: Pretraining #@save d2l.
DATA_HUB['ptb'] = (d2l.
DATA_URL + 'ptb.
zip', '319d85e578af0cdc590547f26231e4e31cdf1e42') #@save def read_ptb(): """Load the PTB dataset into a list of text lines.""" data_dir = d2l.
download_extract('ptb') # Read the training set with open(os.
path.
join(data_dir, 'ptb.
train.
txt')) as f: raw_text = f.
read() return [line.
split() for line in raw_text.
split('\n')] sentences = read_ptb() f'# sentences: {len(sentences)}' â†©! ptb.
zip...
'# sentences: 42069' Afterreadingthetrainingset, webuildavocabularyforthecorpus, whereanywordthat appearslessthan10timesisreplacedbytheâ€œ<unk>â€token.
Notethattheoriginaldataset alsocontainsâ€œ<unk>â€tokensthatrepresentrare(unknown)words.
vocab = d2l.
Vocab(sentences, min_freq=10) f'vocab size: {len(vocab)}' 'vocab size: 6719' 15.3.2 Subsampling Textdatatypicallyhavehigh-frequencywordssuchasâ€œtheâ€,â€œaâ€, andâ€œinâ€: theymayeven occur billions of times in very large corpora.
However, these words often co-occur with many different words in context windows, providing little useful signals.
For instance, consider the word â€œchipâ€ in a context window: intuitively its co-occurrence with a low- frequency word â€œintelâ€ is more useful in training than the co-occurrence with a high- frequency word â€œaâ€.
Moreover, training with vast amounts of (high-frequency) words is slow.
Thus, when training word embedding models, high-frequency words can be sub- sampled (Mikolovetal.,2013).
Specifically, eachindexedwordğ‘¤ ğ‘– inthedatasetwillbe discardedwithprobability r ğ‘¡ ğ‘ƒâ€ğ‘¤ ğ‘– â€ =max 1 ğ‘“â€ğ‘¤ â€ ,0 , (15.3.1) ğ‘– where ğ‘“â€ğ‘¤ ğ‘– â€ is the ratio of the number of words ğ‘¤ ğ‘– to the total number of words in the dataset, andtheconstantğ‘¡ isahyperparameter(10 4 intheexperiment).
Wecanseethat 701 The Datasetfor Pretraining Word Embeddings onlywhentherelativefrequency ğ‘“â€ğ‘¤ ğ‘– â€ >ğ‘¡canthe(high-frequency)wordğ‘¤ ğ‘–bediscarded, andthehighertherelativefrequencyoftheword, thegreatertheprobabilityofbeingdis- carded.
#@save def subsample(sentences, vocab): """Subsample high-frequency words.""" # Exclude unknown tokens ('<unk>') sentences = [[token for token in line if vocab[token] != vocab.
unk] for line in sentences] counter = collections.
Counter([ token for line in sentences for token in line]) num_tokens = sum(counter.
values()) # Return True if `token` is kept during subsampling def keep(token): return(random.
uniform(0, 1) < math.
sqrt(1e-4 / counter[token] * num_tokens)) return ([[token for token in line if keep(token)] for line in sentences], counter) subsampled, counter = subsample(sentences, vocab) Thefollowingcodesnippetplotsthehistogramofthenumberoftokenspersentencebe- foreandaftersubsampling.
Asexpected, subsamplingsignificantlyshortenssentencesby droppinghigh-frequencywords, whichwillleadtotrainingspeedup.
d2l.
show_list_len_pair_hist(['origin', 'subsampled'], '# tokens per sentence', 'count', sentences, subsampled); For individual tokens, the sampling rate of the high-frequency word â€œtheâ€ is less than 1/20.
def compare_counts(token): return (f'# of "{token}": ' f'before={sum([l.
count(token) for l in sentences])}, ' f'after={sum([l.
count(token) for l in subsampled])}') compare_counts('the') 702 Natural Language Processing: Pretraining '# of "the": before=50770, after=2010' Incontrast, low-frequencywordsâ€œjoinâ€arecompletelykept.
compare_counts('join') '# of "join": before=45, after=45' Aftersubsampling, wemaptokenstotheirindicesforthecorpus.
corpus = [vocab[line] for line in subsampled] corpus[:3] [[], [4127, 3228, 1773], [3922, 1922, 4743, 2696]] 15.3.3 Extracting Center Wordsand Context Words Thefollowingget_centers_and_contextsfunctionextractsallthecenterwordsandtheir contextwordsfromcorpus.
Ituniformlysamplesanintegerbetween1andmax_window_size atrandomasthecontextwindowsize.
Foranycenterword, thosewordswhosedistance fromitdoesnotexceedthesampledcontextwindowsizeareitscontextwords.
#@save def get_centers_and_contexts(corpus, max_window_size): """Return center words and context words in skip-gram.""" centers, contexts = [], [] for line in corpus: # To form a "center word--context word" pair, each sentence needs to # have at least 2 words if len(line) < 2: continue centers += line for i in range(len(line)): # Context window centered at `i` window_size = random.
randint(1, max_window_size) indices = list(range(max(0, i - window_size), min(len(line), i + 1 + window_size))) # Exclude the center word from the context words indices.
remove(i) contexts.
append([line[idx] for idx in indices]) return centers, contexts Next, wecreateanartificialdatasetcontainingtwosentencesof7and3words, respectively.
Letthemaximumcontextwindowsizebe2andprintallthecenterwordsandtheircontext words.
703 The Datasetfor Pretraining Word Embeddings tiny_dataset = [list(range(7)), list(range(7, 10))] print('dataset', tiny_dataset) for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)): print('center', center, 'has contexts', context) dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]] center 0 has contexts [1] center 1 has contexts [0, 2] center 2 has contexts [0, 1, 3, 4] center 3 has contexts [1, 2, 4, 5] center 4 has contexts [2, 3, 5, 6] center 5 has contexts [3, 4, 6] center 6 has contexts [5] center 7 has contexts [8, 9] center 8 has contexts [7, 9] center 9 has contexts [7, 8] When training on the PTB dataset, we set the maximum context window size to 5.
The followingextractsallthecenterwordsandtheircontextwordsinthedataset.
all_centers, all_contexts = get_centers_and_contexts(corpus, 5) f'# center-context pairs: {sum([len(contexts) for contexts in all_contexts])}' '# center-context pairs: 1503420' 15.3.4 Negative Sampling Weusenegativesamplingforapproximatetraining.
Tosamplenoisewordsaccordingtoa predefineddistribution, wedefinethefollowing Random Generatorclass, wherethe(possi- blyunnormalized)samplingdistributionispassedviatheargumentsampling_weights.
#@save class Random Generator: """Randomly draw among {1, ..., n} according to n sampling weights.""" def __init__(self, sampling_weights): # Exclude self.
population = list(range(1, len(sampling_weights) + 1)) self.
sampling_weights = sampling_weights self.
candidates = [] self.
i = 0 def draw(self): if self.
i == len(self.
candidates): # Cache `k` random sampling results self.
candidates = random.
choices( self.
population, self.
sampling_weights, k=10000) self.
i = 0 self.
i += 1 return self.
candidates[self.
i - 1] 704 Natural Language Processing: Pretraining Forexample, wecandraw10randomvariablesğ‘‹ amongindices1,2, and3withsampling probabilitiesğ‘ƒâ€ğ‘‹ =1â€ =2 9,ğ‘ƒâ€ğ‘‹ =2â€ =3 9, andğ‘ƒâ€ğ‘‹ =3â€ =4 9asfollows.
Forapairofcenterwordandcontextword, werandomlysample K(5intheexperiment) noisewords.
Accordingtothesuggestionsintheword2vecpaper, thesamplingprobability ğ‘ƒâ€ğ‘¤â€ofanoisewordğ‘¤issettoitsrelativefrequencyinthedictionaryraisedtothepower of0.75(Mikolovetal.,2013).
#@save def get_negatives(all_contexts, vocab, counter, K): """Return noise words in negative sampling.""" # Sampling weights for words with indices 1, 2, ...
(index 0 is the # excluded unknown token) in the vocabulary sampling_weights = [counter[vocab.
to_tokens(i)]**0.75 for i in range(1, len(vocab))] all_negatives, generator = [], Random Generator(sampling_weights) for contexts in all_contexts: negatives = [] while len(negatives) < len(contexts) * K: neg = generator.
draw() # Noise words cannot be context words if neg not in contexts: negatives.
append(neg) all_negatives.
append(negatives) return all_negatives all_negatives = get_negatives(all_contexts, vocab, counter, 5) 15.3.5 Loading Training Examplesin Minibatches Afterallthecenterwordstogetherwiththeircontextwordsandsamplednoisewordsare extracted, they will be transformed into minibatches of examples that can be iteratively loadedduringtraining.
Inaminibatch, theğ‘–thexampleincludesacenterwordanditsğ‘› ğ‘–contextwordsandğ‘š ğ‘–noise words.
Duetovaryingcontextwindowsizes,ğ‘› ğ‘– â€šğ‘š ğ‘– variesfordifferentğ‘–.
Thus, foreach example we concatenate its context words and noise words in the contexts_negatives variable, andpadzerosuntiltheconcatenationlengthreachesmaxğ‘– ğ‘› ğ‘– â€šğ‘š ğ‘– (max_len).
To excludepaddingsinthecalculationoftheloss, wedefineamaskvariablemasks.
Thereisa one-to-onecorrespondencebetweenelementsinmasksandelementsincontexts_negatives, wherezeros(otherwiseones)inmaskscorrespondtopaddingsincontexts_negatives.
To distinguish between positive and negative examples, we separate context words from noisewordsincontexts_negativesviaalabelsvariable.
Similartomasks, thereisalso aone-to-onecorrespondencebetweenelementsinlabelsandelementsincontexts_negatives, whereones(otherwisezeros)inlabelscorrespondtocontextwords(positiveexamples) incontexts_negatives.
The above idea is implemented in the following batchify function.
Its input data is a list with length equal to the batch size, where each element is an example consisting of thecenterwordcenter, itscontextwordscontext, anditsnoisewordsnegative.
This 705 The Datasetfor Pretraining Word Embeddings function returns a minibatch that can be loaded for calculations during training, such as includingthemaskvariable.
#@save def batchify(data): """Return a minibatch of examples for skip-gram with negative sampling.""" max_len = max(len(c) + len(n) for _, c, n in data) centers, contexts_negatives, masks, labels = [], [], [], [] for center, context, negative in data: cur_len = len(context) + len(negative) centers += [center] contexts_negatives += [context + negative + [0] * (max_len - cur_len)] masks += [[1] * cur_len + [0] * (max_len - cur_len)] labels += [[1] * len(context) + [0] * (max_len - len(context))] return (torch.
tensor(centers).
reshape((-1, 1)), torch.
tensor( contexts_negatives), torch.
tensor(masks), torch.
tensor(labels)) Letâ€™stestthisfunctionusingaminibatchoftwoexamples.
x_1 = (1, [2, 2], [3, 3, 3, 3]) x_2 = (1, [2, 2, 2], [3, 3]) batch = batchify((x_1, x_2)) names = ['centers', 'contexts_negatives', 'masks', 'labels'] for name, data in zip(names, batch): print(name, '=', data) centers = tensor([[1], [1]]) contexts_negatives = tensor([[2, 2, 3, 3, 3, 3], [2, 2, 2, 3, 3, 0]]) masks = tensor([[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0]]) labels = tensor([[1, 1, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0]]) 15.3.6 Putting It All Together Last, wedefinetheload_data_ptbfunctionthatreadsthe PTBdatasetandreturnsthedata iteratorandthevocabulary.
#@save def load_data_ptb(batch_size, max_window_size, num_noise_words): """Download the PTB dataset and then load it into memory.""" num_workers = d2l.
get_dataloader_workers() sentences = read_ptb() vocab = d2l.
Vocab(sentences, min_freq=10) subsampled, counter = subsample(sentences, vocab) corpus = [vocab[line] for line in subsampled] all_centers, all_contexts = get_centers_and_contexts( corpus, max_window_size) (continuesonnextpage) 706 Natural Language Processing: Pretraining (continuedfrompreviouspage) all_negatives = get_negatives( all_contexts, vocab, counter, num_noise_words) class PTBDataset(torch.
utils.
data.
Dataset): def __init__(self, centers, contexts, negatives): assert len(centers) == len(contexts) == len(negatives) self.
centers = centers self.
contexts = contexts self.
negatives = negatives def __getitem__(self, index): return (self.
centers[index], self.
contexts[index], self.
negatives[index]) def __len__(self): return len(self.
centers) dataset = PTBDataset(all_centers, all_contexts, all_negatives) data_iter = torch.
utils.
data.
Data Loader(dataset, batch_size, shuffle=True, collate_fn=batchify, num_workers=num_workers) return data_iter, vocab Letâ€™sprintthefirstminibatchofthedataiterator.
data_iter, vocab = load_data_ptb(512, 5, 5) for batch in data_iter: for name, data in zip(names, batch): print(name, 'shape:', data.
shape) break centers shape: torch.
Size([512, 1]) contexts_negatives shape: torch.
Size([512, 60]) masks shape: torch.
Size([512, 60]) labels shape: torch.
Size([512, 60]) 15.3.7 Summary High-frequency words may not be so useful in training.
We can subsample them for speedupintraining.
For computational efficiency, we load examples in minibatches.
We can define other variablestodistinguishpaddingsfromnon-paddings, andpositiveexamplesfromneg- ativeones.
15.3.8 Exercises 1.
Howdoestherunningtimeofcodeinthissectionchangesifnotusingsubsampling? 707 Pretrainingword2vec 2.
The Random Generatorclasscacheskrandomsamplingresults.
Setktoothervalues andseehowitaffectsthedataloadingspeed.
3.
What other hyperparameters in the code of this section may affect the data loading speed? Discussions231.
231 15.4 Pretraining word2vec Wegoontoimplementtheskip-grammodeldefinedin Section15.1.
Thenwewillpretrain word2vec using negative sampling on the PTB dataset.
First of all, letâ€™s obtain the data iterator and the vocabulary for this dataset by calling the d2l.
load_data_ptb function, whichwasdescribedin Section15.3 import math import torch from torch import nn from d2l import torch as d2l batch_size, max_window_size, num_noise_words = 512, 5, 5 data_iter, vocab = d2l.
load_data_ptb(batch_size, max_window_size, num_noise_words) 15.4.1 The Skip-Gram Model Weimplementtheskip-grammodelbyusingembeddinglayersandbatchmatrixmultipli- cations.
First, letâ€™sreviewhowembeddinglayerswork.
Embedding Layer Asdescribedin Section10.7, anembeddinglayermapsatokenâ€™sindextoitsfeaturevec- tor.
The weight of this layer is a matrix whose number of rows equals to the dictio- nary size (input_dim) and number of columns equals to the vector dimension for each token (output_dim).
After a word embedding model is trained, this weight is what we need.
embed = nn.
Embedding(num_embeddings=20, embedding_dim=4) print(f'Parameter embedding_weight ({embed.
weight.
shape}, ' f'dtype={embed.
weight.
dtype})') Parameter embedding_weight (torch.
Size([20, 4]), dtype=torch.
float32) Theinputofanembeddinglayeristheindexofatoken(word).
Foranytokenindexğ‘–, its 708 Natural Language Processing: Pretraining vectorrepresentationcanbeobtainedfromtheğ‘–throwoftheweightmatrixintheembedding layer.
Sincethevectordimension(output_dim)wassetto4, theembeddinglayerreturns vectorswithshape(2,3,4)foraminibatchoftokenindiceswithshape(2,3).
x = torch.
tensor([[1, 2, 3], [4, 5, 6]]) embed(x) tensor([[[ 0.7606, 0.3872, -0.1864, 1.1732], [ 1.5035, 2.3623, -1.7542, -1.4990], [-1.2639, -1.5313, 2.1719, 0.4151]], [[-1.9079, 0.2434, 1.5395, 1.2990], [ 0.7470, 1.0129, 0.4039, 0.0591], [-0.6293, -0.1814, -0.4782, -0.5289]]], grad_fn=<Embedding Backward0>) Definingthe Forward Propagation In the forward propagation, the input of the skip-gram model includes the center word indicescenterofshape(batchsize,1)andtheconcatenatedcontextandnoisewordindices contexts_and_negatives of shape (batch size, max_len), where max_len is defined in Section15.3.5.
Thesetwovariablesarefirsttransformedfromthetokenindicesintovectors viatheembeddinglayer, thentheirbatchmatrixmultiplication(describedin Section11.3.2) returnsanoutputofshape(batchsize,1, max_len).
Eachelementintheoutputisthedot productofacenterwordvectorandacontextornoisewordvector.
def skip_gram(center, contexts_and_negatives, embed_v, embed_u): v = embed_v(center) u = embed_u(contexts_and_negatives) pred = torch.
bmm(v, u.
permute(0, 2, 1)) return pred Letâ€™sprinttheoutputshapeofthisskip_gramfunctionforsomeexampleinputs.
skip_gram(torch.
ones((2, 1), dtype=torch.
long), torch.
ones((2, 4), dtype=torch.
long), embed, embed).
shape torch.
Size([2, 1, 4]) 15.4.2 Training Beforetrainingtheskip-grammodelwithnegativesampling, letâ€™sfirstdefineitslossfunc- tion.
Binary Cross-Entropy Loss Accordingtothedefinitionofthelossfunctionfornegativesamplingin Section15.2.1, we willusethebinarycross-entropyloss.
709 Pretrainingword2vec class Sigmoid BCELoss(nn.
Module): # Binary cross-entropy loss with masking def __init__(self): super().__init__() def forward(self, inputs, target, mask=None): out = nn.
functional.
binary_cross_entropy_with_logits( inputs, target, weight=mask, reduction="none") return out.
mean(dim=1) loss = Sigmoid BCELoss() Recallourdescriptionsofthemaskvariableandthelabelvariablein Section15.3.5.
The followingcalculatesthebinarycross-entropylossforthegivenvariables.
mask = torch.
tensor([[1, 1, 1, 1], [1, 1, 0, 0]]) loss(pred, label, mask) * mask.
shape[1] / mask.
sum(axis=1) tensor([0.9352, 1.8462]) Belowshowshowtheaboveresultsarecalculated(inalessefficientway)usingthesigmoid activationfunctioninthebinarycross-entropyloss.
Wecanconsiderthetwooutputsastwo normalizedlossesthatareaveragedovernon-maskedpredictions.
def sigmd(x): return -math.
log(1 / (1 + math.
exp(-x))) print(f'{(sigmd(-1.1) + sigmd(-2.2)) / 2:.4f}') 0.9352 1.8462 Initializing Model Parameters Wedefinetwoembeddinglayersforallthewordsinthevocabularywhentheyareusedas centerwordsandcontextwords, respectively.
Thewordvectordimensionembed_sizeis setto100.
embed_size = 100 net = nn.
Sequential(nn.
Embedding(num_embeddings=len(vocab), embedding_dim=embed_size), nn.
Embedding(num_embeddings=len(vocab), embedding_dim=embed_size)) 710 Natural Language Processing: Pretraining Definingthe Training Loop Thetrainingloopisdefinedbelow.
Becauseoftheexistenceofpadding, thecalculationof thelossfunctionisslightlydifferentcomparedtotheprevioustrainingfunctions.
def train(net, data_iter, lr, num_epochs, device=d2l.
try_gpu()): def init_weights(module): if type(module) == nn.
Embedding: nn.
init.
xavier_uniform_(module.
weight) net.
apply(init_weights) net = net.
to(device) optimizer = torch.
optim.
Adam(net.
parameters(), lr=lr) animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[1, num_epochs]) # Sum of normalized losses, no.
of normalized losses metric = d2l.
Accumulator(2) for epoch in range(num_epochs): timer, num_batches = d2l.
Timer(), len(data_iter) for i, batch in enumerate(data_iter): optimizer.
zero_grad() center, context_negative, mask, label = [ data.
to(device) for data in batch] pred = skip_gram(center, context_negative, net[0], net[1]) l = (loss(pred.
reshape(label.
shape).
float(), label.
float(), mask) / mask.
sum(axis=1) * mask.
shape[1]) l.
sum().
backward() optimizer.
step() metric.
add(l.
sum(), l.
numel()) if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.
add(epoch + (i + 1) / num_batches, (metric[0] / metric[1],)) print(f'loss {metric[0] / metric[1]:.3f}, ' f'{metric[1] / timer.
stop():.1f} tokens/sec on {str(device)}') Nowwecantrainaskip-grammodelusingnegativesampling.
lr, num_epochs = 0.002, 5 train(net, data_iter, lr, num_epochs) loss 0.410, 223485.0 tokens/sec on cuda:0 711 Word Embeddingwith Global Vectors(Glo Ve) 15.4.3 Applying Word Embeddings Aftertrainingtheword2vecmodel, wecanusethecosinesimilarityofwordvectorsfrom thetrainedmodeltofindwordsfromthedictionarythataremostsemanticallysimilarto aninputword.
def get_similar_tokens(query_token, k, embed): W = embed.
weight.
data x = W[vocab[query_token]] # Compute the cosine similarity.
Add 1e-9 for numerical stability cos = torch.
mv(W, x) / torch.
sqrt(torch.
sum(W * W, dim=1) * torch.
sum(x * x) + 1e-9) topk = torch.
topk(cos, k=k+1)[1].
cpu().
numpy().
astype('int32') for i in topk[1:]: # Remove the input words print(f'cosine sim={float(cos[i]):.3f}: {vocab.
to_tokens(i)}') get_similar_tokens('chip', 3, net[0]) cosine sim=0.702: microprocessor cosine sim=0.649: mips cosine sim=0.643: intel 15.4.4 Summary Wecantrainaskip-grammodelwithnegativesamplingusingembeddinglayersandthe binarycross-entropyloss.
Applicationsofwordembeddingsincludefindingsemanticallysimilarwordsforagiven wordbasedonthecosinesimilarityofwordvectors.
15.4.5 Exercises 1.
Usingthetrainedmodel, findsemanticallysimilarwordsforotherinputwords.
Canyou improvetheresultsbytuninghyperparameters? 2.
When a training corpus is huge, we often sample context words and noise words for the center words in the current minibatch when updating model parameters.
In other words, thesamecenterwordmayhavedifferentcontextwordsornoisewordsindifferent trainingepochs.
Whatarethebenefitsofthismethod? Trytoimplementthistraining method.
Discussions232.
232 15.5 Word Embedding with Global Vectors (Glo Ve) Word-wordco-occurrenceswithincontextwindowsmaycarryrichsemanticinformation.
For example, in a large corpus word â€œsolidâ€ is more likely to co-occur with â€œiceâ€ than 712 Natural Language Processing: Pretraining â€œsteamâ€, butwordâ€œgasâ€probablyco-occurswithâ€œsteamâ€morefrequentlythanâ€œiceâ€.
Be- sides, global corpus statistics of such co-occurrences can be precomputed: this can lead tomoreefficienttraining.
Toleveragestatisticalinformationintheentirecorpusforword embedding, letâ€™sfirstrevisittheskip-grammodelin Section15.1.3, butinterpretingitusing globalcorpusstatisticssuchasco-occurrencecounts.
15.5.1 Skip-Gramwith Global Corpus Statistics Denotingbyğ‘ ğ‘–ğ‘— theconditionalprobability ğ‘ƒâ€ğ‘¤ ğ‘— j ğ‘¤ ğ‘– â€ ofwordğ‘¤ ğ‘— givenwordğ‘¤ ğ‘– inthe skip-grammodel, wehave expâ€u> ğ‘— vğ‘– â€ ğ‘ ğ‘–ğ‘— = Ë ğ‘˜2Vexpâ€u> ğ‘˜ vğ‘– â€ , (15.5.1) whereforanyindexğ‘– vectorsvğ‘– anduğ‘– representwordğ‘¤ ğ‘– asthecenterwordandcontext word, respectively, and V = f0,1,..., j Vj 1gistheindexsetofthevocabulary.
Considerwordğ‘¤ ğ‘– thatmayoccurmultipletimesinthecorpus.
Intheentirecorpus, allthe contextwordswhereverğ‘¤ ğ‘– istakenastheircenterwordformamultiset C ğ‘– ofwordindices thatallowsformultipleinstancesofthesameelement.
Foranyelement, itsnumberofin- stancesiscalleditsmultiplicity.
Toillustratewithanexample, supposethatwordğ‘¤ ğ‘–occurs twiceinthecorpusandindicesofthecontextwordsthattakeğ‘¤ ğ‘– astheircenterwordinthe twocontextwindowsareğ‘˜, ğ‘—,ğ‘š,ğ‘˜andğ‘˜,ğ‘™,ğ‘˜, ğ‘—.
Thus, multiset C ğ‘– = fğ‘—, ğ‘—,ğ‘˜,ğ‘˜,ğ‘˜,ğ‘˜,ğ‘™,ğ‘šg, wheremultiplicitiesofelements ğ‘—,ğ‘˜,ğ‘™,ğ‘šare2,4,1,1, respectively.
Nowletâ€™sdenotethemultiplicityofelement ğ‘— inmultiset C ğ‘– asğ‘¥ ğ‘–ğ‘—.
Thisistheglobalco- occurrence count of word ğ‘¤ ğ‘— (as the context word) and word ğ‘¤ ğ‘– (as the center word) in thesamecontextwindowintheentirecorpus.
Usingsuchglobalcorpusstatistics, theloss functionoftheskip-grammodelisequivalentto ğ‘¥ ğ‘–ğ‘—log ğ‘ ğ‘–ğ‘— .
(15.5.2) ğ‘–2V ğ‘—2V Wefurtherdenotebyğ‘¥ ğ‘– thenumberofallthecontextwordsinthecontextwindowswhere ğ‘¤ ğ‘– occursastheircenterword, whichisequivalentto j C ğ‘– j.
Letting ğ‘ ğ‘–ğ‘— betheconditional probability ğ‘¥ ğ‘–ğ‘— ğ‘¥ ğ‘– for generating context word ğ‘¤ ğ‘— given center word ğ‘¤ ğ‘–, (15.5.2) can be rewrittenas ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘—log ğ‘ ğ‘–ğ‘— .
(15.5.3) ğ‘–2V ğ‘—2V Ë In(15.5.3), ğ‘—2V ğ‘ ğ‘–ğ‘—log ğ‘ ğ‘–ğ‘— calculatesthecross-entropyoftheconditionaldistribution ğ‘ ğ‘–ğ‘—ofglobalcorpusstatisticsandtheconditionaldistributionğ‘ ğ‘–ğ‘—ofmodelpredictions.
This loss is also weighted by ğ‘¥ ğ‘– as explained above.
Minimizing the loss function in (15.5.3) willallowthepredictedconditionaldistributiontogetclosetotheconditionaldistribution fromtheglobalcorpusstatistics.
Thoughbeingcommonlyusedformeasuringthedistancebetweenprobabilitydistributions, the cross-entropy loss function may not be a good choice here.
On the one hand, as we mentioned in Section 15.2, the cost of properly normalizing ğ‘ ğ‘–ğ‘— results in the sum over 713 Word Embeddingwith Global Vectors(Glo Ve) theentirevocabulary, whichcanbecomputationallyexpensive.
Ontheotherhand, alarge numberofrareeventsfromalargecorpusareoftenmodeledbythecross-entropylossto beassignedwithtoomuchweight.
15.5.2 The Glo Ve Model In view of this, the Glo Ve model makes three changes to the skip-gram model based on squaredloss(Penningtonetal.,2014): 1.
Use variables ğ‘ ğ‘– 0 ğ‘— = ğ‘¥ ğ‘–ğ‘— and ğ‘ ğ‘– 0 ğ‘— = expâ€u> ğ‘— vğ‘– â€ that are not p robability distribu tions 2 and take the logarithm of both, so the squared loss term is log ğ‘0 log ğ‘0 = ğ‘–ğ‘— ğ‘–ğ‘— 2 u> ğ‘— vğ‘– log ğ‘¥ ğ‘–ğ‘— .
2.
Add two scalar model parameters for each word ğ‘¤ ğ‘–: the center word bias ğ‘ ğ‘– and the contextwordbiasğ‘ ğ‘–.
3.
Replace the weight of each loss term with the weight function â„â€ğ‘¥ ğ‘–ğ‘— â€, where â„â€ğ‘¥â€ is increasingintheintervalof Â»0,1â€¦.
Puttingallthingstogether, training Glo Veistominimizethefollowinglossfunction: 2 â„â€ğ‘¥ ğ‘–ğ‘— â€ u > ğ‘— vğ‘– â€šğ‘ ğ‘– â€šğ‘ ğ‘— log ğ‘¥ ğ‘–ğ‘— .
(15.5.4) ğ‘–2V ğ‘—2V Fortheweightfunction, asuggestedchoiceis: â„â€ğ‘¥â€ = â€ğ‘¥ ğ‘â€ğ›¼ (e.
gğ›¼ =0.75)ifğ‘¥ < ğ‘(e.
g., ğ‘ =100); otherwiseâ„â€ğ‘¥â€ =1.
Inthiscase, becauseâ„â€0â€ =0, thesquaredlosstermforany ğ‘¥ ğ‘–ğ‘— = 0canbeomittedforcomputationalefficiency.
Forexample, whenusingminibatch stochasticgradientdescentfortraining, ateachiterationwerandomlysampleaminibatch of non-zero ğ‘¥ ğ‘–ğ‘— to calculate gradients and update the model parameters.
Note that these non-zeroğ‘¥ ğ‘–ğ‘— areprecomputedglobalcorpusstatistics; thus, themodeliscalled Glo Vefor Global Vectors.
Itshouldbeemphasizedthatifword ğ‘¤ ğ‘– appearsinthecontextwindowofword ğ‘¤ ğ‘—, then vice versa.
Therefore, ğ‘¥ ğ‘–ğ‘— = ğ‘¥ ğ‘—ğ‘–.
Unlike word2vec that fits the asymmetric conditional probability ğ‘ ğ‘–ğ‘—, Glo Ve fits the symmetric log ğ‘¥ ğ‘–ğ‘—.
Therefore, the center word vector and the context word vector of any word are mathematically equivalent in the Glo Ve model.
However in practice, owing to different initialization values, the same word may still get different values in these two vectors after training: Glo Ve sums them up as the output vector.
15.5.3 Interpreting Glo Vefromthe Ratioof Co-occurrence Probabilities Wecanalsointerpretthe Glo Vemodelfromanotherperspective.
Usingthesamenotation in Section15.5.1, let ğ‘ ğ‘–ğ‘— d = ef ğ‘ƒâ€ğ‘¤ ğ‘— j ğ‘¤ ğ‘– â€ betheconditionalprobabilityofgeneratingthe context word ğ‘¤ ğ‘— given ğ‘¤ ğ‘– as the center word in the corpus.
tab_glove lists several co- occurrenceprobabilitiesgivenwordsâ€œiceâ€andâ€œsteamâ€andtheirratiosbasedonstatistics fromalargecorpus.
714 Natural Language Processing: Pretraining : Word-wordco-occurrenceprobabilitiesandtheirratiosfromalargecorpus(adaptedfrom Table1in Penningtonetal.
(2014)) Table 15.5.1: label: tab_glove ğ‘¤ ğ‘˜= solid gas water fashion ğ‘ 1 = ğ‘ƒâ€ğ‘¤ ğ‘˜ j iceâ€ 0.00019 0.000066 0.003 0.000017 ğ‘ 2 = ğ‘ƒâ€ğ‘¤ ğ‘˜ j steamâ€ 0.000022 0.00078 0.0022 0.000018 ğ‘ ğ‘ 8.9 0.085 1.36 0.96 1 2 Wecanobservethefollowingfromtab_glove: Forawordğ‘¤ ğ‘˜ thatisrelatedtoâ€œiceâ€butunrelatedtoâ€œsteamâ€, suchasğ‘¤ ğ‘˜ = solid, we expectalargerratioofco-occurenceprobabilities, suchas8.9.
For a word ğ‘¤ ğ‘˜ that is related to â€œsteamâ€ but unrelated to â€œiceâ€, such as ğ‘¤ ğ‘˜ = gas, we expectasmallerratioofco-occurenceprobabilities, suchas0.085.
Forawordğ‘¤ ğ‘˜ thatisrelatedtobothâ€œiceâ€andâ€œsteamâ€, suchasğ‘¤ ğ‘˜ = water, weexpect aratioofco-occurenceprobabilitiesthatiscloseto1, suchas1.36.
For a word ğ‘¤ ğ‘˜ that is unrelated to both â€œiceâ€ and â€œsteamâ€, such as ğ‘¤ ğ‘˜ = fashion, we expectaratioofco-occurenceprobabilitiesthatiscloseto1, suchas0.96.
Itcanbeseenthattheratioofco-occurrenceprobabilitiescanintuitivelyexpresstherela- tionship between words.
Thus, we can design a function of three word vectors to fit this ratio.
Fortheratioofco-occurrenceprobabilitiesğ‘ ğ‘–ğ‘— ğ‘ ğ‘–ğ‘˜withğ‘¤ ğ‘–beingthecenterwordand ğ‘¤ ğ‘— andğ‘¤ ğ‘˜ beingthecontextwords, wewanttofitthisratiousingsomefunction ğ‘“: ğ‘ ğ‘–ğ‘— ğ‘“â€uğ‘— , uğ‘˜ , vğ‘– â€ ğ‘ .
(15.5.5) ğ‘–ğ‘˜ Among many possible designs for ğ‘“, we only pick a reasonable choice in the following.
Since the ratio of co-occurrence probabilities is a scalar, we require that ğ‘“ be a scalar function, such as ğ‘“â€uğ‘— , uğ‘˜ , vğ‘– â€ = ğ‘“ â€uğ‘— uğ‘˜ â€>vğ‘– .
Switching word indices ğ‘— and ğ‘˜ in (15.5.5), itmustholdthat ğ‘“â€ğ‘¥â€ğ‘“â€ ğ‘¥â€ =1, soonepossibilityis ğ‘“â€ğ‘¥â€ =expâ€ğ‘¥â€, i.
e., exp u> ğ‘— vğ‘– ğ‘ ğ‘–ğ‘— ğ‘“â€uğ‘— , uğ‘˜ , vğ‘– â€ = ğ‘ .
(15.5.6) exp u> ğ‘˜ vğ‘– ğ‘–ğ‘˜ Nowletâ€™spickexp u> ğ‘— vğ‘– ğ›¼ğ‘ ğ‘–ğ‘—, whereğ›¼isaconstant.
Since ğ‘ ğ‘–ğ‘— =ğ‘¥ ğ‘–ğ‘— ğ‘¥ ğ‘–, aftertaking thelogarithmonbothsideswegetu> ğ‘— vğ‘– log ğ›¼â€šlog ğ‘¥ ğ‘–ğ‘— log ğ‘¥ ğ‘–.
Wemayuseadditional biastermstofit log ğ›¼â€šlog ğ‘¥ ğ‘–, suchasthecenterwordbiasğ‘ ğ‘– andthecontextwordbias ğ‘ ğ‘—: u > ğ‘— vğ‘– â€šğ‘ ğ‘– â€šğ‘ ğ‘— log ğ‘¥ ğ‘–ğ‘— .
(15.5.7) Measuringthesquarederrorof(15.5.7)withweights, the Glo Velossfunctionin(15.5.4) isobtained.
715 Subword Embedding 15.5.4 Summary Theskip-grammodelcanbeinterpretedusingglobalcorpusstatisticssuchasword-word co-occurrencecounts.
The cross-entropy loss may not be a good choice for measuring the difference of two probabilitydistributions, especiallyforalargecorpus.
Glo Veusessquaredlosstofit precomputedglobalcorpusstatistics.
The center word vector and the context word vector are mathematically equivalent for anywordin Glo Ve.
Glo Vecanbeinterpretedfromtheratioofword-wordco-occurrenceprobabilities.
15.5.5 Exercises 1.
Ifwordsğ‘¤ ğ‘–andğ‘¤ ğ‘— co-occurinthesamecontextwindow, howcanweusetheirdistance inthetextsequencetoredesignthemethodforcalculatingtheconditionalprobability ğ‘ ğ‘–ğ‘—? Hint: see Section4.2ofthe Glo Vepaper(Penningtonetal.,2014).
2.
Foranyword, areitscenterwordbiasandcontextwordbiasmathematicallyequivalent in Glo Ve? Why? Discussions233.
233 15.6 Subword Embedding In English, wordssuchasâ€œhelpsâ€,â€œhelpedâ€, andâ€œhelpingâ€areinflectedformsofthesame wordâ€œhelpâ€.
Therelationshipbetweenâ€œdogâ€andâ€œdogsâ€isthesameasthatbetweenâ€œcatâ€ andâ€œcatsâ€, andtherelationshipbetweenâ€œboyâ€andâ€œboyfriendâ€isthesameasthatbetween â€œgirlâ€andâ€œgirlfriendâ€.
Inotherlanguagessuchas Frenchand Spanish, manyverbshave over40inflectedforms, whilein Finnish, anounmayhaveupto15cases.
Inlinguistics, morphologystudieswordformationandwordrelationships.
However, theinternalstructure ofwordswasneitherexploredinword2vecnorin Glo Ve.
15.6.1 Thefast Text Model Recallhowwordsarerepresentedinword2vec.
Inboththeskip-grammodelandthecon- tinuousbag-of-wordsmodel, differentinflectedformsofthesamewordaredirectlyrepre- sentedbydifferentvectorswithoutsharedparameters.
Tousemorphologicalinformation, thefast Textmodelproposedasubwordembeddingapproach, whereasubwordisacharac- terğ‘›-gram(Bojanowskietal.,2017).
Insteadoflearningword-levelvectorrepresentations, fast Textcanbeconsideredasthesubword-levelskip-gram, whereeachcenterwordisrep- resentedbythesumofitssubwordvectors.
Letâ€™s illustrate how to obtain subwords for each center word in fast Text using the word 716 Natural Language Processing: Pretraining â€œwhereâ€.
First, add special characters â€œ<â€ and â€œ>â€ at the beginning and end of the word todistinguishprefixesandsuffixesfromothersubwords.
Then, extractcharacterğ‘›-grams from the word.
For example, when ğ‘› = 3, we obtain all subwords of length 3: â€œ<whâ€, â€œwheâ€,â€œherâ€,â€œereâ€,â€œre>â€, andthespecialsubwordâ€œ<where>â€.
Infast Text, foranywordğ‘¤, denoteby G ğ‘¤ theunionofallitssubwordsoflengthbetween 3and6anditsspecialsubword.
Thevocabularyistheunionofthesubwordsofallwords.
Lettingzğ‘”bethevectorofsubwordğ‘”inthedictionary, thevectorvğ‘¤forwordğ‘¤asacenter wordintheskip-grammodelisthesumofitssubwordvectors: vğ‘¤ = zğ‘” .
(15.6.1) ğ‘”2Gğ‘¤ The rest of fast Text is the same as the skip-gram model.
Compared with the skip-gram model, thevocabularyinfast Textislarger, resultinginmoremodelparameters.
Besides, tocalculatetherepresentationofaword, allitssubwordvectorshavetobesummed, leading tohighercomputationalcomplexity.
However, thankstosharedparametersfromsubwords among words with similar structures, rare words and even out-of-vocabulary words may obtainbettervectorrepresentationsinfast Text.
15.6.2 Byte Pair Encoding Infast Text, alltheextractedsubwordshavetobeofthespecifiedlengths, suchas3to6, thus the vocabulary size cannot be predefined.
To allow for variable-length subwords in afixed-sizevocabulary, wecanapplyacompressionalgorithmcalledbytepairencoding (BPE)toextractsubwords(Sennrichetal.,2015).
Bytepairencodingperformsastatisticalanalysisofthetrainingdatasettodiscovercom- mon symbols within a word, such as consecutive characters of arbitrary length.
Starting fromsymbolsoflength1, bytepairencodingiterativelymergesthemostfrequentpairof consecutivesymbolstoproducenewlongersymbols.
Notethatforefficiency, pairscross- ingwordboundariesarenotconsidered.
Intheend, wecanusesuchsymbolsassubwords tosegmentwords.
Bytepairencodinganditsvariantshasbeenusedforinputrepresenta- tions in popular natural language processing pretraining models such as GPT-2 (Radford etal.,2019)and Ro BERTa(Liuetal.,2019).
Inthefollowing, wewillillustratehowbyte pairencodingworks.
First, we initialize the vocabulary of symbols as all the English lowercase characters, a specialend-of-wordsymbol'_', andaspecialunknownsymbol'[UNK]'.
import collections symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]'] Since we do not consider symbol pairs that cross boundaries of words, we only need a dictionaryraw_token_freqsthatmapswordstotheirfrequencies(numberofoccurrences) in a dataset.
Note that the special symbol '_' is appended to each word so that we can 717 Subword Embedding easily recover a word sequence (e.
g., â€œa taller manâ€) from a sequence of output symbols ( e.
g., â€œa_ tall er_ manâ€).
Since we start the merging process from a vocabulary of only singlecharactersandspecialsymbols, spaceisinsertedbetweeneverypairofconsecutive characterswithineachword(keysofthedictionarytoken_freqs).
Inotherwords, space isthedelimiterbetweensymbolswithinaword.
raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4} token_freqs = {} for token, freq in raw_token_freqs.
items(): token_freqs[' '.
join(list(token))] = raw_token_freqs[token] token_freqs {'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4} Wedefinethefollowingget_max_freq_pairfunctionthatreturnsthemostfrequentpair ofconsecutivesymbolswithinaword, wherewordscomefromkeysoftheinputdictionary token_freqs.
def get_max_freq_pair(token_freqs): pairs = collections.
defaultdict(int) for token, freq in token_freqs.
items(): symbols = token.
split() for i in range(len(symbols) - 1): # Key of `pairs` is a tuple of two consecutive symbols pairs[symbols[i], symbols[i + 1]] += freq return max(pairs, key=pairs.
get) # Key of `pairs` with the max value Asagreedyapproachbasedonfrequencyofconsecutivesymbols, bytepairencodingwill usethefollowingmerge_symbolsfunctiontomergethemostfrequentpairofconsecutive symbolstoproducenewsymbols.
def merge_symbols(max_freq_pair, token_freqs, symbols): symbols.
append(''.
join(max_freq_pair)) new_token_freqs = dict() for token, freq in token_freqs.
items(): new_token = token.
replace(' '.
join(max_freq_pair), ''.
join(max_freq_pair)) new_token_freqs[new_token] = token_freqs[token] return new_token_freqs Nowweiterativelyperformthebytepairencodingalgorithmoverthekeysofthedictionary token_freqs.
Inthefirstiteration, themostfrequentpairofconsecutivesymbolsare't' and 'a', thus byte pair encoding merges them to produce a new symbol 'ta'.
In the seconditeration, bytepairencodingcontinuestomerge'ta'and'l'toresultinanother newsymbol'tal'.
num_merges = 10 for i in range(num_merges): (continuesonnextpage) 718 Natural Language Processing: Pretraining (continuedfrompreviouspage) max_freq_pair = get_max_freq_pair(token_freqs) token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols) print(f'merge #{i + 1}:', max_freq_pair) merge #1: ('t', 'a') merge #2: ('ta', 'l') merge #3: ('tal', 'l') merge #4: ('f', 'a') merge #5: ('fa', 's') merge #6: ('fas', 't') merge #7: ('e', 'r') merge #8: ('er', '_') merge #9: ('tall', '_') merge #10: ('fast', '_') After 10 iterations of byte pair encoding, we can see that list symbols now contains 10 moresymbolsthatareiterativelymergedfromothersymbols.
print(symbols) ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p â†©!', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal â†©!', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_'] Forthesamedatasetspecifiedinthekeysofthedictionaryraw_token_freqs, eachword inthedatasetisnowsegmentedbysubwordsâ€œfast_â€,â€œfastâ€,â€œer_â€,â€œtall_â€, andâ€œtallâ€asa resultofthebytepairencodingalgorithm.
Forinstance, wordsâ€œfaster_â€andâ€œtaller_â€are segmentedasâ€œfaster_â€andâ€œtaller_â€, respectively.
print(list(token_freqs.
keys())) ['fast_', 'fast er_', 'tall_', 'tall er_'] Notethattheresultofbytepairencodingdependsonthedatasetbeingused.
Wecanalso use the subwords learned from one dataset to segment words of another dataset.
As a greedyapproach, thefollowingsegment_BPEfunctiontriestobreakwordsintothelongest possiblesubwordsfromtheinputargumentsymbols.
def segment_BPE(tokens, symbols): outputs = [] for token in tokens: start, end = 0, len(token) cur_output = [] # Segment token with the longest possible subwords from symbols while start < len(token) and start < end: if token[start: end] in symbols: (continuesonnextpage) 719 Subword Embedding (continuedfrompreviouspage) cur_output.
append(token[start: end]) start = end end = len(token) else: end -= 1 if start < len(token): cur_output.
append('[UNK]') outputs.
append(' '.
join(cur_output)) return outputs Inthefollowing, weusethesubwordsinlistsymbols, whichislearnedfromtheaforemen- tioneddataset, tosegmenttokensthatrepresentanotherdataset.
tokens = ['tallest_', 'fatter_'] print(segment_BPE(tokens, symbols)) ['tall e s t _', 'fa t t er_'] 15.6.3 Summary Thefast Textmodelproposesasubwordembeddingapproach.
Basedontheskip-gram modelinword2vec, itrepresentsacenterwordasthesumofitssubwordvectors.
Bytepairencodingperformsastatisticalanalysisofthetrainingdatasettodiscovercom- mon symbols within a word.
As a greedy approach, byte pair encoding iteratively mergesthemostfrequentpairofconsecutivesymbols.
Subwordembeddingmayimprovethequalityofrepresentationsofrarewordsandout- of-dictionarywords.
15.6.4 Exercises 1.
Asanexample, thereareabout3 108 possible6-gramsin English.
Whatistheissue whentherearetoomanysubwords? Howtoaddresstheissue? Hint: refertotheendof Section3.2ofthefast Textpaper(Bojanowskietal.,2017).
2.
How to design a subword embedding model based on the continuous bag-of-words model? 3.
Togetavocabularyofsizeğ‘š, howmanymergingoperationsareneededwhentheinitial symbolvocabularysizeisğ‘›? 234 4.
Howtoextendtheideaofbytepairencodingtoextractphrases? Discussions234.
720 Natural Language Processing: Pretraining 15.7 Word Similarity and Analogy In Section 15.4, we trained a word2vec model on a small dataset, and applied it to find semanticallysimilarwordsforaninputword.
Inpractice, wordvectorsthatarepretrained on large corpora can be applied to downstream natural language processing tasks, which willbecoveredlaterin Chapter16.
Todemonstratesemanticsofpretrainedwordvectors from large corpora in a straightforward way, letâ€™s apply them in the word similarity and analogytasks.
import os import torch from torch import nn from d2l import torch as d2l 15.7.1 Loading Pretrained Word Vectors Below lists pretrained Glo Ve embeddings of dimension 50, 100, and 300, which can be downloadedfromthe Glo Vewebsite235.
Thepretrainedfast Textembeddingsareavailable 235 inmultiplelanguages.
Hereweconsiderone Englishversion(300-dimensionalâ€œwiki.
enâ€) thatcanbedownloadedfromthefast Textwebsite236.
#@save '0b8703943ccdb6eb788e6f091b8946e82231bc4d') #@save 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a') #@save 'b5116e234e9eb9076672cfeabf5469f3eec904fa') #@save 'c1816da3821ae9f43899be655002f6c723e91b88') Toloadthesepretrained Glo Veandfast Textembeddings, wedefinethefollowing Token- Embeddingclass.
#@save class Token Embedding: """Token Embedding.""" def __init__(self, embedding_name): self.
idx_to_token, self.
idx_to_vec = self._load_embedding( embedding_name) self.
unknown_idx = 0 (continuesonnextpage) 721 Word Similarityand Analogy (continuedfrompreviouspage) self.
token_to_idx = {token: idx for idx, token in enumerate(self.
idx_to_token)} def _load_embedding(self, embedding_name): idx_to_token, idx_to_vec = ['<unk>'], [] data_dir = d2l.
download_extract(embedding_name) # Glo Ve website: https://nlp.
stanford.
edu/projects/glove/ # fast Text website: https://fasttext.
cc/ with open(os.
path.
join(data_dir, 'vec.
txt'), 'r') as f: for line in f: elems = line.
rstrip().
split(' ') token, elems = elems[0], [float(elem) for elem in elems[1:]] # Skip header information, such as the top row in fast Text if len(elems) > 1: idx_to_token.
append(token) idx_to_vec.
append(elems) idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec return idx_to_token, torch.
tensor(idx_to_vec) def __getitem__(self, tokens): indices = [self.
token_to_idx.
get(token, self.
unknown_idx) for token in tokens] vecs = self.
idx_to_vec[torch.
tensor(indices)] return vecs def __len__(self): return len(self.
idx_to_token) Below we load the 50-dimensional Glo Ve embeddings (pretrained on a Wikipedia sub- set).
Whencreatingthe Token Embeddinginstance, thespecifiedembeddingfilehastobe downloadedifitwasnotyet.
glove_6b50d = Token Embedding('glove.6b.50d') Outputthevocabularysize.
Thevocabularycontains400000words(tokens)andaspecial unknowntoken.
len(glove_6b50d) 400001 Wecangettheindexofawordinthevocabulary, andviceversa.
glove_6b50d.
token_to_idx['beautiful'], glove_6b50d.
idx_to_token[3367] 722 Natural Language Processing: Pretraining (3367, 'beautiful') 15.7.2 Applying Pretrained Word Vectors Usingtheloaded Glo Vevectors, wewilldemonstratetheirsemanticsbyapplyingthemin thefollowingwordsimilarityandanalogytasks.
Word Similarity Similar to Section 15.4.3, in order to find semantically similar words for an input word based on cosine similarities between word vectors, we implement the following knn (ğ‘˜- nearestneighbors)function.
def knn(W, x, k): # Add 1e-9 for numerical stability cos = torch.
mv(W, x.
reshape(-1,)) / ( torch.
sqrt(torch.
sum(W * W, axis=1) + 1e-9) * torch.
sqrt((x * x).
sum())) _, topk = torch.
topk(cos, k=k) return topk, [cos[int(i)] for i in topk] Then, we search for similar words using the pretrained word vectors from the Token Em- beddinginstanceembed.
def get_similar_tokens(query_token, k, embed): topk, cos = knn(embed.
idx_to_vec, embed[[query_token]], k + 1) for i, c in zip(topk[1:], cos[1:]): # Exclude the input word print(f'cosine sim={float(c):.3f}: {embed.
idx_to_token[int(i)]}') The vocabulary of the pretrained word vectors in glove_6b50d contains 400000 words andaspecialunknowntoken.
Excludingtheinputwordandunknowntoken, amongthis vocabularyletâ€™sfindthreemostsemanticallysimilarwordstowordâ€œchipâ€.
get_similar_tokens('chip', 3, glove_6b50d) cosine sim=0.856: chips cosine sim=0.749: intel cosine sim=0.749: electronics Belowoutputssimilarwordstoâ€œbabyâ€andâ€œbeautifulâ€.
get_similar_tokens('baby', 3, glove_6b50d) cosine sim=0.839: babies cosine sim=0.800: boy cosine sim=0.792: girl 723 Word Similarityand Analogy get_similar_tokens('beautiful', 3, glove_6b50d) cosine sim=0.921: lovely cosine sim=0.893: gorgeous cosine sim=0.830: wonderful Word Analogy Besidesfindingsimilarwords, wecanalsoapplywordvectorstowordanalogytasks.
For example, â€œmanâ€:â€œwomanâ€::â€œsonâ€:â€œdaughterâ€ is the form of a word analogy: â€œmanâ€ is to â€œwomanâ€asâ€œsonâ€istoâ€œdaughterâ€.
Specifically, thewordanalogycompletiontaskcanbe definedas: forawordanalogyğ‘ : ğ‘ :: ğ‘ : ğ‘‘, giventhefirstthreewordsğ‘,ğ‘andğ‘, findğ‘‘.
Denotethevectorofword ğ‘¤ byvecâ€ğ‘¤â€.
Tocompletetheanalogy, wewillfindtheword whosevectorismostsimilartotheresultofvecâ€ğ‘â€â€švecâ€ğ‘â€ vecâ€ğ‘â€.
def get_analogy(token_a, token_b, token_c, embed): vecs = embed[[token_a, token_b, token_c]] x = vecs[1] - vecs[0] + vecs[2] topk, cos = knn(embed.
idx_to_vec, x, 1) return embed.
idx_to_token[int(topk[0])] # Remove unknown words Letâ€™sverifytheâ€œmale-femaleâ€analogyusingtheloadedwordvectors.
get_analogy('man', 'woman', 'son', glove_6b50d) 'daughter' Below completes a â€œcapital-countryâ€ analogy: â€œbeijingâ€:â€œchinaâ€::â€œtokyoâ€:â€œjapanâ€.
This demonstratessemanticsinthepretrainedwordvectors.
get_analogy('beijing', 'china', 'tokyo', glove_6b50d) 'japan' For the â€œadjective-superlative adjectiveâ€ analogy such as â€œbadâ€:â€œworstâ€::â€œbigâ€:â€œbiggestâ€, wecanseethatthepretrainedwordvectorsmaycapturethesyntacticinformation.
get_analogy('bad', 'worst', 'big', glove_6b50d) 'biggest' Toshowthecapturednotionofpasttenseinthepretrainedwordvectors, wecantestthe syntaxusingtheâ€œpresenttense-pasttenseâ€analogy: â€œdoâ€:â€œdidâ€::â€œgoâ€:â€œwentâ€.
724 Natural Language Processing: Pretraining get_analogy('do', 'did', 'go', glove_6b50d) 'went' 15.7.3 Summary In practice, word vectors that are pretrained on large corpora can be applied to down- streamnaturallanguageprocessingtasks.
Pretrainedwordvectorscanbeappliedtothewordsimilarityandanalogytasks.
15.7.4 Exercises 1.
Testthefast Textresultsusing Token Embedding('wiki.
en').
2.
Whenthevocabularyisextremelylarge, howcanwefindsimilarwordsorcompletea wordanalogyfaster? 237 Discussions237.
15.8 Bidirectional Encoder Representations from Transformers (BERT) Wehaveintroducedseveralwordembeddingmodelsfornaturallanguageunderstanding.
Afterpretraining, theoutputcanbethoughtofasamatrixwhereeachrowisavectorthat representsawordofapredefinedvocabulary.
Infact, thesewordembeddingmodelsare allcontext-independent.
Letâ€™sbeginbyillustratingthisproperty.
15.8.1 From Context-Independentto Context-Sensitive Recalltheexperimentsin Section15.4and Section15.7.
Forinstance, word2vecand Glo Ve both assign the same pretrained vector to the same word regardless of the context of the word (if any).
Formally, a context-independent representation of any token ğ‘¥ is a func- tion ğ‘“â€ğ‘¥â€ that only takes ğ‘¥ as its input.
Given the abundance of polysemy and complex semanticsinnaturallanguages, context-independentrepresentationshaveobviouslimita- tions.
For instance, the word â€œcraneâ€ in contexts â€œa crane is flyingâ€ and â€œa crane driver cameâ€hascompletelydifferentmeanings; thus, thesamewordmaybeassigneddifferent representationsdependingoncontexts.
Thismotivatesthedevelopmentofcontext-sensitivewordrepresentations, whererepresen- tations of words depend on their contexts.
Hence, a context-sensitive representation of 725 Bidirectional Encoder Representationsfrom Transformers(BERT) tokenğ‘¥isafunction ğ‘“â€ğ‘¥,ğ‘â€ğ‘¥â€â€dependingonbothğ‘¥anditscontextğ‘â€ğ‘¥â€.
Popularcontext- sensitiverepresentationsinclude Tag LM(language-model-augmentedsequencetagger)(Pe- tersetal.,2017), Co Ve(Context Vectors)(Mc Cannetal.,2017), and ELMo(Embeddings from Language Models)(Petersetal.,2018).
Forexample, bytakingtheentiresequenceasinput, ELMoisafunctionthatassignsarep- resentation to each word from the input sequence.
Specifically, ELMo combines all the intermediatelayerrepresentationsfrompretrainedbidirectional LSTMastheoutputrep- resentation.
Thenthe ELMorepresentationwillbeaddedtoadownstreamtaskâ€™sexisting supervised model as additional features, such as by concatenating ELMo representation andtheoriginalrepresentation(e.
g., Glo Ve)oftokensintheexistingmodel.
Ontheone hand, alltheweightsinthe pretrainedbidirectional LSTMmodelarefrozenafter ELMo representationsareadded.
Ontheotherhand, theexistingsupervisedmodelisspecifically customized for a given task.
Leveraging different best models for different tasks at that time, adding ELMo improved the state of the art across six natural language processing tasks: sentimentanalysis, naturallanguageinference, semanticrolelabeling, coreference resolution, namedentityrecognition, andquestionanswering.
15.8.2 From Task-Specificto Task-Agnostic Although ELMohassignificantlyimprovedsolutionstoadiversesetofnaturallanguage processing tasks, each solution still hinges on a task-specific architecture.
However, it is practicallynon-trivialtocraftaspecificarchitectureforeverynaturallanguageprocessing task.
The GPT(Generative Pre-Training)modelrepresentsaneffortindesigningageneral task-agnosticmodelforcontext-sensitiverepresentations(Radfordetal.,2018).
Builton a Transformerdecoder, GPTpretrainsalanguagemodelthatwillbeusedtorepresenttext sequences.
Whenapplying GPTtoadownstreamtask, theoutputofthelanguagemodel willbefedintoanaddedlinearoutputlayertopredictthelabelofthetask.
Insharpcontrast to ELMothatfreezesparametersofthepretrainedmodel, GPTfine-tunesalltheparame- tersinthepretrained Transformerdecoderduringsupervisedlearningofthedownstream task.
GPTwasevaluatedontwelvetasksofnaturallanguageinference, questionanswer- ing, sentencesimilarity, andclassification, andimprovedthestateoftheartinnineofthem withminimalchangestothemodelarchitecture.
However, due to the autoregressive nature of language models, GPT only looks forward (left-to-right).
In contexts â€œi went to the bank to deposit cashâ€ and â€œi went to the bank to sit downâ€, as â€œbankâ€ is sensitive to the context to its left, GPT will return the same representationforâ€œbankâ€, thoughithasdifferentmeanings.
15.8.3 BERT: Combiningthe Bestof Both Worlds Aswehaveseen, ELMoencodescontextbidirectionallybutusestask-specificarchitectures; while GPTistask-agnosticbutencodescontextleft-to-right.
Combiningthebestofboth worlds, BERT (Bidirectional Encoder Representations from Transformers) encodes con- textbidirectionallyandrequiresminimalarchitecturechangesforawiderangeofnatural languageprocessingtasks(Devlinetal.,2018).
Usingapretrained Transformerencoder, BERTisabletorepresentanytokenbasedonitsbidirectionalcontext.
Duringsupervised 726 Natural Language Processing: Pretraining learning of downstream tasks, BERT is similar to GPT in two aspects.
First, BERT rep- resentations will be fed into an added output layer, with minimal changes to the model architecturedependingonnatureoftasks, suchaspredictingforeverytokenvs.
predicting fortheentiresequence.
Second, alltheparametersofthepretrained Transformerencoder arefine-tuned, whiletheadditionaloutputlayerwillbetrainedfromscratch.
.8.1 depictsthedifferencesamong ELMo, GPT, and BERT.
t .8.1 Acomparisonof ELMo, GPT, and BERT.
BERT further improved the state of the art on eleven natural language processing tasks underbroadcategoriesof(i)singletextclassification(e.
g., sentimentanalysis),(ii)textpair classification(e.
g., naturallanguageinference),(iii)questionanswering,(iv)texttagging (e.
g., named entity recognition).
All proposed in 2018, from context-sensitive ELMo to task-agnostic GPTand BERT, conceptuallysimpleyetempiricallypowerfulpretrainingof deeprepresentationsfornaturallanguageshaverevolutionizedsolutionstovariousnatural languageprocessingtasks.
Intherestofthischapter, wewilldiveintothepretrainingof BERT.
Whennaturallanguage processingapplicationsareexplainedin Chapter16, wewillillustratefine-tuningof BERT fordownstreamapplications.
import torch from torch import nn from d2l import torch as d2l 15.8.4 Input Representation In natural language processing, some tasks (e.
g., sentiment analysis) take single text as input, while in some other tasks (e.
g., natural language inference), the input is a pair of textsequences.
The BERTinputsequenceunambiguouslyrepresentsbothsingletextand text pairs.
In the former, the BERT input sequence is the concatenation of the special classification token â€œ<cls>â€, tokens of a text sequence, and the special separation token â€œ<sep>â€.
In the latter, the BERT input sequence is the concatenation of â€œ<cls>â€, tokens ofthefirsttextsequence,â€œ<sep>â€, tokensofthesecondtextsequence, andâ€œ<sep>â€.
We willconsistentlydistinguishtheterminologyâ€œBERTinputsequenceâ€fromothertypesof 727 Bidirectional Encoder Representationsfrom Transformers(BERT) â€œsequencesâ€.
Forinstance, one BERTinputsequencemayincludeeitheronetextsequence ortwotextsequences.
To distinguish text pairs, the learned segment embeddings eğ´ and eğµ are added to the tokenembeddingsofthefirstsequenceandthesecondsequence, respectively.
Forsingle textinputs, onlyeğ´isused.
Thefollowingget_tokens_and_segmentstakeseitheronesentenceortwosentencesas input, then returns tokens of the BERT input sequence and their corresponding segment IDs.
#@save def get_tokens_and_segments(tokens_a, tokens_b=None): """Get tokens of the BERT input sequence and their segment IDs.""" tokens = ['<cls>'] + tokens_a + ['<sep>'] # 0 and 1 are marking segment A and B, respectively segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + ['<sep>'] segments += [1] * (len(tokens_b) + 1) return tokens, segments BERTchoosesthe Transformerencoderasitsbidirectionalarchitecture.
Commoninthe Transformerencoder, positionalembeddingsareaddedateverypositionofthe BERTinput sequence.
However, differentfromtheoriginal Transformerencoder, BERTuseslearnable positional embeddings.
To sum up, .8.2 shows that the embeddings of the BERT inputsequencearethesumofthetokenembeddings, segmentembeddings, andpositional embeddings.
t .8.2 Theembeddingsofthe BERTinputsequencearethesumofthetokenembeddings, segmentembeddings, andpositionalembeddings.
Thefollowing BERTEncoderclassissimilartothe Transformer Encoderclassasimple- mentedin Section11.7.
Differentfrom Transformer Encoder, BERTEncoderusessegment embeddingsandlearnablepositionalembeddings.
#@save class BERTEncoder(nn.
Module): """BERT encoder.""" def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, max_len=1000, **kwargs): (continuesonnextpage) 728 Natural Language Processing: Pretraining (continuedfrompreviouspage) super(BERTEncoder, self).__init__(**kwargs) self.
token_embedding = nn.
Embedding(vocab_size, num_hiddens) self.
segment_embedding = nn.
Embedding(2, num_hiddens) self.
blks = nn.
Sequential() for i in range(num_blks): self.
blks.
add_module(f"{i}", d2l.
Transformer Encoder Block( num_hiddens, ffn_num_hiddens, num_heads, dropout, True)) # In BERT, positional embeddings are learnable, thus we create a # parameter of positional embeddings that are long enough self.
pos_embedding = nn.
Parameter(torch.
randn(1, max_len, num_hiddens)) def forward(self, tokens, segments, valid_lens): # Shape of `X` remains unchanged in the following code snippet: # (batch size, max sequence length, `num_hiddens`) X = self.
token_embedding(tokens) + self.
segment_embedding(segments) X = X + self.
pos_embedding[:, : X.
shape[1], :] for blk in self.
blks: X = blk(X, valid_lens) return X Supposethatthevocabularysizeis10000.
Todemonstrateforwardinferenceof BERTEn- coder, letâ€™screateaninstanceofitandinitializeitsparameters.
vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4 ffn_num_input, num_blks, dropout = 768, 2, 0.2 encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout) Wedefinetokenstobe2BERTinputsequencesoflength8, whereeachtokenisanindex ofthevocabulary.
Theforwardinferenceof BERTEncoderwiththeinputtokensreturns theencodedresultwhereeachtokenisrepresentedbyavectorwhoselengthispredefined by the hyperparameter num_hiddens.
This hyperparameter is usually referred to as the hiddensize(numberofhiddenunits)ofthe Transformerencoder.
tokens = torch.
randint(0, vocab_size, (2, 8)) segments = torch.
tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]]) encoded_X = encoder(tokens, segments, None) encoded_X.
shape torch.
Size([2, 8, 768]) 15.8.5 Pretraining Tasks The forward inference of BERTEncoder gives the BERT representation of each token of the input text and the inserted special tokens â€œ<cls>â€ and â€œ<seq>â€.
Next, we will use theserepresentationstocomputethelossfunctionforpretraining BERT.
Thepretraining is composed of the following two tasks: masked language modeling and next sentence prediction.
729 Bidirectional Encoder Representationsfrom Transformers(BERT) Masked Language Modeling As illustrated in Section 9.3, a language model predicts a token using the context on its left.
Toencodecontextbidirectionallyforrepresentingeachtoken, BERTrandomlymasks tokens and uses tokens from the bidirectional context to predict the masked tokens in a self-supervisedfashion.
Thistaskisreferredtoasamaskedlanguagemodel.
Inthispretrainingtask,15%oftokenswillbeselectedatrandomasthemaskedtokensfor prediction.
To predict a masked token without cheating by using the label, one straight- forwardapproachistoalwaysreplaceitwithaspecialâ€œ<mask>â€tokeninthe BERTinput sequence.
However, theartificialspecialtokenâ€œ<mask>â€willneverappearinfine-tuning.
To avoid such a mismatch between pretraining and fine-tuning, if a token is masked for prediction(e.
g.,â€œgreatâ€isselectedtobemaskedandpredictedinâ€œthismovieisgreatâ€), in theinputitwillbereplacedwith: aspecialâ€œ<mask>â€tokenfor80%ofthetime(e.
g.,â€œthismovieisgreatâ€becomesâ€œthis movieis<mask>â€); arandomtokenfor10%ofthetime(e.
g.,â€œthismovieisgreatâ€becomesâ€œthismovieis drinkâ€); theunchangedlabeltokenfor10%ofthetime(e.
g.,â€œthismovieisgreatâ€becomesâ€œthis movieisgreatâ€).
Notethatfor10%of15%timearandomtokenisinserted.
Thisoccasionalnoiseencourages BERTtobelessbiasedtowardsthemaskedtoken(especiallywhenthelabeltokenremains unchanged)initsbidirectionalcontextencoding.
Weimplementthefollowing Mask LMclasstopredictmaskedtokensinthemaskedlanguage modeltaskof BERTpretraining.
Thepredictionusesaone-hidden-layer MLP(self.
mlp).
Inforwardinference, ittakestwoinputs: theencodedresultof BERTEncoderandthetoken positionsforprediction.
Theoutputisthepredictionresultsatthesepositions.
#@save class Mask LM(nn.
Module): """The masked language model task of BERT.""" def __init__(self, vocab_size, num_hiddens, **kwargs): super(Mask LM, self).__init__(**kwargs) self.
mlp = nn.
Sequential(nn.
Lazy Linear(num_hiddens), nn.
Re LU(), nn.
Layer Norm(num_hiddens), nn.
Lazy Linear(vocab_size)) def forward(self, X, pred_positions): num_pred_positions = pred_positions.
shape[1] pred_positions = pred_positions.
reshape(-1) batch_size = X.
shape[0] batch_idx = torch.
arange(0, batch_size) # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then # `batch_idx` is `torch.
tensor([0, 0, 0, 1, 1, 1])` batch_idx = torch.
repeat_interleave(batch_idx, num_pred_positions) masked_X = X[batch_idx, pred_positions] (continuesonnextpage) 730 Natural Language Processing: Pretraining (continuedfrompreviouspage) masked_X = masked_X.
reshape((batch_size, num_pred_positions, -1)) mlm_Y_hat = self.
mlp(masked_X) return mlm_Y_hat Todemonstratetheforwardinferenceof Mask LM, wecreateitsinstancemlmandinitialize it.
Recallthatencoded_Xfromtheforwardinferenceof BERTEncoderrepresents2BERT inputsequences.
Wedefinemlm_positionsasthe3indicestopredictineither BERTinput sequenceofencoded_X.
Theforwardinferenceofmlmreturnspredictionresultsmlm_Y_hat atallthemaskedpositionsmlm_positionsofencoded_X.
Foreachprediction, thesizeof theresultisequaltothevocabularysize.
mlm = Mask LM(vocab_size, num_hiddens) mlm_positions = torch.
tensor([[1, 5, 2], [6, 1, 5]]) mlm_Y_hat = mlm(encoded_X, mlm_positions) mlm_Y_hat.
shape torch.
Size([2, 3, 10000]) With the ground truth labels mlm_Y of the predicted tokens mlm_Y_hat under masks, we cancalculatethecross-entropylossofthemaskedlanguagemodeltaskin BERTpretrain- ing.
mlm_Y = torch.
tensor([[7, 8, 9], [10, 20, 30]]) loss = nn.
Cross Entropy Loss(reduction='none') mlm_l = loss(mlm_Y_hat.
reshape((-1, vocab_size)), mlm_Y.
reshape(-1)) mlm_l.
shape torch.
Size([6]) Next Sentence Prediction Althoughmaskedlanguagemodelingisabletoencodebidirectionalcontextforrepresent- ingwords, itdoesnotexplicitlymodelthelogicalrelationshipbetweentextpairs.
Tohelp understandtherelationshipbetweentwotextsequences, BERTconsidersabinaryclassi- ficationtask, nextsentenceprediction, initspretraining.
Whengeneratingsentencepairs for pretraining, for half of the time they are indeed consecutive sentences with the label â€œTrueâ€; whilefortheotherhalfofthetimethesecondsentenceisrandomlysampledfrom thecorpuswiththelabelâ€œFalseâ€.
Thefollowing Next Sentence Predclassusesaone-hidden-layer MLPtopredictwhether thesecondsentenceisthenextsentenceofthefirstinthe BERTinputsequence.
Dueto self-attention in the Transformer encoder, the BERT representation of the special token â€œ<cls>â€ encodes both the two sentences from the input.
Hence, the output layer (self.
731 Bidirectional Encoder Representationsfrom Transformers(BERT) output)ofthe MLPclassifiertakes Xasinput, where Xistheoutputofthe MLPhidden layerwhoseinputistheencodedâ€œ<cls>â€token.
#@save class Next Sentence Pred(nn.
Module): """The next sentence prediction task of BERT.""" def __init__(self, **kwargs): super(Next Sentence Pred, self).__init__(**kwargs) self.
output = nn.
Lazy Linear(2) def forward(self, X): # `X` shape: (batch size, `num_hiddens`) return self.
output(X) We can see that the forward inference of an Next Sentence Pred instance returns binary predictionsforeach BERTinputsequence.
# Py Torch by default will not flatten the tensor as seen in mxnet where, if # flatten=True, all but the first axis of input data are collapsed together encoded_X = torch.
flatten(encoded_X, start_dim=1) # input_shape for NSP: (batch size, `num_hiddens`) nsp = Next Sentence Pred() nsp_Y_hat = nsp(encoded_X) nsp_Y_hat.
shape torch.
Size([2, 2]) Thecross-entropylossofthe2binaryclassificationscanalsobecomputed.
nsp_y = torch.
tensor([0, 1]) nsp_l = loss(nsp_Y_hat, nsp_y) nsp_l.
shape torch.
Size([2]) Itisnoteworthythatallthelabelsinboththeaforementionedpretrainingtaskscanbetriv- ially obtained from the pretraining corpus without manual labeling effort.
The original BERThasbeenpretrainedontheconcatenationof Book Corpus(Zhuetal.,2015)and En- glish Wikipedia.
These two text corpora are huge: they have 800 million words and 2.5 billionwords, respectively.
15.8.6 Putting It All Together When pretraining BERT, the final loss function is a linear combination of both the loss functions for masked language modeling and next sentence prediction.
Now we can de- fine the BERTModel class by instantiating the three classes BERTEncoder, Mask LM, and Next Sentence Pred.
Theforwardinferencereturnstheencoded BERTrepresentationsen- 732 Natural Language Processing: Pretraining coded_X, predictionsofmaskedlanguagemodelingmlm_Y_hat, andnextsentencepredic- tionsnsp_Y_hat.
#@save class BERTModel(nn.
Module): """The BERT model.""" def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, max_len=1000): super(BERTModel, self).__init__() self.
encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, max_len=max_len) self.
hidden = nn.
Sequential(nn.
Lazy Linear(num_hiddens), nn.
Tanh()) self.
mlm = Mask LM(vocab_size, num_hiddens) self.
nsp = Next Sentence Pred() def forward(self, tokens, segments, valid_lens=None, pred_positions=None): encoded_X = self.
encoder(tokens, segments, valid_lens) if pred_positions is not None: mlm_Y_hat = self.
mlm(encoded_X, pred_positions) else: mlm_Y_hat = None # The hidden layer of the MLP classifier for next sentence prediction.
# 0 is the index of the '<cls>' token nsp_Y_hat = self.
nsp(self.
hidden(encoded_X[:, 0, :])) return encoded_X, mlm_Y_hat, nsp_Y_hat 15.8.7 Summary Wordembeddingmodelssuchasword2vecand Glo Vearecontext-independent.
They assign the same pretrained vector to the same word regardless of the context of the word (if any).
It is hard for them to handle well polysemy or complex semantics in naturallanguages.
For context-sensitive word representations such as ELMo and GPT, representations of wordsdependontheircontexts.
ELMoencodescontextbidirectionallybutusestask-specificarchitectures(however, itis practicallynon-trivialto craftaspecific architectureforevery naturallanguagepro- cessingtask); while GPTistask-agnosticbutencodescontextleft-to-right.
BERTcombinesthebestofbothworlds: itencodescontextbidirectionallyandrequires minimalarchitecturechangesforawiderangeofnaturallanguageprocessingtasks.
The embeddings of the BERT input sequence are the sum of the token embeddings, segmentembeddings, andpositionalembeddings.
Pretraining BERTiscomposedoftwotasks: maskedlanguagemodelingandnextsen- tenceprediction.
Theformerisabletoencodebidirectionalcontextforrepresenting words, whilethelatterexplicitlymodelsthelogicalrelationshipbetweentextpairs.
733 The Datasetfor Pretraining BERT 15.8.8 Exercises 1.
Allotherthingsbeingequal, willamaskedlanguagemodelrequiremoreorfewerpre- trainingstepstoconvergethanaleft-to-rightlanguagemodel? Why? 2.
Intheoriginalimplementationof BERT, thepositionwisefeed-forwardnetworkin BERTEn- coder(viad2l.
Transformer Encoder Block)andthefullyconnectedlayerin Mask LM bothusethe Gaussianerrorlinearunit(GELU)(Hendrycksand Gimpel, 2016)asthe activationfunction.
Researchintothedifferencebetween GELUand Re LU.
Discussions238.
238 15.9 The Dataset for Pretraining BERT Topretrainthe BERTmodelasimplementedin Section15.8, weneedtogeneratethedataset intheidealformattofacilitatethetwopretrainingtasks: maskedlanguagemodelingand next sentence prediction.
On the one hand, the original BERT model is pretrained on the concatenation of two huge corpora Book Corpus and English Wikipedia (see Section 15.8.5), making it hard to run for most readers of this book.
On the other hand, the off- the-shelf pretrained BERT model may not fit for applications from specific domains like medicine.
Thus, itisgettingpopulartopretrain BERTonacustomizeddataset.
Tofacil- itatethedemonstrationof BERTpretraining, weuseasmallercorpus Wiki Text-2(Merity etal.,2016).
Comparingwiththe PTBdatasetusedforpretrainingword2vecin Section15.3, Wiki Text- 2 (i) retains the original punctuation, making it suitable for next sentence prediction; (ii) retainstheoriginalcaseandnumbers;(iii)isovertwicelarger.
import os import random import torch from d2l import torch as d2l In the Wiki Text-2 dataset, each line represents a paragraph where space is inserted be- tweenanypunctuationanditsprecedingtoken.
Paragraphswithatleasttwosentencesare retained.
To split sentences, we only use the period as the delimiter for simplicity.
We leavediscussionsofmorecomplexsentencesplittingtechniquesintheexercisesattheend ofthissection.
#@save d2l.
DATA_HUB['wikitext-2'] = ( 'https://s3.
amazonaws.
com/research.
metamind.
io/wikitext/' 'wikitext-2-v1.
zip', '3c914d17d80b1459be871a5039ac23e752a53cbe') #@save (continuesonnextpage) 734 Natural Language Processing: Pretraining (continuedfrompreviouspage) def _read_wiki(data_dir): file_name = os.
path.
join(data_dir, 'wiki.
train.
tokens') with open(file_name, 'r') as f: lines = f.
readlines() # Uppercase letters are converted to lowercase ones paragraphs = [line.
strip().
lower().
split(' .
') for line in lines if len(line.
split(' .
')) >= 2] random.
shuffle(paragraphs) return paragraphs 15.9.1 Defining Helper Functionsfor Pretraining Tasks Inthefollowing, webeginbyimplementinghelperfunctionsforthetwo BERTpretraining tasks: next sentence prediction and masked language modeling.
These helper functions will be invoked later when transforming the raw text corpus into the dataset of the ideal formattopretrain BERT.
Generatingthe Next Sentence Prediction Task Accordingtodescriptionsof Section15.8.5, the_get_next_sentencefunctiongenerates atrainingexampleforthebinaryclassificationtask.
#@save def _get_next_sentence(sentence, next_sentence, paragraphs): if random.
random() < 0.5: is_next = True else: # `paragraphs` is a list of lists of lists next_sentence = random.
choice(random.
choice(paragraphs)) is_next = False return sentence, next_sentence, is_next Thefollowingfunctiongeneratestrainingexamplesfornextsentencepredictionfromthe inputparagraphbyinvokingthe_get_next_sentencefunction.
Hereparagraphisalist ofsentences, whereeachsentenceisalistoftokens.
Theargumentmax_lenspecifiesthe maximumlengthofa BERTinputsequenceduringpretraining.
#@save def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len): nsp_data_from_paragraph = [] for i in range(len(paragraph) - 1): tokens_a, tokens_b, is_next = _get_next_sentence( paragraph[i], paragraph[i + 1], paragraphs) # Consider 1 '<cls>' token and 2 '<sep>' tokens if len(tokens_a) + len(tokens_b) + 3 > max_len: continue tokens, segments = d2l.
get_tokens_and_segments(tokens_a, tokens_b) nsp_data_from_paragraph.
append((tokens, segments, is_next)) return nsp_data_from_paragraph 735 The Datasetfor Pretraining BERT Generatingthe Masked Language Modeling Task Inordertogeneratetrainingexamplesforthemaskedlanguagemodelingtaskfroma BERT inputsequence, wedefinethefollowing_replace_mlm_tokensfunction.
Initsinputs, to- kensisalistoftokensrepresentinga BERTinputsequence, candidate_pred_positions isalistoftokenindicesofthe BERTinputsequenceexcludingthoseofspecialtokens(spe- cialtokensarenotpredictedinthemaskedlanguagemodelingtask), andnum_mlm_preds indicatesthenumberofpredictions(recall15%randomtokenstopredict).
Followingthe definitionofthemaskedlanguagemodelingtaskin Section15.8.5, ateachpredictionposi- tion, theinputmaybereplacedbyaspecialâ€œ<mask>â€tokenorarandomtoken, orremain unchanged.
Intheend, thefunctionreturnstheinputtokensafterpossiblereplacement, the tokenindiceswherepredictionstakeplaceandlabelsforthesepredictions.
#@save def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds, vocab): # For the input of a masked language model, make a new copy of tokens and # replace some of them by '<mask>' or random tokens mlm_input_tokens = [token for token in tokens] pred_positions_and_labels = [] # Shuffle for getting 15% random tokens for prediction in the masked # language modeling task random.
shuffle(candidate_pred_positions) for mlm_pred_position in candidate_pred_positions: if len(pred_positions_and_labels) >= num_mlm_preds: break masked_token = None # 80% of the time: replace the word with the '<mask>' token if random.
random() < 0.8: masked_token = '<mask>' else: # 10% of the time: keep the word unchanged if random.
random() < 0.5: masked_token = tokens[mlm_pred_position] # 10% of the time: replace the word with a random word else: masked_token = random.
choice(vocab.
idx_to_token) mlm_input_tokens[mlm_pred_position] = masked_token pred_positions_and_labels.
append( (mlm_pred_position, tokens[mlm_pred_position])) return mlm_input_tokens, pred_positions_and_labels Byinvokingtheaforementioned_replace_mlm_tokensfunction, thefollowingfunction takesa BERTinputsequence(tokens)asaninputandreturnsindicesoftheinputtokens (afterpossibletokenreplacementasdescribedin Section15.8.5), thetokenindiceswhere predictionstakeplace, andlabelindicesforthesepredictions.
#@save def _get_mlm_data_from_tokens(tokens, vocab): candidate_pred_positions = [] # `tokens` is a list of strings for i, token in enumerate(tokens): (continuesonnextpage) 736 Natural Language Processing: Pretraining (continuedfrompreviouspage) # Special tokens are not predicted in the masked language modeling # task if token in ['<cls>', '<sep>']: continue candidate_pred_positions.
append(i) # 15% of random tokens are predicted in the masked language modeling task num_mlm_preds = max(1, round(len(tokens) * 0.15)) mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens( tokens, candidate_pred_positions, num_mlm_preds, vocab) pred_positions_and_labels = sorted(pred_positions_and_labels, key=lambda x: x[0]) pred_positions = [v[0] for v in pred_positions_and_labels] mlm_pred_labels = [v[1] for v in pred_positions_and_labels] return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels] 15.9.2 Transforming Textintothe Pretraining Dataset Nowwearealmostreadytocustomizea Datasetclassforpretraining BERT.
Beforethat, westillneedtodefineahelperfunction_pad_bert_inputstoappendthespecialâ€œ<pad>â€ tokens to the inputs.
Its argument examples contain the outputs from the helper func- tions _get_nsp_data_from_paragraph and _get_mlm_data_from_tokens for the two pretrainingtasks.
#@save def _pad_bert_inputs(examples, max_len, vocab): max_num_mlm_preds = round(max_len * 0.15) all_token_ids, all_segments, valid_lens, = [], [], [] all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], [] nsp_labels = [] for (token_ids, pred_positions, mlm_pred_label_ids, segments, is_next) in examples: all_token_ids.
append(torch.
tensor(token_ids + [vocab['<pad>']] * ( max_len - len(token_ids)), dtype=torch.
long)) all_segments.
append(torch.
tensor(segments + [0] * ( max_len - len(segments)), dtype=torch.
long)) # `valid_lens` excludes count of '<pad>' tokens valid_lens.
append(torch.
tensor(len(token_ids), dtype=torch.
float32)) all_pred_positions.
append(torch.
tensor(pred_positions + [0] * ( max_num_mlm_preds - len(pred_positions)), dtype=torch.
long)) # Predictions of padded tokens will be filtered out in the loss via # multiplication of 0 weights all_mlm_weights.
append( torch.
tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * ( max_num_mlm_preds - len(pred_positions)), dtype=torch.
float32)) all_mlm_labels.
append(torch.
tensor(mlm_pred_label_ids + [0] * ( max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.
long)) nsp_labels.
append(torch.
tensor(is_next, dtype=torch.
long)) return (all_token_ids, all_segments, valid_lens, all_pred_positions, all_mlm_weights, all_mlm_labels, nsp_labels) Puttingthehelperfunctionsforgeneratingtrainingexamplesofthetwopretrainingtasks, 737 The Datasetfor Pretraining BERT and the helper function for padding inputs together, we customize the following _Wiki- Text Datasetclassasthe Wiki Text-2datasetforpretraining BERT.
Byimplementingthe __getitem__function, wecanarbitrarilyaccessthepretraining(maskedlanguagemodel- ing and next sentence prediction) examples generated from a pair of sentences from the Wiki Text-2corpus.
The original BERT model uses Word Piece embeddings whose vocabulary size is 30000 (Wu et al., 2016).
The tokenization method of Word Piece is a slight modification of the original byte pair encoding algorithm in Section 15.6.2.
For simplicity, we use the d2l.
tokenizefunctionfortokenization.
Infrequenttokensthatappearlessthanfivetimesare filteredout.
#@save class _Wiki Text Dataset(torch.
utils.
data.
Dataset): def __init__(self, paragraphs, max_len): # Input `paragraphs[i]` is a list of sentence strings representing a # paragraph; while output `paragraphs[i]` is a list of sentences # representing a paragraph, where each sentence is a list of tokens paragraphs = [d2l.
tokenize( paragraph, token='word') for paragraph in paragraphs] sentences = [sentence for paragraph in paragraphs for sentence in paragraph] self.
vocab = d2l.
Vocab(sentences, min_freq=5, reserved_tokens=[ '<pad>', '<mask>', '<cls>', '<sep>']) # Get data for the next sentence prediction task examples = [] for paragraph in paragraphs: examples.
extend(_get_nsp_data_from_paragraph( paragraph, paragraphs, self.
vocab, max_len)) # Get data for the masked language model task examples = [(_get_mlm_data_from_tokens(tokens, self.
vocab) + (segments, is_next)) for tokens, segments, is_next in examples] # Pad inputs (self.
all_token_ids, self.
all_segments, self.
valid_lens, self.
all_pred_positions, self.
all_mlm_weights, self.
all_mlm_labels, self.
nsp_labels) = _pad_bert_inputs( examples, max_len, self.
vocab) def __getitem__(self, idx): return (self.
all_token_ids[idx], self.
all_segments[idx], self.
valid_lens[idx], self.
all_pred_positions[idx], self.
all_mlm_weights[idx], self.
all_mlm_labels[idx], self.
nsp_labels[idx]) def __len__(self): return len(self.
all_token_ids) Byusingthe_read_wikifunctionandthe_Wiki Text Datasetclass, wedefinethefollow- ingload_data_wikitodownloadand Wiki Text-2datasetandgeneratepretrainingexam- plesfromit.
738 Natural Language Processing: Pretraining #@save def load_data_wiki(batch_size, max_len): """Load the Wiki Text-2 dataset.""" num_workers = d2l.
get_dataloader_workers() data_dir = d2l.
download_extract('wikitext-2', 'wikitext-2') paragraphs = _read_wiki(data_dir) train_set = _Wiki Text Dataset(paragraphs, max_len) train_iter = torch.
utils.
data.
Data Loader(train_set, batch_size, shuffle=True, num_workers=num_workers) return train_iter, train_set.
vocab Setting the batch size to 512 and the maximum length of a BERT input sequence to be 64, we print out the shapes of a minibatch of BERT pretraining examples.
Note that in each BERTinputsequence,10(64 0.15)positionsarepredictedforthemaskedlanguage modelingtask.
batch_size, max_len = 512, 64 train_iter, vocab = load_data_wiki(batch_size, max_len) for (tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y, nsp_y) in train_iter: print(tokens_X.
shape, segments_X.
shape, valid_lens_x.
shape, pred_positions_X.
shape, mlm_weights_X.
shape, mlm_Y.
shape, nsp_y.
shape) break torch.
Size([512, 64]) torch.
Size([512, 64]) torch.
Size([512]) torch.
Size([512,â£ â†©!10]) torch.
Size([512, 10]) torch.
Size([512, 10]) torch.
Size([512]) Intheend, letâ€™stakealookatthevocabularysize.
Evenafterfilteringoutinfrequenttokens, itisstillovertwicelargerthanthatofthe PTBdataset.
len(vocab) 20256 15.9.3 Summary Comparingwiththe PTBdataset, the Wiki Text-2datesetretainstheoriginalpunctuation, caseandnumbers, andisovertwicelarger.
Wecanarbitrarilyaccessthepretraining(maskedlanguagemodelingandnextsentence prediction)examplesgeneratedfromapairofsentencesfromthe Wiki Text-2corpus.
15.9.4 Exercises 739 Pretraining BERT 1.
Forsimplicity, theperiodisusedastheonlydelimiterforsplittingsentences.
Tryother sentence splitting techniques, such as the spa Cy and NLTK.
Take NLTK as an exam- ple.
You need to install NLTK first: pip install nltk.
In the code, first import nltk.
Then, downloadthe Punktsentencetokenizer: nltk.
download('punkt').
To split sentences such as sentences = 'This is great ! Why not ?', invok- ing nltk.
tokenize.
sent_tokenize(sentences) will return a list of two sentence strings: ['This is great !', 'Why not ?'].
2.
Whatisthevocabularysizeifwedonotfilteroutanyinfrequenttoken? Discussions239.
239 15.10 Pretraining BERT Withthe BERTmodelimplementedin Section15.8andthepretrainingexamplesgenerated from the Wiki Text-2 dataset in Section 15.9, we will pretrain BERT on the Wiki Text-2 datasetinthissection.
import torch from torch import nn from d2l import torch as d2l Tostart, weloadthe Wiki Text-2datasetasminibatchesofpretrainingexamplesformasked languagemodelingandnextsentenceprediction.
Thebatchsizeis512andthemaximum lengthofa BERTinputsequenceis64.
Notethatintheoriginal BERTmodel, themaximum lengthis512.
batch_size, max_len = 512, 64 train_iter, vocab = d2l.
load_data_wiki(batch_size, max_len) 15.10.1 Pretraining BERT Theoriginal BERThastwoversionsofdifferentmodelsizes(Devlinetal.,2018).
Thebase model (BERT ) uses 12 layers (Transformer encoder blocks) with 768 hidden units BASE (hidden size) and 12 self-attention heads.
The large model (BERT ) uses 24 layers LARGE with 1024 hidden units and 16 self-attention heads.
Notably, the former has 110 million parameterswhilethelatterhas340millionparameters.
Fordemonstrationwithease, we defineasmall BERT, using2layers,128hiddenunits, and2self-attentionheads.
net = d2l.
BERTModel(len(vocab), num_hiddens=128, ffn_num_hiddens=256, num_heads=2, num_blks=2, dropout=0.2) devices = d2l.
try_all_gpus() loss = nn.
Cross Entropy Loss() 740 Natural Language Processing: Pretraining Before defining the training loop, we define a helper function _get_batch_loss_bert.
Giventheshardoftrainingexamples, thisfunctioncomputesthelossforboththemasked language modeling and next sentence prediction tasks.
Note that the final loss of BERT pretrainingisjustthesumofboththemaskedlanguagemodelinglossandthenextsentence predictionloss.
#@save def _get_batch_loss_bert(net, loss, vocab_size, tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y, nsp_y): # Forward pass _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X, valid_lens_x.
reshape(-1), pred_positions_X) # Compute masked language model loss mlm_l = loss(mlm_Y_hat.
reshape(-1, vocab_size), mlm_Y.
reshape(-1)) *\ mlm_weights_X.
reshape(-1, 1) mlm_l = mlm_l.
sum() / (mlm_weights_X.
sum() + 1e-8) # Compute next sentence prediction loss nsp_l = loss(nsp_Y_hat, nsp_y) l = mlm_l + nsp_l return mlm_l, nsp_l, l Invokingthetwoaforementionedhelperfunctions, thefollowingtrain_bertfunctionde- finestheproceduretopretrain BERT(net)onthe Wiki Text-2(train_iter)dataset.
Train- ing BERTcantakeverylong.
Insteadofspecifyingthenumberofepochsfortrainingasin thetrain_ch13function(see Section14.1), theinputnum_stepsofthefollowingfunction specifiesthenumberofiterationstepsfortraining.
def train_bert(train_iter, net, loss, vocab_size, devices, num_steps): net(*next(iter(train_iter))[:4]) net = nn.
Data Parallel(net, device_ids=devices).
to(devices[0]) trainer = torch.
optim.
Adam(net.
parameters(), lr=0.01) step, timer = 0, d2l.
Timer() animator = d2l.
Animator(xlabel='step', ylabel='loss', xlim=[1, num_steps], legend=['mlm', 'nsp']) # Sum of masked language modeling losses, sum of next sentence prediction # losses, no.
of sentence pairs, count metric = d2l.
Accumulator(4) num_steps_reached = False while step < num_steps and not num_steps_reached: for tokens_X, segments_X, valid_lens_x, pred_positions_X,\ mlm_weights_X, mlm_Y, nsp_y in train_iter: tokens_X = tokens_X.
to(devices[0]) segments_X = segments_X.
to(devices[0]) valid_lens_x = valid_lens_x.
to(devices[0]) pred_positions_X = pred_positions_X.
to(devices[0]) mlm_weights_X = mlm_weights_X.
to(devices[0]) mlm_Y, nsp_y = mlm_Y.
to(devices[0]), nsp_y.
to(devices[0]) trainer.
zero_grad() timer.
start() mlm_l, nsp_l, l = _get_batch_loss_bert( (continuesonnextpage) 741 Pretraining BERT (continuedfrompreviouspage) net, loss, vocab_size, tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y, nsp_y) l.
backward() trainer.
step() metric.
add(mlm_l, nsp_l, tokens_X.
shape[0], 1) timer.
stop() animator.
add(step + 1, (metric[0] / metric[3], metric[1] / metric[3])) step += 1 if step == num_steps: num_steps_reached = True break print(f'MLM loss {metric[0] / metric[3]:.3f}, ' f'NSP loss {metric[1] / metric[3]:.3f}') print(f'{metric[2] / timer.
sum():.1f} sentence pairs/sec on ' f'{str(devices)}') Wecanplotboththemaskedlanguagemodelinglossandthenextsentencepredictionloss during BERTpretraining.
train_bert(train_iter, net, loss, len(vocab), devices, 50) MLM loss 5.885, NSP loss 0.760 4413.2 sentence pairs/sec on [device(type='cuda', index=0), device(type='cuda', â†©! index=1)] 15.10.2 Representing Textwith BERT After pretraining BERT, wecan use it to represent single text, textpairs, or anytokenin them.
The following function returns the BERT (net) representations for all tokens in tokens_aandtokens_b.
def get_bert_encoding(net, tokens_a, tokens_b=None): tokens, segments = d2l.
get_tokens_and_segments(tokens_a, tokens_b) token_ids = torch.
tensor(vocab[tokens], device=devices[0]).
unsqueeze(0) segments = torch.
tensor(segments, device=devices[0]).
unsqueeze(0) (continuesonnextpage) 742 Natural Language Processing: Pretraining (continuedfrompreviouspage) valid_len = torch.
tensor(len(tokens), device=devices[0]).
unsqueeze(0) encoded_X, _, _ = net(token_ids, segments, valid_len) return encoded_X Considerthesentenceâ€œacraneisflyingâ€.
Recalltheinputrepresentationof BERTasdis- cussed in Section 15.8.4.
After inserting special tokens â€œ<cls>â€ (used for classification) and â€œ<sep>â€ (used for separation), the BERT input sequence has a length of six.
Since zeroistheindexoftheâ€œ<cls>â€token, encoded_text[:, 0, :] isthe BERTrepresen- tationoftheentireinputsentence.
Toevaluatethepolysemytokenâ€œcraneâ€, wealsoprint outthefirstthreeelementsofthe BERTrepresentationofthetoken.
tokens_a = ['a', 'crane', 'is', 'flying'] encoded_text = get_bert_encoding(net, tokens_a) # Tokens: '<cls>', 'a', 'crane', 'is', 'flying', '<sep>' encoded_text_cls = encoded_text[:, 0, :] encoded_text_crane = encoded_text[:, 2, :] encoded_text.
shape, encoded_text_cls.
shape, encoded_text_crane[0][:3] (torch.
Size([1, 6, 128]), torch.
Size([1, 128]), tensor([0.8414, 1.4830, 0.8226], device='cuda:0', grad_fn=<Slice Backward0>)) Nowconsiderasentencepairâ€œacranedrivercameâ€andâ€œhejustleftâ€.
Similarly, encoded_pair[:, 0, :] istheencodedresultoftheentiresentencepairfromthepretrained BERT.
Notethat the first three elements of the polysemy token â€œcraneâ€ are different from those when the contextisdifferent.
Thissupportsthat BERTrepresentationsarecontext-sensitive.
tokens_a, tokens_b = ['a', 'crane', 'driver', 'came'], ['he', 'just', 'left'] encoded_pair = get_bert_encoding(net, tokens_a, tokens_b) # Tokens: '<cls>', 'a', 'crane', 'driver', 'came', '<sep>', 'he', 'just', # 'left', '<sep>' encoded_pair_cls = encoded_pair[:, 0, :] encoded_pair_crane = encoded_pair[:, 2, :] encoded_pair.
shape, encoded_pair_cls.
shape, encoded_pair_crane[0][:3] (torch.
Size([1, 10, 128]), torch.
Size([1, 128]), tensor([0.0430, 1.6132, 0.0437], device='cuda:0', grad_fn=<Slice Backward0>)) In Chapter16, wewillfine-tuneapretrained BERTmodelfordownstreamnaturallanguage processingapplications.
15.10.3 Summary Theoriginal BERThastwoversions, wherethebasemodelhas110millionparameters andthelargemodelhas340millionparameters.
743 Pretraining BERT Afterpretraining BERT, wecanuseittorepresentsingletext, textpairs, oranytokenin them.
Intheexperiment, thesametokenhasdifferent BERTrepresentationwhentheircontexts aredifferent.
Thissupportsthat BERTrepresentationsarecontext-sensitive.
15.10.4 Exercises 1.
Intheexperiment, wecanseethatthemaskedlanguagemodelinglossissignificantly higherthanthenextsentencepredictionloss.
Why? 2.
Setthemaximumlengthofa BERTinputsequencetobe512(sameastheoriginal BERT model).
Usetheconfigurationsoftheoriginal BERTmodelsuchas BERT .
Do LARGE youencounteranyerrorwhenrunningthissection? Why? Discussions240.
240 Natural Language Processing: 16 Applications Wehaveseenhowtorepresenttokensintextsequencesandtraintheirrepresentationsin Chapter15.
Suchpretrainedtextrepresentationscanbefedtovariousmodelsfordifferent downstreamnaturallanguageprocessingtasks.
Infact, earlierchaptershavealreadydiscussedsomenaturallanguageprocessingapplica- tionswithoutpretraining, justforexplainingdeeplearningarchitectures.
Forinstance, in Chapter9, wehavereliedon RNNstodesignlanguagemodelstogeneratenovella-liketext.
In Chapter10and Chapter11, wehavealsodesignedmodelsbasedon RNNsandattention mechanismsformachinetranslation.
However, thisbookdoesnotintendtocoverallsuchapplicationsinacomprehensiveman- ner.
Instead, ourfocusisonhowtoapply(deep)representationlearningoflanguagesto addressingnaturallanguageprocessingproblems.
Givenpretrainedtextrepresentations, thischapterwillexploretwopopularandrepresentativedownstreamnaturallanguagepro- cessingtasks: sentimentanalysisandnaturallanguageinference, whichanalyzesingletext andrelationshipsoftextpairs, respectively.
t .1 Pretrainedtextrepresentationscanbefedtovariousdeeplearningarchitecturesfor differentdownstreamnaturallanguageprocessingapplications.
Thischapterfocuseson howtodesignmodelsfordifferentdownstreamnaturallanguageprocessingapplications.
Asdepictedin.1, thischapterfocusesondescribingthebasicideasofdesigningnat- urallanguageprocessingmodelsusingdifferenttypesofdeeplearningarchitectures, such as MLPs, CNNs, RNNs, and attention.
Though it is possible to combine any pretrained textrepresentationswithanyarchitectureforeitherapplicationin.1, weselectafew representativecombinations.
Specifically, wewillexplorepopulararchitecturesbasedon RNNsand CNNsforsentimentanalysis.
Fornaturallanguageinference, wechooseatten- 744 745 Sentiment Analysisandthe Dataset tionand MLPstodemonstratehowtoanalyzetextpairs.
Intheend, weintroducehowto fine-tuneapretrained BERTmodelforawiderangeofnaturallanguageprocessingappli- cations, suchasonasequencelevel(singletextclassificationandtextpairclassification) andatokenlevel(texttaggingandquestionanswering).
Asaconcreteempiricalcase, we willfine-tune BERTfornaturallanguageinference.
Aswehaveintroducedin Section15.8, BERTrequiresminimalarchitecturechangesfora widerangeofnaturallanguageprocessingapplications.
However, thisbenefitcomesatthe cost of fine-tuning a huge number of BERT parameters for the downstream applications.
Whenspaceortimeislimited, thosecraftedmodelsbasedon MLPs, CNNs, RNNs, and attentionaremorefeasible.
Inthefollowing, westartbythesentimentanalysisapplication andillustratethemodeldesignbasedon RNNsand CNNs, respectively.
16.1 Sentiment Analysis and the Dataset Withtheproliferationofonlinesocialmediaandreviewplatforms, aplethoraofopinion- ateddatahasbeenlogged, bearinggreatpotentialforsupportingdecisionmakingprocesses.
Sentimentanalysisstudiespeopleâ€™ssentimentsintheirproducedtext, suchasproductre- views, blog comments, and forum discussions.
It enjoys wide applications to fields as diverseaspolitics(e.
g., analysisofpublicsentimentstowardspolicies), finance(e.
g., anal- ysisofsentimentsofthemarket), andmarketing(e.
g., productresearchandbrandmanage- ment).
Sincesentimentscanbecategorizedasdiscretepolaritiesorscales(e.
g., positiveandneg- ative), wecanconsidersentimentanalysisasatextclassificationtask, whichtransformsa varying-lengthtextsequenceintoafixed-lengthtextcategory.
Inthischapter, wewilluse Stanfordâ€™slargemoviereviewdataset241 forsentimentanalysis.
Itconsistsofatrainingset 241 andatestingset, eithercontaining25000moviereviewsdownloadedfrom IMDb.
Inboth datasets, there are equal number of â€œpositiveâ€ and â€œnegativeâ€ labels, indicating different sentimentpolarities.
import os import torch from torch import nn from d2l import torch as d2l 16.1.1 Readingthe Dataset First, downloadandextractthis IMDbreviewdatasetinthepath../data/acl Imdb.
#@save d2l.
DATA_HUB['acl Imdb'] = (d2l.
DATA_URL + 'acl Imdb_v1.
tar.
gz', '01ada507287d82875905620988597833ad4e0903') (continuesonnextpage) 746 Natural Language Processing: Applications (continuedfrompreviouspage) data_dir = d2l.
download_extract('acl Imdb', 'acl Imdb') Next, read the training and test datasets.
Each example is a review and its label: 1 for â€œpositiveâ€and0forâ€œnegativeâ€.
#@save def read_imdb(data_dir, is_train): """Read the IMDb review dataset text sequences and labels.""" data, labels = [], [] for label in ('pos', 'neg'): folder_name = os.
path.
join(data_dir, 'train' if is_train else 'test', label) for file in os.
listdir(folder_name): with open(os.
path.
join(folder_name, file), 'rb') as f: review = f.
read().
decode('utf-8').
replace('\n', '') data.
append(review) labels.
append(1 if label == 'pos' else 0) return data, labels train_data = read_imdb(data_dir, is_train=True) print('# trainings:', len(train_data[0])) for x, y in zip(train_data[0][:3], train_data[1][:3]): print('label:', y, 'review:', x[:60]) # trainings: 25000 label: 1 review: Zentropa has much in common with The Third Man, another noir label: 1 review: Zentropa is the most original movie I've seen in years.
If y label: 1 review: Lars Von Trier is never backward in trying out new technique 16.1.2 Preprocessingthe Dataset Treating each word as a token and filtering out words that appear less than 5 times, we createavocabularyoutofthetrainingdataset.
train_tokens = d2l.
tokenize(train_data[0], token='word') vocab = d2l.
Vocab(train_tokens, min_freq=5, reserved_tokens=['<pad>']) Aftertokenization, letâ€™splotthehistogramofreviewlengthsintokens.
d2l.
set_figsize() d2l.
plt.
xlabel('# tokens per review') d2l.
plt.
ylabel('count') d2l.
plt.
hist([len(line) for line in train_tokens], bins=range(0, 1000, 50)); 747 Sentiment Analysisandthe Dataset Asweexpected, thereviewshavevaryinglengths.
Toprocessaminibatchofsuchreviews ateachtime, wesetthelengthofeachreviewto500withtruncationandpadding, whichis similartothepreprocessingstepforthemachinetranslationdatasetin Section10.5.
num_steps = 500 # sequence length train_features = torch.
tensor([d2l.
truncate_pad( vocab[line], num_steps, vocab['<pad>']) for line in train_tokens]) print(train_features.
shape) torch.
Size([25000, 500]) 16.1.3 Creating Data Iterators Nowwecancreatedataiterators.
Ateachiteration, aminibatchofexamplesarereturned.
train_iter = d2l.
load_array((train_features, torch.
tensor(train_data[1])), 64) for X, y in train_iter: print('X:', X.
shape, ', y:', y.
shape) break print('# batches:', len(train_iter)) X: torch.
Size([64, 500]) , y: torch.
Size([64]) # batches: 391 16.1.4 Putting It All Together Last, we wrap up the above steps into the load_data_imdb function.
It returns training andtestdataiteratorsandthevocabularyofthe IMDbreviewdataset.
#@save def load_data_imdb(batch_size, num_steps=500): """Return data iterators and the vocabulary of the IMDb review dataset.""" data_dir = d2l.
download_extract('acl Imdb', 'acl Imdb') train_data = read_imdb(data_dir, True) test_data = read_imdb(data_dir, False) (continuesonnextpage) 748 Natural Language Processing: Applications (continuedfrompreviouspage) train_tokens = d2l.
tokenize(train_data[0], token='word') test_tokens = d2l.
tokenize(test_data[0], token='word') vocab = d2l.
Vocab(train_tokens, min_freq=5) train_features = torch.
tensor([d2l.
truncate_pad( vocab[line], num_steps, vocab['<pad>']) for line in train_tokens]) test_features = torch.
tensor([d2l.
truncate_pad( vocab[line], num_steps, vocab['<pad>']) for line in test_tokens]) train_iter = d2l.
load_array((train_features, torch.
tensor(train_data[1])), batch_size) test_iter = d2l.
load_array((test_features, torch.
tensor(test_data[1])), batch_size, is_train=False) return train_iter, test_iter, vocab 16.1.5 Summary Sentimentanalysisstudiespeopleâ€™ssentimentsintheirproducedtext, whichisconsid- ered as a text classification problem that transforms a varying-length text sequence intoafixed-lengthtextcategory.
After preprocessing, we can load Stanfordâ€™s large movie review dataset (IMDb review dataset)intodataiteratorswithavocabulary.
16.1.6 Exercises 1.
What hyperparameters in this section can we modify to accelerate training sentiment analysismodels? 242 2.
Can you implement a function to load the dataset of Amazon reviews242 into data iteratorsandlabelsforsentimentanalysis? Discussions243.
243 16.2 Sentiment Analysis: Using Recurrent Neural Networks Likewordsimilarityandanalogytasks, wecanalsoapplypretrainedwordvectorstosen- timentanalysis.
Sincethe IMDbreviewdatasetin Section16.1isnotverybig, usingtext representations that were pretrained on large-scale corpora may reduce overfitting of the model.
Asaspecificexampleillustratedin.2.1, wewillrepresenteachtokenusing the pretrained Glo Ve model, and feed these token representations into a multilayer bidi- rectional RNNtoobtainthetextsequencerepresentation, whichwillbetransformedinto sentimentanalysisoutputs(Maasetal.,2011).
Forthesamedownstreamapplication, we willconsideradifferentarchitecturalchoicelater.
749 Sentiment Analysis: Using Recurrent Neural Networks t .2.1 Thissectionfeedspretrained Glo Vetoan RNN-basedarchitectureforsentimentanalysis.
import torch from torch import nn from d2l import torch as d2l batch_size = 64 train_iter, test_iter, vocab = d2l.
load_data_imdb(batch_size) 16.2.1 Representing Single Textwith RNNs Intextclassificationstasks, suchassentimentanalysis, avarying-lengthtextsequencewill betransformedintofixed-lengthcategories.
Inthefollowing Bi RNNclass, whileeachtoken of a text sequence gets its individual pretrained Glo Ve representation via the embedding layer (self.
embedding), the entire sequence is encoded by a bidirectional RNN (self.
encoder).
Moreconcretely, thehiddenstates(atthelastlayer)ofthebidirectional LSTM at both the initial and final time steps are concatenated as the representation of the text sequence.
This single text representation is then transformed into output categories by a fullyconnectedlayer(self.
decoder)withtwooutputs(â€œpositiveâ€andâ€œnegativeâ€).
class Bi RNN(nn.
Module): def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs): super(Bi RNN, self).__init__(**kwargs) self.
embedding = nn.
Embedding(vocab_size, embed_size) # Set `bidirectional` to True to get a bidirectional RNN self.
encoder = nn.
LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True) self.
decoder = nn.
Linear(4 * num_hiddens, 2) def forward(self, inputs): # The shape of `inputs` is (batch size, no.
of time steps).
Because # LSTM requires its input's first dimension to be the temporal # dimension, the input is transposed before obtaining token # representations.
The output shape is (no.
of time steps, batch size, # word vector dimension) embeddings = self.
embedding(inputs.
T) self.
encoder.
flatten_parameters() # Returns hidden states of the last hidden layer at different time (continuesonnextpage) 750 Natural Language Processing: Applications (continuedfrompreviouspage) # steps.
The shape of `outputs` is (no.
of time steps, batch size, # 2 * no.
of hidden units) outputs, _ = self.
encoder(embeddings) # Concatenate the hidden states at the initial and final time steps as # the input of the fully connected layer.
Its shape is (batch size, # 4 * no.
of hidden units) encoding = torch.
cat((outputs[0], outputs[-1]), dim=1) outs = self.
decoder(encoding) return outs Letâ€™sconstructabidirectional RNNwithtwohiddenlayerstorepresentsingletextforsen- timentanalysis.
embed_size, num_hiddens, num_layers, devices = 100, 100, 2, d2l.
try_all_gpus() net = Bi RNN(len(vocab), embed_size, num_hiddens, num_layers) def init_weights(module): if type(module) == nn.
Linear: nn.
init.
xavier_uniform_(module.
weight) if type(module) == nn.
LSTM: for param in module._flat_weights_names: if "weight" in param: nn.
init.
xavier_uniform_(module._parameters[param]) net.
apply(init_weights); 16.2.2 Loading Pretrained Word Vectors Belowweloadthepretrained100-dimensional(needstobeconsistentwithembed_size) Glo Veembeddingsfortokensinthevocabulary.
glove_embedding = d2l.
Token Embedding('glove.6b.100d') Printtheshapeofthevectorsforallthetokensinthevocabulary.
embeds = glove_embedding[vocab.
idx_to_token] embeds.
shape torch.
Size([49346, 100]) Weusethesepretrainedwordvectorstorepresenttokensinthereviewsandwillnotupdate thesevectorsduringtraining.
net.
embedding.
weight.
data.
copy_(embeds) net.
embedding.
weight.
requires_grad = False 16.2.3 Trainingand Evaluatingthe Model 751 Sentiment Analysis: Using Recurrent Neural Networks Nowwecantrainthebidirectional RNNforsentimentanalysis.
lr, num_epochs = 0.01, 5 trainer = torch.
optim.
Adam(net.
parameters(), lr=lr) loss = nn.
Cross Entropy Loss(reduction="none") d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) loss 0.277, train acc 0.884, test acc 0.861 2608.4 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Wedefinethefollowingfunctiontopredictthesentimentofatextsequenceusingthetrained modelnet.
#@save def predict_sentiment(net, vocab, sequence): """Predict the sentiment of a text sequence.""" sequence = torch.
tensor(vocab[sequence.
split()], device=d2l.
try_gpu()) label = torch.
argmax(net(sequence.
reshape(1, -1)), dim=1) return 'positive' if label == 1 else 'negative' Finally, letâ€™susethetrainedmodeltopredictthesentimentfortwosimplesentences.
predict_sentiment(net, vocab, 'this movie is so great') 'positive' predict_sentiment(net, vocab, 'this movie is so bad') 'negative' 16.2.4 Summary Pretrainedwordvectorscanrepresentindividualtokensinatextsequence.
752 Natural Language Processing: Applications Bidirectional RNNscanrepresentatextsequence, suchasviatheconcatenationofits hiddenstatesattheinitialandfinaltimesteps.
Thissingletextrepresentationcanbe transformedintocategoriesusingafullyconnectedlayer.
16.2.5 Exercises 1.
Increasethenumberofepochs.
Canyouimprovethetrainingandtestingaccuracies? Howabouttuningotherhyperparameters? 2.
Uselargerpretrainedwordvectors, suchas300-dimensional Glo Veembeddings.
Does itimproveclassificationaccuracy? 3.
Canweimprovetheclassificationaccuracybyusingthespa Cytokenization? Youneed to install spa Cy (pip install spacy) and install the English package (python -m spacy download en).
Inthecode, first, importspa Cy(import spacy).
Then, load the spa Cy English package (spacy_en = spacy.
load('en')).
Finally, define the function def tokenizer(text): return [tok.
text for tok in spacy_en.
tokenizer(text)] and replace the original tokenizer function.
Note the different formsofphrasetokensin Glo Veandspa Cy.
Forexample, thephrasetokenâ€œnewyorkâ€ takes the form of â€œnew-yorkâ€ in Glo Ve and the form of â€œnew yorkâ€ after the spa Cy tokenization.
244 Discussions244.
16.3 Sentiment Analysis: Using Convolutional Neural Networks In Chapter7, weinvestigatedmechanismsforprocessingtwo-dimensionalimagedatawith two-dimensional CNNs, whichwereappliedtolocalfeaturessuchasadjacentpixels.
Though originallydesignedforcomputervision, CNNsarealsowidelyusedfornaturallanguage processing.
Simplyput, justthinkofanytextsequenceasaone-dimensionalimage.
Inthis way, one-dimensional CNNscanprocesslocalfeaturessuchasğ‘›-gramsintext.
In this section, we will use the text CNN model to demonstrate how to design a CNN ar- chitecture for representing single text (Kim, 2014).
Compared with .2.1 that uses an RNNarchitecturewith Glo Vepretrainingforsentimentanalysis, theonlydifferencein .3.1liesinthechoiceofthearchitecture.
import torch from torch import nn from d2l import torch as d2l batch_size = 64 train_iter, test_iter, vocab = d2l.
load_data_imdb(batch_size) 753 Sentiment Analysis: Using Convolutional Neural Networks t .3.1 Thissectionfeedspretrained Glo Vetoa CNN-basedarchitectureforsentimentanalysis.
16.3.1 One-Dimensional Convolutions Before introducing the model, letâ€™s see how a one-dimensional convolution works.
Bear inmindthatitisjustaspecialcaseofatwo-dimensionalconvolutionbasedonthecross- correlationoperation.
t .3.2 One-dimensionalcross-correlationoperation.
Theshadedportionsarethefirstoutput elementaswellastheinputandkerneltensorelementsusedfortheoutputcomputation: 0 1â€š1 2=2.
Asshownin.3.2, intheone-dimensionalcase, theconvolutionwindowslidesfrom left to right across the input tensor.
During sliding, the input subtensor (e.
g., 0 and 1 in .3.2)containedintheconvolutionwindowatacertainpositionandthekerneltensor positionoftheoutputtensor.
Weimplementone-dimensionalcross-correlationinthefollowingcorr1dfunction.
Given aninputtensor Xandakerneltensor K, itreturnstheoutputtensor Y.
def corr1d(X, K): w = K.
shape[0] Y = torch.
zeros((X.
shape[0] - w + 1)) for i in range(Y.
shape[0]): Y[i] = (X[i: i + w] * K).
sum() return Y Wecanconstructtheinputtensor Xandthekerneltensor Kfrom.3.2tovalidatethe outputoftheaboveone-dimensionalcross-correlationimplementation.
X, K = torch.
tensor([0, 1, 2, 3, 4, 5, 6]), torch.
tensor([1, 2]) corr1d(X, K) 754 Natural Language Processing: Applications Foranyone-dimensionalinputwithmultiplechannels, theconvolutionkernelneedstohave the same number of input channels.
Then for each channel, perform a cross-correlation operation on the one-dimensional tensor of the input and the one-dimensional tensor of the convolution kernel, summing the results over all the channels to produce the one- dimensional output tensor.
.3.3 shows a one-dimensional cross-correlation oper- ationwith3inputchannels.
t .3.3 One-dimensionalcross-correlationoperationwith3inputchannels.
Theshadedportions arethefirstoutputelementaswellastheinputandkerneltensorelementsusedforthe outputcomputation: 0 1â€š1 2â€š1 3â€š2 4â€š2 â€ 1â€â€š3 â€ 3â€ =2.
Wecanimplementtheone-dimensionalcross-correlationoperationformultipleinputchan- nelsandvalidatetheresultsin.3.3.
def corr1d_multi_in(X, K): # First, iterate through the 0th dimension (channel dimension) of `X` and # `K`.
Then, add them together return sum(corr1d(x, k) for x, k in zip(X, K)) X = torch.
tensor([[0, 1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 7], [2, 3, 4, 5, 6, 7, 8]]) K = torch.
tensor([[1, 2], [3, 4], [-1, -3]]) corr1d_multi_in(X, K) Notethatmulti-input-channelone-dimensionalcross-correlationsareequivalenttosingle- input-channeltwo-dimensionalcross-correlations.
Toillustrate, anequivalentformofthe multi-input-channel one-dimensional cross-correlation in .3.3 is the single-input- channeltwo-dimensionalcross-correlationin.3.4, wheretheheightoftheconvolu- tionkernelhastobethesameasthatoftheinputtensor.
dimensional convolutions with multiple output channels described in Section 7.4.2, we canalsospecifymultipleoutputchannelsforone-dimensionalconvolutions.
16.3.2 Max-Over-Time Pooling Similarly, wecanusepoolingtoextractthehighestvaluefromsequencerepresentationsas themostimportantfeatureacrosstimesteps.
Themax-over-timepoolingusedintext CNN 755 Sentiment Analysis: Using Convolutional Neural Networks t .3.4 Two-dimensionalcross-correlationoperationwithasingleinputchannel.
Theshaded portionsarethefirstoutputelementaswellastheinputandkerneltensorelementsused fortheoutputcomputation: 2 â€ 1â€â€š3 â€ 3â€â€š1 3â€š2 4â€š0 1â€š1 2=2.
worksliketheone-dimensionalglobalmax-pooling(Collobertetal.,2011).
Foramulti- channelinputwhereeachchannelstoresvaluesatdifferenttimesteps, theoutputateach channelisthemaximumvalueforthatchannel.
Notethatthemax-over-timepoolingallows differentnumbersoftimestepsatdifferentchannels.
16.3.3 Thetext CNNModel Using the one-dimensional convolution and max-over-time pooling, the text CNN model takesindividualpretrainedtokenrepresentationsasinput, thenobtainsandtransformsse- quencerepresentationsforthedownstreamapplication.
Forasingletextsequencewithğ‘›tokensrepresentedbyğ‘‘-dimensionalvectors, thewidth, height, and number of channels of the input tensor are ğ‘›, 1, and ğ‘‘, respectively.
The text CNNmodeltransformstheinputintotheoutputasfollows: 1.
Define multiple one-dimensional convolution kernels and perform convolution opera- tionsseparatelyontheinputs.
Convolutionkernelswithdifferentwidthsmaycapture localfeaturesamongdifferentnumbersofadjacenttokens.
2.
Performmax-over-timepoolingonalltheoutputchannels, andthenconcatenateallthe scalarpoolingoutputsasavector.
3.
Transformtheconcatenatedvectorintotheoutputcategoriesusingthefullyconnected layer.
Dropoutcanbeusedforreducingoverfitting.
.3.5illustratesthemodelarchitectureoftext CNNwithaconcreteexample.
Theinput isasentencewith11tokens, whereeachtokenisrepresentedbya6-dimensionalvectors.
So we have a 6-channel input with width 11.
Define two one-dimensional convolution kernelsofwidths2and4, with4and5outputchannels, respectively.
Theyproduce4output channelswithwidth11 2â€š1=10and5outputchannelswithwidth11 4â€š1=8.
Despite different widths of these 9 channels, the max-over-time pooling gives a concatenated 9- dimensional vector, which is finally transformed into a 2-dimensional output vector for binarysentimentpredictions.
Definingthe Model Weimplementthetext CNNmodelinthefollowingclass.
Comparedwiththebidirectional RNNmodelin Section16.2, besidesreplacingrecurrentlayerswithconvolutionallayers, 756 Natural Language Processing: Applications t .3.5 Themodelarchitectureoftext CNN.
we also use two embedding layers: one with trainable weights and the other with fixed weights.
class Text CNN(nn.
Module): def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels, **kwargs): super(Text CNN, self).__init__(**kwargs) self.
embedding = nn.
Embedding(vocab_size, embed_size) # The embedding layer not to be trained self.
constant_embedding = nn.
Embedding(vocab_size, embed_size) self.
dropout = nn.
Dropout(0.5) self.
decoder = nn.
Linear(sum(num_channels), 2) # The max-over-time pooling layer has no parameters, so this instance # can be shared self.
pool = nn.
Adaptive Avg Pool1d(1) self.
relu = nn.
Re LU() # Create multiple one-dimensional convolutional layers self.
convs = nn.
Module List() for c, k in zip(num_channels, kernel_sizes): self.
convs.
append(nn.
Conv1d(2 * embed_size, c, k)) def forward(self, inputs): # Concatenate two embedding layer outputs with shape (batch size, no.
# of tokens, token vector dimension) along vectors embeddings = torch.
cat(( self.
embedding(inputs), self.
constant_embedding(inputs)), dim=2) # Per the input format of one-dimensional convolutional layers, # rearrange the tensor so that the second dimension stores channels embeddings = embeddings.
permute(0, 2, 1) # For each one-dimensional convolutional layer, after max-over-time # pooling, a tensor of shape (batch size, no.
of channels, 1) is # obtained.
Remove the last dimension and concatenate along channels encoding = torch.
cat([ (continuesonnextpage) 757 Sentiment Analysis: Using Convolutional Neural Networks (continuedfrompreviouspage) torch.
squeeze(self.
relu(self.
pool(conv(embeddings))), dim=-1) for conv in self.
convs], dim=1) outputs = self.
decoder(self.
dropout(encoding)) return outputs Letâ€™screateatext CNNinstance.
Ithas3convolutionallayerswithkernelwidthsof3,4, and5, allwith100outputchannels.
embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100] devices = d2l.
try_all_gpus() net = Text CNN(len(vocab), embed_size, kernel_sizes, nums_channels) def init_weights(module): if type(module) in (nn.
Linear, nn.
Conv1d): nn.
init.
xavier_uniform_(module.
weight) net.
apply(init_weights); Loading Pretrained Word Vectors Sameas Section16.2, weloadpretrained100-dimensional Glo Veembeddingsastheini- tialized token representations.
These token representations (embedding weights) will be trainedinembeddingandfixedinconstant_embedding.
glove_embedding = d2l.
Token Embedding('glove.6b.100d') embeds = glove_embedding[vocab.
idx_to_token] net.
embedding.
weight.
data.
copy_(embeds) net.
constant_embedding.
weight.
data.
copy_(embeds) net.
constant_embedding.
weight.
requires_grad = False Trainingand Evaluatingthe Model Nowwecantrainthetext CNNmodelforsentimentanalysis.
lr, num_epochs = 0.001, 5 trainer = torch.
optim.
Adam(net.
parameters(), lr=lr) loss = nn.
Cross Entropy Loss(reduction="none") d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) loss 0.066, train acc 0.979, test acc 0.868 4354.2 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Belowweusethetrainedmodeltopredictthesentimentfortwosimplesentences.
d2l.
predict_sentiment(net, vocab, 'this movie is so great') 758 Natural Language Processing: Applications 'positive' d2l.
predict_sentiment(net, vocab, 'this movie is so bad') 'negative' 16.3.4 Summary One-dimensional CNNscanprocesslocalfeaturessuchasğ‘›-gramsintext.
Multi-input-channel one-dimensional cross-correlations are equivalent to single-input- channeltwo-dimensionalcross-correlations.
Themax-over-timepoolingallowsdifferentnumbersoftimestepsatdifferentchannels.
Thetext CNNmodeltransformsindividualtokenrepresentationsintodownstreamappli- cationoutputsusingone-dimensionalconvolutionallayersandmax-over-timepooling layers.
16.3.5 Exercises 1.
Tunehyperparametersandcomparethetwoarchitecturesforsentimentanalysisin Sec- tion16.2andinthissection, suchasinclassificationaccuracyandcomputationaleffi- ciency.
2.
Canyoufurtherimprovetheclassificationaccuracyofthemodelbyusingthemethods introducedintheexercisesof Section16.2? 245 3.
Addpositionalencodingintheinputrepresentations.
Doesitimprovetheclassification accuracy? Discussions245.
759 Natural Language Inferenceandthe Dataset 16.4 Natural Language Inference and the Dataset In Section 16.1, we discussed the problem of sentiment analysis.
This task aims to clas- sifyasingletextsequenceintopredefinedcategories, suchasasetofsentimentpolarities.
However, when there is a need to decide whether one sentence can be inferred form an- other, or eliminate redundancy by identifying sentences that are semantically equivalent, knowinghowtoclassifyonetextsequenceisinsufficient.
Instead, weneedtobeableto reasonoverpairsoftextsequences.
16.4.1 Natural Language Inference Naturallanguageinferencestudieswhethera hypothesiscanbeinferredfroma premise, wherebothareatextsequence.
Inotherwords, naturallanguageinferencedeterminesthe logicalrelationshipbetweenapairoftextsequences.
Suchrelationshipsusuallyfallinto threetypes: Entailment: thehypothesiscanbeinferredfromthepremise.
Contradiction: thenegationofthehypothesiscanbeinferredfromthepremise.
Neutral: alltheothercases.
Naturallanguageinferenceisalsoknownastherecognizingtextualentailmenttask.
For example, thefollowingpairwillbelabeledasentailment becauseâ€œshowingaffectionâ€in thehypothesiscanbeinferredfromâ€œhuggingoneanotherâ€inthepremise.
Premise: Twowomenarehuggingeachother.
Hypothesis: Twowomenareshowingaffection.
The following is an example of contradiction as â€œrunning the coding exampleâ€ indicates â€œnotsleepingâ€ratherthanâ€œsleepingâ€.
Premise: Amanisrunningthecodingexamplefrom Diveinto Deep Learning.
Hypothesis: Themanissleeping.
The third example shows a neutrality relationship because neither â€œfamousâ€ nor â€œnot fa- mousâ€canbeinferredfromthefactthatâ€œareperformingforusâ€.
Premise: Themusiciansareperformingforus.
Hypothesis: Themusiciansarefamous.
Natural language inference has been a central topic for understanding natural language.
It enjoys wide applications ranging from information retrieval to open-domain question answering.
Tostudythisproblem, wewillbeginbyinvestigatingapopularnaturallanguage inferencebenchmarkdataset.
760 Natural Language Processing: Applications 16.4.2 The Stanford Natural Language Inference(SNLI)Dataset Stanford Natural Language Inference(SNLI)Corpusisacollectionofover500000labeled Englishsentencepairs(Bowmanetal.,2015).
Wedownloadandstoretheextracted SNLI datasetinthepath../data/snli_1.0.
import os import re import torch from torch import nn from d2l import torch as d2l #@save d2l.
DATA_HUB['SNLI'] = ( 'https://nlp.
stanford.
edu/projects/snli/snli_1.0.
zip', '9fcde07509c7e87ec61c640c1b2753d9041758e4') data_dir = d2l.
download_extract('SNLI') Readingthe Dataset Theoriginal SNLI datasetcontainsmuchricherinformationthan whatwereallyneedin ourexperiments.
Thus, wedefineafunctionread_snlitoonlyextractpartofthedataset, thenreturnlistsofpremises, hypotheses, andtheirlabels.
#@save def read_snli(data_dir, is_train): """Read the SNLI dataset into premises, hypotheses, and labels.""" def extract_text(s): # Remove information that will not be used by us s = re.
sub('\\(', '', s) s = re.
sub('\\)', '', s) # Substitute two or more consecutive whitespace with space s = re.
sub('\\s{2,}', ' ', s) return s.
strip() label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2} file_name = os.
path.
join(data_dir, 'snli_1.0_train.
txt' if is_train else 'snli_1.0_test.
txt') with open(file_name, 'r') as f: rows = [row.
split('\t') for row in f.
readlines()[1:]] premises = [extract_text(row[1]) for row in rows if row[0] in label_set] hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set] labels = [label_set[row[0]] for row in rows if row[0] in label_set] return premises, hypotheses, labels Nowletâ€™sprintthefirst3pairsofpremiseandhypothesis, aswellastheirlabels(â€œ0â€,â€œ1â€, andâ€œ2â€correspondtoâ€œentailmentâ€,â€œcontradictionâ€, andâ€œneutralâ€, respectively).
train_data = read_snli(data_dir, is_train=True) for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]): print('premise:', x0) (continuesonnextpage) 761 Natural Language Inferenceandthe Dataset (continuedfrompreviouspage) print('hypothesis:', x1) print('label:', y) premise: A person on a horse jumps over a broken down airplane .
hypothesis: A person is training his horse for a competition .
label: 2 premise: A person on a horse jumps over a broken down airplane .
hypothesis: A person is at a diner , ordering an omelette .
label: 1 premise: A person on a horse jumps over a broken down airplane .
hypothesis: A person is outdoors , on a horse .
label: 0 Thetrainingsethasabout550000pairs, andthetestingsethasabout10000pairs.
Thefol- lowingshowsthatthethreelabelsâ€œentailmentâ€,â€œcontradictionâ€, andâ€œneutralâ€arebalanced inboththetrainingsetandthetestingset.
test_data = read_snli(data_dir, is_train=False) for data in [train_data, test_data]: print([[row for row in data[2]].
count(i) for i in range(3)]) [183416, 183187, 182764] [3368, 3237, 3219] Defininga Classfor Loadingthe Dataset Belowwedefineaclassforloadingthe SNLIdatasetbyinheritingfromthe Datasetclass in Gluon.
Theargumentnum_stepsintheclassconstructorspecifiesthelengthofatext sequence so that each minibatch of sequences will have the same shape.
In other words, tokensafterthefirstnum_stepsonesinlongersequencearetrimmed, whilespecialtokens â€œ<pad>â€willbeappendedtoshortersequencesuntiltheirlengthbecomesnum_steps.
By implementingthe__getitem__function, wecanarbitrarilyaccessthepremise, hypothesis, andlabelwiththeindexidx.
#@save class SNLIDataset(torch.
utils.
data.
Dataset): """A customized dataset to load the SNLI dataset.""" def __init__(self, dataset, num_steps, vocab=None): self.
num_steps = num_steps all_premise_tokens = d2l.
tokenize(dataset[0]) all_hypothesis_tokens = d2l.
tokenize(dataset[1]) if vocab is None: self.
vocab = d2l.
Vocab(all_premise_tokens + all_hypothesis_tokens, min_freq=5, reserved_tokens=['<pad>']) else: self.
vocab = vocab self.
premises = self._pad(all_premise_tokens) (continuesonnextpage) 762 Natural Language Processing: Applications (continuedfrompreviouspage) self.
hypotheses = self._pad(all_hypothesis_tokens) self.
labels = torch.
tensor(dataset[2]) print('read ' + str(len(self.
premises)) + ' examples') def _pad(self, lines): return torch.
tensor([d2l.
truncate_pad( self.
vocab[line], self.
num_steps, self.
vocab['<pad>']) for line in lines]) def __getitem__(self, idx): return (self.
premises[idx], self.
hypotheses[idx]), self.
labels[idx] def __len__(self): return len(self.
premises) Putting It All Together Nowwecaninvoketheread_snlifunctionandthe SNLIDatasetclasstodownloadthe SNLIdatasetandreturn Data Loaderinstancesforbothtrainingandtestingsets, together withthevocabularyofthetrainingset.
Itisnoteworthythatwemustusethevocabulary constructedfromthetrainingsetasthatofthetestingset.
Asaresult, anynewtokenfrom thetestingsetwillbeunknowntothemodeltrainedonthetrainingset.
#@save def load_data_snli(batch_size, num_steps=50): """Download the SNLI dataset and return data iterators and vocabulary.""" num_workers = d2l.
get_dataloader_workers() data_dir = d2l.
download_extract('SNLI') train_data = read_snli(data_dir, True) test_data = read_snli(data_dir, False) train_set = SNLIDataset(train_data, num_steps) test_set = SNLIDataset(test_data, num_steps, train_set.
vocab) train_iter = torch.
utils.
data.
Data Loader(train_set, batch_size, shuffle=True, num_workers=num_workers) test_iter = torch.
utils.
data.
Data Loader(test_set, batch_size, shuffle=False, num_workers=num_workers) return train_iter, test_iter, train_set.
vocab Herewesetthebatchsizeto128andsequencelengthto50, andinvoketheload_data_snli functiontogetthedataiteratorsandvocabulary.
Thenweprintthevocabularysize.
train_iter, test_iter, vocab = load_data_snli(128, 50) len(vocab) read 549367 examples read 9824 examples 763 Natural Language Inference: Using Attention 18678 Nowweprinttheshapeofthefirstminibatch.
Contrarytosentimentanalysis, wehavetwo inputs X[0]and X[1]representingpairsofpremisesandhypotheses.
for X, Y in train_iter: print(X[0].
shape) print(X[1].
shape) print(Y.
shape) break torch.
Size([128, 50]) torch.
Size([128, 50]) torch.
Size([128]) 16.4.3 Summary Naturallanguageinferencestudieswhetherahypothesiscanbeinferredfromapremise, wherebothareatextsequence.
In natural language inference, relationships between premises and hypotheses include entailment, contradiction, andneutral.
Stanford Natural Language Inference(SNLI)Corpusisapopularbenchmarkdatasetof naturallanguageinference.
16.4.4 Exercises 1.
Machinetranslationhaslongbeenevaluatedbasedonsuperficialğ‘›-grammatchingbe- tweenanoutputtranslationandaground-truthtranslation.
Canyoudesignameasure forevaluatingmachinetranslationresultsbyusingnaturallanguageinference? 2.
Howcanwechangehyperparameterstoreducethevocabularysize? 246 Discussions246.
16.5 Natural Language Inference: Using Attention Weintroducedthenaturallanguageinferencetaskandthe SNLIdatasetin Section16.4.
In viewofmanymodelsthatarebasedoncomplexanddeeparchitectures, Parikhetal.
(2016) proposedtoaddressnaturallanguageinferencewithattentionmechanismsandcalledita â€œdecomposableattentionmodelâ€.
Thisresultsinamodelwithoutrecurrentorconvolutional layers, achievingthebestresultatthetimeonthe SNLIdatasetwithmuchfewerparameters.
764 Natural Language Processing: Applications Inthissection, wewilldescribeandimplementthisattention-basedmethod(with MLPs) fornaturallanguageinference, asdepictedin.5.1.
t .5.1 Thissectionfeedspretrained Glo Vetoanarchitecturebasedonattentionand MLPsfor naturallanguageinference.
16.5.1 The Model Simplerthanpreservingtheorderoftokensinpremisesandhypotheses, wecanjustalign tokensinonetextsequencetoeverytokenintheother, andviceversa, thencompareand aggregatesuchinformation topredict thelogical relationshipsbetweenpremises andhy- potheses.
Similartoalignmentoftokensbetweensourceandtargetsentencesinmachine translation, thealignmentoftokensbetweenpremisesandhypothesescanbeneatlyaccom- plishedbyattentionmechanisms.
t .5.2 Naturallanguageinferenceusingattentionmechanisms.
.5.2depictsthenaturallanguageinferencemethodusingattentionmechanisms.
Ata highlevel, itconsistsofthreejointlytrainedsteps: attending, comparing, andaggregating.
Wewillillustratethemstepbystepinthefollowing.
import torch from torch import nn from torch.
nn import functional as F from d2l import torch as d2l 765 Natural Language Inference: Using Attention Attending Thefirststepistoaligntokensinonetextsequencetoeachtokenintheothersequence.
Suppose that the premise is â€œi do need sleepâ€ and the hypothesis is â€œi am tiredâ€.
Due to semanticalsimilarity, wemaywishtoalignâ€œiâ€inthehypothesiswithâ€œiâ€inthepremise, and align â€œtiredâ€ in the hypothesis with â€œsleepâ€ in the premise.
Likewise, we may wish toalignâ€œiâ€inthepremisewithâ€œiâ€inthehypothesis, andalignâ€œneedâ€andâ€œsleepâ€inthe premise with â€œtiredâ€ in the hypothesis.
Note that such alignment is soft using weighted average, whereideallylargeweightsareassociatedwiththetokenstobealigned.
Forease ofdemonstration,.5.2showssuchalignmentinahardway.
Now we describe the soft alignment using attention mechanisms in more detail.
Denote by A = â€a 1 ,..., ağ‘š â€ and B = â€b 1 ,..., bğ‘› â€ thepremiseandhypothesis, whosenumber ğ‘‘-dimensionalwordvector.
Forsoftalignment, wecomputetheattentionweightsğ‘’ ğ‘–ğ‘— 2 R as ğ‘’ ğ‘–ğ‘— = ğ‘“â€ağ‘– â€>ğ‘“â€bğ‘— â€, (16.5.1) wherethefunction ğ‘“ isan MLPdefinedinthefollowingmlpfunction.
Theoutputdimen- sionof ğ‘“ isspecifiedbythenum_hiddensargumentofmlp.
def mlp(num_inputs, num_hiddens, flatten): net = [] net.
append(nn.
Dropout(0.2)) net.
append(nn.
Linear(num_inputs, num_hiddens)) net.
append(nn.
Re LU()) if flatten: net.
append(nn.
Flatten(start_dim=1)) net.
append(nn.
Dropout(0.2)) net.
append(nn.
Linear(num_hiddens, num_hiddens)) net.
append(nn.
Re LU()) if flatten: net.
append(nn.
Flatten(start_dim=1)) return nn.
Sequential(*net) It should be highlighted that, in (16.5.1) ğ‘“ takes inputs ağ‘– and bğ‘— separately rather than takesapairofthemtogetherasinput.
Thisdecompositiontrickleadstoonlyğ‘šâ€šğ‘›applica- tions(linearcomplexity)of ğ‘“ ratherthanğ‘šğ‘›applications(quadraticcomplexity).
Normalizing the attention weights in (16.5.1), we compute the weighted average of all thetokenvectorsinthehypothesistoobtainrepresentationofthehypothesisthatissoftly alignedwiththetokenindexedbyğ‘–inthepremise: ğ‘› expâ€ğ‘’ ğ‘–ğ‘— â€ ğœ· ğ‘– = ğ‘—=1 Ë ğ‘› ğ‘˜=1 expâ€ğ‘’ ğ‘–ğ‘˜ â€ bğ‘— .
(16.5.2) Likewise, wecomputesoftalignmentofpremisetokensforeachtokenindexedby ğ‘— inthe 766 Natural Language Processing: Applications hypothesis: ğ‘š expâ€ğ‘’ ğ‘–ğ‘— â€ ğœ¶ ğ‘— = ğ‘–=1 Ë ğ‘š ğ‘˜=1 expâ€ğ‘’ ğ‘˜ğ‘— â€ ağ‘– .
(16.5.3) Belowwedefinethe Attendclasstocomputethesoftalignmentofhypotheses(beta)with inputpremises Aandsoftalignmentofpremises(alpha)withinputhypotheses B.
class Attend(nn.
Module): def __init__(self, num_inputs, num_hiddens, **kwargs): super(Attend, self).__init__(**kwargs) self.
f = mlp(num_inputs, num_hiddens, flatten=False) def forward(self, A, B): # Shape of `A`/`B`: (`batch_size`, no.
of tokens in sequence A/B, # `embed_size`) # Shape of `f_A`/`f_B`: (`batch_size`, no.
of tokens in sequence A/B, # `num_hiddens`) f_A = self.
f(A) f_B = self.
f(B) # Shape of `e`: (`batch_size`, no.
of tokens in sequence A, # no.
of tokens in sequence B) e = torch.
bmm(f_A, f_B.
permute(0, 2, 1)) # Shape of `beta`: (`batch_size`, no.
of tokens in sequence A, # `embed_size`), where sequence B is softly aligned with each token # (axis 1 of `beta`) in sequence A beta = torch.
bmm(F.
softmax(e, dim=-1), B) # Shape of `alpha`: (`batch_size`, no.
of tokens in sequence B, # `embed_size`), where sequence A is softly aligned with each token # (axis 1 of `alpha`) in sequence B alpha = torch.
bmm(F.
softmax(e.
permute(0, 2, 1), dim=-1), A) return beta, alpha Comparing Inthenextstep, wecompareatokeninonesequencewiththeothersequencethatissoftly aligned with that token.
Note that in soft alignment, all the tokens from one sequence, though with probably different attention weights, will be compared with a token in the other sequence.
For easy of demonstration, .5.2 pairs tokens with aligned tokens in a hard way.
For example, suppose that the attending step determines that â€œneedâ€ and â€œsleepâ€inthepremisearebothalignedwithâ€œtiredâ€inthehypothesis, thepairâ€œtiredâ€“need sleepâ€willbecompared.
In the comparing step, we feed the concatenation (operator Â» , â€¦) of tokens from one se- quenceandalignedtokensfromtheothersequenceintoafunctionğ‘”(an MLP): vğ´,ğ‘– =ğ‘”â€Â»ağ‘– ,ğœ· ğ‘– â€¦â€,ğ‘– =1,...,ğ‘š (16.5.4) vğµ,ğ‘— =ğ‘”â€Â»bğ‘— ,ğœ¶ ğ‘— â€¦â€, ğ‘— =1,...,ğ‘›.
In(16.5.4), vğ´,ğ‘– isthecomparisonbetweentokenğ‘– inthepremiseandallthehypothesis tokensthataresoftlyalignedwithtokenğ‘–; whilevğµ,ğ‘— isthecomparisonbetweentoken ğ‘— in 767 Natural Language Inference: Using Attention thehypothesisandallthepremisetokensthataresoftlyalignedwithtoken ğ‘—.
Thefollowing Compareclassdefinessuchascomparingstep.
class Compare(nn.
Module): def __init__(self, num_inputs, num_hiddens, **kwargs): super(Compare, self).__init__(**kwargs) self.
g = mlp(num_inputs, num_hiddens, flatten=False) def forward(self, A, B, beta, alpha): V_A = self.
g(torch.
cat([A, beta], dim=2)) V_B = self.
g(torch.
cat([B, alpha], dim=2)) return V_A, V_B Aggregating in the last step we will aggregate such information to infer the logical relationship.
We beginbysummingupbothsets: ğ‘š ğ‘› vğ´= vğ´,ğ‘– , vğµ = vğµ,ğ‘— .
(16.5.5) ğ‘–=1 ğ‘—=1 Nextwefeedtheconcatenationofbothsummarizationresultsintofunctionâ„(an MLP)to obtaintheclassificationresultofthelogicalrelationship: yË† = â„â€Â»vğ´ , vğµ â€¦â€.
(16.5.6) Theaggregationstepisdefinedinthefollowing Aggregateclass.
class Aggregate(nn.
Module): def __init__(self, num_inputs, num_hiddens, num_outputs, **kwargs): super(Aggregate, self).__init__(**kwargs) self.
h = mlp(num_inputs, num_hiddens, flatten=True) self.
linear = nn.
Linear(num_hiddens, num_outputs) def forward(self, V_A, V_B): # Sum up both sets of comparison vectors V_A = V_A.
sum(dim=1) V_B = V_B.
sum(dim=1) # Feed the concatenation of both summarization results into an MLP Y_hat = self.
linear(self.
h(torch.
cat([V_A, V_B], dim=1))) return Y_hat Putting It All Together Byputtingtheattending, comparing, andaggregatingstepstogether, wedefinethedecom- posableattentionmodeltojointlytrainthesethreesteps.
768 Natural Language Processing: Applications class Decomposable Attention(nn.
Module): def __init__(self, vocab, embed_size, num_hiddens, num_inputs_attend=100, num_inputs_compare=200, num_inputs_agg=400, **kwargs): super(Decomposable Attention, self).__init__(**kwargs) self.
embedding = nn.
Embedding(len(vocab), embed_size) self.
attend = Attend(num_inputs_attend, num_hiddens) self.
compare = Compare(num_inputs_compare, num_hiddens) # There are 3 possible outputs: entailment, contradiction, and neutral self.
aggregate = Aggregate(num_inputs_agg, num_hiddens, num_outputs=3) def forward(self, X): premises, hypotheses = X A = self.
embedding(premises) B = self.
embedding(hypotheses) beta, alpha = self.
attend(A, B) V_A, V_B = self.
compare(A, B, beta, alpha) Y_hat = self.
aggregate(V_A, V_B) return Y_hat 16.5.2 Trainingand Evaluatingthe Model Now we will train and evaluate the defined decomposable attention model on the SNLI dataset.
Webeginbyreadingthedataset.
Readingthedataset Wedownloadandreadthe SNLIdatasetusingthefunctiondefinedin Section16.4.
The batchsizeandsequencelengtharesetto256and50, respectively.
batch_size, num_steps = 256, 50 train_iter, test_iter, vocab = d2l.
load_data_snli(batch_size, num_steps) read 549367 examples read 9824 examples Creatingthe Model We use the pretrained 100-dimensional Glo Ve embedding to represent the input tokens.
Thus, we predefine the dimension of vectors ağ‘– and bğ‘— in (16.5.1) as 100.
The output modelinstance, initializeitsparameters, andloadthe Glo Veembeddingtoinitializevectors ofinputtokens.
embed_size, num_hiddens, devices = 100, 200, d2l.
try_all_gpus() net = Decomposable Attention(vocab, embed_size, num_hiddens) (continuesonnextpage) 769 Natural Language Inference: Using Attention (continuedfrompreviouspage) glove_embedding = d2l.
Token Embedding('glove.6b.100d') embeds = glove_embedding[vocab.
idx_to_token] net.
embedding.
weight.
data.
copy_(embeds); Trainingand Evaluatingthe Model Incontrasttothesplit_batchfunctionin Section13.5thattakessingleinputssuchastext sequences(orimages), wedefineasplit_batch_multi_inputsfunctiontotakemultiple inputssuchaspremisesandhypothesesinminibatches.
Nowwecantrainandevaluatethemodelonthe SNLIdataset.
lr, num_epochs = 0.001, 4 trainer = torch.
optim.
Adam(net.
parameters(), lr=lr) loss = nn.
Cross Entropy Loss(reduction="none") d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) loss 0.496, train acc 0.805, test acc 0.828 20383.2 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] Usingthe Model Finally, definethepredictionfunctiontooutputthelogicalrelationshipbetweenapairof premiseandhypothesis.
#@save def predict_snli(net, vocab, premise, hypothesis): """Predict the logical relationship between the premise and hypothesis.""" net.
eval() premise = torch.
tensor(vocab[premise], device=d2l.
try_gpu()) (continuesonnextpage) 770 Natural Language Processing: Applications (continuedfrompreviouspage) hypothesis = torch.
tensor(vocab[hypothesis], device=d2l.
try_gpu()) label = torch.
argmax(net([premise.
reshape((1, -1)), hypothesis.
reshape((1, -1))]), dim=1) return 'entailment' if label == 0 else 'contradiction' if label == 1 \ else 'neutral' Wecanusethetrainedmodeltoobtainthenaturallanguageinferenceresultforasample pairofsentences.
predict_snli(net, vocab, ['he', 'is', 'good', '.'], ['he', 'is', 'bad', '.']) 'contradiction' 16.5.3 Summary Thedecomposableattentionmodelconsistsofthreestepsforpredictingthelogicalrela- tionshipsbetweenpremisesandhypotheses: attending, comparing, andaggregating.
Withattentionmechanisms, wecanaligntokensinonetextsequencetoeverytokenin theother, andviceversa.
Suchalignmentissoftusingweightedaverage, whereideally largeweightsareassociatedwiththetokenstobealigned.
Thedecompositiontrickleadstoamoredesirablelinearcomplexitythanquadraticcom- plexitywhencomputingattentionweights.
Wecanusepretrainedwordvectorsastheinputrepresentationfordownstreamnatural languageprocessingtasksuchasnaturallanguageinference.
16.5.4 Exercises 1.
Trainthemodelwithothercombinationsofhyperparameters.
Canyougetbetteraccu- racyonthetestset? 2.
What are major drawbacks of the decomposable attention model for natural language 247 inference? 3.
Supposethatwewanttogetthelevelofsemanticalsimilarity(e.
g., acontinuousvalue between0and1)foranypairofsentences.
Howshallwecollectandlabelthedataset? Canyoudesignamodelwithattentionmechanisms? Discussions247.
771 Fine-Tuning BERTfor Sequence-Leveland Token-Level Applications 16.6 Fine-Tuning BERT for Sequence-Level and Token-Level Applications Intheprevioussectionsofthischapter, wehavedesigneddifferentmodelsfornaturallan- guageprocessingapplications, suchasbasedon RNNs, CNNs, attention, and MLPs.
These modelsarehelpfulwhenthereisspaceortimeconstraint, however, craftingaspecificmodel foreverynaturallanguageprocessingtaskispracticallyinfeasible.
In Section15.8, wein- troducedapretrainingmodel, BERT, thatrequiresminimalarchitecturechangesforawide rangeofnaturallanguageprocessingtasks.
Ontheonehand, atthetimeofitsproposal, BERTimprovedthestateoftheartonvariousnaturallanguageprocessingtasks.
Onthe otherhand, asnotedin Section15.10, thetwoversionsoftheoriginal BERTmodelcome with110millionand340millionparameters.
Thus, whentherearesufficientcomputational resources, wemayconsiderfine-tuning BERTfordownstreamnaturallanguageprocessing applications.
In the following, we generalize a subset of natural language processing applications as sequence-levelandtoken-level.
Onthesequencelevel, weintroducehowtotransformthe BERT representation of the text input to the output label in single text classification and textpairclassificationorregression.
Onthetokenlevel, wewillbrieflyintroducenewap- plications such as text tagging and question answering and shed light on how BERT can representtheirinputsandgettransformedintooutputlabels.
Duringfine-tuning, theâ€œmini- malarchitecturechangesâ€requiredby BERTacrossdifferentapplicationsaretheextrafully connectedlayers.
Duringsupervisedlearningofadownstreamapplication, parametersof theextralayersarelearnedfromscratchwhilealltheparametersinthepretrained BERT modelarefine-tuned.
16.6.1 Single Text Classification Singletextclassificationtakesasingletextsequenceasinputandoutputsitsclassification result.
Besidessentimentanalysisthatwehavestudiedinthischapter, the Corpusof Lin- guistic Acceptability(Co LA)isalsoadatasetforsingletextclassification, judgingwhether agivensentenceisgrammaticallyacceptableornot(Warstadtetal.,2019).
Forinstance, â€œIshouldstudy.â€ isacceptablebutâ€œIshouldstudying.â€ isnot.
Section15.8describestheinputrepresentationof BERT.
The BERTinputsequenceunam- biguouslyrepresentsbothsingletextandtextpairs, wherethespecialclassificationtoken â€œ<cls>â€ is used for sequence classification and the special classification token â€œ<sep>â€ markstheendofsingletextorseparatesapairoftext.
Asshownin.6.1, insingle textclassificationapplications, the BERTrepresentationofthespecialclassificationtoken â€œ<cls>â€encodestheinformationoftheentireinputtextsequence.
Astherepresentationof theinputsingletext, itwillbefedintoasmall MLPconsistingoffullyconnected(dense) layerstooutputthedistributionofallthediscretelabelvalues.
16.6.2 Text Pair Classificationor Regression 772 Natural Language Processing: Applications t .6.1 Fine-tuning BERTforsingletextclassificationapplications, suchassentimentanalysis andtestinglinguisticacceptability.
Supposethattheinputsingletexthassixtokens.
Wehavealsoexaminednaturallanguageinferenceinthischapter.
Itbelongstotextpair classification, atypeofapplicationclassifyingapairoftext.
Takingapairoftextasinputbutoutputtingacontinuousvalue, semantictextualsimilarity isapopulartextpairregressiontask.
Thistaskmeasuressemanticsimilarityofsentences.
Forinstance, inthe Semantic Textual Similarity Benchmarkdataset, thesimilarityscoreof apairofsentencesisanordinalscalerangingfrom0(nomeaningoverlap)to5(meaning equivalence) (Cer et al., 2017).
The goal is to predict these scores.
Examples from the Semantic Textual Similarity Benchmarkdatasetinclude(sentence1, sentence2, similarity score): â€œAplaneistakingoff.â€,â€œAnairplaneistakingoff.â€,5.000; â€œAwomaniseatingsomething.â€,â€œAwomaniseatingmeat.â€,3.000; â€œAwomanisdancing.â€,â€œAmanistalking.â€,0.000.
t .6.2 Fine-tuning BERTfortextpairclassificationorregressionapplications, suchasnatural languageinferenceandsemantictextualsimilarity.
Supposethattheinputtextpairhas twoandthreetokens.
Comparing with single text classification in .6.1, fine-tuning BERT for text pair classificationin.6.2isdifferentintheinputrepresentation.
Fortextpairregression taskssuchassemantictextualsimilarity, trivialchangescanbeappliedsuchasoutputting 773 Fine-Tuning BERTfor Sequence-Leveland Token-Level Applications a continuous label value and using the mean squared loss: they are common for regres- sion.
16.6.3 Text Tagging Nowletâ€™sconsidertoken-leveltasks, suchastexttagging, whereeachtokenisassigneda label.
Amongtexttaggingtasks, part-of-speechtaggingassignseachwordapart-of-speech tag(e.
g., adjectiveanddeterminer)accordingtotheroleofthewordinthesentence.
For example, according to the Penn Treebank II tag set, the sentence â€œJohn Smith â€™s car is newâ€ should be tagged as â€œNNP (noun, proper singular) NNP POS (possessive ending) NN(noun, singularormass)VB(verb, baseform)JJ(adjective)â€.
t .6.3 Fine-tuning BERTfortexttaggingapplications, suchaspart-of-speechtagging.
Suppose thattheinputsingletexthassixtokens.
Fine-tuning BERT for text tagging applications is illustrated in .6.3.
Comparing with.6.1, theonlydistinctionliesinthatintexttagging, the BERTrepresentation ofeverytokenoftheinputtextisfedintothesameextrafullyconnectedlayerstooutput thelabelofthetoken, suchasapart-of-speechtag.
16.6.4 Question Answering Asanothertoken-levelapplication, questionansweringreflectscapabilitiesofreadingcom- prehension.
Forexample, the Stanford Question Answering Dataset(SQu ADv1.1)consists ofreadingpassagesandquestions, wheretheanswertoeveryquestionisjustasegmentof text (text span) from the passage that the question is about (Rajpurkar et al., 2016).
To explain, consider a passage â€œSome experts report that a maskâ€™s efficacy is inconclusive.
However, maskmakersinsistthattheirproducts, suchas N95respiratormasks, canguard againstthevirus.â€ andaquestionâ€œWhosaythat N95respiratormaskscanguardagainst thevirus?â€.
Theanswershouldbethetextspanâ€œmaskmakersâ€inthepassage.
Thus, the goalin SQu ADv1.1istopredictthestartandendofthetextspaninthepassagegivena pairofquestionandpassage.
Tofine-tune BERTforquestionanswering, thequestionandpassagearepackedasthefirst andsecondtextsequence, respectively, intheinputof BERT.
Topredictthepositionofthe start of the text span, the same additional fully connected layer will transform the BERT 774 Natural Language Processing: Applications t .6.4 Fine-tuning BERTforquestionanswering.
Supposethattheinputtextpairhastwoand threetokens.
representationofanytokenfromthepassageofpositionğ‘–intoascalarscoreğ‘  ğ‘–.
Suchscores ofallthepassagetokensarefurthertransformedbythesoftmaxoperationintoaprobability distribution, sothateachtokenpositionğ‘–inthepassageisassignedaprobabilityğ‘ ğ‘–ofbeing thestartofthetextspan.
Predictingtheendofthetextspanisthesameasabove, exceptthat parametersinitsadditionalfullyconnectedlayerareindependentfromthoseforpredicting thestart.
Whenpredictingtheend, anypassagetokenofpositionğ‘– istransformedbythe samefullyconnectedlayerintoascalarscoreğ‘’ ğ‘–.
.6.4depictsfine-tuning BERTfor questionanswering.
Forquestionanswering, thesupervisedlearningâ€™strainingobjectiveisasstraightforwardas maximizingthelog-likelihoodsoftheground-truthstartandendpositions.
Whenpredict- ingthespan, wecancomputethescoreğ‘  ğ‘– â€šğ‘’ ğ‘— foravalidspanfrompositionğ‘–toposition ğ‘— (ğ‘– ğ‘—), andoutputthespanwiththehighestscore.
16.6.5 Summary BERTrequiresminimalarchitecturechanges(extrafullyconnectedlayers)forsequence- levelandtoken-levelnaturallanguageprocessingapplications, suchassingletextclas- sification(e.
g., sentimentanalysisandtestinglinguisticacceptability), textpairclassi- ficationorregression(e.
g., naturallanguageinferenceandsemantictextualsimilarity), texttagging(e.
g., part-of-speechtagging), andquestionanswering.
Duringsupervisedlearningofadownstreamapplication, parametersoftheextralayers arelearnedfromscratchwhilealltheparametersinthepretrained BERTmodelare fine-tuned.
16.6.6 Exercises 1.
Letâ€™sdesignasearchenginealgorithmfornewsarticles.
Whenthesystemreceivesan query (e.
g., â€œoil industry during the coronavirus outbreakâ€), it should return a ranked listofnewsarticlesthataremostrelevanttothequery.
Supposethatwehaveahugepool ofnewsarticlesandalargenumberofqueries.
Tosimplifytheproblem, supposethat themostrelevantarticlehasbeenlabeledforeachquery.
Howcanweapplynegative sampling(see Section15.2.1)and BERTinthealgorithmdesign? 775 Natural Language Inference: Fine-Tuning BERT 2.
Howcanweleverage BERTintraininglanguagemodels? 3.
Canweleverage BERTinmachinetranslation? Discussions248.
248 16.7 Natural Language Inference: Fine-Tuning BERT In earlier sections of this chapter, we have designed an attention-based architecture (in Section 16.5) for the natural language inference task on the SNLI dataset (as described in Section 16.4).
Now we revisit this task by fine-tuning BERT.
As discussed in Section 16.6, natural language inference is a sequence-level text pair classification problem, and fine-tuning BERTonlyrequiresanadditional MLP-basedarchitecture, asillustratedin.7.1.
t .7.1 Thissectionfeedspretrained BERTtoan MLP-basedarchitecturefornaturallanguage inference.
Inthissection, wewilldownloadapretrainedsmallversionof BERT, thenfine-tuneitfor naturallanguageinferenceonthe SNLIdataset.
import json import multiprocessing import os import torch from torch import nn from d2l import torch as d2l 16.7.1 Loading Pretrained BERT We have explained how to pretrain BERT on the Wiki Text-2 dataset in Section 15.9 and Section15.10(notethattheoriginal BERTmodelispretrainedonmuchbiggercorpora).
Asdiscussedin Section15.10, theoriginal BERTmodelhashundredsofmillionsofparam- eters.
Inthefollowing, weprovidetwoversionsofpretrained BERT:â€œbert.
baseâ€isabout 776 Natural Language Processing: Applications asbigastheoriginal BERTbasemodelthatrequiresalotofcomputationalresourcesto fine-tune, whileâ€œbert.
smallâ€isasmallversiontofacilitatedemonstration.
'225d66f04cae318b841a13d32af3acc165f253ac') 'c72329e68a732bef0452e4b96a1c341c8910f81f') Eitherpretrained BERTmodelcontainsaâ€œvocab.
jsonâ€filethatdefinesthevocabularyset andaâ€œpretrained.
paramsâ€fileofthepretrainedparameters.
Weimplementthefollowing load_pretrained_modelfunctiontoloadpretrained BERTparameters.
def load_pretrained_model(pretrained_model, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, max_len, devices): data_dir = d2l.
download_extract(pretrained_model) # Define an empty vocabulary to load the predefined vocabulary vocab = d2l.
Vocab() vocab.
token_to_idx = {token: idx for idx, token in enumerate( vocab.
idx_to_token)} bert = d2l.
BERTModel( len(vocab), num_hiddens, ffn_num_hiddens=ffn_num_hiddens, num_heads=4, num_blks=2, dropout=0.2, max_len=max_len) # Load pretrained BERT parameters bert.
load_state_dict(torch.
load(os.
path.
join(data_dir, 'pretrained.
params'))) return bert, vocab Tofacilitatedemonstrationonmostofmachines, wewillloadandfine-tunethesmallver- sion (â€œbert.
smallâ€) of the pretrained BERT in this section.
In the exercise, we will show how to fine-tune the much larger â€œbert.
baseâ€ to significantly improve the testing accu- racy.
devices = d2l.
try_all_gpus() bert, vocab = load_pretrained_model( 'bert.
small', num_hiddens=256, ffn_num_hiddens=512, num_heads=4, num_blks=2, dropout=0.1, max_len=512, devices=devices) 16.7.2 The Datasetfor Fine-Tuning BERT Forthedownstreamtasknaturallanguageinferenceonthe SNLIdataset, wedefineacus- tomized dataset class SNLIBERTDataset.
In each example, the premise and hypothesis form a pair of text sequence and is packed into one BERT input sequence as depicted in andthehypothesisina BERTinputsequence.
Withthepredefinedmaximumlengthofa BERTinputsequence(max_len), thelasttokenofthelongeroftheinputtextpairkeeps 777 Natural Language Inference: Fine-Tuning BERT getting removed until max_len is met.
To accelerate generation of the SNLI dataset for fine-tuning BERT, we use 4 worker processes to generate training or testing examples in parallel.
class SNLIBERTDataset(torch.
utils.
data.
Dataset): def __init__(self, dataset, max_len, vocab=None): all_premise_hypothesis_tokens = [[ p_tokens, h_tokens] for p_tokens, h_tokens in zip( *[d2l.
tokenize([s.
lower() for s in sentences]) for sentences in dataset[:2]])] self.
labels = torch.
tensor(dataset[2]) self.
vocab = vocab self.
max_len = max_len (self.
all_token_ids, self.
all_segments, self.
valid_lens) = self._preprocess(all_premise_hypothesis_tokens) print('read ' + str(len(self.
all_token_ids)) + ' examples') def _preprocess(self, all_premise_hypothesis_tokens): pool = multiprocessing.
Pool(4) # Use 4 worker processes out = pool.
map(self._mp_worker, all_premise_hypothesis_tokens) all_token_ids = [ token_ids for token_ids, segments, valid_len in out] all_segments = [segments for token_ids, segments, valid_len in out] valid_lens = [valid_len for token_ids, segments, valid_len in out] return (torch.
tensor(all_token_ids, dtype=torch.
long), torch.
tensor(all_segments, dtype=torch.
long), torch.
tensor(valid_lens)) def _mp_worker(self, premise_hypothesis_tokens): p_tokens, h_tokens = premise_hypothesis_tokens self._truncate_pair_of_tokens(p_tokens, h_tokens) tokens, segments = d2l.
get_tokens_and_segments(p_tokens, h_tokens) token_ids = self.
vocab[tokens] + [self.
vocab['<pad>']] \ * (self.
max_len - len(tokens)) segments = segments + [0] * (self.
max_len - len(segments)) valid_len = len(tokens) return token_ids, segments, valid_len def _truncate_pair_of_tokens(self, p_tokens, h_tokens): # Reserve slots for '<CLS>', '<SEP>', and '<SEP>' tokens for the BERT # input while len(p_tokens) + len(h_tokens) > self.
max_len - 3: if len(p_tokens) > len(h_tokens): p_tokens.
pop() else: h_tokens.
pop() def __getitem__(self, idx): return (self.
all_token_ids[idx], self.
all_segments[idx], self.
valid_lens[idx]), self.
labels[idx] def __len__(self): return len(self.
all_token_ids) Afterdownloadingthe SNLIdataset, wegeneratetrainingandtestingexamplesbyinstan- 778 Natural Language Processing: Applications tiating the SNLIBERTDataset class.
Such examples will be read in minibatches during trainingandtestingofnaturallanguageinference.
# Reduce `batch_size` if there is an out of memory error.
In the original BERT # model, `max_len` = 512 batch_size, max_len, num_workers = 512, 128, d2l.
get_dataloader_workers() data_dir = d2l.
download_extract('SNLI') train_set = SNLIBERTDataset(d2l.
read_snli(data_dir, True), max_len, vocab) test_set = SNLIBERTDataset(d2l.
read_snli(data_dir, False), max_len, vocab) train_iter = torch.
utils.
data.
Data Loader(train_set, batch_size, shuffle=True, num_workers=num_workers) test_iter = torch.
utils.
data.
Data Loader(test_set, batch_size, num_workers=num_workers) read 549367 examples read 9824 examples 16.7.3 Fine-Tuning BERT As.6.2indicates, fine-tuning BERTfornaturallanguageinferencerequiresonlyan extra MLPconsistingoftwofullyconnectedlayers(seeself.
hiddenandself.
output inthefollowing BERTClassifierclass).
This MLPtransformsthe BERTrepresentation of the special â€œ<cls>â€ token, which encodes the information of both the premise and the hypothesis, intothreeoutputsofnaturallanguageinference: entailment, contradiction, and neutral.
class BERTClassifier(nn.
Module): def __init__(self, bert): super(BERTClassifier, self).__init__() self.
encoder = bert.
encoder self.
hidden = bert.
hidden self.
output = nn.
Lazy Linear(3) def forward(self, inputs): tokens_X, segments_X, valid_lens_x = inputs encoded_X = self.
encoder(tokens_X, segments_X, valid_lens_x) return self.
output(self.
hidden(encoded_X[:, 0, :])) Inthefollowing, thepretrained BERTmodelbertisfedintothe BERTClassifierinstance net for the downstream application.
In common implementations of BERT fine-tuning, onlytheparametersoftheoutputlayeroftheadditional MLP(net.
output)willbelearned fromscratch.
Alltheparametersofthepretrained BERTencoder(net.
encoder)andthe hiddenlayeroftheadditional MLP(net.
hidden)willbefine-tuned.
net = BERTClassifier(bert) Recall that in Section 15.8 both the Mask LM class and the Next Sentence Pred class have parametersintheiremployed MLPs.
Theseparametersarepartofthoseinthepretrained BERT model bert, and thus part of parameters in net.
However, such parameters are 779 Natural Language Inference: Fine-Tuning BERT only for computing the masked language modeling loss and the next sentence prediction lossduringpretraining.
Thesetwolossfunctionsareirrelevanttofine-tuningdownstream applications, thustheparametersoftheemployed MLPsin Mask LMand Next Sentence Pred arenotupdated(staled)when BERTisfine-tuned.
Toallowparameterswithstalegradients, theflagignore_stale_grad=Trueissetinthe stepfunctionof d2l.
train_batch_ch13.
Weusethisfunctiontotrainandevaluatethe modelnetusingthetrainingset(train_iter)andthetestingset(test_iter)of SNLI.
Duetothelimitedcomputationalresources, thetrainingandtestingaccuracycanbefurther improved: weleaveitsdiscussionsintheexercises.
lr, num_epochs = 1e-4, 5 trainer = torch.
optim.
Adam(net.
parameters(), lr=lr) loss = nn.
Cross Entropy Loss(reduction='none') net(next(iter(train_iter))[0]) d2l.
train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) loss 0.520, train acc 0.791, test acc 0.786 10588.8 examples/sec on [device(type='cuda', index=0), device(type='cuda',â£ â†©! index=1)] 16.7.4 Summary Wecanfine-tunethepretrained BERTmodelfordownstreamapplications, suchasnat- urallanguageinferenceonthe SNLIdataset.
During fine-tuning, the BERT model becomes part of the model for the downstream application.
Parameters that are only related to pretraining loss will not be updated duringfine-tuning.
16.7.5 Exercises 1.
Fine-tuneamuchlargerpretrained BERTmodelthatisaboutasbigastheoriginal BERT basemodelifyourcomputationalresourceallows.
Setargumentsintheload_pretrained_model functionas: replacingâ€˜bert.
smallâ€™withâ€˜bert.
baseâ€™, increasingvaluesofnum_hiddens=256, ffn_num_hiddens=512, num_heads=4, andnum_blks=2to768,3072,12, and12, re- 780 Natural Language Processing: Applications spectively.
Byincreasingfine-tuningepochs(andpossiblytuningotherhyperparame- ters), canyougetatestingaccuracyhigherthan0.86? 2.
How to truncate a pair of sequences according to their ratio of length? Compare this pairtruncationmethodandtheoneusedinthe SNLIBERTDatasetclass.
Whataretheir prosandcons? Discussions249.
249 17 Reinforcement Learning Pratik Chaudhari(Universityof Pennsylvaniaand Amazon), Rasool Fakoor(Amazon), and Kavosh Asadi(Amazon) Reinforcement Learning(RL)isasuiteoftechniquesthatallowsustobuildmachinelearn- ingsystemsthattakedecisionssequentially.
Forexample, apackagecontainingnewclothes thatyoupurchasedfromanonlineretailerarrivesatyourdoorstepafterasequenceofde- cisions, e.
g., theretailerfindingtheclothesinthewarehouseclosesttoyourhouse, putting theclothesinabox, transportingtheboxvialandorbyair, anddeliveringittoyourhouse withinthecity.
Therearemanyvariablesthataffectthedeliveryofthepackagealongthe way, e.
g., whetherornottheclotheswereavailableinthewarehouse, howlongittookto transport the box, whether it arrived in your city before the daily delivery truck left, etc.
The key idea is that at each stage these variables that we do not often control affect the entiresequenceofeventsinthefuture, e.
g., ifthereweredelaysinpackingtheboxinthe warehousetheretailermayneedtosendthepackageviaairinsteadofgroundtoensurea timelydelivery.
Reinforcement Learningmethodsallowustotaketheappropriateaction at each stage of a sequential decision making problem in order to maximize some utility eventually, e.
g., thetimelydeliveryofthepackagetoyou.
Suchsequentialdecisionmakingproblemsareseeninnumerousotherplaces, e.
g., while playing Go250 yourcurrentmovedeterminesthenextmovesandtheopponentâ€™smovesare 250 thevariablesthatyoucannotcontrolâ€¦asequenceofmoveseventuallydetermineswhether ornotyouwin; themoviesthat Netflixrecommendstoyounowdeterminewhatyouwatch, whetheryoulikethemovieornotisunknownto Netflix, eventuallyasequenceofmovie recommendationsdetermineshowsatisfiedyouarewith Netflix.
Reinforcementlearning is being used today to develop effective solutions to these problems (Mnih et al., 2013, Silveretal.,2016).
Thekeydistinctionbetweenreinforcementlearningandstandarddeep learningisthatinstandarddeeplearningthepredictionofatrainedmodelononetestdatum doesnotaffectthepredictionsonafuturetestdatum; inreinforcementlearningdecisions atfutureinstants(in RL, decisionsarealsocalledactions)areaffectedbywhatdecisions weremadeinthepast.
In this chapter, we will develop the fundamentals of reinforcement learning and obtain hands-onexperienceinimplementingsomepopularreinforcementlearningmethods.
We willfirstdevelopaconceptcalleda Markov Decision Process(MDP)whichallowsusto think of such sequential decision making problems.
An algorithm called Value Iteration willbeourfirstinsightintosolvingreinforcementlearningproblemsundertheassumption thatweknowhowtheuncontrolledvariablesinan MDP(in RL, thesecontrolledvariables 781 782 Reinforcement Learning are called the environment) typically behave.
Using the more general version of Value Iteration, analgorithmcalled Q-Learning, wewillbeabletotakeappropriateactionseven whenwedonotnecessarilyhavefullknowledgeoftheenvironment.
Wewillthenstudy howtousedeepnetworksforreinforcementlearningproblemsbyimitatingtheactionsof anexpert.
Andfinally, wewilldevelopareinforcementlearningmethodthatusesadeep networktotakeactionsinunknownenvironments.
Thesetechniquesformthebasisofmore advanced RLalgorithmsthatareusedtodayinavarietyofreal-worldapplications, some ofwhichwewillpointtointhechapter.
t .1 Reinforcement Learning Structure 17.1 Markov Decision Process (MDP) In this section, we will discuss how to formulate reinforcement learning problems using Markov decision processes (MDPs) and describe various components of MDPs in de- tail.
17.1.1 Definitionofan MDP AMarkovdecisionprocess(MDP)(Bellman,1957)isamodelforhowthestateofasystem evolves as different actions are applied to the system.
A few different quantities come togethertoforman MDP.
Let Sbethesetofstatesinthe MDP.
Asaconcreteexamplesee.1.1, forarobot thatisnavigatingagridworld.
Inthiscase, S correspondstothesetoflocationsthat therobotcanbeatanygiventimestep.
Let Abethesetofactionsthattherobotcantakeateachstate, e.
g.,â€œgoforwardâ€,â€œturn 783 Markov Decision Process(MDP) t .1.1 Asimplegridworldnavigationtaskwheretherobotnotonlyhastofinditswaytothegoal location(shownasagreenhouse)butalsohastoavoidtraplocations(shownasredcross signs).
rightâ€, â€œturn leftâ€, â€œstay at the same locationâ€, etc.
Actions can change the current stateoftherobottosomeotherstatewithintheset S.
Itmayhappenthatwedonotknowhowtherobotmovesexactlybutonlyknowitupto someapproximation.
Wemodelthissituationinreinforcementlearningasfollows: if therobottakesanactionâ€œgoforwardâ€, theremightbeasmallprobabilitythatitstays atthecurrentstate, anothersmallprobabilitythatitâ€œturnsleftâ€, etc.
Mathematically, this amounts to defining a â€œtransition functionâ€ğ‘‡ : S A S ! Â»0,1â€¦ such that ğ‘‡â€ğ‘ ,ğ‘,ğ‘ 0â€ = ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€usingtheconditionalprobabilityofreachingastateğ‘ 0 given thattherobotwasatstateğ‘ andtookanactionğ‘.
Thetransitionfunctionisaprobability Ë distributionandwethereforehave ğ‘ 02S ğ‘‡â€ğ‘ ,ğ‘,ğ‘ 0â€ =1forallğ‘  2Sandğ‘ 2 A, i.
e., therobothastogotosomestateifittakesanaction.
Wenowconstructanotionofwhichactionsareusefulandwhichonesarenotusingthe conceptofaâ€œrewardâ€ğ‘Ÿ : S A ! R.
Wesaythattherobotgetsarewardğ‘Ÿâ€ğ‘ ,ğ‘â€ if the robot takes an action ğ‘ at state ğ‘ .
If the rewardğ‘Ÿâ€ğ‘ ,ğ‘â€ is large, this indicates thattakingtheactionğ‘atstateğ‘ ismoreusefultoachievingthegoaloftherobot, i.
e., goingtothegreenhouse.
Iftherewardğ‘Ÿâ€ğ‘ ,ğ‘â€issmall, thenactionğ‘islessusefulto achievingthisgoal.
Itisimportanttonotethattherewardisdesignedbytheuser(the personwhocreatesthereinforcementlearningalgorithm)withthegoalinmind.
17.1.2 Returnand Discount Factor Thedifferentcomponentsabovetogetherforma Markovdecisionprocess(MDP) MDP: â€S, A,ğ‘‡,ğ‘Ÿâ€.
(17.1.1) 784 Reinforcement Learning Letâ€™s now consider the situation when the robot starts at a particular state ğ‘  2 S and 0 continuestakingactionstoresultinatrajectory 0 0 0 1 1 1 2 2 2 Ateachtimestepğ‘¡therobotisatastateğ‘  ğ‘¡ andtakesanactionğ‘ ğ‘¡ whichresultsinareward ğ‘Ÿ ğ‘¡ = ğ‘Ÿâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€.
The return of a trajectory is the total reward obtained by the robot along suchatrajectory ğ‘…â€ğœâ€ =ğ‘Ÿ â€šğ‘Ÿ â€šğ‘Ÿ â€š .
(17.1.3) 0 1 2 Thegoalinreinforcementlearningistofindatrajectorythathasthelargestreturn.
Think of the situation when the robot continues to travel in the gridworld without ever reaching the goal location.
The sequence of states and actions in a trajectory can be in- finitelylonginthiscaseandthereturnofanysuchinfinitelylongtrajectorywillbeinfinite.
Inordertokeepthereinforcementlearningformulationmeaningfulevenforsuchtrajecto- ries, weintroducethenotionofadiscountfactor ğ›¾ < 1.
Wewritethediscountedreturn as 1 ğ‘…â€ğœâ€ =ğ‘Ÿ 0 â€šğ›¾ğ‘Ÿ 1 â€šğ›¾2ğ‘Ÿ 2 â€š = ğ›¾ğ‘¡ğ‘Ÿ ğ‘¡ .
(17.1.4) ğ‘¡=0 Note that if ğ›¾ is very small, the rewards earned by the robot in the far future, say ğ‘¡ = 1000, areheavilydiscountedbythefactorğ›¾1000.
Thisencouragestherobottoselectshort trajectoriesthatachieveitsgoal, namelythatofgoingtothegreenhouseinthegridwold isencouragedtoexploreandthenfindthebesttrajectorytogotothegoallocation.
17.1.3 Discussionofthe Markov Assumption Letusthinkofanewrobotwherethestate ğ‘  ğ‘¡ isthelocationasabovebuttheactionğ‘ ğ‘¡ is theaccelerationthattherobotappliestoitswheelsinsteadofanabstractcommandlikeâ€œgo forwardâ€.
Ifthisrobothassomenon-zerovelocityatstateğ‘  ğ‘¡, thenthenextlocationğ‘  ğ‘¡â€š1 is afunctionofthepastlocationğ‘  ğ‘¡, theaccelerationğ‘ ğ‘¡, alsothevelocityoftherobotattime ğ‘¡ whichisproportionaltoğ‘  ğ‘¡ ğ‘  ğ‘¡ 1 .
Thisindicatesthatweshouldhave ğ‘  ğ‘¡â€š1 =somefunctionâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ ,ğ‘  ğ‘¡ 1 â€; (17.1.5) theâ€œsomefunctionâ€inourcasewouldbe Newtonâ€™slawofmotion.
Thisisquitedifferent fromourtransitionfunctionthatsimplydependsuponğ‘  ğ‘¡ andğ‘ ğ‘¡.
Markovsystemsareallsystemswherethenextstate ğ‘  ğ‘¡â€š1 isonlyafunctionofthecurrent stateğ‘  ğ‘¡ andtheactionğ‘ ğ‘¡ takenatthecurrentstate.
In Markovsystems, thenextstatedoes notdependonwhichactionsweretakeninthepastorthestatesthattherobotwasatinthe past.
Forexample, thenewrobotthathasaccelerationastheactionaboveisnot Markovian because the next location ğ‘  ğ‘¡â€š1 depends upon the previous state ğ‘  ğ‘¡ 1 through the velocity.
Itmayseemthat Markoviannatureofasystemisarestrictiveassumption, butitisnotso.
Markov Decision Processesarestillcapableofmodelingaverylargeclassofrealsystems.
For example, for our new robot, if we chose our state ğ‘  ğ‘¡ to the tuple â€location, velocityâ€ 785 Value Iteration thenthesystemis Markovianbecauseitsnextstateâ€locationğ‘¡â€š1 , velocity ğ‘¡â€š1 â€dependsonly uponthecurrentstateâ€locationğ‘¡ , velocity ğ‘¡ â€andtheactionatthecurrentstateğ‘ ğ‘¡.
17.1.4 Summary The reinforcement learning problem is typically modeled using Markov Decision Pro- cesses.
AMarkovdecisionprocess(MDP)isdefinedbyatupleoffourentitiesâ€S, A,ğ‘‡,ğ‘Ÿâ€ where S isthestatespace, A istheactionspace,ğ‘‡ isthetransitionfunctionthatencodes thetransitionprobabilitiesofthe MDPandğ‘Ÿ istheimmediaterewardobtainedbytaking actionataparticularstate.
17.1.5 Exercises 1.
Supposethatwewanttodesignan MDPtomodel Mountain Car251 problem.
251 1.
Whatwouldbethesetofstates? 2.
Whatwouldbethesetofactions? 3.
Whatwouldbethepossiblerewardfunctions? 252 2.
Howwouldyoudesignan MDPforan Atarigamelike Ponggame252? Discussions253.
253 17.2 Value Iteration In this section we will discuss how to pick the best action for the robot at each state to maximizethereturnofthetrajectory.
Wewilldescribeanalgorithmcalled Value Iteration andimplementitforasimulatedrobotthattravelsoverafrozenlake.
17.2.1 Stochastic Policy Astochasticpolicydenotedasğœ‹â€ğ‘ j ğ‘ â€ (policyforshort)isaconditionaldistributionover the actions ğ‘ 2 A given the state ğ‘  2 S, ğœ‹â€ğ‘ j ğ‘ â€ ğ‘ƒâ€ğ‘ j ğ‘ â€.
As an example, if the robot has four actions A = {go left, go down, go right, go up}.
The policy at a state ğ‘  2 S for such a set of actions A is a categorical distribution where the probabilities of the four actions could be Â»0.4,0.2,0.1,0.3â€¦; at some other state ğ‘ 0 2 S the probabilities Ë ğ‘ ğœ‹â€ğ‘ j ğ‘ â€ = 1 for any state ğ‘ .
A deterministic policy is a special case of a stochastic policy in that the distribution ğœ‹â€ğ‘ j ğ‘ â€ only gives non-zero probability to one particular action, e.
g., Â»1,0,0,0â€¦ forourexamplewithfouractions.
Tomakethenotationlesscumbersome, wewilloftenwriteğœ‹â€ğ‘ â€ astheconditionaldistri- butioninsteadofğœ‹â€ğ‘ j ğ‘ â€.
786 Reinforcement Learning 17.2.2 Value Function Imagine now that the robot starts at a state ğ‘  and at each time instant, it first samples 0 an action from the policy ğ‘ ğ‘¡ ğœ‹â€ğ‘  ğ‘¡ â€ and takes this action to result in the next state ğ‘  ğ‘¡â€š1 .
Thetrajectoryğœ = â€ğ‘  0 ,ğ‘ 0 ,ğ‘Ÿ 0 ,ğ‘  1 ,ğ‘ 1 ,ğ‘Ÿ 1 ,...â€, canbedifferentdependinguponwhich particula Ë r action ğ‘ ğ‘¡ is sampled at intermediate instants.
We define the average return ğ‘…â€ğœâ€ = 1 ğ‘¡=0 ğ›¾ğ‘¡ğ‘Ÿâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€ofallsuchtrajectories h i h 1 i ğ‘‰ğœ‹â€ğ‘  0 â€ = ğ¸ ğ‘ğ‘¡ ğœ‹â€ğ‘ ğ‘¡â€ ğ‘…â€ğœâ€ = ğ¸ ğ‘ğ‘¡ ğœ‹â€ğ‘ ğ‘¡â€ ğ›¾ğ‘¡ğ‘Ÿâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€ , (17.2.1) ğ‘¡=0 whereğ‘  ğ‘¡â€š1 ğ‘ƒâ€ğ‘  ğ‘¡â€š1 j ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€isthenextstateoftherobotandğ‘Ÿâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€istheinstantaneous rewardobtainedbytakingactionğ‘ ğ‘¡ instateğ‘  ğ‘¡ attimeğ‘¡.
Thisiscalledtheâ€œvaluefunctionâ€ forthepolicyğœ‹.
Insimplewords, thevalueofastateğ‘  forapolicyğœ‹, denotedbyğ‘‰ğœ‹â€ğ‘  â€, 0 0 istheexpectedğ›¾-discountedreturnobtainedbytherobotifitbeginsatstateğ‘  andtakes 0 actionsfromthepolicyğœ‹ateachtimeinstant.
Wenextbreakdownthetrajectoryintotwostages(i)thefirststagewhichcorrespondsto ğ‘  ! ğ‘  upon taking the action ğ‘ , and (ii) a second stage which is the trajectory ğœ0 = 0 1 0 â€ğ‘  ,ğ‘ ,ğ‘Ÿ ,...â€ thereafter.
Thekeyideabehindallalgorithmsinreinforcementlearningis 1 1 1 that the value of state ğ‘  can be written as the average reward obtained in the first stage 0 andthevaluefunctionaveragedoverallpossiblenextstatesğ‘  .
Thisisquiteintuitiveand 1 arisesfromour Markovassumption: theaveragereturnfromthecurrentstateisthesum oftheaveragereturnfromthenextstateandtheaveragerewardofgoingtothenextstate.
Mathematically, wewritethetwostagesas h h ii ğ‘‰ğœ‹â€ğ‘  0 â€ =ğ‘Ÿâ€ğ‘  0 ,ğ‘ 0 â€â€šğ›¾ ğ¸ ğ‘ 0 ğœ‹â€ğ‘  0 â€ ğ¸ ğ‘  1 ğ‘ƒâ€ğ‘  1 jğ‘  0 ,ğ‘ 0 â€ ğ‘‰ğœ‹â€ğ‘  1 â€ .
(17.2.2) Thisdecompositionisverypowerful: itisthefoundationoftheprincipleofdynamicpro- gramming upon which all reinforcement learning algorithms are based.
Notice that the secondstagegetstwoexpectations, oneoverthechoicesoftheactionğ‘ takeninthefirst 0 stageusingthestochasticpolicyandanotheroverthepossiblestatesğ‘  obtainedfromthe 1 chosenaction.
Wecanwrite(17.2.2)usingthetransitionprobabilitiesinthe Markovde- cisionprocess(MDP)as h i ğ‘‰ğœ‹â€ğ‘ â€ = ğœ‹â€ğ‘ j ğ‘ â€ ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ğœ‹â€ğ‘ 0â€ ; forallğ‘  2S.
(17.2.3) ğ‘2A ğ‘ 02S Animportantthingtonoticehereisthattheaboveidentityholdsforallstatesğ‘  2Sbecause wecanthinkofanytrajectorythatbeginsatthatstateandbreakdownthetrajectoryinto twostages.
17.2.3 Action-Value Function Inimplementations, itisoftenusefultomaintainaquantitycalledtheâ€œactionvalueâ€func- tion which is a closely related quantity to the value function.
This is defined to be the averagereturnofatrajectorythatbeginsatğ‘  butwhentheactionofthefirststageisfixed 0 787 Value Iteration tobeğ‘ 0 h 1 i ğ‘„ğœ‹â€ğ‘  0 ,ğ‘ 0 â€ =ğ‘Ÿâ€ğ‘  0 ,ğ‘ 0 â€â€šğ¸ ğ‘ğ‘¡ ğœ‹â€ğ‘ ğ‘¡â€ ğ›¾ğ‘¡ğ‘Ÿâ€ğ‘  ğ‘¡ ,ğ‘ ğ‘¡ â€ , (17.2.4) ğ‘¡=1 notethatthesummationinsidetheexpectationisfromğ‘¡ =1,...,1becausetherewardof thefirststageisfixedinthiscase.
Wecanagainbreakdownthetrajectoryintotwoparts andwrite ğ‘„ğœ‹â€ğ‘ ,ğ‘â€ =ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ ğœ‹â€ğ‘0 j ğ‘ 0â€ğ‘„ğœ‹â€ğ‘ 0,ğ‘0â€; forallğ‘  2S,ğ‘ 2 A.
ğ‘ 02S ğ‘02A (17.2.5) Thisversionistheanalogof(17.2.3)fortheactionvaluefunction.
17.2.4 Optimal Stochastic Policy Boththevaluefunctionandtheaction-valuefunctiondependuponthepolicythattherobot chooses.
We will next think of the â€œoptimal policyâ€ that achieves the maximal average return ğœ‹ =argmaxğ‘‰ğœ‹â€ğ‘  0 â€.
(17.2.6) ğœ‹ Of all possible stochastic policies that the robot could have taken, the optimal policy ğœ‹ achievesthelargestaveragediscountedreturnfortrajectoriesstartingfromstateğ‘  .
Letus 0 denotethevaluefunctionandtheaction-valuefunctionoftheoptimalpolicyasğ‘‰ ğ‘‰ğœ‹ andğ‘„ ğ‘„ğœ‹ .
Letusobservethatforadeterministicpolicywherethereisonlyoneactionthatispossible underthepolicyatanygivenstate.
Thisgivesus h i ğœ‹ â€ğ‘ â€ =argmax ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ â€ğ‘ 0â€ .
(17.2.7) ğ‘2A ğ‘ 02S Agoodmnemonictorememberthisisthattheoptimalactionatstateğ‘ (foradeterministic policy) is the one that maximizes the sum of reward ğ‘Ÿâ€ğ‘ ,ğ‘â€ from the first stage and the averagereturnofthetrajectoriesstartingfromthenextsate ğ‘ 0 , averagedoverallpossible nextstatesğ‘ 0 fromthesecondstage.
17.2.5 Principleof Dynamic Programming Our developement in the previous section in (17.2.2) or (17.2.5) can be turned into an algorithm to compute the optimal value functionğ‘‰ or the action-value function ğ‘„ , re- spectively.
Observethat h i ğ‘‰ â€ğ‘ â€ = ğœ‹ â€ğ‘ j ğ‘ â€ ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ â€ğ‘ 0â€ ; forallğ‘  2S.
(17.2.8) ğ‘2A ğ‘ 02S For a deterministic optimal policy ğœ‹ , since there is only one action that can be taken at stateğ‘ , wecanalsowrite n o ğ‘‰ â€ğ‘ â€ =argmax ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ â€ğ‘ 0â€ ğ‘2A (17.2.9) ğ‘ 02S 788 Reinforcement Learning forallstatesğ‘  2 S.
Thisidentityiscalledtheâ€œprincipleofdynamicprogrammingâ€(Bell- man, 1952, Bellman, 1957).
Itwasformulatedby Richard Bellmanin1950sandwecan rememberitasâ€œtheremainderofanoptimaltrajectoryisalsooptimalâ€.
17.2.6 Value Iteration Wecanturntheprincipleofdynamicprogrammingintoanalgorithmforfindingtheoptimal valuefunctioncalledvalueiteration.
Thekeyideabehindvalueiterationistothinkofthis identityasasetofconstraintsthattietogetherğ‘‰ â€ğ‘ â€atdifferentstatesğ‘  2S.
Weinitialize thevaluefunctiontosomearbitraryvaluesğ‘‰ â€ğ‘ â€ forallstatesğ‘  2 S.
Atthe ğ‘˜th iteration, 0 the Value Iterationalgorithmupdatesthevaluefunctionas n o ğ‘‰ ğ‘˜â€š1 â€ğ‘ â€ =max ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ ğ‘˜ â€ğ‘ 0â€ ; forallğ‘  2S.
(17.2.10) ğ‘2A ğ‘ 02S Itturnsoutthatas ğ‘˜ ! 1thevaluefunctionestimatedbythe Value Iterationalgorithm convergestotheoptimalvaluefunctionirrespectiveoftheinitializationğ‘‰ , 0 ğ‘‰ â€ğ‘ â€ = lim ğ‘‰ ğ‘˜ â€ğ‘ â€; forallstatesğ‘  2S.
(17.2.11) ğ‘˜!1 Thesame Value Iterationalgorithmcanbeequivalentlywrittenusingtheaction-valuefunc- tionas ğ‘„ ğ‘˜â€š1 â€ğ‘ ,ğ‘â€ =ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ max ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘„ ğ‘˜ â€ğ‘ 0,ğ‘0â€; forallğ‘  2S,ğ‘ 2 A.
ğ‘02A ğ‘ 02S (17.2.12) Inthiscaseweinitializeğ‘„ â€ğ‘ ,ğ‘â€tosomearbitraryvaluesforallğ‘  2Sandğ‘ 2 A.
Again 0 wehaveğ‘„ â€ğ‘ ,ğ‘â€ =limğ‘˜!1 ğ‘„ ğ‘˜ â€ğ‘ ,ğ‘â€forallğ‘  2Sandğ‘ 2 A.
17.2.7 Policy Evaluation Value Iterationenablesustocomputetheoptimalvaluefunction, i.
e.,ğ‘‰ğœ‹ oftheoptimal deterministic policy ğœ‹ .
We can also use similar iterative updates to compute the value function associated with any other, potentially stochastic, policy ğœ‹.
We again initialize ğ‘‰ğœ‹â€ğ‘ â€ to some arbitrary values for all states ğ‘  2 S and at the ğ‘˜th iteration, perform the 0 updates h i ğ‘‰ğœ‹ â€ğ‘ â€ = ğœ‹â€ğ‘ j ğ‘ â€ ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ğ‘‰ğœ‹â€ğ‘ 0â€ ; forallğ‘  2S.
ğ‘˜â€š1 ğ‘˜ (17.2.13) ğ‘2A ğ‘ 02S Thisalgorithmisknownaspolicyevaluationandisusefultocomputethevaluefunction giventhepolicy.
Again, itturnsoutthatas ğ‘˜ ! 1theseupdatesconvergetothecorrect valuefunctionirrespectiveoftheinitializationğ‘‰ , 0 ğ‘‰ğœ‹â€ğ‘ â€ = lim ğ‘‰ ğ‘˜ ğœ‹â€ğ‘ â€; forallstatesğ‘  2S.
(17.2.14) ğ‘˜!1 The algorithm for computing the action-value function ğ‘„ğœ‹â€ğ‘ ,ğ‘â€ of a policy ğœ‹ is analo- gous.
789 Value Iteration 17.2.8 Implementationof Value Iteration Wenextshowhowtoimplement Value Iterationforanavigationproblemcalled Frozen Lake from Open AIGym254.
Wefirstneedtosetuptheenviromentasshowninthefollowing 254 code.
%matplotlib inline import random import numpy as np from d2l import torch as d2l seed = 0 # Random number generator seed gamma = 0.95 # Discount factor num_iters = 10 # Number of iterations random.
seed(seed) # Set the random seed to ensure results can be reproduced np.
random.
seed(seed) # Now set up the environment env_info = d2l.
make_env('Frozen Lake-v1', seed=seed) Inthe Frozen Lakeenvironment, therobotmovesona4 4grid(thesearethestates)with actions that are â€œupâ€ ("), â€œdownâ€ (!), â€œleftâ€ ( ), and â€œrightâ€ (!).
The environment containsanumberofholes(H)cellsandfrozen(F)cellsaswellasagoalcell(G), allof which are unknown to the robot.
To keep the problem simple, we assume the robot has reliableactions, i.
e.ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ =1forallğ‘  2S,ğ‘ 2 A.
Iftherobotreachesthegoal, the trialendsandtherobotreceivesarewardof1irrespectiveoftheaction; therewardatany otherstateis0forallactions.
Theobjectiveoftherobotistolearnapolicythatreachesthe goallocation(G)fromagivenstartlocation(S)(thisisğ‘  )tomaximizethereturn.
0 The following function implements Value Iteration, where env_info contains MDP and environmentrelatedinformationandgammaisthediscountfactor: def value_iteration(env_info, gamma, num_iters): env_desc = env_info['desc'] # 2D array shows what each item means prob_idx = env_info['trans_prob_idx'] nextstate_idx = env_info['nextstate_idx'] reward_idx = env_info['reward_idx'] num_states = env_info['num_states'] num_actions = env_info['num_actions'] mdp = env_info['mdp'] V = np.
zeros((num_iters + 1, num_states)) Q = np.
zeros((num_iters + 1, num_states, num_actions)) pi = np.
zeros((num_iters + 1, num_states)) for k in range(1, num_iters + 1): for s in range(num_states): for a in range(num_actions): # Calculate \sum_{s'} p(s'\mid s, a) [r + \gamma v_k(s')] for pxrds in mdp[(s, a)]: # mdp(s, a): [(p1, next1, r1, d1),(p2, next2, r2, d2),..] pr = pxrds[prob_idx] # p(s'\mid s, a) (continuesonnextpage) 790 Reinforcement Learning (continuedfrompreviouspage) nextstate = pxrds[nextstate_idx] # Next state reward = pxrds[reward_idx] # Reward Q[k, s, a] += pr * (reward + gamma * V[k - 1, nextstate]) # Record max value and max action V[k, s] = np.
max(Q[k, s,:]) pi[k, s] = np.
argmax(Q[k, s,:]) d2l.
show_value_function_progress(env_desc, V[:-1], pi[:-1]) value_iteration(env_info=env_info, gamma=gamma, num_iters=num_iters) Theabovepicturesshowthepolicy(thearrowindicatestheaction)andvaluefunction(the changeincolorshowshowthevaluefunctionchangesovertimefromtheinitialvalueshown bydarkcolortotheoptimalvalueshownbylightcolors.).
Aswesee, Value Iterationfinds theoptimalvaluefunctionafter10iterationsandthegoalstate(G)canbereachedstarting fromanystateaslongasitisnotan Hcell.
Anotherinterestingaspectoftheimplementation is that in addition to finding the optimal value function, we also automatically found the optimalpolicyğœ‹ correspondingtothisvaluefunction.
17.2.9 Summary Themainideabehindthe Value Iterationalgorithmistousetheprincipleofdynamicpro- grammingtofindtheoptimalaveragereturnobtainedfromagivenstate.
Notethatimple- 791 Q-Learning mentingthe Value Iterationalgorithmrequiresthatweknowthe Markovdecisionprocess (MDP), e.
g., thetransitionandrewardfunctions, completely.
17.2.10 Exercises 1.
Tryincreasingthegridsizeto8 8.
Comparedwith4 4grid, howmanyiterations doesittaketofindtheoptimalvaluefunction? 2.
Whatisthecomputationalcomplexityofthe Value Iterationalgorithm? 3.
Runthe Value Iterationalgorithmagainwithğ›¾ (i.
e.â€œgammaâ€intheabovecode)when itequalsto0,0.5, and1andanalyzeitsresults.
4.
How does the value of ğ›¾ affect the number of iterations taken by Value Iteration to converge? Whathappenswhenğ›¾ =1? Discussions255.
255 17.3 Q-Learning Intheprevioussection, wediscussedthe Value Iterationalgorithmwhichrequiresaccessing thecomplete Markovdecisionprocess(MDP), e.
g., thetransitionandrewardfunctions.
In thissection, wewilllookat Q-Learning(Watkinsand Dayan,1992)whichisanalgorithm tolearnthevaluefunctionwithoutnecessarilyknowingthe MDP.
Thisalgorithmembodies the central idea behind reinforcement learning: it will enable the robot to obtain its own data.
17.3.1 The Q-Learning Algorithm Recallthatvalueiterationfortheaction-valuefunctionin Value Iteration(page785)cor- respondstotheupdate ğ‘„ ğ‘˜â€š1 â€ğ‘ ,ğ‘â€ =ğ‘Ÿâ€ğ‘ ,ğ‘â€â€šğ›¾ ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ maxğ‘„ ğ‘˜ â€ğ‘ 0,ğ‘0â€; forallğ‘  2Sandğ‘ 2 A.
ğ‘02A ğ‘ 02S (17.3.1) Aswediscussed, implementingthisalgorithmrequiresknowingthe MDP, specificallythe transitionfunctionğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€.
Thekeyideabehind Q-Learningistoreplacethesumma- tionoverall ğ‘ 0 2 S intheaboveexpressionbyasummationoverthestatesvisitedbythe robot.
Thisallowsustosubverttheneedtoknowthetransitionfunction.
17.3.2 An Optimization Problem Underlying Q-Learning Letusimaginethattherobotusesapolicyğœ‹ ğ‘’ â€ğ‘ j ğ‘ â€ totakeactions.
Justliketheprevious Recall that value iteration is really a set of constraints that ties together the action-value 792 Reinforcement Learning ğ‘„ â€ğ‘ ,ğ‘â€ ofdifferentstatesandactionstoeachother.
Wecanimplementanapproximate versionofvalueiterationusingthedatathattherobothascollectedusingğœ‹ ğ‘’ as ğ‘› ğ‘‡ 1 1 ğ‘„Ë† =m ğ‘„ in ğ‘›ğ‘‡ â€ğ‘„â€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€ ğ‘Ÿâ€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€ ğ›¾m ğ‘ a 0 xğ‘„â€ğ‘  ğ‘¡ ğ‘– â€š1 ,ğ‘0â€â€2.
| ğ‘– = 1 ğ‘¡ = 0 {z } (17.3.2) d=efâ„“â€ğ‘„â€ Letusfirstobservethesimilaritiesanddifferencesbetweenthisexpressionandvalueiter- ationabove.
Iftherobotâ€™spolicyğœ‹ ğ‘’wereequaltotheoptimalpolicyğœ‹ , andifitcollected aninfiniteamountofdata, thenthisoptimizationproblemwouldbeidenticaltotheopti- mizationproblemunderlyingvalueiteration.
Butwhilevalueiterationrequiresustoknow ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€, theoptimizationobjectivedoesnothavethisterm.
Wehavenotcheated: as therobotusesthepolicy ğœ‹ ğ‘’ totakeanactionğ‘ğ‘– ğ‘¡ atstate ğ‘  ğ‘¡ ğ‘– , thenextstate ğ‘  ğ‘¡ ğ‘– â€š1 isasample drawn from the transition function.
So the optimization objective also has access to the transitionfunction, butimplicitlyintermsofthedatacollectedbytherobot.
Thevariablesofouroptimizationproblemareğ‘„â€ğ‘ ,ğ‘â€ forall ğ‘  2 S and ğ‘ 2 A.
Wecan minimize the objective using gradient descent.
For every pair â€ğ‘ ğ‘–,ğ‘ğ‘–â€ in our dataset, we ğ‘¡ ğ‘¡ canwrite ğ‘„â€ğ‘ ğ‘–,ğ‘ğ‘–â€ ğ‘„â€ğ‘ ğ‘–,ğ‘ğ‘–â€ ğ›¼r â„“â€ğ‘„â€ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘„â€ğ‘ ğ‘–,ğ‘ğ‘–â€ ğ‘¡ ğ‘¡ (17.3.3) = â€1 ğ›¼â€ğ‘„â€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€ ğ›¼ ğ‘Ÿâ€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€â€šğ›¾m ğ‘ a 0 xğ‘„â€ğ‘  ğ‘¡ ğ‘– â€š1 ,ğ‘0â€ , whereğ›¼ isthelearningrate.
Typicallyinrealproblems, whentherobotreachesthegoal location, thetrajectoriesend.
Thevalueofsuchaterminalstateiszerobecausetherobot doesnottakeanyfurtheractionsbeyondthisstate.
Weshouldmodifyourupdatetohandle suchstatesas ğ‘„â€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€ = â€1 ğ›¼â€ğ‘„â€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€ ğ›¼ ğ‘Ÿâ€ğ‘  ğ‘¡ ğ‘–,ğ‘ğ‘– ğ‘¡ â€â€šğ›¾â€1 âŠ® ğ‘  ğ‘¡ ğ‘– â€š1 isterminal â€m ğ‘ a 0 xğ‘„â€ğ‘  ğ‘¡ ğ‘– â€š1 ,ğ‘0â€ .
(17.3.4) w ot h h e e r r e w âŠ® is ğ‘  e ğ‘¡ ğ‘– â€š .
1 T is h te e rm v i a n l a u l e is o a f n st i a n t d e i - c a a c t t o io r n va tu r p ia l b es le â€ t ğ‘  h , a ğ‘ t â€ is th o a n t e ar i e f n ğ‘  ğ‘¡ ğ‘– o â€š t 1 a is pa a rt te o r f m t i h n e al da st t a a t s e et a i n s d se z t er t o o 1.
Thisalgorithmisknownas Q-Learning.
Given the solution of these updates ğ‘„Ë†, which is an approximation of the optimal value function ğ‘„ , we can obtain the optimal deterministic policy corresponding to this value functioneasilyusing ğœ‹Ë†â€ğ‘ â€ =argmax ğ‘„Ë†â€ğ‘ ,ğ‘â€.
(17.3.5) ğ‘ Therecanbesituationswhentherearemultipledeterministicpoliciesthatcorrespondto thesameoptimalvaluefunction; suchtiescanbebrokenarbitrarilybecausetheyhavethe samevaluefunction.
17.3.3 Explorationin Q-Learning 793 Q-Learning Thepolicyusedbytherobottocollectdatağœ‹ ğ‘’ iscriticaltoensurethat Q-Learningworks well.
Afterall, wehavereplacedtheexpectationoverğ‘ 0 usingthetransitionfunctionğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ usingthedatacollectedbytherobot.
Ifthepolicyğœ‹ ğ‘’ doesnotreachdiversepartsof thestate-actionspace, thenitiseasytoimagineourestimateğ‘„Ë†willbeapoorapproximation oftheoptimalğ‘„ .
Itisalsoimportanttonotethatinsuchasituation, theestimateofğ‘„ at allstatesğ‘  2Swillbebad, notjusttheonesvisitedbyğœ‹ ğ‘’.
Thisisbecausethe Q-Learning objective (or value iteration) is a constraint that ties together the value of all state-action pairs.
Itisthereforecriticaltopickthecorrectpolicyğœ‹ ğ‘’ tocollectdata.
Wecanmitigatethisconcernbypickingacompletelyrandompolicyğœ‹ ğ‘’thatsamplesactions uniformlyrandomlyfrom A.
Suchapolicywouldvisitallstates, butitwilltakealarge numberoftrajectoriesbeforeitdoesso.
We thus arrive at the second key idea in Q-Learning, namely exploration.
Typical im- plementations of Q-Learning tie together the current estimate of ğ‘„ and the policy ğœ‹ ğ‘’ to set ( ğœ‹ ğ‘’ â€ğ‘ j ğ‘ â€ = argmax ğ‘0 ğ‘„Ë†â€ğ‘ ,ğ‘0â€ withprob.
1 ğœ– (17.3.6) uniformâ€Aâ€ withprob.
ğœ–, whereğœ– iscalledtheâ€œexplorationparameterâ€andischosenbytheuser.
Thepolicy ğœ‹ ğ‘’ is called an exploration policy.
This particular ğœ‹ ğ‘’ is called an ğœ–-greedy exploration policy becauseitchoosestheoptimalaction(underthecurrentestimateğ‘„Ë†)withprobability1 ğœ– but explores randomly with the remainder probability ğœ–.
We can also use the so-called softmaxexplorationpolicy ğ‘’ğ‘„Ë†â€ğ‘ ,ğ‘â€ ğ‘‡ ğœ‹ ğ‘’ â€ğ‘ j ğ‘ â€ = Ë ; (17.3.7) ğ‘’ğ‘„Ë†â€ğ‘ ,ğ‘0â€ ğ‘‡ ğ‘0 wherethehyper-parameterğ‘‡ iscalledtemperature.
Alargevalueofğœ– inğœ–-greedypolicy functionssimilarlytoalargevalueoftemperatureğ‘‡ forthesoftmaxpolicy.
It is important to note that when we pick an exploration that depends upon the current estimateoftheaction-valuefunctionğ‘„Ë†, weneedtoresolvetheoptimizationproblemperi- odically.
Typicalimplementationsof Q-Learningmakeonemini-batchupdateusingafew state-action pairs in the collected dataset (typically the ones collected from the previous timestepoftherobot)aftertakingeveryactionusingğœ‹ ğ‘’.
17.3.4 Theâ€œSelf-correctingâ€Propertyof Q-Learning Thedatasetcollectedbytherobotduring Q-Learninggrowswithtime.
Boththeexploration policy ğœ‹ ğ‘’ and the estimateğ‘„Ë† evolve as the robot collects more data.
This gives us a key insight into why Q-Learning works well.
Consider a state ğ‘ : if a particular action ğ‘ has a large value under the current estimateğ‘„Ë†â€ğ‘ ,ğ‘â€, then both the ğœ–-greedy and the softmax explorationpolicieshavealargerprobabilityofpickingthisaction.
Ifthisactionactuallyis nottheidealaction, thenthefuturestatesthatarisefromthisactionwillhavepoorrewards.
Thenextupdateofthe Q-Learningobjectivewillthereforereducethevalueğ‘„Ë†â€ğ‘ ,ğ‘â€, which willreducetheprobabilityofpickingthisactionthenexttimetherobotvisitsstateğ‘ .
Bad 794 Reinforcement Learning actions, e.
g., oneswhosevalueisoverestimatedinğ‘„Ë†â€ğ‘ ,ğ‘â€, areexploredbytherobotbut their value is correct in the next update of the Q-Learning objective.
Good actions, e.
g., whosevalueğ‘„Ë†â€ğ‘ ,ğ‘â€ islarge, areexploredmoreoftenbytherobotandtherebyreinforced.
Thispropertycanbeusedtoshowthat Q-Learningcanconvergetotheoptimalpolicyeven ifitbeginswitharandompolicyğœ‹ ğ‘’ (Watkinsand Dayan,1992).
Thisabilitytonotonlycollectnewdatabutalsocollecttherightkindofdataisthecen- tralfeatureofreinforcementlearningalgorithms, andthisiswhatdistinguishesthemfrom supervised learning.
Q-Learning, using deep neural networks (which we will see in the DQNchapeterlater), isresponsiblefortheresurgenceofreinforcementlearning(Mnihet al.,2013).
17.3.5 Implementationof Q-Learning Wenowshowhowtoimplement Q-Learningon Frozen Lakefrom Open AIGym256.
Note 256 thisisthesamesetupasweconsiderin Value Iteration(page785)experiment.
%matplotlib inline import random import numpy as np from d2l import torch as d2l seed = 0 # Random number generator seed gamma = 0.95 # Discount factor num_iters = 256 # Number of iterations alpha = 0.9 # Learing rate epsilon = 0.9 # Epsilon in epsilion gready algorithm random.
seed(seed) # Set the random seed np.
random.
seed(seed) # Now set up the environment env_info = d2l.
make_env('Frozen Lake-v1', seed=seed) Inthe Frozen Lakeenvironment, therobotmovesona4 4grid(thesearethestates)with actions that are â€œupâ€ ("), â€œdownâ€ (!), â€œleftâ€ ( ), and â€œrightâ€ (!).
The environment containsanumberofholes(H)cellsandfrozen(F)cellsaswellasagoalcell(G), allof which are unknown to the robot.
To keep the problem simple, we assume the robot has reliableactions, i.
e.ğ‘ƒâ€ğ‘ 0 j ğ‘ ,ğ‘â€ =1forallğ‘  2S,ğ‘ 2 A.
Iftherobotreachesthegoal, the trialendsandtherobotreceivesarewardof1irrespectiveoftheaction; therewardatany otherstateis0forallactions.
Theobjectiveoftherobotistolearnapolicythatreachesthe goallocation(G)fromagivenstartlocation(S)(thisisğ‘  )tomaximizethereturn.
0 Wefirstimplementğœ–-greedymethodasfollows: def e_greedy(env, Q, s, epsilon): if random.
random() < epsilon: return env.
action_space.
sample() else: return np.
argmax(Q[s,:]) 795 Q-Learning Wearenowreadytoimplement Q-learning: def q_learning(env_info, gamma, num_iters, alpha, epsilon): env_desc = env_info['desc'] # 2D array specifying what each grid itemâ£ â†©! means env = env_info['env'] # 2D array specifying what each grid item means num_states = env_info['num_states'] num_actions = env_info['num_actions'] Q = np.
zeros((num_states, num_actions)) V = np.
zeros((num_iters + 1, num_states)) pi = np.
zeros((num_iters + 1, num_states)) for k in range(1, num_iters + 1): # Reset environment state, done = env.
reset(), False while not done: # Select an action for a given state and acts in env based onâ£ â†©! selected action action = e_greedy(env, Q, state, epsilon) next_state, reward, done, _ = env.
step(action) # Q-update: y = reward + gamma * np.
max(Q[next_state,:]) Q[state, action] = Q[state, action] + alpha * (y - Q[state,â£ â†©! action]) # Move to the next state state = next_state # Record max value and max action for visualization purpose only for s in range(num_states): V[k, s] = np.
max(Q[s,:]) pi[k, s] = np.
argmax(Q[s,:]) d2l.
show_Q_function_progress(env_desc, V[:-1], pi[:-1]) q_learning(env_info=env_info, gamma=gamma, num_iters=num_iters, alpha=alpha,â£ â†©! epsilon=epsilon) Thisresultshowsthat Q-learningcanfindtheoptimalsolutionforthisproblemroughlyafter 250iterations.
However, whenwecomparethisresultwiththe Value Iterationalgorithmâ€™s result(see Implementationof Value Iteration(page789)), wecanseethatthe Value Iteration algorithm needs way fewer iterations to find the optimal solution for this problem.
This happens because the Value Iteration algorithm has access to the full MDP whereas Q- learningdoesnot.
17.3.6 Summary Q-learningisoneofthemostfundamentalreinforcement-learningalgorithms.
Ithasbeen attheepicenteroftherecentsuccessofreinforcementlearning, mostnotablyinlearning to play video games (Mnih et al., 2013).
Implementing Q-learning does not require that we know the Markov decision process (MDP), e.
g., the transition and reward functions, completely.
796 Reinforcement Learning 17.3.7 Exercises 1.
Tryincreasingthegridsizeto8 8.
Comparedwith4 4grid, howmanyiterations doesittaketofindtheoptimalvaluefunction? 2.
Run the Q-learning algorithm again with ğ›¾ (i.
e.
â€œgammaâ€ in the above code) when it equalsto0,0.5, and1andanalyzeitsresults.
3.
Run the Q-learning algorithm again with ğœ– (i.
e.
â€œepsilonâ€ in the above code) when it equalsto0,0.5, and1andanalyzeitsresults.
Discussions257.
257 18 Gaussian Processes Andrew Gordon Wilson(New York Universityand Amazon) Gaussianprocesses(GPs)areubitiquous.
Youhavealreadyencounteredmanyexamplesof GPswithoutrealizingit.
Anymodelthatislinearinitsparameterswitha Gaussiandistri- butionovertheparametersisa Gaussianprocess.
Thisclassspansdiscretemodels, includ- ingrandomwalks, andautoregressiveprocesses, aswellascontinuousmodels, including Bayesianlinearregressionmodels, polynomials, Fourierseries, radialbasisfunctions, and evenneuralnetworkswithaninfinitenumberofhiddenunits.
Thereisarunningjokethat â€œeverythingisaspecialcaseofa Gaussianprocessâ€.
Learningabout Gaussianprocessesisimportantforthreereasons: (1)theyprovideafunc- tionspaceperspectiveofmodelling, whichmakesunderstandingavarietyofmodelclasses, includingdeepneuralnetworks, muchmoreapproachable;(2)theyhaveanextraordinary range of applications where they are state-of-the-art, including active learning, hyperpa- rameter learning, auto-ML, and spatiotemporal regression; (3) over the last few years, algorithmic advances have made Gaussian processes increasingly scalable and relevant, harmonizing with deep learning through frameworks such as GPy Torch258 (Gardner et 258 al.,2018).
Indeed, GPsandanddeepneuralnetworksarenotcompetingapproaches, but highlycomplementary, andcanbecombinedtogreateffect.
Thesealgorithmicadvances arenotjustrelevantto Gaussianprocesses, butprovideafoundationinnumericalmethods thatisbroadlyusefulindeeplearning.
In this chapter, we introduce Gaussian processes.
In the introductory notebook, we start by reasoning intuitively about what Gaussian processes are and how they directly model functions.
In the priors notebook, we focus on how to specify Gaussian process priors.
Wedirectlyconnectthetradiationalweight-spaceapproachtomodellingtofunctionspace, which will help us reason about constructing and understanding machine learning mod- els, includingdeepneuralnetworks.
Wethenintroducepopularcovariancefunctions, also known as kernels, which control the generalization properties of a Gaussian process.
A GPwithagivenkerneldefinesaprioroverfunctions.
Intheinferencenotebook, wewill show how to use data to infer a posterior, in order to make predictions.
This notebook containsfrom-scratchcodeformakingpredictionswitha Gaussianprocess, aswellasan introductionto GPy Torch.
Inupcomingnotebooks, wewillintroducethenumericsbehind Gaussianprocesses, whichisusefulforscaling Gaussianprocessesbutalsoapowerfulgen- eralfoundationfordeeplearning, andadvanceduse-casessuchashyperparametertuningin deeplearning.
Ourexampleswillmakeuseof GPy Torch, whichmakes Gaussianprocesses scale, andiscloselyintegratedwithdeeplearningfunctionalityand Py Torch.
797 798 Gaussian Processes 18.1 Introduction to Gaussian Processes Inmanycases, machinelearningamountstoestimatingparametersfromdata.
Thesepa- rametersareoftennumerousandrelativelyuninterpretableâ€”suchastheweightsofaneu- ralnetwork.
Gaussianprocesses, bycontrast, provideamechanismfordirectlyreasoning aboutthehigh-levelpropertiesoffunctionsthatcouldfitourdata.
Forexample, wemay haveasenseofwhetherthesefunctionsarequicklyvarying, periodic, involveconditional independencies, ortranslationinvariance.
Gaussianprocessesenableustoeasilyincorpo- ratethesepropertiesintoourmodel, bydirectlyspecifyinga Gaussiandistributionoverthe functionvaluesthatcouldfitourdata.
Letâ€™sgetafeelforhow Gaussianprocessesoperate, bystartingwithsomeexamples.
Suppose we observe the following dataset, of regression targets (outputs), ğ‘¦, indexed by inputs, ğ‘¥.
Asanexample, thetargetscouldbechangesincarbondioxideconcentrations, and the inputs could be the times at which these targets have been recorded.
What are somefeaturesofthedata? Howquicklydoesitseemtovarying? Dowehavedatapoints collectedatregularintervals, oraretheremissinginputs? Howwouldyouimaginefilling inthemissingregions, orforecastingupuntilğ‘¥ =25? t .1.1 Observeddata.
Inordertofitthedatawitha Gaussianprocess, westartbyspecifyingapriordistribution over what types of functions we might believe to be reasonable.
Here we show several sample functions from a Gaussian process.
Does this prior look reasonable? Note here wearenotlookingforfunctionsthatfitourdataset, butinsteadforspecifyingreasonable high-levelpropertiesofthesolutions, suchashowquicklytheyvarywithinputs.
Notethat wewillseecodeforreproducingalloftheplotsinthisnotebook, inthenextnotebookson priorsandinference.
Onceweconditionondata, wecanusethispriortoinferaposteriordistributionoverfunc- tionsthatcouldfitthedata.
Hereweshowsampleposteriorfunctions.
Weseethateachofthesefunctionsareentirelyconsistentwithourdata, perfectlyrunning througheachobservation.
Inordertousetheseposteriorsamplestomakepredictions, we canaveragethevaluesofeverypossiblesamplefunctionfromtheposterior, tocreatethe 799 Introductionto Gaussian Processes t .1.2 Samplepriorfunctionsthatwemaywanttorepresentwithourmodel.
t .1.3 Sampleposteriorfunctions, oncewehaveobservedthedata.
curvebelow, inthickblue.
Notethatwedonotactuallyhavetotakeaninfinitenumberof samplestocomputethisexpectation; aswewillseelater, wecancomputetheexpectation inclosedform.
t .1.4 Posteriorsamples, alongsideposteriormean, whichcanbeusedforpointpredictions, in blue.
We may also want a representation of uncertainty, so we know how confident we should be in our predictions.
Intuitively, we should have more uncertainty where there is more variabilityinthesampleposteriorfunctions, asthistellsustherearemanymorepossible valuesthetruefunctioncouldtake.
Thistypeofuncertaintyiscalledepistemicuncertainty, whichisthereducibleuncertaintyassociatedwithlackofinformation.
Asweacquiremore data, thistypeofuncertaintydisappears, astherewillbeincreasinglyfewersolutionscon- sistentwithwhatweobserve.
Likewiththeposteriormean, wecancomputetheposterior variance (the variability of these functions in the posterior) in closed form.
With shade, weshowtwotimestheposteriorstandarddeviationoneithersideofthemean, creatinga 800 Gaussian Processes credibleintervalthathasa95%probabilityofcontainingthetruevalueofthefunctionfor anyinputğ‘¥.
t .1.5 Posteriorsamples, including95%credibleset.
The plot looks somewhat cleaner if we remove the posterior samples, simply visualizing the data, posterior mean, and 95% credible set.
Notice how the uncertainty grows away fromthedata, apropertyofepistemicuncertainty.
t .1.6 Pointpredictions, andcredibleset.
Thepropertiesofthe Gaussianprocessthatweusedtofitthedataarestronglycontrolled bywhatâ€™scalledacovariancefunction, alsoknownasakernel.
Thecovariancefunction weusediscalledthe RBF(Radial Basis Function)kernel, whichhastheform 1 ğ‘˜ â€ğ‘¥,ğ‘¥0â€ =Covâ€ğ‘“â€ğ‘¥â€, ğ‘“â€ğ‘¥0â€â€ =ğ‘2exp jjğ‘¥ ğ‘¥0jj2 (18.1.1) RBF 2â„“2 Thehyperparametersofthiskernelareinterpretable.
Theamplitudeparameterğ‘controls theverticalscaleoverwhichthefunctionisvarying, andthelength-scaleparameterâ„“con- trolstherateofvariation(thewiggliness)ofthefunction.
Largerğ‘ meanslargerfunction values, andlargerâ„“ meansmoreslowlyvaryingfunctions.
Letâ€™sseewhathappenstoour samplepriorandposteriorfunctionsaswevaryğ‘andâ„“.
Thelength-scalehasaparticularlypronouncedeffectonthepredictionsanduncertaintyof a GP.
At jjğ‘¥ ğ‘¥0jj = â„“ , thecovariancebetweenapairoffunctionvaluesisğ‘2expâ€ 0.5â€.
Atlargerdistancesthanâ„“, thevaluesofthefunctionvaluesbecomesnearlyuncorrelated.
This means that if we want to make a prediction at a point ğ‘¥ , then function values with inputsğ‘¥suchthatjjğ‘¥ ğ‘¥0jj >â„“willnothaveastrongeffectonourpredictions.
Letâ€™s see how changing the lengthscale affects sample prior and posterior functions, and 801 Introductionto Gaussian Processes crediblesets.
Theabovefitsusealength-scaleof2.
Letâ€™snowconsiderâ„“ =0.1,0.5,2,5,10 .
Alength-scaleof0.1isverysmallrelativetotherangeoftheinputdomainweareconsid- ering,25.
Forexample, thevaluesofthefunctionatğ‘¥ =5andğ‘¥ =10willhaveessentially nocorrelationatsuchalength-scale.
Ontheotherhand, foralength-scaleof10, thefunc- tionvaluesattheseinputswillbehighlycorrelated.
Notethattheverticalscalechangesin thefollowingfigures.
802 Gaussian Processes 803 Introductionto Gaussian Processes Notice as the length-scale increases the â€˜wigglinessâ€™ of the functions decrease, and our uncertaintydecreases.
Ifthelength-scaleissmall, theuncertaintywillquicklyincreaseas wemoveawayfromthedata, asthedatapointsbecomelessinformativeaboutthefunction values.
Now, letâ€™svarytheamplitudeparameter, holdingthelength-scalefixedat2.
Notethever- ticalscaleisheldfixedforthepriorsamples, andvariesfortheposteriorsamples, soyou canclearlyseeboththeincreasingscaleofthefunction, andthefitstothedata.
804 Gaussian Processes Weseetheamplitudeparameteraffectsthescaleofthefunction, butnottherateofvariation.
Atthispoint, wealsohavethesensethatthegeneralizationperformanceofourprocedure willdependonhavingreasonablevaluesforthesehyperparameters.
Valuesofâ„“ =2andğ‘ = 1appearedtoprovidereasonablefits, whilesomeoftheothervaluesdidnot.
Fortunately, thereisarobustandautomaticwaytospecifythesehyperparameters, usingwhatiscalled themarginallikelihood, whichwewillreturntointhenotebookoninference.
805 Introductionto Gaussian Processes So what is a GP, really? As we started, a GP simply says that any collection of function variate Gaussian distribution.
The mean vector ğœ‡ of this distribution is given by a mean function, whichistypicallytakentobeaconstantorzero.
Thecovariancematrixofthis distributionisgivenbythekernelevaluatedatallpairsoftheinputsğ‘¥.
2 ğ‘“â€ğ‘¥â€3 2ğ‘˜â€ğ‘¥,ğ‘¥â€ ğ‘˜â€ğ‘¥,ğ‘¥ â€ ...
ğ‘˜â€ğ‘¥,ğ‘¥ â€3 6 7 ' 6 1 ğ‘› 7â€œ 6ğ‘“â€ğ‘¥ â€7 â€º 6ğ‘˜â€ğ‘¥ ,ğ‘¥â€ ğ‘˜â€ğ‘¥ ,ğ‘¥ â€ ...
ğ‘˜â€ğ‘¥ ,ğ‘¥ â€7fi 6 1 7 â€º 6 1 1 1 1 ğ‘› 7fi 6 6 6 .
.
.
7 7 7 Nâ€º â€º â€º ğœ‡,6 6 6 .
.
.
.
.
.
.
7 7 7 fi fi fi (18.1.2) 6 7 6 7 4ğ‘“â€ğ‘¥ ğ‘› â€5 Â« 4ğ‘˜â€ğ‘¥ ğ‘› ,ğ‘¥â€ ğ‘˜â€ğ‘¥ ğ‘› ,ğ‘¥ 1 â€ ...
ğ‘˜â€ğ‘¥ ğ‘› ,ğ‘¥ ğ‘› â€5â€¹ Equation(18.1.2)specifiesa GPprior.
Wecancomputetheconditionaldistributionof ğ‘“â€ğ‘¥â€ foranyğ‘¥ given ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€, thefunctionvalueswehaveobserved.
Thisconditional distributioniscalledtheposterior, anditiswhatweusetomakepredictions.
Inparticular, where ğ‘š = ğ‘˜â€ğ‘¥,ğ‘¥ 1:ğ‘› â€ğ‘˜â€ğ‘¥ 1:ğ‘› ,ğ‘¥ 1:ğ‘› â€ 1ğ‘“â€ğ‘¥ 1:ğ‘› â€ (18.1.4) ğ‘ 2 = ğ‘˜â€ğ‘¥,ğ‘¥â€ ğ‘˜â€ğ‘¥,ğ‘¥ 1:ğ‘› â€ğ‘˜â€ğ‘¥ 1:ğ‘› ,ğ‘¥ 1:ğ‘› â€ 1ğ‘˜â€ğ‘¥,ğ‘¥ 1:ğ‘› â€ (18.1.5) where ğ‘˜â€ğ‘¥,ğ‘¥ 1:ğ‘› â€ is a 1 ğ‘› vector formed by evaluating ğ‘˜â€ğ‘¥,ğ‘¥ ğ‘– â€ for ğ‘– = 1,...,ğ‘› and ğ‘˜â€ğ‘¥ 1:ğ‘› ,ğ‘¥ 1:ğ‘› â€ is an ğ‘› ğ‘› matrix formed by evaluating ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€ for ğ‘–, ğ‘— = 1,...,ğ‘›.
ğ‘š is whatwecanuseasapointpredictorforanyğ‘¥, andğ‘ 2iswhatweuseforuncertainty: ifwe wanttocreateanintervalwitha95%probabilitythat ğ‘“â€ğ‘¥â€isintheinterval, wewoulduse ğ‘š 2ğ‘ .
Thepredictivemeansanduncertaintiesforalltheabovefigureswerecreatedusing theseequations.
Theobserveddatapointsweregivenby ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€andchoseafine grainedsetofğ‘¥pointstomakepredictions.
Letâ€™s suppose we observe a single datapoint, ğ‘“â€ğ‘¥ â€, and we want to determine the value 1 of ğ‘“â€ğ‘¥â€ at some ğ‘¥.
Because ğ‘“â€ğ‘¥â€ is described by a Gaussian process, we know the joint distributionoverâ€ğ‘“â€ğ‘¥â€, ğ‘“â€ğ‘¥ â€â€is Gaussian: 1 ğ‘“â€ğ‘¥â€ ğ‘˜â€ğ‘¥,ğ‘¥â€ ğ‘˜â€ğ‘¥,ğ‘¥ â€ N ğœ‡, 1 (18.1.6) ğ‘“â€ğ‘¥ â€ ğ‘˜â€ğ‘¥ ,ğ‘¥â€ ğ‘˜â€ğ‘¥ ,ğ‘¥ â€ 1 1 1 1 Theoff-diagonalexpressionğ‘˜â€ğ‘¥,ğ‘¥ â€ = ğ‘˜â€ğ‘¥ ,ğ‘¥â€tellsushowcorrelatedthefunctionvalues 1 1 willbeâ€”howstronglydetermined ğ‘“â€ğ‘¥â€willbefrom ğ‘“â€ğ‘¥ â€.
Wehaveseenalreadythatif 1 weusealargelength-scale, relativetothedistancebetweenğ‘¥ andğ‘¥ , jjğ‘¥ ğ‘¥ jj, thenthe 1 1 functionvalueswillbehighlycorrelated.
Wecanvisualizetheprocessofdetermining ğ‘“â€ğ‘¥â€ from ğ‘“â€ğ‘¥ â€ both in the space of functions, and in the joint distribution over ğ‘“â€ğ‘¥ â€, ğ‘“â€ğ‘¥â€.
1 1 Letâ€™s initially consider an ğ‘¥ such that ğ‘˜â€ğ‘¥,ğ‘¥ â€ = 0.9, and ğ‘˜â€ğ‘¥,ğ‘¥â€ = 1, meaning that the 1 valueof ğ‘“â€ğ‘¥â€ismoderatelycorrelatedwiththevalueof ğ‘“â€ğ‘¥ â€.
Inthejointdistribution, the 1 contoursofconstantprobabilitywillberelativelynarrowellipses.
Suppose we observe ğ‘“â€ğ‘¥ â€ = 1.2.
To condition on this value of ğ‘“â€ğ‘¥ â€, we can draw a 1 1 806 Gaussian Processes horizontal line at 1.2 on our plot of the density, and see that the value of ğ‘“â€ğ‘¥â€ is mostly constrainedto Â»0.64,1.52â€¦.
Wehavealsodrawnthisplotinfunctionspace, showingthe observedpoint ğ‘“â€ğ‘¥ â€inorange, and1standarddeviationofthe Gaussianprocesspredictive 1 distributionfor ğ‘“â€ğ‘¥â€inblue, aboutthemeanvalueof1.08.
Nowsupposewehaveastrongercorrelation, ğ‘˜â€ğ‘¥,ğ‘¥ â€ = 0.95.
Nowtheellipseshavenar- 1 rowed further, and the value of ğ‘“â€ğ‘¥â€ is even more strongly determined by ğ‘“â€ğ‘¥ â€.
Draw- 1 ing a horizontal line at 1.2, we see the contours for ğ‘“â€ğ‘¥â€ support values mostly within Â»0.83,1.45â€¦.
Again, wealsoshowtheplotinfunctionspace, withonestandarddeviation aboutthemeanpredictivevalueof1.14.
807 Introductionto Gaussian Processes We see that the posterior mean predictor of our Gaussian process is closer to 1.2, be- causethereisnowastrongercorrelation.
Wealsoseethatouruncertainty(theerrorbars) have somewhat decreased.
Despite the strong correlation between these function values, our uncertainty is still righly quite large, because we have only observed a single data point! Thisprocedurecangiveusaposterioron ğ‘“â€ğ‘¥â€foranyğ‘¥, foranynumberofpointswehave observed.
Supposeweobserve ğ‘“â€ğ‘¥ â€, ğ‘“â€ğ‘¥ â€.
Wenowvisualizetheposteriorfor ğ‘“â€ğ‘¥â€ ata 1 2 particularğ‘¥ = ğ‘¥0 infunctionspace.
Theexactdistributionfor ğ‘“â€ğ‘¥â€ isgivenbytheabove equations.
ğ‘“â€ğ‘¥â€is Gaussiandistributed, withmean ğ‘š = ğ‘˜â€ğ‘¥,ğ‘¥ â€ğ‘˜â€ğ‘¥ ,ğ‘¥ â€ 1ğ‘“â€ğ‘¥ â€ (18.1.7) 1:3 1:3 1:3 1:3 andvariance ğ‘ 2 = ğ‘˜â€ğ‘¥,ğ‘¥â€ ğ‘˜â€ğ‘¥,ğ‘¥ â€ğ‘˜â€ğ‘¥ ,ğ‘¥ â€ 1ğ‘˜â€ğ‘¥,ğ‘¥ â€ (18.1.8) 1:3 1:3 1:3 1:3 Inthisintroductorynotebook, wehavebeenconsideringnoisefreeobservations.
Aswewill see, itiseasytoincludeobservationnoise.
Ifweassumethatthedataaregeneratedfroma latentnoisefreefunction ğ‘“â€ğ‘¥â€plusiid Gaussiannoiseğœ–â€ğ‘¥â€ Nâ€0,ğœ2â€withvarianceğœ2, thenourcovariancefunctionsimplybecomesğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€ ! ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€â€šğ›¿ ğ‘–ğ‘— ğœ2, whereğ›¿ ğ‘–ğ‘— =1 ifğ‘– = ğ‘— and0otherwise.
Wehavealreadystartedgettingsomeintuitionabouthowwecanusea Gaussianprocess to specify a prior and posterior over solutions, and how the kernel function affects the propertiesofthesesolutions.
Inthefollowingnotebooks, wewillpreciselyshowhowto specifya Gaussianprocessprior, introduceandderivevariouskernelfunctions, andthen gothroughthemechanicsofhowtoautomaticallylearnkernelhyperparameters, andform a Gaussianprocessposteriortomakepredictions.
Whileittakestimeandpracticetoget usedtoconceptssuchasaâ€œdistributionsoverfunctionsâ€, theactualmechanicsoffinding the GP predictive equations is actually quite simple â€” making it easy to get practice to formanintuitiveunderstandingoftheseconcepts.
18.1.1 Summary In typical machine learning, we specify a function with some free parameters (such as a neural network and its weights), and we focus on estimating those parameters, which 808 Gaussian Processes maynotbeinterpretable.
Witha Gaussianprocess, weinsteadreasonaboutdistributions over functions directly, which enables us to reason about the high-level properties of the solutions.
Thesepropertiesarecontrolledbyacovariancefunction(kernel), whichoften hasafewhighlyinterpretablehyperparameters.
Thesehyperparametersincludethelength- scale, whichcontrolshowrapidly(howwiggily)thefunctionsare.
Anotherhyperparameter is the amplitude, which controls the vertical scale over which our functions are varying.
Representingmanydifferentfunctionsthatcanfitthedata, andcombiningthemalltogether intoapredictivedistribution, isadistinctivefeatureof Bayesianmethods.
Becausethere is a greater amount of variability between possible solutions far away from the data, our uncertaintyintuitivelygrowsaswemovefromthedata.
A Gaussian process represents a distribution over functions by specifying a multivariate normal (Gaussian) distribution over all possible function values.
It is possible to easily manipulate Gaussiandistributionstofindthedistributionofonefunctionvaluebasedon thevaluesofanysetofothervalues.
Inotherwords, ifweobserveasetofpoints, thenwe canconditiononthesepointsandinferadistributionoverwhatthevalueofthefunction mightlooklikeatanyotherinput.
Howwemodelthecorrelationsbetweenthesepointsis determinedbythecovariancefunctionandiswhatdefinesthegeneralizationpropertiesof the Gaussianprocess.
Whileittakestimetogetusedto Gaussianprocesses, theyareeasy to work with, have many applications, and help us understand and develop other model classes, likeneuralnetworks.
18.1.2 Exercises 1.
Whatisthedifferencebetweenepistemicuncertaintyversusobservationuncertainty? 2.
Besides rate of variation and amplitude, what other properties of functions might we wanttoconsider, andwhatwouldbereal-worldexamplesoffunctionsthathavethose properties? 3.
The RBF covariance function we considered says that covariances (and correlations) betweenobservationsdecreasewiththeirdistanceintheinputspace(times, spatiallo- cations, etc.).
Isthisareasonableassumption? Whyorwhynot? 4.
Isasumoftwo Gaussianvariables Gaussian? Isaproductoftwo Gaussianvariables Gaussian? If(a, b)haveajoint Gaussiandistribution, isa|b(agivenb)Gaussian? Isa Gaussian? 5.
Repeattheexercisewhereweobserveadatapointat ğ‘“â€ğ‘¥ â€ =1.2, butnowsupposewe 1 2 1 2 moreorlesscertainaboutthevalueof ğ‘“â€ğ‘¥â€, thanwhenwehadonlyobserved ğ‘“â€ğ‘¥ â€? 1 Whatisthemeanand95%crediblesetforourvalueof ğ‘“â€ğ‘¥â€now? 6.
Doyouthinkincreasingourestimateofobservationnoisewouldincreaseordecrease ourestimateofthelength-scaleofthegroundtruthfunction? 7.
Aswemoveawayfromthedata, supposetheuncertaintyinourpredictivedistribution increasestoapoint, thenstopsincreasing.
Whymightthathappen? 809 Gaussian Process Priors Discussions259.
259 18.2 Gaussian Process Priors Understanding Gaussianprocesses(GPs)isimportantforreasoningaboutmodelconstruc- tionandgeneralization, andforachievingstate-of-the-artperformanceinavarietyofappli- cations, includingactivelearning, andhyperparametertuningindeeplearning.
GPsareev- erywhere, anditisinourintereststoknowwhattheyareandhowwecanusethem.
Inthissection, weintroduce Gaussianprocesspriorsoverfunctions.
Inthenextnotebook, we show how to use these priors to do posterior inference and make predictions.
The nextsectioncanbeviewedasâ€œGPsinanutshellâ€, quicklygivingwhatyouneedtoapply Gaussianprocessesinpractice.
import numpy as np from scipy.
spatial import distance_matrix from d2l import torch as d2l d2l.
set_figsize() 18.2.1 Definition A Gaussian process is defined as a collection of random variables, any finite number of which have a joint Gaussian distribution.
If a function ğ‘“â€ğ‘¥â€ is a Gaussian process, with meanfunctionğ‘šâ€ğ‘¥â€andcovariancefunctionorkernelğ‘˜â€ğ‘¥,ğ‘¥0â€, ğ‘“â€ğ‘¥â€ GPâ€ğ‘š,ğ‘˜â€, thenany collectionoffunctionvaluesqueriedatanycollectionofinputpointsğ‘¥ (times, spatiallo- cations, imagepixels, etc.), hasajointmultivariate Gaussiandistributionwithmeanvector ğœ‡andcovariancematrixğ¾: ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€ Nâ€ğœ‡,ğ¾â€, where ğœ‡ ğ‘– = ğ¸Â»ğ‘“â€ğ‘¥ ğ‘– â€â€¦ = ğ‘šâ€ğ‘¥ ğ‘– â€ andğ¾ ğ‘–ğ‘— =Covâ€ğ‘“â€ğ‘¥ ğ‘– â€, ğ‘“â€ğ‘¥ ğ‘— â€â€ = ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€.
Thisdefinitionmayseemabstractandinaccessible, but Gaussianprocessesareinfactvery simpleobjects.
Anyfunction ğ‘“â€ğ‘¥â€ =ğ‘¤>ğœ™â€ğ‘¥â€ = hğ‘¤,ğœ™â€ğ‘¥â€i, (18.2.1) withğ‘¤drawnfroma Gaussian(normal)distribution, andğœ™beinganyvectorofbasisfunc- tions, forexample ğœ™â€ğ‘¥â€ = â€1,ğ‘¥,ğ‘¥2,...,ğ‘¥ğ‘‘â€> , isa Gaussianprocess.
Moreover, any Gaus- sianprocessf(x)canbeexpressedintheformofequation(18.2.1).
Letâ€™sconsiderafew concrete examples, to begin getting acquainted with Gaussian processes, after which we canappreciatehowsimpleandusefultheyreallyare.
18.2.2 ASimple Gaussian Process 810 Gaussian Processes Suppose ğ‘“â€ğ‘¥â€ = ğ‘¤ â€šğ‘¤ ğ‘¥, and ğ‘¤ ,ğ‘¤ Nâ€0,1â€, with ğ‘¤ ,ğ‘¤ ,ğ‘¥ all in one dimension.
0 1 0 1 0 1 We can equivalently write this function as the inner product ğ‘“â€ğ‘¥â€ = â€ğ‘¤ ,ğ‘¤ â€â€1,ğ‘¥â€> .
In 0 1 (18.2.1)above,ğ‘¤ = â€ğ‘¤ ,ğ‘¤ â€> andğœ™â€ğ‘¥â€ = â€1,ğ‘¥â€> .
0 1 For any ğ‘¥, ğ‘“â€ğ‘¥â€ is a sum of two Gaussian random variables.
Since Gaussians are closed underaddition, ğ‘“â€ğ‘¥â€isalsoa Gaussianrandomvariableforanyğ‘¥.
Infact, wecancompute foranyparticularğ‘¥ that ğ‘“â€ğ‘¥â€ is Nâ€0,1â€šğ‘¥2â€.
Similarly, thejointdistributionforanycol- multivariate Gaussiandistribution.
Therefore ğ‘“â€ğ‘¥â€isa Gaussianprocess.
In short, ğ‘“â€ğ‘¥â€ is a random function, or a distribution over functions.
We can gain some insightsintothisdistributionbyrepeatedlysamplingvaluesforğ‘¤ ,ğ‘¤ , andvisualizingthe 0 1 correspondingfunctions ğ‘“â€ğ‘¥â€, whicharestraightlineswithslopesanddifferentintercepts, asfollows: def lin_func(x, n_sample): preds = np.
zeros((n_sample, x.
shape[0])) for ii in range(n_sample): w = np.
random.
normal(0, 1, 2) y = w[0] + w[1] * x preds[ii, :] = y return preds x_points = np.
linspace(-5, 5, 50) outs = lin_func(x_points, 10) lw_bd = -2 * np.
sqrt((1 + x_points ** 2)) up_bd = 2 * np.
sqrt((1 + x_points ** 2)) d2l.
plt.
fill_between(x_points, lw_bd, up_bd, alpha=0.25) d2l.
plt.
plot(x_points, np.
zeros(len(x_points)), linewidth=4, color='black') d2l.
plt.
plot(x_points, outs.
T) d2l.
plt.
xlabel("x", fontsize=20) d2l.
plt.
ylabel("f(x)", fontsize=20) d2l.
plt.
show() Ifğ‘¤ andğ‘¤ areinsteaddrawnfrom Nâ€0,ğ›¼2â€, howdoyouimaginevaryingğ›¼affectsthe 0 1 distributionoverfunctions? 18.2.3 From Weight Spaceto Function Space 811 Gaussian Process Priors Intheplotabove, wesawhowadistributionoverparametersinamodelinducesadistri- butionoverfunctions.
Whileweoftenhaveideasaboutthefunctionswewanttomodelâ€” whethertheyâ€™resmooth, periodic, quicklyvarying, etc.
â€”itisrelativelytedioustoreason abouttheparameters, whicharelargelyuninterpretable.
Fortunately, Gaussianprocesses provideaneasymechanismtoreasondirectlyaboutfunctions.
Sincea Gaussiandistribu- tionisentirelydefinedbyitsfirsttwomoments, itsmeanandcovariancematrix, a Gaussian processbyextensionisdefinedbyitsmeanfunctionandcovariancefunction.
Intheaboveexample, themeanfunction ğ‘šâ€ğ‘¥â€ = ğ¸Â»ğ‘“â€ğ‘¥â€â€¦ = ğ¸Â»ğ‘¤ â€šğ‘¤ ğ‘¥â€¦ = ğ¸Â»ğ‘¤ â€¦â€šğ¸Â»ğ‘¤ â€¦ğ‘¥ =0â€š0=0.
(18.2.2) 0 1 0 1 Similarly, thecovariancefunctionis ğ‘˜â€ğ‘¥,ğ‘¥0â€ =Covâ€ğ‘“â€ğ‘¥â€, ğ‘“â€ğ‘¥0â€â€ = ğ¸Â»ğ‘“â€ğ‘¥â€ğ‘“â€ğ‘¥0â€â€¦ ğ¸Â»ğ‘“â€ğ‘¥â€â€¦ğ¸Â»ğ‘“â€ğ‘¥0â€â€¦ = ğ¸Â»ğ‘¤2â€šğ‘¤ ğ‘¤ ğ‘¥0â€šğ‘¤ ğ‘¤ ğ‘¥â€šğ‘¤2ğ‘¥ğ‘¥0â€¦ =1â€šğ‘¥ğ‘¥0.
0 0 1 1 0 1 (18.2.3) Our distribution over functions can now be directly specified and sampled from, without needingtosamplefromthedistributionoverparameters.
Forexample, todrawfrom ğ‘“â€ğ‘¥â€, wecansimplyformourmultivariate Gaussiandistributionassociatedwithanycollectionof ğ‘¥wewanttoquery, andsamplefromitdirectly.
Wewillbegintoseejusthowadvantageous thisformulationwillbe.
First, wenotethatessentiallythesamederivationforthesimplestraightlinemodelabove canbeappliedtofindthemeanandcovariancefunctionforanymodeloftheform ğ‘“â€ğ‘¥â€ = ğ‘¤>ğœ™â€ğ‘¥â€, with ğ‘¤ Nâ€ğ‘¢,ğ‘†â€.
In this case, the mean function ğ‘šâ€ğ‘¥â€ = ğ‘¢>ğœ™â€ğ‘¥â€, and the covariancefunctionğ‘˜â€ğ‘¥,ğ‘¥0â€ = ğœ™â€ğ‘¥â€>ğ‘†ğœ™â€ğ‘¥0â€.
Sinceğœ™â€ğ‘¥â€canrepresentavectorofanynon- linear basis functions, we are considering a very general model class, including models withanevenaninfinitenumberofparameters.
18.2.4 The Radial Basis Function(RBF)Kernel Theradialbasisfunction(RBF)kernelisthemostpopularcovariancefunctionfor Gaus- sian pro cesses, and ke rnel machines in general.
This kernel has the form ğ‘˜ RBF â€ğ‘¥,ğ‘¥0â€ = ğ‘2exp 1 jjğ‘¥ ğ‘¥0jj2 , whereğ‘ isanamplitudeparameter, andâ„“ isalengthscalehyper- 2â„“2 parameter.
Letâ€™sderivethiskernelstartingfromweightspace.
Considerthefunction ğ½ ğœ2 â€ğ‘¥ ğ‘ â€2 ğ‘“â€ğ‘¥â€ = ğ‘¤ ğ‘– ğœ™ ğ‘– â€ğ‘¥â€,ğ‘¤ ğ‘– N 0, ğ½ ,ğœ™ ğ‘– â€ğ‘¥â€ =exp 2â„“2 ğ‘– .
(18.2.4) ğ‘–=1 ğ‘“â€ğ‘¥â€ isasumofradialbasisfunctions, withwidthâ„“, centredatthepointsğ‘ ğ‘–, asshownin thefollowingfigure.
Wecanrecognize ğ‘“â€ğ‘¥â€ ashavingtheform ğ‘¤>ğœ™â€ğ‘¥â€, where ğ‘¤ = â€ğ‘¤ 1 ,...,ğ‘¤ ğ½ â€> and ğœ™â€ğ‘¥â€ is a vector containing each of the radial basis functions.
The covariance function of this 812 Gaussian Processes Gaussianprocessisthen ğœ2 ğ½ ğ‘˜â€ğ‘¥,ğ‘¥0â€ = ğ½ ğœ™ ğ‘– â€ğ‘¥â€ğœ™ ğ‘– â€ğ‘¥0â€.
(18.2.5) ğ‘–=1 Nowletâ€™sconsiderwhathappensaswetakethenumberofparameters(andbasisfunctions) toinfinity.
Let ğ‘ ğ½ = logğ½, ğ‘ 1 = logğ½, and ğ‘ ğ‘–â€š1 ğ‘ ğ‘– = Î”ğ‘ = 2log ğ½ ğ½ , and ğ½ ! 1.
The covariancefunctionbecomesthe Riemannsum: â€ ğœ2 ğ½ ğ‘1 ğ‘˜â€ğ‘¥,ğ‘¥0â€ = ğ½ l ! im 1 ğ½ ğ‘–=1 ğœ™ ğ‘– â€ğ‘¥â€ğœ™ ğ‘– â€ğ‘¥0â€ = ğ‘ 0 ğœ™ ğ‘ â€ğ‘¥â€ğœ™ ğ‘ â€ğ‘¥0â€ğ‘‘ğ‘.
(18.2.6) Bysettingğ‘ 0 = 1andğ‘ 1 =1, wespreadtheinfinitelymanybasisfunctionsacrossthe wholerealline, eachadistanceÎ”ğ‘ !0apart: â€ 1 â€ğ‘¥ ğ‘â€2 â€ğ‘¥0 ğ‘â€2 p â€ğ‘¥ ğ‘¥0â€2 ğ‘˜â€ğ‘¥,ğ‘¥0â€ = expâ€ â€expâ€ â€ğ‘‘ğ‘ = ğœ‹â„“ğœ2expâ€ p â€ / ğ‘˜ â€ğ‘¥,ğ‘¥0â€.
1 2â„“2 2â„“2 2â€ 2â„“â€2 RBF (18.2.7) Itisworthtakingamomenttoabsorbwhatwehavedonehere.
Bymovingintothefunction spacerepresentation, wehavederivedhowtorepresentamodelwithaninfinitenumberof parameters, usingafiniteamountofcomputation.
AGaussianprocesswithan RBFkernel isauniversalapproximator, capableofrepresentinganycontinuousfunctiontoarbitrary precision.
We can intuitively see why from the above derivation.
We can collapse each radialbasisfunctiontoapointmasstakingâ„“ !0, andgiveeachpointmassanyheightwe wish.
Soa Gaussianprocesswithan RBFkernelisamodelwithaninfinitenumberofparam- etersandmuchmoreflexibilitythananyfiniteneuralnetwork.
Perhapsallthefussabout overparametrized neural networks is misplaced.
As we will see, GPs with RBF kernels do not overfit, and in fact provide especially compelling generalization performance on small datasets.
Moreover, the examples in (Zhang et al., 2021), such as the ability to fit imageswithrandomlabelsperfectly, butstillgeneralizewellonstructuredproblems,(can be perfectly reproduced using Gaussian processes) (Wilson and Izmailov, 2020).
Neural networksarenotasdistinctaswemakethemouttobe.
Wecanbuildfurtherintuitionabout Gaussianprocesseswith RBFkernels, andhyperpa- rameters such as length-scale, by sampling directly from the distribution over functions.
Asbefore, thisinvolvesasimpleprocedure: 1.
Choosetheinputğ‘¥pointswewanttoquerythe GP:ğ‘¥ 1 ,...,ğ‘¥ ğ‘›.
meanvectorandcovariancematrixğœ‡andğ¾, whereâ€ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€â€ Nâ€ğœ‡,ğ¾â€.
3.
Samplefromthismultivariate Gaussiandistributiontoobtainthesamplefunctionval- ues.
4.
Samplemoretimestovisualizemoresamplefunctionsqueriedatthosepoints.
Weillustratethisprocessinthefigurebelow.
813 Gaussian Process Priors def rbfkernel(x1, x2, ls=4.): #@save dist = distance_matrix(np.
expand_dims(x1, 1), np.
expand_dims(x2, 1)) return np.
exp(-(1.
/ ls / 2) * (dist ** 2)) x_points = np.
linspace(0, 5, 50) meanvec = np.
zeros(len(x_points)) covmat = rbfkernel(x_points, x_points, 1) prior_samples= np.
random.
multivariate_normal(meanvec, covmat, size=5); d2l.
plt.
plot(x_points, prior_samples.
T, alpha=0.5) d2l.
plt.
show() 18.2.5 The Neural Network Kernel Research on Gaussian processes in machine learning was triggered by research on neu- ralnetworks.
Radford Nealwaspursuingeverlarger Bayesianneuralnetworks, ultimately showing in 1994 (later published in 1996, as it was one of the most infamous Neur IPS rejections) that such networks with an infinite number of hidden units become Gaussian processeswithparticularkernelfunctions(Neal,1996).
Interestinthisderivationhasre- surfaced, withideasliketheneuraltangentkernelbeingusedtoinvestigatethegeneraliza- tion properties of neural networks (Matthews et al., 2018) (Novak et al., 2018).
We can derivetheneuralnetworkkernelasfollows.
Consideraneuralnetworkfunction ğ‘“â€ğ‘¥â€withonehiddenlayer: ğ½ ğ‘“â€ğ‘¥â€ = ğ‘â€š ğ‘£ ğ‘– â„â€ğ‘¥;ğ‘¢ ğ‘– â€.
(18.2.8) ğ‘–=1 ğ‘ is a bias, ğ‘£ ğ‘– are the hidden to output weights, â„ is any bounded hidden unit transfer function,ğ‘¢ ğ‘– aretheinputtohiddenweights, andğ½isthenumberofhiddenunits.
Letğ‘and ğ‘£ ğ‘– beindependentwithzeromeanandvariancesğœ ğ‘ 2 andğœ ğ‘£ 2 ğ½, respectively, andlettheğ‘¢ ğ‘– haveindependentidenticaldistributions.
Wecanthenusethecentrallimittheoremtoshow thatanycollection of function values ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€ hasa joint multivariate Gaussian distribution.
Themeanandcovariancefunctionofthecorresponding Gaussianprocessare: ğ‘šâ€ğ‘¥â€ = ğ¸Â»ğ‘“â€ğ‘¥â€â€¦ =0 (18.2.9) 814 Gaussian Processes ğ½ 1 ğ‘˜â€ğ‘¥,ğ‘¥0â€ =covÂ»ğ‘“â€ğ‘¥â€, ğ‘“â€ğ‘¥0â€â€¦ = ğ¸Â»ğ‘“â€ğ‘¥â€ğ‘“â€ğ‘¥0â€â€¦ =ğœ ğ‘ 2â€š ğ½ ğœ ğ‘£ 2ğ¸Â»â„ ğ‘– â€ğ‘¥;ğ‘¢ ğ‘– â€â„ ğ‘– â€ğ‘¥0 ;ğ‘¢ ğ‘– â€â€¦ ğ‘–=1 (18.2.10) In some cases, we c Ë an essentially evaluate this covaflriance function in closed form.
Let â„â€ğ‘¥;ğ‘¢â€ = erfâ€ğ‘¢ 0 â€š ğ‘ƒ ğ‘—=1 ğ‘¢ ğ‘— ğ‘¥ ğ‘— â€, where erfâ€ğ‘§â€ = p2 ğœ‹ 0 ğ‘§ ğ‘’ ğ‘¡2ğ‘‘ğ‘¡, and ğ‘¢ Nâ€0,Î£â€.
Then ğ‘˜â€ğ‘¥,ğ‘¥0â€ = 2sinâ€p 2ğ‘¥Ëœ>Î£ğ‘¥Ëœ0 â€.
ğœ‹ â€1â€š2ğ‘¥Ëœ>Î£ğ‘¥Ëœâ€â€1â€š2ğ‘¥Ëœ0>Î£ğ‘¥Ëœ0â€ The RBF kernel is stationary, meaning that it is translation invariant, and therefore can be written as a function of ğœ = ğ‘¥ ğ‘¥0 .
Intuitively, stationarity means that the high-level properties of the function, such as rate of variation, do not change as we move in input space.
The neural network kernel, however, is non-stationary.
Below, we show sample functions from a Gaussian process with this kernel.
We can see that the function looks qualitativelydifferentneartheorigin.
18.2.6 Summary Thefirststepinperforming Bayesianinferenceinvolvesspecifyingaprior.
Gaussianpro- cesses can be used to specify a whole prior over functions.
Starting from a traditional â€œweightspaceâ€viewofmodelling, wecaninduceaprioroverfunctionsbystartingwiththe functionalformofamodel, andintroducingadistributionoveritsparameters.
Wecanal- ternativelyspecifyapriordistributiondirectlyinfunctionspace, withpropertiescontrolled byakernel.
Thefunction-spaceapproachhasmanyadvantages.
Wecanbuildmodelsthat actuallycorrespondtoaninfinitenumberofparameters, butuseafiniteamountofcom- putation! Moreover, whilethesemodelshaveagreatamountofflexibility, theyalsomake strongassumptionsaboutwhattypesoffunctionsareapriorilikely, leadingtorelatively goodgeneralizationonsmalldatasets.
Theassumptionsofmodelsinfunctionspaceareintuitivelycontrolledbykernels, whichof- tenencodehigherlevelpropertiesoffunctions, suchassmoothnessandperiodicity.
Many kernelsarestationary, meaningthattheyaretranslationinvariant.
Functionsdrawnfrom a Gaussian process with a stationary kernel have roughly the same high-level properties (suchasrateofvariation)regardlessofwherewelookintheinputspace.
Gaussianprocessesarearelativelygeneralmodelclass, containingmanyexamplesofmod- elswearealreadyfamiliarwith, includingpolynomials, Fourierseries, andsoon, aslong aswehavea Gaussianpriorovertheparameters.
Theyalsoincludeneuralnetworkswith aninfinitenumberofparameters, evenwithout Gaussiandistributionsovertheparameters.
This connection, discovered by Radford Neal, triggered machine learning researchers to moveawayfromneuralnetworks, andtowards Gaussianprocesses.
18.2.7 Exercises 1.
Draw sampleprio rfunctionsfroma GPwithan Ornstein-Uhlenbeck(OU)kernel,ğ‘˜ OU â€ğ‘¥,ğ‘¥0â€ = exp 1 jjğ‘¥ ğ‘¥0j .
Ifyoufixthelengthscaleâ„“ tobethesame, howdothesefunctions 2â„“ lookdifferentthansamplefunctionsfroma GPwithan RBFkernel? 815 Gaussian Process Inference 2.
How does changing the amplitude ğ‘2 of the RBF kernel affect the distribution over functions? 3.
Supposeweformğ‘¢â€ğ‘¥â€ = ğ‘“â€ğ‘¥â€â€š2ğ‘”â€ğ‘¥â€, where ğ‘“â€ğ‘¥â€ GPâ€ğ‘š ,ğ‘˜ â€andğ‘”â€ğ‘¥â€ GPâ€ğ‘š ,ğ‘˜ â€.
1 1 2 2 Isğ‘¢â€ğ‘¥â€a Gaussianprocess, andifso, whatisitsmeanandcovariancefunction? 4.
Supposeweform ğ‘”â€ğ‘¥â€ = ğ‘â€ğ‘¥â€ğ‘“â€ğ‘¥â€, where ğ‘“â€ğ‘¥â€ GPâ€0,ğ‘˜â€ and ğ‘â€ğ‘¥â€ = ğ‘¥2.
Is ğ‘”â€ğ‘¥â€ a Gaussian process, and if so, what is its mean and covariance function? What is the effectofğ‘â€ğ‘¥â€? Whatdosamplefunctionsdrawnfromğ‘”â€ğ‘¥â€looklike? 5.
Supposeweformğ‘¢â€ğ‘¥â€ = ğ‘“â€ğ‘¥â€ğ‘”â€ğ‘¥â€, where ğ‘“â€ğ‘¥â€ GPâ€ğ‘š ,ğ‘˜ â€andğ‘”â€ğ‘¥â€ GPâ€ğ‘š ,ğ‘˜ â€.
1 1 2 2 Isğ‘¢â€ğ‘¥â€a Gaussianprocess, andifso, whatisitsmeanandcovariancefunction? Discussions260.
260 18.3 Gaussian Process Inference Inthissection, wewillshowhowtoperformposteriorinferenceandmakepredictionsusing the GPpriorsweintroducedinthelastsection.
Wewillstartwithregression, wherewecan performinferenceinclosedform.
Thisisaâ€œGPsinanutshellâ€sectiontoquicklygetup andrunningwith Gaussianprocessesinpractice.
Weâ€™llstartcodingallthebasicoperations fromscratch, andthenintroduce GPy Torch261, whichwillmakeworkingwithstate-of-the- 261 art Gaussianprocessesandintegrationwithdeepneuralnetworksmuchmoreconvenient.
Wewillconsiderthesemoreadvancedtopicsindepthinthenextsection.
Inthatsection, we will also consider settings where approximate inference is required â€” classification, pointprocesses, oranynon-Gaussianlikelihoods.
18.3.1 Posterior Inferencefor Regression An observation model relates the function we want to learn, ğ‘“â€ğ‘¥â€, to our observations ğ‘¦â€ğ‘¥â€, both indexed by some input ğ‘¥.
In classification, ğ‘¥ could be the pixels of an image, andğ‘¦couldbetheassociatedclasslabel.
Inregression,ğ‘¦typicallyrepresentsacontinuous output, suchasalandsurfacetemperature, asea-level, ağ¶ğ‘‚ concentration, etc.
2 Inregression, weoftenassumetheoutputsaregivenbyalatentnoise-freefunction ğ‘“â€ğ‘¥â€ plusi.
i.
d.
Gaussiannoiseğœ–â€ğ‘¥â€: ğ‘¦â€ğ‘¥â€ = ğ‘“â€ğ‘¥â€â€šğœ–â€ğ‘¥â€, (18.3.1) with ğœ–â€ğ‘¥â€ Nâ€0,ğœ2â€.
Lety = ğ‘¦â€ğ‘‹â€ = â€ğ‘¦â€ğ‘¥ 1 â€,...,ğ‘¦â€ğ‘¥ ğ‘› â€â€> beavectorofourtraining observations, and f = â€ğ‘“â€ğ‘¥ 1 â€,..., ğ‘“â€ğ‘¥ ğ‘› â€â€> be a vector of the latent noise-free function values, queriedatthetraininginputs ğ‘‹ =ğ‘¥ 1 ,...,ğ‘¥ ğ‘›.
Wewillassume ğ‘“â€ğ‘¥â€ GPâ€ğ‘š,ğ‘˜â€, whichmeansthatanycollectionoffunctionvaluesf hasajointmultivariate Gaussiandistribution, withmeanvect orğœ‡ ğ‘– =ğ‘šâ€ğ‘¥ ğ‘– â€an dcovariance matrixğ¾ ğ‘–ğ‘— = ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€.
The RBFkernel ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€ = ğ‘2exp 2 1 â„“2 jjğ‘¥ ğ‘– ğ‘¥ ğ‘— jj2 wouldbea 816 Gaussian Processes standardchoiceofcovariancefunction.
Fornotationalsimplicity, wewillassumethemean functionğ‘šâ€ğ‘¥â€ =0; ourderivationscaneasilybegeneralizedlateron.
Supposewewanttomakepredictionsatasetofinputs Then we want to find ğ‘¥2 and ğ‘â€f jy,ğ‘‹â€.
In the regression setting, we can conveniently findthisdistributionbyusing Gaussianidentities, afterfindingthejointdistributionover f = ğ‘“â€ğ‘‹ â€andy.
If we evaluate equation (18.3.1) at the training inputs ğ‘‹, we have y = f â€š ffl.
By the definitionofa Gaussianprocess(seelastsection), f Nâ€0,ğ¾â€ğ‘‹,ğ‘‹â€â€ where ğ¾â€ğ‘‹,ğ‘‹â€ is anğ‘› ğ‘›matrixformedbyevaluatingourcovariancefunction(akakernel)atallpossible pairsofinputsğ‘¥ ğ‘– ,ğ‘¥ ğ‘— 2 ğ‘‹.
fflissimplyavectorcomprisedofiidsamplesfrom Nâ€0,ğœ2â€ andthushasdistribution Nâ€0,ğœ2ğ¼â€.
yisthereforeasumoftwoindependentmultivariate Gaussian variables, and thus has distribution Nâ€0,ğ¾â€ğ‘‹,ğ‘‹â€ â€šğœ2ğ¼â€.
One can also show thatcovâ€f , yâ€ = covâ€y, f â€> = ğ¾â€ğ‘‹ ,ğ‘‹â€ where ğ¾â€ğ‘‹ ,ğ‘‹â€ isanğ‘š ğ‘› matrixformedby evaluatingthekernelatallpairsoftestandtraininginputs.
y N 0, A= ğ¾â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼ ğ¾â€ğ‘‹,ğ‘‹ â€ (18.3.3) f ğ¾â€ğ‘‹ ,ğ‘‹â€ ğ¾â€ğ‘‹ ,ğ‘‹ â€ Wecanthenusestandard Gaussianidentitiestofindtheconditionaldistributionfromthe joint distribution (see, e.
g., Bishop Chapter 2), f jy,ğ‘‹,ğ‘‹ Nâ€ğ‘š ,ğ‘† â€, where ğ‘š = ğ¾â€ğ‘‹ ,ğ‘‹â€Â»ğ¾â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1y, andğ‘† =ğ¾â€ğ‘‹ ,ğ‘‹ â€ ğ¾â€ğ‘‹ ,ğ‘‹â€Â»ğ¾â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1ğ¾â€ğ‘‹,ğ‘‹ â€.
Typically, wedonotneedtomakeuseofthefullpredictivecovariancematrix ğ‘†, andin- steadusethediagonalofğ‘†foruncertaintyabouteachprediction.
Oftenforthisreasonwe write the predictive distribution for a single test point ğ‘¥ , rather than a collection of test points.
Thekernelmatrixhasparametersğœƒthatwealsowishtoestimate, suchtheamplitudeğ‘and lengthscaleâ„“ofthe RBFkernelabove.
Forthesepurposesweusethemarginallikelihood, ğ‘â€yjğœƒ,ğ‘‹â€, whichwealreadyderivedinworkingoutthemarginaldistributionstofindthe jointdistributionovery, f .
Aswewillsee, themarginallikelihoodcompartmentalizesinto modelfitandmodelcomplexityterms, andautomaticallyencodesanotionof Occamâ€™srazor forlearninghyperparameters.
Forafulldiscussion, see Mac Kay Ch.
28(Mac Kay,2003), and Rasmussenand Williams Ch.
5(Rasmussenand Williams,2006).
import math import os import gpytorch import matplotlib.
pyplot as plt import numpy as np import torch from scipy import optimize from scipy.
spatial import distance_matrix from d2l import torch as d2l d2l.
set_figsize() 817 Gaussian Process Inference 18.3.2 Equationsfor Making Predictionsand Learning Kernel Hyperparametersin GPRegression Welistheretheequationsyouwilluseforlearninghyperparametersandmakingpredictions in Gaussianprocessregression.
Again, weassumeavectorofregressiontargetsy, indexed byinputsğ‘‹ = fğ‘¥ 1 ,...,ğ‘¥ ğ‘› g, andwewishtomakeapredictionatatestinputğ‘¥ .
Weassume i.
i.
d.
additive zero-mean Gaussian noise with variance ğœ2.
We use a Gaussian process prior ğ‘“â€ğ‘¥â€ GPâ€ğ‘š,ğ‘˜â€forthelatentnoise-freefunction, withmeanfunctionğ‘šandkernel function ğ‘˜.
Thekernelitselfhasparam eters ğœƒ thatwe wanttolearn.
Forexample, ifwe usean RBFkernel,ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€ =ğ‘2exp 2 1 â„“2 jjğ‘¥ ğ‘¥0jj2 , wewanttolearnğœƒ = fğ‘2,â„“2g.
Let ğ¾â€ğ‘‹,ğ‘‹â€ representanğ‘› ğ‘›matrixcorrespondingtoevaluatingthekernelforallpossible pairs of ğ‘› training inputs.
Let ğ¾â€ğ‘¥ ,ğ‘‹â€ represent a 1 ğ‘› vector formed by evaluating ğ‘˜â€ğ‘¥ ,ğ‘¥ ğ‘– â€, ğ‘– = 1,...,ğ‘›.
Let ğœ‡ be a mean vector formed by evaluating the mean function ğ‘šâ€ğ‘¥â€ateverytrainingpointsğ‘¥.
Typicallyinworkingwith Gaussianprocesses, wefollowatwo-stepprocedure.
1.
Learn kernelhyperparametersğœƒË†bymaximizingthemarginallikelihoodwithrespecttothesehy- perparameters.
2.
Usethepredictivemeanasapointpredictor, and2timesthepredictive standarddeviationtoforma95%credibleset, conditioningontheselearnedhyperparam- etersğœƒË†.
Thelogmarginallikelihoodissimplyalog Gaussiandensity, whichhastheform: 1 1 logğ‘â€yjğœƒ,ğ‘‹â€ = y >Â»ğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1y logjğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€jâ€šğ‘ (18.3.4) 2 2 Thepredictivedistributionhastheform: ğ‘â€ğ‘¦ jğ‘¥ , y,ğœƒâ€ =Nâ€ğ‘ ,ğ‘£ â€ (18.3.5) ğ‘ = ğ‘˜ ğœƒ â€ğ‘¥ ,ğ‘‹â€Â»ğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1â€y ğœ‡â€â€šğœ‡ (18.3.6) ğ‘£ = ğ‘˜ ğœƒ â€ğ‘¥ ,ğ‘¥ â€ ğ¾ ğœƒ â€ğ‘¥ ,ğ‘‹â€Â»ğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1ğ‘˜ ğœƒ â€ğ‘‹,ğ‘¥ â€ (18.3.7) 18.3.3 Interpreting Equationsfor Learningand Predictions There are some key points to note about the predictive distributions for Gaussian pro- cesses: Despitetheflexibilityofthemodelclass, itispossibletodoexact Bayesianinferencefor GPregressioninclosedform.
Asidefromlearningthekernelhyperparameters, there is no training.
We can write down exactly what equations we want to use to make predictions.
Gaussian processes are relatively exceptional in this respect, and it has greatlycontributedtotheirconvenience, versatility, andcontinuedpopularity.
Thepredictivemeanğ‘ isalinearcombinationofthetrainingtargetsy, weightedbythe kernelğ‘˜ ğœƒ â€ğ‘¥ ,ğ‘‹â€Â»ğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€â€šğœ2ğ¼â€¦ 1.
Aswewillsee, thekernel(anditshyperparam- eters)thusplaysacrucialroleinthegeneralizationpropertiesofthemodel.
818 Gaussian Processes Thepredictivemeanexplicitlydependsonthetargetvaluesybutthepredictivevariance does not.
The predictive uncertainty instead grows as the test input ğ‘¥ moves away fromthetargetlocationsğ‘‹, asgovernedbythekernelfunction.
However, uncertainty willimplicitlydependonthevaluesofthetargetsythroughthekernelhyperparameters ğœƒ, whicharelearnedfromthedata.
The marginal likelihood compartmentalizes into model fit and model complexity (log determinant)terms.
Themarginallikelihoodtendstoselectforhyperparametersthat providethesimplestfitsthatarestillconsistentwiththedata.
The key computational bottlenecks come from solving a linear system and computing a log determinant over an ğ‘› ğ‘› symmetric positive definite matrix ğ¾â€ğ‘‹,ğ‘‹â€ for ğ‘› trainingpoints.
Naively, theseoperationseachincur Oâ€ğ‘›3â€ computations, aswellas Oâ€ğ‘›2â€ storageforeachentryofthekernel(covariance)matrix, oftenstartingwitha Choleskydecomposition.
Historically, thesebottleneckshavelimited GPstoproblems with fewer than about 10,000 training points, and have given GPs a reputation for â€œbeingslowâ€thathasbeeninaccuratenowforalmostadecade.
Inadvancedtopics, wewilldiscusshow GPscanbescaledtoproblemswithmillionsofpoints.
Forpopularchoicesofkernelfunctions, ğ¾â€ğ‘‹,ğ‘‹â€ isoftenclosetosingular, whichcan cause numerical issues when performing Cholesky decompositions or other opera- tionsintendedtosolvelinearsystems.
Fortunately, inregressionweareoftenworking with ğ¾ ğœƒ â€ğ‘‹,ğ‘‹â€ â€šğœ2ğ¼, suchthatthenoisevariance ğœ2 getsaddedtothediagonalof ğ¾â€ğ‘‹,ğ‘‹â€, significantly improving its conditioning.
If the noise variance is small, or we are doing noise free regression, it is common practice to add a small amount of â€œjitterâ€tothediagonal, ontheorderof10 6, toimproveconditioning.
18.3.4 Worked Examplefrom Scratch Letâ€™screatesomeregressiondata, andthenfitthedatawitha GP, implementingeverystep fromscratch.
Weâ€™llsampledatafrom 1 ğ‘¦â€ğ‘¥â€ =sinâ€ğ‘¥â€â€š sinâ€4ğ‘¥â€â€šğœ–, (18.3.8) 2 withğœ– Nâ€0,ğœ2â€.
Thenoisefreefunctionwewishtofindis ğ‘“â€ğ‘¥â€ = sinâ€ğ‘¥â€â€š 1sinâ€4ğ‘¥â€.
2 Weâ€™llstartbyusinganoisestandarddeviationğœ =0.25.
def data_maker1(x, sig): sig = 0.25 train_x, test_x = np.
linspace(0, 5, 50), np.
linspace(0, 5, 500) train_y, test_y = data_maker1(train_x, sig=sig), data_maker1(test_x, sig=0.) d2l.
plt.
scatter(train_x, train_y) d2l.
plt.
plot(test_x, test_y) d2l.
plt.
xlabel("x", fontsize=20) d2l.
plt.
ylabel("Observations y", fontsize=20) d2l.
plt.
show() 819 Gaussian Process Inference Hereweseethenoisyobservationsascircles, andthenoise-freefunctioninbluethatwe wishtofind.
Now, letâ€™sspecifya GPprioroverthelatentnoise-freefunction, ğ‘“â€ğ‘¥â€ GPâ€ğ‘š,ğ‘˜â€.
Weâ€™ll useameanfunctionğ‘šâ€ğ‘¥â€ =0, andan RBFcovariancefunction(kernel) 1 ğ‘˜â€ğ‘¥ ğ‘– ,ğ‘¥ ğ‘— â€ =ğ‘2exp 2â„“2 jjğ‘¥ ğ‘¥0jj2 .
(18.3.9) mean = np.
zeros(test_x.
shape[0]) cov = d2l.
rbfkernel(test_x, test_x, ls=0.2) Wehavestartedwithalength-scaleof0.2.
Beforewefitthedata, itisimportanttoconsider whetherwehavespecifiedareasonableprior.
Letâ€™svisualizesomesamplefunctionsfrom this prior, as well as the 95% credible set (we believe thereâ€™s a 95% chance that the true functioniswithinthisregion).
prior_samples = np.
random.
multivariate_normal(mean=mean, cov=cov, size=5) d2l.
plt.
plot(test_x, prior_samples.
T, color='black', alpha=0.5) d2l.
plt.
plot(test_x, mean, linewidth=2.) d2l.
plt.
fill_between(test_x, mean - 2 * np.
diag(cov), mean + 2 * np.
diag(cov), alpha=0.25) d2l.
plt.
show() Dothesesampleslookreasonable? Arethehigh-levelpropertiesofthefunctionsaligned withthetypeofdatawearetryingtomodel? Nowletâ€™sformthemeanandvarianceoftheposteriorpredictivedistributionatanyarbitrary 820 Gaussian Processes testpointğ‘¥ .
ğ‘“Â¯ =ğ¾â€ğ‘¥,ğ‘¥ â€ğ‘‡â€ğ¾â€ğ‘¥,ğ‘¥â€â€šğœ2ğ¼â€ 1ğ‘¦ (18.3.10) ğ‘‰â€ğ‘“ â€ =ğ¾â€ğ‘¥ ,ğ‘¥ â€ ğ¾â€ğ‘¥,ğ‘¥ â€ğ‘‡â€ğ¾â€ğ‘¥,ğ‘¥â€â€šğœ2ğ¼â€ 1ğ¾â€ğ‘¥,ğ‘¥ â€ (18.3.11) Beforewemakepredictions, weshouldlearnourkernelhyperparametersğœƒandnoisevari- anceğœ2.
Letâ€™sinitializeourlength-scaleat0.75, asourpriorfunctionslookedtooquickly varyingcomparedtothedatawearefitting.
Weâ€™llalsoguessanoisestandarddeviationğœ of0.75.
Inordertolearntheseparameters, wewillmaximizethemarginallikelihoodwithrespect totheseparameters.
â€ logğ‘â€ğ‘¦jğ‘‹â€ =log ğ‘â€ğ‘¦jğ‘“,ğ‘‹â€ğ‘â€ğ‘“jğ‘‹â€ğ‘‘ğ‘“ (18.3.12) 1 1 ğ‘› logğ‘â€ğ‘¦jğ‘‹â€ = ğ‘¦ğ‘‡â€ğ¾â€ğ‘¥,ğ‘¥â€â€šğœ2ğ¼â€ 1ğ‘¦ logjğ¾â€ğ‘¥,ğ‘¥â€â€šğœ2ğ¼j log2ğœ‹ (18.3.13) 2 2 2 Perhaps our prior functions were too quickly varying.
Letâ€™s guess a length-scale of 0.4.
Weâ€™llalsoguessanoisestandarddeviationof0.75.
Thesearesimplyhyperparameterini- tializationsâ€”wewilllearntheseparametersfromthemarginallikelihood.
ell_est = 0.4 post_sig_est = 0.5 def neg_MLL(pars): K = d2l.
rbfkernel(train_x, train_x, ls=pars[0]) kernel_term = -0.5 * train_y @ \ np.
linalg.
inv(K + pars[1] ** 2 * np.
eye(train_x.
shape[0])) @ train_y logdet = -0.5 * np.
log(np.
linalg.
det(K + pars[1] ** 2 * \ np.
eye(train_x.
shape[0]))) const = -train_x.
shape[0] / 2.
* np.
log(2 * np.
pi) return -(kernel_term + logdet + const) learned_hypers = optimize.
minimize(neg_MLL, x0=np.
array([ell_est, post_sig_ â†©! est]), bounds=((0.01, 10.), (0.01, 10.))) ell = learned_hypers.
x[0] post_sig_est = learned_hypers.
x[1] Inthisinstance, welearnalength-scaleof0.299, andanoisestandarddeviationof0.24.
Notethatthelearnednoiseisextremelyclosetothetruenoise, whichhelpsindicatethat our GPisaverywell-specifiedtothisproblem.
Ingeneral, itiscrucialtoputcarefulthoughtintoselectingthekernelandinitializingthe hyperparameters.
While marginallikelihood optimization can be relatively robust to ini- tialization, it is not immune to poor initializations.
Try running the above script with a varietyofinitializationsandseewhatresultsyoufind.
Now, letâ€™smakepredictionswiththeselearnedhypers.
821 Gaussian Process Inference K_x_xstar = d2l.
rbfkernel(train_x, test_x, ls=ell) K_x_x = d2l.
rbfkernel(train_x, train_x, ls=ell) K_xstar_xstar = d2l.
rbfkernel(test_x, test_x, ls=ell) post_mean = K_x_xstar.
T @ np.
linalg.
inv((K_x_x + \ post_sig_est ** 2 * np.
eye(train_x.
shape[0]))) @ train_y post_cov = K_xstar_xstar - K_x_xstar.
T @ np.
linalg.
inv((K_x_x + \ post_sig_est ** 2 * np.
eye(train_x.
shape[0]))) @ K_x_xstar lw_bd = post_mean - 2 * np.
sqrt(np.
diag(post_cov)) up_bd = post_mean + 2 * np.
sqrt(np.
diag(post_cov)) d2l.
plt.
scatter(train_x, train_y) d2l.
plt.
plot(test_x, test_y, linewidth=2.) d2l.
plt.
plot(test_x, post_mean, linewidth=2.) d2l.
plt.
fill_between(test_x, lw_bd, up_bd, alpha=0.25) d2l.
plt.
legend(['Observed Data', 'True Function', 'Predictive Mean', '95% Setâ£ â†©! on True Func']) d2l.
plt.
show() Weseetheposteriormeaninorangealmostperfectlymatchesthetruenoisefreefunction! Notethatthe95%crediblesetweareshowingisforthelatentnoisefree(true)function, andnotthedatapoints.
Weseethatthiscrediblesetentirelycontainsthetruefunction, and doesnotseemoverlywideornarrow.
Wewouldnotwantnorexpectittocontainthedata points.
Ifwewishtohaveacrediblesetfortheobservations, weshouldcompute lw_bd_observed = post_mean - 2 * np.
sqrt(np.
diag(post_cov) + post_sig_est ** 2) up_bd_observed = post_mean + 2 * np.
sqrt(np.
diag(post_cov) + post_sig_est ** 2) Therearetwosourcesofuncertainty, epistemicuncertainty, representingreducibleuncer- tainty, andaleatoricorirreducibleuncertainty.
Theepistemicuncertaintyhererepresents uncertaintyaboutthetruevaluesofthenoisefreefunction.
Thisuncertaintyshouldgrow aswemoveawayfromthedatapoints, asawayfromthedatathereareagreatervarietyof functionvaluesconsistentwithourdata.
Asweobservemoreandmoredata, ourbeliefs aboutthetruefunctionbecomemoreconfident, andtheepistemicuncertaintydisappears.
Thealeatoricuncertaintyinthisinstanceistheobservationnoise, sincethedataaregiven touswiththisnoise, anditcannotbereduced.
Theepistemicuncertaintyinthedataiscapturedbyvarianceofthelatentnoisefreefunction np.
diag(post_cov).
Thealeatoricuncertaintyiscapturedbythenoisevariancepost_sig_est**2.
822 Gaussian Processes Unfortunately, peopleareoftencarelessabouthowtheyrepresentuncertainty, withmany papersshowingerrorbarsthatarecompletelyundefined, noclearsenseofwhetherweare visualizingepistemicoraleatoricuncertaintyorboth, andconfusingnoisevarianceswith noise standard deviations, standard deviations with standard errors, confidence intervals withcrediblesets, andsoon.
Withoutbeingpreciseaboutwhattheuncertaintyrepresents, itisessentiallymeaningless.
In the spirit of playing close attention to what our uncertainty represents, it is crucial to notethatwearetakingtwotimesthesquarerootofourvarianceestimateforthenoisefree function.
Sinceourpredictivedistributionis Gaussian, thisquantityenablesustoforma 95%credibleset, representingourbeliefsabouttheintervalwhichis95%likelytocontain thegroundtruthfunction.
Thenoisevarianceislivingonacompletelydifferentscale, and ismuchlessinterpretable.
Finally, letâ€™s take a look at 20 posterior samples.
These samples tell us what types of functionswebelievemightfitourdata, aposteriori.
post_samples = np.
random.
multivariate_normal(post_mean, post_cov, size=20) d2l.
plt.
scatter(train_x, train_y) d2l.
plt.
plot(test_x, test_y, linewidth=2.) d2l.
plt.
plot(test_x, post_mean, linewidth=2.) d2l.
plt.
plot(test_x, post_samples.
T, color='gray', alpha=0.25) d2l.
plt.
fill_between(test_x, lw_bd, up_bd, alpha=0.25) plt.
legend(['Observed Data', 'True Function', 'Predictive Mean', 'Posteriorâ£ â†©! Samples']) d2l.
plt.
show() In basic regression applications, it is most common to use the posterior predictive mean and standard deviation as a point predictor and metric for uncertainty, respectively.
In moreadvancedapplications, suchas Bayesianoptimizationwith Monte Carloacquisition functions, or Gaussianprocessesformodel-based RL, itoftennecessarytotakeposterior samples.
However, even if not strictly required in the basic applications, these samples giveusmoreintuitionaboutthefitwehaveforthedata, andareoftenusefultoincludein visualizations.
18.3.5 Making Life Easywith GPy Torch As we have seen, it is actually pretty easy to implement basic Gaussian process regres- sion entirely from scratch.
However, as soon as we want to explore a variety of kernel 823 Gaussian Process Inference choices, considerapproximateinference(whichisneededevenforclassification), combine GPswithneuralnetworks, orevenhaveadatasetlargerthanabout10,000points, thenan implementationfromscratchbecomesunwieldyandcumbersome.
Someofthemosteffec- tivemethodsforscalable GPinference, suchas SKI(alsoknownas KISS-GP), canrequire hundredsoflinesofcodeimplementingadvancednumericallinearalgebraroutines.
Inthesecases, the GPy Torchlibrarywillmakeourlivesaloteasier.
Weâ€™llbediscussing GPy Torchmoreinfuturenotebookson Gaussianprocessnumerics, andadvancedmethods.
The GPy Torchlibrarycontainsmanyexamples262.
Togetafeelforthepackage, wewill 262 walkthroughthesimpleregressionexample263, showinghowitcanbeadaptedtoreproduce ouraboveresultsusing GPy Torch.
Thismayseemlikealotofcodetosimplyreproducethe basicregressionabove, andinasense, itis.
Butwecanimmediatelyuseavarietyofkernels, scalableinferencetechniques, andapproximateinference, byonlychangingafewlinesof 263 codefrombelow, insteadofwritingpotentiallythousandsoflinesofnewcode.
# First let's convert our data into tensors for use with Py Torch train_x = torch.
tensor(train_x) train_y = torch.
tensor(train_y) test_y = torch.
tensor(test_y) # We are using exact GP inference with a zero mean and RBF kernel class Exact GPModel(gpytorch.
models.
Exact GP): def __init__(self, train_x, train_y, likelihood): super(Exact GPModel, self).__init__(train_x, train_y, likelihood) self.
mean_module = gpytorch.
means.
Zero Mean() self.
covar_module = gpytorch.
kernels.
Scale Kernel( gpytorch.
kernels.
RBFKernel()) def forward(self, x): mean_x = self.
mean_module(x) covar_x = self.
covar_module(x) return gpytorch.
distributions.
Multivariate Normal(mean_x, covar_x) Thiscodeblockputsthedataintherightformatfor GPy Torch, andspecifiesthatweare using exact inference, as well the mean function (zero) and kernel function (RBF) that we want to use.
We can use any other kernel very easily, by calling, for instance, gpy- haveonlydiscussedexactinference, whereitispossibletoinferapredictivedistribution withoutmakinganyapproximations.
For Gaussianprocesses, wecanonlyperformexact inferencewhenwehavea Gaussianlikelihood; morespecifically, whenweassumethatour observationsaregeneratedasanoise-freefunctionrepresentedbya Gaussianprocess, plus Gaussiannoise.
Infuturenotebooks, wewillconsiderothersettings, suchasclassification, wherewecannotmaketheseassumptions.
# Initialize Gaussian likelihood likelihood = gpytorch.
likelihoods.
Gaussian Likelihood() model = Exact GPModel(train_x, train_y, likelihood) training_iter = 50 # Find optimal model hyperparameters (continuesonnextpage) 824 Gaussian Processes (continuedfrompreviouspage) model.
train() likelihood.
train() # Use the adam optimizer, includes Gaussian Likelihood parameters optimizer = torch.
optim.
Adam(model.
parameters(), lr=0.1) # Set our loss as the negative log GP marginal likelihood mll = gpytorch.
mlls.
Exact Marginal Log Likelihood(likelihood, model) Here, weexplicitlyspecifythelikelihoodwewanttouse(Gaussian), theobjectivewewill usefortrainingkernelhyperparameters(here, themarginallikelihood), andtheprocedure wewewanttouseforoptimizingthatobjective(inthiscase, Adam).
Wenotethatwhile weareusing Adam, whichisaâ€œstochasticâ€optimizer, inthiscase, itisfull-batch Adam.
Becausethemarginallikelihooddoesnotfactorizeoverdatainstances, wecannotusean optimizeroverâ€œmini-batchesâ€ofdataandbeguaranteedconvergence.
Otheroptimizers, suchas L-BFGS, arealsosupportedby GPy Torch.
Unlikeinstandarddeeplearning, doing agoodjobofoptimizingthemarginallikelihoodcorrespondsstronglywithgoodgeneral- ization, whichofteninclinesustowardspowerfuloptimizerslike L-BFGS, assumingthey arenotprohibitivelyexpensive.
for i in range(training_iter): # Zero gradients from previous iteration optimizer.
zero_grad() # Output from model output = model(train_x) # Calc loss and backprop gradients loss = -mll(output, train_y) loss.
backward() if i % 10 == 0: print(f'Iter {i+1: d}/{training_iter: d} - Loss: {loss.
item():.3f} ' f'squared lengthscale: ' f'noise variance: {model.
likelihood.
noise.
item():.3f}') optimizer.
step() Iter 1/50 - Loss: 1.000 squared lengthscale: 0.693 noise variance: 0.693 Iter 11/50 - Loss: 0.711 squared lengthscale: 0.490 noise variance: 0.312 Iter 21/50 - Loss: 0.451 squared lengthscale: 0.506 noise variance: 0.127 Iter 31/50 - Loss: 0.330 squared lengthscale: 0.485 noise variance: 0.055 Iter 41/50 - Loss: 0.344 squared lengthscale: 0.472 noise variance: 0.038 Hereweactuallyruntheoptimizationprocedure, outputtingthevaluesofthelossevery10 iterations.
# Get into evaluation (predictive posterior) mode test_x = torch.
tensor(test_x) model.
eval() likelihood.
eval() observed_pred = likelihood(model(test_x)) Theabovecodeblockenablesustomakepredictionsonourtestinputs.
825 Gaussian Process Inference with torch.
no_grad(): # Initialize plot f, ax = d2l.
plt.
subplots(1, 1, figsize=(4, 3)) # Get upper and lower bounds for 95\% credible set (in this case, in # observation space) lower, upper = observed_pred.
confidence_region() ax.
scatter(train_x.
numpy(), train_y.
numpy()) ax.
plot(test_x.
numpy(), test_y.
numpy(), linewidth=2.) ax.
set_ylim([-1.5, 1.5]) ax.
legend(['True Function', 'Predictive Mean', 'Observed Data', '95% Credible Set']) Finally, weplotthefit.
We see the fits are virtually identical.
A few things to note: GPy Torch is working with squaredlength-scalesandobservationnoise.
Forexample, ourlearnednoisestandardde- viation in the for scratch code is about 0.283.
The noise variance found by GPy Torch is 0.81 0.2832.
In the GPy Torch plot, we also show the credible set in the observation spaceratherthanthelatentfunctionspace, todemonstratethattheyindeedcovertheob- serveddatapoints.
18.3.6 Summary Wecancombinea Gaussianprocesspriorwithdatatoformaposterior, whichweuseto makepredictions.
Wecanalsoformamarginallikelihood, whichisusefulforautomatic learningofkernelhyperparameters, whichcontrolpropertiessuchastherateofvariationof the Gaussianprocess.
Themechanicsofformingtheposteriorandlearningkernelhyperpa- rametersforregressionaresimple, involvingaboutadozenlinesofcode.
Thisnotebookis agoodreferenceforanyreaderwantingtoquicklygetâ€œupandrunningâ€with Gaussianpro- cesses.
Wealsointroducedthe GPy Torchlibrary.
Althoughthe GPy Torchcodeforbasic regressionisrelativelylong, itcanbetriviallymodifiedforotherkernelfunctions, ormore advancedfunctionalitywewilldiscussinfuturenotebooks, suchasscalableinference, or non-Gaussianlikelihoodsforclassification.
18.3.7 Exercises 826 Gaussian Processes 1.
Wehaveemphasizedtheimportanceoflearningkernelhyperparameters, andtheeffect ofhyperparametersandkernelsonthegeneralizationpropertiesof Gaussianprocesses.
Tryskippingthestepwherewelearnhypers, andinsteadguessavarietyoflength-scales andnoisevariances, andchecktheireffectonpredictions.
Whathappenswhenyouuse a large length-scale? A small length-scale? A large noise variance? A small noise variance? 2.
Wehavesaidthatthemarginallikelihoodisnotaconvexobjective, butthathyperpa- rameterslikelength-scaleandnoisevariancecanbereliablyestimatedin GPregression.
Thisisgenerallytrueâ€”infact, themarginallikelihoodismuchbetteratlearninglength- scalehyperparametersthanconventionalapproachesinspatialstatistics, whichinvolve fittingempiricalautocorrelationfunctions(â€œcovariogramsâ€).
Arguably, thebiggestcon- tributionfrommachinelearningto Gaussianprocessresearch, atleastbeforerecentwork onscalableinference, wastheintroductionofthemarginallkelihoodforhyperparameter learning.
However, differentpairingsofeventheseparametersprovideinterpretablydifferentplau- sibleexplanationsformanydatasets, leadingtolocaloptimainourobjective.
Ifweusea large length-scale, then we assume the true underlying function is slowly varying.
If the observeddataarevaryingsignificantly, thentheonlywecanplausiblyhavealargelength- scaleiswithalargenoise-variance.
Ifweuseasmalllength-scale, ontheotherhand, ourfit willbeverysensitivetothevariationsinthedata, leavinglittleroomtoexplainvariations withnoise(aleatoricuncertainty).
Tryseeingifyoucanfindtheselocaloptima: initializewithverylargelength-scalewith largenoise, andsmalllength-scaleswithsmallnoise.
Doyouconvergetodifferentsolu- tions? 3.
Wehavesaidthatafundamentaladvantageof Bayesianmethodsisinnaturallyrepre- sentingepistemicuncertainty.
Intheaboveexample, wecannotfullyseetheeffectsof epistemic uncertainty.
Try instead to predict with test_x = np.
linspace(0, 10, 1000).
What happens to the 95% credible set as your predictions move beyond the data? Doesitcoverthetruefunctioninthatinterval? Whathappensifyouonlyvisual- izealeatoricuncertaintyinthatregion? 4.
Try running the above example, but instead with 10,000, 20,000 and 40,000 training points, andmeasuretheruntimes.
Howdoesthetrainingtimescale? Alternatively, how do the runtimes scale with the number of test points? Is it different for the predictive meanandthepredictivevariance? Answerthisquestionbothbytheoreticallyworking out the training and testing time complexities, and by running the code above with a differentnumberofpoints.
5.
Try running the GPy Torch example with different covariance functions, such as the Matern kernel.
How do the results change? How about the spectral mixture kernel, foundinthe GPy Torchlibrary? Aresomeeasiertotrainthemarginallikelihoodthan others? Aresomemorevaluableforlong-rangeversusshort-rangepredictions? 6.
Inour GPy Torchexample, weplottedthepredictivedistributionincludingobservation 827 Gaussian Process Inference noise, while in our â€œfrom scratchâ€ example, we only included epistemic uncertainty.
Re-do the GPy Torch example, but this time only plotting epistemic uncertainty, and comparetothefrom-scratchresults.
Dothepredictivedistributionsnowlookthesame? (Theyshould.) Discussions264.
264 19 Hyperparameter Optimization Aaron Klein (Amazon), Matthias Seeger (Amazon), and Cedric Archambeau (Ama- zon) Theperformanceofeverymachinelearningmodeldependsonitshyperparameters.
They controlthelearningalgorithmorthestructureoftheunderlyingstatisticalmodel.
However, there is no general wayto choose hyperparameters in practice.
Instead, hyperparameters areoftensetinatrial-and-errormannerorsometimeslefttotheirdefaultvaluesbypracti- tioners, leadingtosuboptimalgeneralization.
Hyperparameter optimization provides a systematic approach to this problem, by casting itasanoptimizationproblem: agoodsetofhyperparametersshould(atleast)minimizea validationerror.
Comparedtomostotheroptimizationproblemsarisinginmachinelearn- ing, hyperparameteroptimizationisanestedone, whereeachiterationrequirestrainingand validatingamachinelearningmodel.
Inthischapter, wewillfirstintroducethebasicsofhyperparameteroptimization.
Wewill alsopresentsomerecentadvancementsthatimprovetheoverallefficiencyofhyperparame- teroptimizationbyexploitingcheap-to-evaluateproxiesoftheoriginalobjectivefunction.
At the end of this chapter, you should be able to apply state-of-the-art hyperparameter optimizationtechniquestooptimizethehyperparameterofyourownmachinelearningal- gorithm.
19.1 What Is Hyperparameter Optimization? Aswehaveseeninthepreviouschapters, deepneuralnetworkscomewithalargenumber ofparametersorweightsthatarelearnedduringtraining.
Ontopofthese, everyneuralnet- workhasadditionalhyperparametersthatneedtobeconfiguredbytheuser.
Forexample, toensurethatstochasticgradientdescentconvergestoalocaloptimumofthetrainingloss (see Chapter12), wehavetoadjustthelearningrateandbatchsize.
Toavoidoverfittingon trainingdatasets, wemighthavetosetregularizationparameters, suchasweightdecay(see Section3.7)ordropout(see Section5.6).
Wecandefinethecapacityandinductivebiasof themodelbysettingthenumberoflayersandnumberofunitsorfiltersperlayer(i.
e., the effectivenumberofweights).
828 829 What Is Hyperparameter Optimization? Unfortunately, wecannotsimplyadjustthesehyperparametersbyminimizingthetraining loss, becausethiswouldleadtooverfittingonthetrainingdata.
Forexample, settingreg- ularization parameters, such as dropout or weight decay to zero leads to a small training loss, butmighthurtthegeneralizationperformance.
Set Hyperparameters Loop until validation performance is maximised Train Evaluate Deploy t .1.1 Typicalworkflowinmachinelearningthatconsistsoftrainingthemodelmultipletimes withdifferenthyperparameters.
Withoutadifferentformofautomation, hyperparametershavetobesetmanuallyinatrial- and-errorfashion, inwhatamountstoatime-consuminganddifficultpartofmachinelearn- ing workflows.
For example, consider training a Res Net (see Section 8.6) on CIFAR-10, which requires more than 2 hours on an Amazon Elastic Cloud Compute (EC2) g4dn.
xlarge instance.
Even just trying ten hyperparameter configurations in sequence, this wouldalreadytakeusroughlyoneday.
Tomakemattersworse, hyperparametersareusu- allynotdirectlytransferableacrossarchitecturesanddatasets(Bardenetetal.,2013, Feurer etal.,2022, Wistubaetal.,2018), andneedtobere-optimizedforeverynewtask.
Also, formosthyperparameters, therearenorule-of-thumbs, andexpertknowledgeisrequired tofindsensiblevalues.
Hyperparameter optimization (HPO) algorithms are designed to tackle this problem in a principledandautomatedfashion(Feurerand Hutter,2018), byframingitasaglobalop- timizationproblem.
Thedefaultobjectiveistheerroronahold-outvalidationdataset, but couldinprinciplebeanyotherbusinessmetric.
Itcanbecombinedwithorconstrainedby secondaryobjectives, suchastrainingtime, inferencetime, ormodelcomplexity.
Recently, hyperparameter optimization has been extended to neural architecture search (NAS) (Elsken et al., 2018, Wistuba et al., 2019), where the goal is to find entirely new neuralnetworkarchitectures.
Comparedtoclassical HPO, NASisevenmoreexpensivein termsofcomputationandrequiresadditionaleffortstoremainfeasibleinpractice.
Both, HPOand NAScanbeconsideredassub-fieldsof Auto ML(Hutteretal.,2019), whichaims toautomatetheentire MLpipeline.
In this section we will introduce HPO and show how we can automatically find the best hyperparametersofthelogisticregressionexampleintroducedin Section4.5.
19.1.1 The Optimization Problem Wewillstartwithasimpletoyproblem: searchingforthelearningrateofthemulti-class logisticregressionmodel Softmax Regressionfrom Section4.5tominimizethevalidation 830 Hyperparameter Optimization erroronthe Fashion MNISTdataset.
Whileotherhyperparameterslikebatchsizeornum- berofepochsarealsoworthtuning, wefocusonlearningratealoneforsimplicity.
import numpy as np import torch from scipy import stats from torch import nn from d2l import torch as d2l Beforewecanrun HPO, wefirstneedtodefinetwoingredients: theobjectivefunctionand theconfigurationspace.
The Objective Function Theperformanceofalearningalgorithmcanbeseenasafunction ğ‘“ : X ! Rthatmaps fromthehyperparameterspacex2Xtothevalidationloss.
Foreveryevaluationof ğ‘“â€xâ€, wehavetotrainandvalidateourmachinelearningmodel, whichcanbetimeandcompute intensiveinthecaseofdeepneuralnetworkstrainedonlargedatasets.
Givenourcriterion ğ‘“â€xâ€ourgoalistofindxâ˜… 2argmin x2X ğ‘“â€xâ€.
Thereisnosimplewaytocomputegradientsof ğ‘“ withrespecttox, becauseitwouldrequire to propagate the gradient through the entire training process.
While there is recent work (Franceschietal.,2017, Maclaurinetal.,2015)todrive HPObyapproximateâ€œhypergradi- entsâ€, noneoftheexistingapproachesarecompetitivewiththestate-of-the-artyet, andwe willnotdiscussthemhere.
Furthermore, thecomputationalburdenofevaluating ğ‘“ requires HPOalgorithmstoapproachtheglobaloptimumwithasfewsamplesaspossible.
Thetrainingofneuralnetworksisstochastic(e.
g., weightsarerandomlyinitialized, mini- batchesarerandomlysampled), sothatourobservationswillbenoisy: ğ‘¦ ğ‘“â€xâ€â€šğœ–, where weusuallyassumethattheğœ– ğ‘â€0,ğœâ€observationnoiseis Gaussiandistributed.
Facedwithallthesechallenges, weusuallytrytoidentifyasmallsetofwellperforming hyperparameterconfigurationsquickly, insteadofhittingtheglobaloptimaexactly.
How- ever, duetolargecomputationaldemandsofmostneuralnetworksmodels, eventhiscan takedaysorweeksofcompute.
Wewillexplorein Section19.4howwecanspeed-upthe optimizationprocessbyeitherdistributingthesearchorusingcheaper-to-evaluateapprox- imationsoftheobjectivefunction.
Webeginwithamethodforcomputingthevalidationerrorofamodel.
class HPOTrainer(d2l.
Trainer): #@save def validation_error(self): self.
model.
eval() accuracy = 0 val_batch_idx = 0 for batch in self.
val_dataloader: with torch.
no_grad(): x, y = self.
prepare_batch(batch) y_hat = self.
model(x) (continuesonnextpage) 831 What Is Hyperparameter Optimization? (continuedfrompreviouspage) accuracy += self.
model.
accuracy(y_hat, y) val_batch_idx += 1 return 1 - accuracy / val_batch_idx We optimize validation error with respect to the hyperparameter configuration config, consistingofthelearning_rate.
Foreachevaluation, wetrainourmodelformax_epochs epochs, thencomputeandreturnitsvalidationerror: def hpo_objective_softmax_classification(config, max_epochs=8): learning_rate = config["learning_rate"] trainer = d2l.
HPOTrainer(max_epochs=max_epochs) data = d2l.
Fashion MNIST(batch_size=16) model = d2l.
Softmax Regression(num_outputs=10, lr=learning_rate) trainer.
fit(model=model, data=data) return trainer.
validation_error().
detach().
numpy() The Configuration Space Alongwiththeobjectivefunction ğ‘“â€xâ€, wealsoneedtodefinethefeasiblesetx 2 X to optimizeover, knownasconfigurationspaceorsearchspace.
Forourlogisticregression example, wewilluse: config_space = {"learning_rate": stats.
loguniform(1e-4, 1)} Hereweusetheusetheloguniformobjectfrom Sci Py, whichrepresentsauniformdistri- butionbetween-4and-1inthelogarithmicspace.
Thisobjectallowsustosamplerandom variablesfromthisdistribution.
Eachhyperparameterhasadatatype, suchasfloatforlearning_rate, aswellasaclosed boundedrange(i.
e., lowerandupperbounds).
Weusuallyassignapriordistribution(e.
g, uniformorlog-uniform)toeachhyperparametertosamplefrom.
Somepositiveparameters, suchaslearning_rate, arebestrepresentedonalogarithmicscaleasoptimalvaluescan differbyseveralordersofmagnitude, whileothers, suchasmomentum, comewithlinear scale.
Belowweshowasimpleexampleofaconfigurationspaceconsistingoftypicalhyperpa- rametersofamulti-layerperceptronincludingtheirtypeandstandardranges.
: Exampleconfigurationspaceofmulti-layerperceptron Table 19.1.1: label: tab_example_configspace 832 Hyperparameter Optimization Name Type Hyperparameter log-scale Ranges learningrate float : math:â€˜ [10^{- yes 6},10^{-1}]â€˜ batchsize integer Â»8,256â€¦ yes momentum float Â»0,0.99â€¦ no activationfunction categorical : mat h:{textrm{tanh} , textrm{relu}} numberofunits integer Â»32,1024â€¦ yes numberoflayers integer Â»1,6â€¦ no Ingeneral, thestructureoftheconfigurationspace X canbecomplexanditcanbequite differentfrom Rğ‘‘ .
Inpractice, somehyperparametersmaydependonthevalueofothers.
Forexample, assumewetrytotunethenumberoflayersforamulti-layerperceptron, and foreachlayerthenumberofunits.
Thenumberofunitsoftheğ‘™-thlayerisrelevantonlyif thenetworkhasatleastğ‘™â€š1layers.
Theseadvanced HPOproblemsarebeyondthescope of this chapter.
We refer the interested reader to (Baptista and Poloczek, 2018, Hutter et al.,2011, Jenattonetal.,2017).
The configuration space plays an important role for hyperparameter optimization, since noalgorithmscanfindsomethingthatisnotincludedintheconfigurationspace.
Onthe other hand, if the ranges are too large, the computation budget to find well performing configurationsmightbecomeinfeasible.
19.1.2 Random Search Randomsearchisthefirsthyperparameteroptimizationalgorithmwewillconsider.
The mainideaofrandomsearchistoindependentlysamplefromtheconfigurationspaceuntil a predefined budget (e.
g maximum number of iterations) is exhausted, and to return the bestobservedconfiguration.
Allevaluationscanbeexecutedindependentlyinparallel(see Section19.3), buthereweuseasequentialloopforsimplicity.
errors, values = [], [] num_iterations = 5 for i in range(num_iterations): learning_rate = config_space["learning_rate"].
rvs() print(f"Trial {i}: learning_rate = {learning_rate}") y = hpo_objective_softmax_classification({"learning_rate": learning_rate}) print(f" validation_error = {y}") values.
append(learning_rate) errors.
append(y) validation_error = 0.17070001363754272 Thebestlearningrateisthensimplytheonewiththelowestvalidationerror.
833 19.1 What Is Hyperparameter Optimization? 834 Hyperparameter Optimization best_idx = np.
argmin(errors) print(f"optimal learning rate = {values[best_idx]}") optimal learning rate = 0.09844872561810249 Duetoitssimplicityandgenerality, randomsearchisoneofthemostfrequentlyused HPO algorithms.
It does not require any sophisticated implementation and can be applied to any configuration space as long as we can define some probability distribution for each hyperparameter.
Unfortunatelyrandomsearchalsocomeswithafewshortcomings.
First, itdoesnotadapt the sampling distribution based on the previous observations it collected so far.
Hence, it is equally likely to sample a poorly performing configuration than a better performing configuration.
Second, thesameamountofresourcesarespentforallconfigurations, even thoughsomemayshowpoorinitialperformanceandarelesslikelytooutperformpreviously seenconfigurations.
In the next sections we will look at more sample efficient hyperparameter optimization algorithms that overcome the shortcomings of random search by using a model to guide thesearch.
Wewillalsolookatalgorithmsthatautomaticallystoptheevaluationprocess ofpoorlyperformingconfigurationstospeeduptheoptimizationprocess.
19.1.3 Summary Inthissectionweintroducedhyperparameteroptimization(HPO)andhowwecanphrase it as a global optimization by defining a configuration space and an objective function.
Wealsoimplementedourfirst HPOalgorithm, randomsearch, andapplieditonasimple softmaxclassificationproblem.
Whilerandomsearchisverysimple, itisthebetteralternativetogridsearch, whichsimply evaluates a fixed set of hyperparameters.
Random search somewhat mitigates the curse of dimensionality (Bellman, 1966), and can be far more efficient than grid search if the criterionmoststronglydependsonasmallsubsetofthehyperparameters.
19.1.4 Exercises 835 What Is Hyperparameter Optimization? 1.
Inthischapter, weoptimizethevalidationerrorofamodelaftertrainingonadisjoint trainingset.
Forsimplicity, ourcodeuses Trainer.
val_dataloader, whichmapstoa loaderaround Fashion MNIST.
val.
1.
Convinceyourself(bylookingatthecode)thatthismeansweusetheoriginal Fash- ion MNISTtrainingset(60000examples)fortraining, andtheoriginaltestset(10000 examples)forvalidation.
2.
Whycouldthispracticebeproblematic? Hint: Re-read Section3.6, especiallyabout modelselection.
3.
Whatshouldwehavedoneinstead? 2.
Westatedabovethathyperparameteroptimizationbygradientdescentisveryhardtodo.
Considerasmallproblem, suchastrainingatwo-layerperceptrononthe Fashion MNIST dataset(Section5.2)withabatchsizeof256.
Wewouldliketotunethelearningrate of SGDinordertominimizeavalidationmetricafteroneepochoftraining.
1.
Whycannotweusevalidationerrorforthispurpose? Whatmetriconthevalidation setwouldyouuse? 2.
Sketch(roughly)thecomputationalgraphofthevalidationmetricaftertrainingfor oneepoch.
Youmayassumethatinitialweightsandhyperparameters(suchaslearn- ingrate)areinputnodestothisgraph.
Hint: Re-readaboutcomputationalgraphsin Section5.3.
3.
Givearoughestimateofthenumberoffloatingpointvaluesyouneedtostoreduring a forward pass on this graph.
Hint: Fashion MNIST has 60000 cases.
Assume the required memory is dominated by the activations after each layer, and look up the layerwidthsin Section5.2.
4.
Apart from the sheer amount of compute and storage required, what other issues would gradient-based hyperparameter optimization run into? Hint: Re-read about vanishingandexplodinggradientsin Section5.4.
5.
Advanced: Read(Maclaurinetal.,2015)foranelegant(yetstillsomewhatunprac- tical)approachtogradient-based HPO.
3.
Gridsearchisanother HPObaseline, wherewedefineanequi-spacedgridforeachhy- perparameter, theniterateoverthe(combinatorial)Cartesianproductinordertosuggest configurations.
1.
Westatedabovethatrandomsearchcanbemuchmoreefficientthangridsearchfor HPOonasizablenumberofhyperparameters, ifthecriterionmoststronglydepends onasmallsubsetofthehyperparameters.
Whyisthis? Hint: Read(Bergstraetal., 265 2011).
Discussions265.
836 Hyperparameter Optimization 19.2 Hyperparameter Optimization API Before we dive into the methodology, we will first discuss a basic code structure that al- lowsustoefficientlyimplementvarious HPOalgorithms.
Ingeneral, all HPOalgorithms consideredhereneedtoimplementtwodecisionmakingprimitives, searchingandschedul- ing.
First, theyneedtosamplenewhyperparameterconfigurations, whichofteninvolves somekindofsearchovertheconfigurationspace.
Second, foreachconfiguration, an HPO algorithmneedstoscheduleitsevaluationanddecidehowmanyresourcestoallocatefor it.
Oncewestart toevaluateaconfiguration, wewillreferto itasa trial.
Wemapthese decisionstotwoclasses, HPOSearcherand HPOScheduler.
Ontopofthat, wealsoprovide a HPOTunerclassthatexecutestheoptimizationprocess.
Thisconceptofschedulerandsearcherisalsoimplementedinpopular HPOlibraries, such as Syne Tune(Salinasetal.,2022), Ray Tune(Liawetal.,2018)or Optuna(Akibaetal., 2019).
import time from scipy import stats from d2l import torch as d2l 19.2.1 Searcher Belowwedefineabaseclassforsearchers, whichprovidesanewcandidateconfiguration throughthesample_configurationfunction.
Asimplewaytoimplementthisfunction would be to sample configurations uniformly at random, as we did for random search in Section 19.1.
More sophisticated algorithms, such as Bayesian optimization, will make thesedecisionsbasedontheperformanceofprevioustrials.
Asaresult, thesealgorithms areabletosamplemorepromisingcandidatesovertime.
Weaddtheupdatefunctionin ordertoupdatethehistoryofprevioustrials, whichcanthenbeexploitedtoimproveour samplingdistribution.
class HPOSearcher(d2l.
Hyper Parameters): #@save def sample_configuration() -> dict: raise Not Implemented Error def update(self, config: dict, error: float, additional_info=None): pass Thefollowingcode showshowto implement our random searchoptimizer from the pre- vious section in this API.
As a slight extension, we allow the user to prescribe the first configuration to be evaluated via initial_config, while subsequent ones are drawn at random.
class Random Searcher(HPOSearcher): #@save (continuesonnextpage) 837 Hyperparameter Optimization API (continuedfrompreviouspage) def __init__(self, config_space: dict, initial_config=None): self.
save_hyperparameters() def sample_configuration(self) -> dict: if self.
initial_config is not None: result = self.
initial_config self.
initial_config = None else: result = { name: domain.
rvs() for name, domain in self.
config_space.
items() } return result 19.2.2 Scheduler Beyondsamplingconfigurationsfornewtrials, wealsoneedtodecidewhenandforhow longtorunatrial.
Inpractice, allthesedecisionsaredonebythe HPOScheduler, which delegates the choice of new configurations to a HPOSearcher.
The suggest method is calledwheneversomeresourcefortrainingbecomesavailable.
Apartfrominvokingsam- ple_configurationofasearcher, itmayalsodecideuponparameterslikemax_epochs (i.
e., howlongtotrainthemodelfor).
Theupdatemethodiscalledwheneveratrialreturns anewobservation.
class HPOScheduler(d2l.
Hyper Parameters): #@save def suggest(self) -> dict: raise Not Implemented Error def update(self, config: dict, error: float, info=None): raise Not Implemented Error Toimplementrandomsearch, butalsoother HPOalgorithms, weonlyneedabasicsched- ulerthatschedulesanewconfigurationeverytimenewresourcesbecomeavailable.
class Basic Scheduler(HPOScheduler): #@save def __init__(self, searcher: HPOSearcher): self.
save_hyperparameters() def suggest(self) -> dict: return self.
searcher.
sample_configuration() def update(self, config: dict, error: float, info=None): self.
searcher.
update(config, error, additional_info=info) 19.2.3 Tuner Finally, weneedacomponentthatrunsthescheduler/searcheranddoessomebook-keeping oftheresults.
Thefollowingcodeimplementsasequentialexecutionofthe HPOtrialsthat 838 Hyperparameter Optimization evaluatesonetrainingjobafterthenextandwillserveasabasicexample.
Wewilllater use Syne Tuneformorescalabledistributed HPOcases.
class HPOTuner(d2l.
Hyper Parameters): #@save def __init__(self, scheduler: HPOScheduler, objective: callable): self.
save_hyperparameters() # Bookeeping results for plotting self.
incumbent = None self.
incumbent_error = None self.
incumbent_trajectory = [] self.
cumulative_runtime = [] self.
current_runtime = 0 self.
records = [] def run(self, number_of_trials): for i in range(number_of_trials): start_time = time.
time() config = self.
scheduler.
suggest() print(f"Trial {i}: config = {config}") error = self.
objective(**config) error = float(error.
cpu().
detach().
numpy()) self.
scheduler.
update(config, error) runtime = time.
time() - start_time self.
bookkeeping(config, error, runtime) print(f" error = {error}, runtime = {runtime}") 19.2.4 Bookkeepingthe Performanceof HPOAlgorithms With any HPO algorithm, we are mostly interested in the best performing configuration (calledincumbent)anditsvalidationerrorafteragivenwall-clocktime.
Thisiswhywe track runtime per iteration, which includes both the time to run an evaluation (call of objective) and the time to make a decision (call of scheduler.
suggest).
In the se- quel, wewillplotcumulative_runtimeagainstincumbent_trajectoryinordertovisu- alizetheany-timeperformanceofthe HPOalgorithmdefinedintermsofscheduler(and searcher).
This allows us to quantify not only how well the configuration found by an optimizerworks, butalsohowquicklyanoptimizerisabletofindit.
@d2l.
add_to_class(HPOTuner) #@save def bookkeeping(self, config: dict, error: float, runtime: float): self.
records.
append({"config": config, "error": error, "runtime": runtime}) # Check if the last hyperparameter configuration performs better # than the incumbent if self.
incumbent is None or self.
incumbent_error > error: self.
incumbent = config self.
incumbent_error = error # Add current best observed performance to the optimization trajectory self.
incumbent_trajectory.
append(self.
incumbent_error) # Update runtime self.
current_runtime += runtime self.
cumulative_runtime.
append(self.
current_runtime) 839 Hyperparameter Optimization API 19.2.5 Example: Optimizingthe Hyperparametersofa Convolutional Neural Network We now use our new implementation of random search to optimize the batch size and learning rate of the Le Net convolutional neural network from Section 7.6.
We being by definingtheobjectivefunction, whichwilloncemorebevalidationerror.
def hpo_objective_lenet(learning_rate, batch_size, max_epochs=10): #@save model = d2l.
Le Net(lr=learning_rate, num_classes=10) trainer = d2l.
HPOTrainer(max_epochs=max_epochs, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=batch_size) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) trainer.
fit(model=model, data=data) validation_error = trainer.
validation_error() return validation_error We also need to define the configuration space.
Moreover, the first configuration to be evaluatedisthedefaultsettingusedin Section7.6.
config_space = { "learning_rate": stats.
loguniform(1e-2, 1), "batch_size": stats.
randint(32, 256), } initial_config = { "learning_rate": 0.1, "batch_size": 128, } Nowwecanstartourrandomsearch: searcher = Random Searcher(config_space, initial_config=initial_config) scheduler = Basic Scheduler(searcher=searcher) tuner = HPOTuner(scheduler=scheduler, objective=hpo_objective_lenet) tuner.
run(number_of_trials=5) error = 0.9000097513198853, runtime = 62.85189199447632 Belowweplottheoptimizationtrajectoryoftheincumbenttogettheany-timeperformance ofrandomsearch: 840 Hyperparameter Optimization 841 Hyperparameter Optimization API board = d2l.
Progress Board(xlabel="time", ylabel="error") for time_stamp, error in zip( tuner.
cumulative_runtime, tuner.
incumbent_trajectory ): board.
draw(time_stamp, error, "random search", every_n=1) 19.2.6 Comparing HPOAlgorithms Justaswithtrainingalgorithmsormodelarchitectures, itisimportanttounderstandhow tobestcomparedifferent HPOalgorithms.
Each HPOrundependsontwomajorsources ofrandomness: therandomeffectsofthetrainingprocess, suchasrandomweightinitial- izationormini-batchordering, andtheintrinsicrandomnessofthe HPOalgorithmitself, such as the random sampling of random search.
Hence, when comparing different algo- rithms, itiscrucialtoruneachexperimentseveraltimesandreportstatistics, suchasmean ormedian, acrossapopulationofmultiplerepetitionsofanalgorithmbasedondifferent seedsoftherandomnumbergenerator.
Toillustratethis, wecomparerandomsearch(see Section19.1.2)and Bayesianoptimiza- tion(Snoeketal.,2012)ontuningthehyperparametersofafeed-forwardneuralnetwork.
Eachalgorithmwasevaluated50timeswithadifferentrandomseed.
Thesolidlineindi- catestheaverageperformanceoftheincumbentacrossthese50repetitionsandthedashed linethestandarddeviation.
Wecanseethatrandomsearchand Bayesianoptimizationper- form roughlythe same up to ~1000 seconds, but Bayesianoptimization can makeuse of thepastobservationtoidentifybetterconfigurationsandthusquicklyoutperformsrandom searchafterwards.
t .2.1 Exampleany-timeperformanceplottocomparetwoalgorithms Aand B.
842 Hyperparameter Optimization 19.2.7 Summary Thissectionlaidoutasimple, yetflexibleinterfacetoimplementvarious HPOalgorithms thatwewilllookatinthischapter.
Similarinterfacescanbefoundinpopularopen-source HPOframeworks.
Wealsolookedathowwecancompare HPOalgorithms, andpotential pitfalloneneedstobeaware.
19.2.8 Exercises 1.
Thegoalofthisexerciseistoimplementtheobjectivefunctionforaslightlymorechal- lenging HPOproblem, andtorunmorerealisticexperiments.
Wewillusethetwohidden layer MLPDropout MLPimplementedin Section5.6.
1.
Codeuptheobjectivefunction, whichshoulddependonallhyperparametersofthe modelandbatch_size.
Usemax_epochs=50.
GPUsdonothelphere, sonum_gpus=0.
Hint: Modifyhpo_objective_lenet.
2.
Chooseasensiblesearchspace, wherenum_hiddens_1, num_hiddens_2areintegers inÂ»8,1024â€¦, anddropoutvalueslieinÂ»0,0.95â€¦, whilebatch_sizeliesinÂ»16,384â€¦.
Providecodeforconfig_space, usingsensibledistributionsfromscipy.
stats.
3.
Run random search on this example with number_of_trials=20 and plot the re- sults.
Make sure to first evaluate the default configuration of Section 5.6, which is initial_config = {'num_hiddens_1': 256, 'num_hiddens_2': 256, 'dropout_1': 0.5, 'dropout_2': 0.5, 'lr': 0.1, 'batch_size': 256}.
2.
Inthisexercise, youwillimplementanewsearcher(subclassof HPOSearcher)which makesdecisionsbasedonpastdata.
Itdependsonparametersprobab_local, num_init_random.
Itssample_configurationmethodworksasfollows.
Forthefirstnum_init_random calls, dothesameas Random Searcher.
sample_configuration.
Otherwise, withprob- ability1 - probab_local, dothesameas Random Searcher.
sample_configuration.
Otherwise, pick the configuration which attained the smallest validation error so far, select one of its hyperparameters at random, and sample its value randomly like in Random Searcher.
sample_configuration, but leave all other values the same.
Re- turnthisconfiguration, whichisidenticaltothebestconfigurationsofar, exceptinthis onehyperparameter.
1.
Codeupthisnew Local Searcher.
Hint: Yoursearcherrequiresconfig_spaceas argumentatconstruction.
Feelfreetouseamemberoftype Random Searcher.
You willalsohavetoimplementtheupdatemethod.
2.
Re-runtheexperimentfromthepreviousexercise, butusingyournewsearcherin- stead of Random Searcher.
Experiment with different values for probab_local, num_init_random.
However, notethatapropercomparisonbetweendifferent HPO methods requires repeating experiments several times, and ideally considering a 266 numberofbenchmarktasks.
Discussions266.
843 Asynchronous Random Search 19.3 Asynchronous Random Search Aswehaveseenintheprevious Section19.2, wemighthavetowaithoursorevendaysbe- forerandomsearchreturnsagoodhyperparameterconfiguration, becauseoftheexpensive evaluationofhyperparameterconfigurations.
Inpractice, wehaveoftenaccesstoapoolof resourcessuchasmultiple GPUsonthesamemachineormultiplemachineswithasingle GPU.
Thisbegsthequestion: Howdoweeï¬€icientlydistributerandomsearch? Ingeneral, wedistinguishbetweensynchronousandasynchronousparallelhyperparameter optimization (see .3.1).
In the synchronous setting, we wait for all concurrently runningtrialstofinish, beforewestartthenextbatch.
Considerconfigurationspacesthat containhyperparameterssuchasthenumberoffiltersornumberoflayersofadeepneural network.
Hyperparameter configurations that contain a larger number of layers of filters willnaturallytakemoretimetofinish, andallothertrialsinthesamebatchwillhavetowait atsynchronisationpoints(greyareain.3.1)beforewecancontinuetheoptimization process.
Intheasynchronoussettingweimmediatelyscheduleanewtrialassoonasresourcesbe- comeavailable.
Thiswilloptimallyexploitourresources, sincewecanavoidanysynchro- nisationoverhead.
Forrandomsearch, eachnewhyperparameterconfigurationischosen independentlyofallothers, andinparticularwithoutexploitingobservationsfromanyprior evaluation.
Thismeanswecantriviallyparallelizerandomsearchasynchronously.
Thisis notstraight-forwardwithmoresophisticatedmethodsthatmakedecisionbasedonprevi- ousobservations(see Section19.5).
Whileweneedaccesstomoreresourcesthaninthe sequentialsetting, asynchronousrandomsearchexhibitsalinearspeed-up, inthatacertain performanceisreachedğ¾ timesfasterifğ¾ trialscanberuninparallel.
Sequential Trial-0 Trial-1 Trial-2 Trial-3 Trial-4 Trial-5 Trial-0 Trial-2 Trial-4 Synchronous Trial-1 Trial-3 Trial-5 Trial-0 Trial-3 Trial-4 Asynchronous Trial-1 Trial-2 Trial-5 t Time .3.1 Distributingthehyperparameteroptimizationprocesseithersynchronouslyor asynchronously.
Comparedtothesequentialsetting, wecanreducetheoverallwall-clock timewhilekeepthetotalcomputeconstant.
Synchronousschedulingmightleadtoidling workersinthecaseofstragglers.
In this notebook, we will look at asynchronous random search that, where trials are exe- cutedinmultiplepythonprocessesonthesamemachine.
Distributedjobschedulingand execution is difficult to implement from scratch.
We will use Syne Tune (Salinas et al., 2022), whichprovidesuswithasimpleinterfaceforasynchronous HPO.
Syne Tuneisde- 844 Hyperparameter Optimization signedtoberunwithdifferentexecutionback-ends, andtheinterestedreaderisinvitedto studyitssimple APIsinordertolearnmoreaboutdistributed HPO.
import logging from d2l import torch as d2l logging.
basic Config(level=logging.
INFO) from syne_tune import Stopping Criterion, Tuner from syne_tune.
backend.
python_backend import Python Backend from syne_tune.
config_space import loguniform, randint from syne_tune.
experiments import load_experiment from syne_tune.
optimizer.
baselines import Random Search INFO: root: Sage Maker Backend is not imported since dependencies are missing.
Youâ£ â†©! can install them with pip install 'syne-tune[extra]' AWS dependencies are not imported since dependencies are missing.
You canâ£ â†©! install them with pip install 'syne-tune[aws]' or (for everything) pip install 'syne-tune[extra]' AWS dependencies are not imported since dependencies are missing.
You canâ£ â†©! install them with pip install 'syne-tune[aws]' or (for everything) pip install 'syne-tune[extra]' INFO: root: Ray Tune schedulers and searchers are not imported sinceâ£ â†©! dependencies are missing.
You can install them with pip install 'syne-tune[raytune]' or (for everything) pip install 'syne-tune[extra]' 19.3.1 Objective Function First, wehavetodefineanewobjectivefunctionsuchthatitnowreturnstheperformance backto Syne Tuneviathereportcallback.
def hpo_objective_lenet_synetune(learning_rate, batch_size, max_epochs): from syne_tune import Reporter from d2l import torch as d2l model = d2l.
Le Net(lr=learning_rate, num_classes=10) trainer = d2l.
HPOTrainer(max_epochs=1, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=batch_size) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) report = Reporter() for epoch in range(1, max_epochs + 1): if epoch == 1: # Initialize the state of Trainer trainer.
fit(model=model, data=data) else: trainer.
fit_epoch() (continuesonnextpage) 845 Asynchronous Random Search (continuedfrompreviouspage) validation_error = trainer.
validation_error().
cpu().
detach().
numpy() report(epoch=epoch, validation_error=float(validation_error)) Notethatthe Python Backend of Syne Tunerequiresdependencies tobe importedinside thefunctiondefinition.
19.3.2 Asynchronous Scheduler First, wedefinethenumberofworkersthatevaluatetrialsconcurrently.
Wealsoneedto specify how long we want to run random search, by defining an upper limit on the total wall-clocktime.
n_workers = 2 # Needs to be <= the number of available GPUs max_wallclock_time = 12 * 60 # 12 minutes Next, we state which metric we want to optimize and whether we want to minimize or maximizethismetric.
Namely, metricneedstocorrespondtotheargumentnamepassed tothereportcallback.
mode = "min" metric = "validation_error" Weusetheconfigurationspacefromourpreviousexample.
In Syne Tune, thisdictionary can also be used to pass constant attributes to the training script.
We make use of this feature in order to pass max_epochs.
Moreover, we specify the first configuration to be evaluatedininitial_config.
config_space = { "learning_rate": loguniform(1e-2, 1), "batch_size": randint(32, 256), "max_epochs": 10, } initial_config = { "learning_rate": 0.1, "batch_size": 128, } Next, weneedtospecifytheback-endforjobexecutions.
Herewejustconsiderthedistri- butiononalocalmachinewhereparalleljobsareexecutedassub-processes.
However, for largescale HPO, wecouldrunthisalsoonaclusterorcloudenvironment, whereeachtrial consumesafullinstance.
trial_backend = Python Backend( tune_function=hpo_objective_lenet_synetune, config_space=config_space, ) 846 Hyperparameter Optimization Wecannowcreatetheschedulerforasynchronousrandomsearch, whichissimilarinbe- haviourtoour Basic Schedulerfrom Section19.2.
scheduler = Random Search( config_space, metric=metric, mode=mode, points_to_evaluate=[initial_config], ) INFO: syne_tune.
optimizer.
schedulers.
fifo: max_resource_level = 10, as inferredâ£ â†©! from config_space INFO: syne_tune.
optimizer.
schedulers.
fifo: Master random_seed = 2737092907 Syne Tune also features a Tuner, where the main experiment loop and bookkeeping is centralized, andinteractionsbetweenschedulerandback-endaremediated.
stop_criterion = Stopping Criterion(max_wallclock_time=max_wallclock_time) tuner = Tuner( trial_backend=trial_backend, scheduler=scheduler, stop_criterion=stop_criterion, n_workers=n_workers, print_update_interval=int(max_wallclock_time * 0.6), ) Letusrunourdistributed HPOexperiment.
Accordingtoourstoppingcriterion, itwillrun forabout12minutes.
tuner.
run() INFO: syne_tune.
tuner: results of trials will be saved on /home/ci/syne-tune/ â†©! python-entrypoint-2023-08-18-19-45-39-958 INFO: root: Detected 4 GPUs INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.1 --batch_size 128 --max_epochs 10 --tune_function_rootâ£ â†©!/home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/tune_function -- â†©! tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_checkpoint_dir / â†©! home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/0/checkpoints INFO: syne_tune.
tuner:(trial 0) - scheduled config {'learning_rate': 0.1, â†©!'batch_size': 128, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.1702844732454753 --batch_size 114 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!1/checkpoints INFO: syne_tune.
tuner:(trial 1) - scheduled config {'learning_rate': 0.
(continuesonnextpage) 847 Asynchronous Random Search (continuedfrompreviouspage) â†©!1702844732454753, 'batch_size': 114, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 0 completed.
INFO: syne_tune.
tuner: Trial trial_id 1 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.34019846567238493 --batch_size 221 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!2/checkpoints INFO: syne_tune.
tuner:(trial 2) - scheduled config {'learning_rate': 0.
â†©!34019846567238493, 'batch_size': 221, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.014628124155727769 --batch_size 88 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!3/checkpoints INFO: syne_tune.
tuner:(trial 3) - scheduled config {'learning_rate': 0.
â†©!014628124155727769, 'batch_size': 88, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 2 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.1114831485450576 --batch_size 142 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!4/checkpoints INFO: syne_tune.
tuner:(trial 4) - scheduled config {'learning_rate': 0.
â†©!1114831485450576, 'batch_size': 142, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 3 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.014076038679980779 --batch_size 223 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!5/checkpoints INFO: syne_tune.
tuner:(trial 5) - scheduled config {'learning_rate': 0.
â†©!014076038679980779, 'batch_size': 223, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 4 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.02558173674804846 --batch_size 62 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!6/checkpoints INFO: syne_tune.
tuner:(trial 6) - scheduled config {'learning_rate': 0.
â†©!02558173674804846, 'batch_size': 62, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 5 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.026035979388614055 --batch_size 139 --max_epochs 10 -- (continuesonnextpage) 848 Hyperparameter Optimization (continuedfrompreviouspage) â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!7/checkpoints INFO: syne_tune.
tuner:(trial 7) - scheduled config {'learning_rate': 0.
â†©!026035979388614055, 'batch_size': 139, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 6 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.24202494130424274 --batch_size 231 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!8/checkpoints INFO: syne_tune.
tuner:(trial 8) - scheduled config {'learning_rate': 0.
â†©!24202494130424274, 'batch_size': 231, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 7 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.10483132064775551 --batch_size 145 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!9/checkpoints INFO: syne_tune.
tuner:(trial 9) - scheduled config {'learning_rate': 0.
â†©!10483132064775551, 'batch_size': 145, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 8 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.017898854850751864 --batch_size 51 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!10/checkpoints INFO: syne_tune.
tuner:(trial 10) - scheduled config {'learning_rate': 0.
â†©!017898854850751864, 'batch_size': 51, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 9 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.9645419978270817 --batch_size 200 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!11/checkpoints INFO: syne_tune.
tuner:(trial 11) - scheduled config {'learning_rate': 0.
â†©!9645419978270817, 'batch_size': 200, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 11 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.10559888854748693 --batch_size 40 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!12/checkpoints INFO: syne_tune.
tuner:(trial 12) - scheduled config {'learning_rate': 0.
(continuesonnextpage) 849 Asynchronous Random Search (continuedfrompreviouspage) â†©!10559888854748693, 'batch_size': 40, 'max_epochs': 10} INFO: syne_tune.
tuner: tuning status (last metric is reported) trial_id status iter learning_rate batch_size max_epochs epoch â£ â†©! validation_error worker-time 0 Completed 10 0.100000 128 10 10.0 â£ â†©! 0.277195 64.928907 1 Completed 10 0.170284 114 10 10.0 â£ â†©! 0.286225 65.434195 2 Completed 10 0.340198 221 10 10.0 â£ â†©! 0.218990 59.729758 3 Completed 10 0.014628 88 10 10.0 â£ â†©! 0.899920 81.001636 4 Completed 10 0.111483 142 10 10.0 â£ â†©! 0.268684 64.427400 5 Completed 10 0.014076 223 10 10.0 â£ â†©! 0.899922 61.264475 6 Completed 10 0.025582 62 10 10.0 â£ â†©! 0.399520 75.966186 7 Completed 10 0.026036 139 10 10.0 â£ â†©! 0.899988 62.261541 8 Completed 10 0.242025 231 10 10.0 â£ â†©! 0.257636 58.186485 9 Completed 10 0.104831 145 10 10.0 â£ â†©! 0.273898 59.771699 10 In Progress 8 0.017899 51 10 8.0 â£ â†©! 0.496118 66.999746 11 Completed 10 0.964542 200 10 10.0 â£ â†©! 0.181600 59.159662 12 In Progress 0 0.105599 40 10 - â£ â†©! - - 2 trials running, 11 finished (11 until the end), 436.60s wallclock-time INFO: syne_tune.
tuner: Trial trial_id 10 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.5846051207380589 --batch_size 35 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©! tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!13/checkpoints INFO: syne_tune.
tuner:(trial 13) - scheduled config {'learning_rate': 0.
â†©!5846051207380589, 'batch_size': 35, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 12 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.2468891379769198 --batch_size 146 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!14/checkpoints INFO: syne_tune.
tuner:(trial 14) - scheduled config {'learning_rate': 0.
â†©!2468891379769198, 'batch_size': 146, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 13 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
(continuesonnextpage) 850 Hyperparameter Optimization (continuedfrompreviouspage) â†©! py --learning_rate 0.12956867470224812 --batch_size 218 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!15/checkpoints INFO: syne_tune.
tuner:(trial 15) - scheduled config {'learning_rate': 0.
â†©!12956867470224812, 'batch_size': 218, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 14 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.24900745354561854 --batch_size 103 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!16/checkpoints INFO: syne_tune.
tuner:(trial 16) - scheduled config {'learning_rate': 0.
â†©!24900745354561854, 'batch_size': 103, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 15 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.03903577426988046 --batch_size 80 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!17/checkpoints INFO: syne_tune.
tuner:(trial 17) - scheduled config {'learning_rate': 0.
â†©!03903577426988046, 'batch_size': 80, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 16 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.01846559300690354 --batch_size 183 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39- â†©!958/tune_function --tune_function_hash 4d7d5b85e4537ad0c5d0a202623dcec5 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958/ â†©!18/checkpoints INFO: syne_tune.
tuner:(trial 18) - scheduled config {'learning_rate': 0.
â†©!01846559300690354, 'batch_size': 183, 'max_epochs': 10} INFO: syne_tune.
stopping_criterion: reaching max wallclock time (720), stoppingâ£ â†©! there.
INFO: syne_tune.
tuner: Stopping trials that may still be running.
INFO: syne_tune.
tuner: Tuning finished, results of trials can be found on /home/ â†©! ci/syne-tune/python-entrypoint-2023-08-18-19-45-39-958 -------------------- Resource summary (last result is reported): trial_id status iter learning_rate batch_size max_epochs epoch â£ â†©! validation_error worker-time 0 Completed 10 0.100000 128 10 10 â£ â†©! 0.277195 64.928907 1 Completed 10 0.170284 114 10 10 â£ â†©! 0.286225 65.434195 2 Completed 10 0.340198 221 10 10 â£ â†©! 0.218990 59.729758 3 Completed 10 0.014628 88 10 10 â£ â†©! 0.899920 81.001636 4 Completed 10 0.111483 142 10 10 â£ (continuesonnextpage) 851 Asynchronous Random Search (continuedfrompreviouspage) â†©! 0.268684 64.427400 5 Completed 10 0.014076 223 10 10 â£ â†©! 0.899922 61.264475 6 Completed 10 0.025582 62 10 10 â£ â†©! 0.399520 75.966186 7 Completed 10 0.026036 139 10 10 â£ â†©! 0.899988 62.261541 8 Completed 10 0.242025 231 10 10 â£ â†©! 0.257636 58.186485 9 Completed 10 0.104831 145 10 10 â£ â†©! 0.273898 59.771699 10 Completed 10 0.017899 51 10 10 â£ â†©! 0.405545 83.778503 11 Completed 10 0.964542 200 10 10 â£ â†©! 0.181600 59.159662 12 Completed 10 0.105599 40 10 10 â£ â†©! 0.182500 94.734384 13 Completed 10 0.584605 35 10 10 â£ â†©! 0.153846 110.965637 14 Completed 10 0.246889 146 10 10 â£ â†©! 0.215050 65.142847 15 Completed 10 0.129569 218 10 10 â£ â†©! 0.313873 61.310455 16 Completed 10 0.249007 103 10 10 â£ â†©! 0.196101 72.519127 17 In Progress 9 0.039036 80 10 9 â£ â†©! 0.369000 73.403000 18 In Progress 5 0.018466 183 10 5 â£ â†©! 0.900263 34.714568 2 trials running, 17 finished (17 until the end), 722.84s wallclock-time validation_error: best 0.14451533555984497 for trial-id 13 -------------------- Thelogsofallevaluatedhyperparameterconfigurationsarestoredforfurtheranalysis.
At any time during the tuning job, we can easily get the results obtained so far and plot the incumbenttrajectory.
d2l.
set_figsize() tuning_experiment = load_experiment(tuner.
name) tuning_experiment.
plot() WARNING: matplotlib.
legend: No artists with labels found to put in legend.
Noteâ£ â†©! that artists whose label start with an underscore are ignored when legend()â£ â†©! is called with no argument.
19.3.3 Visualizethe Asynchronous Optimization Process Belowwevisualizehowthelearningcurvesofeverytrial(eachcolorintheplotrepresents atrial)evolveduringtheasynchronousoptimizationprocess.
Atanypointintime, there are as many trials running concurrently as we have workers.
Once a trial finishes, we 852 Hyperparameter Optimization immediately start the next trial, without waiting for the other trials to finish.
Idle time ofworkersisreducedtoaminimumwithasynchronousscheduling.
d2l.
set_figsize([6, 2.5]) results = tuning_experiment.
results for trial_id in results.
trial_id.
unique(): df = results[results["trial_id"] == trial_id] d2l.
plt.
plot( df["st_tuner_time"], df["validation_error"], marker="o" ) d2l.
plt.
xlabel("wall-clock time") d2l.
plt.
ylabel("objective function") Text(0, 0.5, 'objective function') 19.3.4 Summary Wecanreducethewaitingtimeforrandomsearchsubstantiallybydistributiontrialsacross parallelresources.
Ingeneral, wedistinguishbetweensynchronousschedulingandasyn- chronousscheduling.
Synchronousschedulingmeansthatwesampleanewbatchofhy- perparameter configurations once the previous batch finished.
If we have a stragglers - trialsthattakesmoretimetofinishthanothertrials-ourworkersneedtowaitatsynchro- nizationpoints.
Asynchronousschedulingevaluatesanewhyperparameterconfigurations 853 Multi-Fidelity Hyperparameter Optimization as soon as resources become available, and, hence, ensures that all workers are busy at anypointintime.
Whilerandomsearchiseasytodistributeasynchronouslyanddoesnot requireanychangeoftheactualalgorithm, othermethodsrequiresomeadditionalmodifi- cations.
19.3.5 Exercises 1.
Considerthe Dropout MLPmodelimplementedin Section5.6, andusedin Exercise1of Section19.2.
1.
Implementanobjectivefunctionhpo_objective_dropoutmlp_synetunetobeused with Syne Tune.
Makesurethatyourfunctionreportsthevalidationerrorafterevery epoch.
2.
Usingthesetupof Exercise1in Section19.2, comparerandomsearchto Bayesian optimization.
If you use Sage Maker, feel free to use Syne Tuneâ€™s benchmarking facilities in order to run experiments in parallel.
Hint: Bayesian optimization is providedassyne_tune.
optimizer.
baselines.
Bayesian Optimization.
3.
Forthisexercise, youneedtorunonaninstancewithatleast4CPUcores.
Forone ofthemethodsusedabove(randomsearch, Bayesianoptimization), runexperiments with n_workers=1, n_workers=2, n_workers=4, and compare results (incumbent trajectories).
At least for random search, you should observe linear scaling with respecttothenumberofworkers.
Hint: Forrobustresults, youmayhavetoaverage overseveralrepetitionseach.
2.
Advanced.
Thegoalofthisexerciseistoimplementanewschedulerin Syne Tune.
1.
Create a virtual environment containing both the d2lbook267 and syne-tune268 267 sources.
2.
Implementthe Local Searcherfrom Exercise2in Section19.2asanewsearcherin Syne Tune.
Hint: Readthistutorial269.
Alternatively, youmayfollowthisexample 268 270.
3.
Compareyournew Local Searcherwith Random Searchonthe Dropout MLPbench- mark.
269 Discussions271.
19.4 Multi-Fidelity Hyperparameter Optimization 270 Training neural networks can be expensive even on moderate size datasets.
Depending 271 ontheconfigurationspace(Section19.1.1), hyperparameteroptimizationrequirestensto hundredsoffunctionevaluationstofindawell-performinghyperparameterconfiguration.
Aswehaveseenin Section19.3, wecansignificantlyspeeduptheoverallwall-clocktimeof 854 Hyperparameter Optimization HPObyexploitingparallelresources, butthisdoesnotreducethetotalamountofcompute required.
Inthissection, wewillshowhowtheevaluationofhyperparameterconfigurationscanbe sped up.
Methods such as random search allocate the same amount of resources (e.
g., number of epochs, training data points) to each hyperparameter evaluation.
.4.1 depictslearning curvesof a set of neural networkstrained with different hyperparameter configurations.
Afterafewepochswearealreadyabletovisuallydistinguishbetweenwell- performingandsuboptimalconfigurations.
However, thelearningcurvesarenoisy, andwe mightstillrequirethefullamountof100epochstoidentifythebestperformingone.
t .4.1 Learningcurvesofrandomhyperparameterconfigurations Multi-fidelityhyperparameteroptimizationallocatesmoreresourcestopromisingconfigu- rationsandstopevaluationsofpoorlyperformingonesearly.
Thisspeedsuptheoptimiza- tionprocess, sincewecantryalargernumberofconfigurationsforthesametotalamount ofresources.
Moreformally, weexpandourdefinitionin Section19.1.1, suchthatourobjectivefunction ğ‘“â€x,ğ‘Ÿâ€ getsanadditionalinputğ‘Ÿ 2 Â»ğ‘Ÿ min ,ğ‘Ÿ ğ‘šğ‘ğ‘¥ â€¦, specifyingtheamountofresourcesthat we are willing to spend for the evaluation of configuration x.
We assume that the error ğ‘“â€x,ğ‘Ÿâ€ decreases with ğ‘Ÿ, whereas the computational cost ğ‘â€x,ğ‘Ÿâ€ increases.
Typically, ğ‘Ÿ represents the number of epochs for training the neural network, but it could also be the trainingsubsetsizeorthenumberofcross-validationfolds.
from collections import defaultdict import numpy as np from scipy import stats from d2l import torch as d2l (continuesonnextpage) 855 Multi-Fidelity Hyperparameter Optimization (continuedfrompreviouspage) d2l.
set_figsize() 19.4.1 Successive Halving Oneofthesimplestwaystoadaptrandomsearchtothemulti-fidelitysettingissuccessive halving(Jamiesonand Talwalkar,2016, Karninetal.,2013).
Thebasicideaistostartwith ğ‘configurations, forexamplerandomlysampledfromtheconfigurationspace, andtotrain eachofthemforğ‘Ÿ epochsonly.
Wethendiscardafractionoftheworstperformingtrials min andtraintheremainingonesforlonger.
Iteratingthisprocess, fewertrialsrunforlonger, untilatleastonetrialreachesğ‘Ÿ ğ‘šğ‘ğ‘¥ epochs.
Moreformally, consideraminimumbudgetğ‘Ÿ (forexample1epoch), amaximumbud- min get ğ‘Ÿ ğ‘šğ‘ğ‘¥, for example max_epochs in our previous example, and a halving constant ğœ‚ 2 Oneroundofsuccessivehalvingproceedsasfollows.
Westartwithrunning ğ‘ trialsun- til the first rungğ‘Ÿ .
Sorting the validation errors, we keep the top 1 ğœ‚ fraction (which min amountstoğœ‚ğ¾ 1 configurations)anddiscardalltherest.
Thesurvivingtrialsaretrained forthenextrung(ğ‘Ÿ ğœ‚epochs), andtheprocessisrepeated.
Ateachrung, a1 ğœ‚fractionof min trialssurvivesandtheirtrainingcontinueswithağœ‚timeslargerbudget.
Withthisparticular choiceof ğ‘, onlyasingletrialwillbetrainedtothefullbudgetğ‘Ÿ ğ‘šğ‘ğ‘¥.
Oncesucharound ofsuccessivehalvingisdone, westartthenextonewithanewsetofinitialconfigurations, iteratinguntilthetotalbudgetisspent.
t .4.2 Learningcurvesofrandomhyperparameterconfigurations.
856 Hyperparameter Optimization Wesubclassthe HPOSchedulerbaseclassfrom Section19.2inordertoimplementsucces- sivehalving, allowingforageneric HPOSearcherobjecttosampleconfigurations(which, inourexamplebelow, willbea Random Searcher).
Additionally, theuserhastopassthe minimumresourceğ‘Ÿ min , themaximumresourceğ‘Ÿ ğ‘šğ‘ğ‘¥ andğœ‚asinput.
Insideourscheduler, wemaintainaqueueofconfigurationsthatstillneedtobeevaluatedforthecurrentrungğ‘Ÿ ğ‘–.
Weupdatethequeueeverytimewejumptothenextrung.
class Successive Halving Scheduler(d2l.
HPOScheduler): #@save def __init__(self, searcher, eta, r_min, r_max, prefact=1): self.
save_hyperparameters() # Compute K, which is later used to determine the number ofâ£ â†©! configurations self.
K = int(np.
log(r_max / r_min) / np.
log(eta)) # Define the rungs self.
rung_levels = [r_min * eta ** k for k in range(self.
K + 1)] if r_max not in self.
rung_levels: # The final rung should be r_max self.
rung_levels.
append(r_max) self.
K += 1 # Bookkeeping self.
observed_error_at_rungs = defaultdict(list) self.
all_observed_error_at_rungs = defaultdict(list) # Our processing queue self.
queue = [] In the beginning our queue is empty, and we fill it with ğ‘› = prefact ğœ‚ğ¾ configurations, which are first evaluated on the smallest rung ğ‘Ÿ .
Here, prefact allows us to reuse our min codeinadifferentcontext.
Forthepurposeofthissection, wefixprefact=1.
Everytime resources become available and the HPOTuner object queries the suggest function, we returnanelementfromthequeue.
Oncewefinishoneroundofsuccessivehalving, which meansthatweevaluatedallsurvivingconfigurationsonthehighestresourcelevelğ‘Ÿ ğ‘šğ‘ğ‘¥and ourqueueisempty, westarttheentireprocessagainwithanew, randomlysampledsetof configurations.
@d2l.
add_to_class(Successive Halving Scheduler) #@save def suggest(self): if len(self.
queue) == 0: # Start a new round of successive halving # Number of configurations for the first rung: n0 = int(self.
prefact * self.
eta ** self.
K) for _ in range(n0): config = self.
searcher.
sample_configuration() config["max_epochs"] = self.
r_min # Set r = r_min self.
queue.
append(config) # Return an element from the queue return self.
queue.
pop() Whenwecollectedanewdatapoint, wefirstupdatethesearchermodule.
Afterwardswe checkifwealreadycollectalldatapointsonthecurrentrung.
Ifso, wesortallconfigura- tionsandpushthetop 1 configurationsintothequeue.
ğœ‚ 857 Multi-Fidelity Hyperparameter Optimization @d2l.
add_to_class(Successive Halving Scheduler) #@save def update(self, config: dict, error: float, info=None): ri = int(config["max_epochs"]) # Rung r_i # Update our searcher, e.
g if we use Bayesian optimization later self.
searcher.
update(config, error, additional_info=info) self.
all_observed_error_at_rungs[ri].
append((config, error)) if ri < self.
r_max: # Bookkeeping self.
observed_error_at_rungs[ri].
append((config, error)) # Determine how many configurations should be evaluated on this rung ki = self.
K - self.
rung_levels.
index(ri) ni = int(self.
prefact * self.
eta ** ki) # If we observed all configuration on this rung r_i, we estimate the # top 1 / eta configuration, add them to queue and promote them for # the next rung r_{i+1} if len(self.
observed_error_at_rungs[ri]) >= ni: kiplus1 = ki - 1 niplus1 = int(self.
prefact * self.
eta ** kiplus1) best_performing_configurations = self.
get_top_n_configurations( rung_level=ri, n=niplus1 ) riplus1 = self.
rung_levels[self.
K - kiplus1] # r_{i+1} # Queue may not be empty: insert new entries at the beginning self.
queue = [ dict(config, max_epochs=riplus1) for config in best_performing_configurations ] + self.
queue self.
observed_error_at_rungs[ri] = [] # Reset Configurationsaresortedbasedontheirobservedperformanceonthecurrentrung.
@d2l.
add_to_class(Successive Halving Scheduler) #@save def get_top_n_configurations(self, rung_level, n): rung = self.
observed_error_at_rungs[rung_level] if not rung: return [] sorted_rung = sorted(rung, key=lambda x: x[1]) return [x[0] for x in sorted_rung[: n]] Let us see how successive halving is doing on our neural network example.
We will use ğ‘Ÿ min =2,ğœ‚ =2,ğ‘Ÿ ğ‘šğ‘ğ‘¥ =10, sothatrunglevelsare2,4,8,10.
min_number_of_epochs = 2 max_number_of_epochs = 10 eta = 2 num_gpus=1 config_space = { "learning_rate": stats.
loguniform(1e-2, 1), "batch_size": stats.
randint(32, 256), } initial_config = { "learning_rate": 0.1, (continuesonnextpage) 858 Hyperparameter Optimization (continuedfrompreviouspage) "batch_size": 128, } Wejustreplacetheschedulerwithournew Successive Halving Scheduler.
searcher = d2l.
Random Searcher(config_space, initial_config=initial_config) scheduler = Successive Halving Scheduler( searcher=searcher, eta=eta, r_min=min_number_of_epochs, r_max=max_number_of_epochs, ) tuner = d2l.
HPOTuner( scheduler=scheduler, objective=d2l.
hpo_objective_lenet, ) tuner.
run(number_of_trials=30) error = 0.17762434482574463, runtime = 53.576584339141846 Wecanvisualizethelearningcurvesofallconfigurationsthatweevaluated.
Mostofthe configurationsarestoppedearlyandonlythebetterperformingconfigurationssurviveuntil ğ‘Ÿ ğ‘šğ‘ğ‘¥.
Comparethistovanillarandomsearch, whichwouldallocateğ‘Ÿ ğ‘šğ‘ğ‘¥ toeveryconfig- uration.
859 19.4 Multi-Fidelity Hyperparameter Optimization 860 Hyperparameter Optimization 861 19.4 Multi-Fidelity Hyperparameter Optimization 862 Hyperparameter Optimization 863 19.4 Multi-Fidelity Hyperparameter Optimization 864 Hyperparameter Optimization 865 19.4 Multi-Fidelity Hyperparameter Optimization 866 Hyperparameter Optimization for rung_index, rung in scheduler.
all_observed_error_at_rungs.
items(): errors = [xi[1] for xi in rung] d2l.
plt.
scatter([rung_index] * len(errors), errors) d2l.
plt.
xlim(min_number_of_epochs - 0.5, max_number_of_epochs + 0.5) d2l.
plt.
xticks( np.
arange(min_number_of_epochs, max_number_of_epochs + 1), np.
arange(min_number_of_epochs, max_number_of_epochs + 1) ) d2l.
plt.
ylabel("validation error") d2l.
plt.
xlabel("epochs") Text(0.5, 0, 'epochs') Finally, notesomeslightcomplexityinourimplementationof Successive Halving Sched- uler.
Saythataworkerisfreetorunajob, andsuggestiscalledwhenthecurrentrung hasalmostbeencompletelyfilled, butanotherworkerisstillbusywithanevaluation.
Since welackthemetricvaluefromthisworker, wecannotdeterminethetop1 ğœ‚fractiontoopen upthenextrung.
Ontheotherhand, wewanttoassignajobtoourfreeworker, soitdoes notremainidle.
Oursolutionistostartanewroundofsuccessivehalvingandassignour workertothefirsttrialthere.
However, oncearungiscompletedinupdate, wemakesure to insert new configurations at the beginning of the queue, so they take precedence over configurationsfromthenextround.
19.4.2 Summary In this section, we introduced the concept of multi-fidelity hyperparameter optimization, whereweassumetohaveaccesstocheap-to-evaluateapproximationsoftheobjectivefunc- tion, suchasvalidationerrorafteracertainnumberofepochsoftrainingasproxytoval- idationerrorafterthefullnumberofepochs.
Multi-fidelityhyperparameteroptimization allowstoreducetheoverallcomputationofthe HPOinsteadofjustreducingthewall-clock time.
Weimplementedandevaluatedsuccessivehalving, asimpleyetefficientmulti-fidelity HPO 272 algorithm.
Discussions272.
867 Asynchronous Successive Halving 19.5 Asynchronous Successive Halving Aswehaveseenin Section19.3, wecanaccelerate HPObydistributingtheevaluationof hyperparameterconfigurationsacrosseithermultipleinstancesormultiples CPUs/GPUs on a single instance.
However, compared to random search, it is not straightforward to runsuccessivehalving(SH)asynchronouslyinadistributedsetting.
Beforewecandecide whichconfigurationtorunnext, wefirsthavetocollectallobservationsatthecurrentrung level.
Thisrequirestosynchronizeworkersateachrunglevel.
Forexample, forthelowest runglevelğ‘Ÿ , wefirsthavetoevaluateallğ‘ =ğœ‚ğ¾ configurations, beforewecanpromote min the 1 ofthemtothenextrunglevel.
ğœ‚ In any distributed system, synchronization typically implies idle time for workers.
First, we often observe high variations in training time across hyperparameter configurations.
Forexample, assumingthenumberoffiltersperlayerisahyperparameter, thennetworks with less filters finish training faster than networks with more filters, which implies idle workertimeduetostragglers.
Moreover, thenumberofslotsinarunglevelisnotalwaysa multipleofthenumberofworkers, inwhichcasesomeworkersmayevensitidleforafull batch.
Figure.5.1showstheschedulingofsynchronous SHwithğœ‚ = 2forfourdifferent trials with two workers.
We start with evaluating Trial-0 and Trial-1 for one epoch and immediatelycontinuewiththenexttwotrialsoncetheyarefinished.
Wefirsthavetowait until Trial-2finishes, whichtakessubstantiallymoretimethantheothertrials, beforewe canpromotethebesttwotrials, i.
e., Trial-0and Trial-3tothenextrunglevel.
Thiscauses idle time for Worker-1.
Then, we continue with Rung 1.
Also, here Trial-3 takes longer than Trial-0, whichleadstoanadditionalidelingtimeof Worker-0.
Once, wereach Rung-2, onlythebesttrial, Trial-0, remainswhichoccupiesonlyoneworker.
Toavoidthat Worker-1 idlesduringthattime, mostimplementaitonsof SHcontinuealreadywiththenextround, andstartevaluatingnewtrials(e.
g Trial-4)onthefirstrung.
Synchronous Successive Halving Worker-0 Trial-0 Trial-2 Trial-0 Trial-0 Worker-1 Trial-1 Trial-3 Trial-3 Trial-4 t Rung 0 Rung 1 Rung 2 .5.1 Synchronoussuccessivehalvingwithtwoworkers.
Asynchronoussuccessivehalving(ASHA)(Lietal.,2018)adapts SHtotheasynchronous parallel scenario.
The main idea of ASHA is to promote configurations to the next rung levelassoonaswecollectedatleastğœ‚observationsonthecurrentrunglevel.
Thisdecision rulemayleadtosuboptimalpromotions: configurationscanbepromotedtothenextrung level, whichinhindsightdonotcomparefavourablyagainstmostothersatthesamerung 868 Hyperparameter Optimization level.
Ontheotherhand, wegetridofallsynchronizationpointsthisway.
Inpractice, such suboptimalinitialpromotionshaveonlyamodestimpactonperformance, notonlybecause therankingofhyperparameterconfigurationsisoftenfairlyconsistentacrossrunglevels, butalsobecauserungsgrowovertimeandreflectthedistributionofmetricvaluesatthis levelbetterandbetter.
Ifaworkerisfree, butnoconfigurationcanbepromoted, westarta newconfigurationwithğ‘Ÿ =ğ‘Ÿ , i.
ethefirstrunglevel.
min .5.2showstheschedulingofthesameconfigurationsfor ASHA.
Once Trial-1fin- ishes, wecollecttheresultsoftwotrials(i.
e Trial-0and Trial-1)andimmediatelypromote thebetterofthem(Trial-0)tothenextrunglevel.
After Trial-0finishesonrung1, there aretoofewtrialsthereinordertosupportafurtherpromotion.
Hence, wecontinuewith rung0andevaluate Trial-3.
Once Trial-3finishes, Trial-2isstillpending.
Atthispointwe have3trialsevaluatedonrung0andonetrialevaluatedalreadyonrung1.
Since Trial-3 performsworsethan Trial-0atrung0, andğœ‚ =2, wecannotpromoteanynewtrialyet, and Worker-1 starts Trial-4 from scratch instead.
However, once Trial-2 finishes and scores worsethan Trial-3, thelatterispromotedtowardsrung1.
Afterwards, wecollected2eval- uationsonrung1, whichmeanswecannowpromote Trial-0towardsrung2.
Atthesame time, Worker-1continueswithevaluatingnewtrials(i.
e., Trial-5)onrung0.
Asynchronous Successive Halving Promotion to Rung 2 Promotion to Rung 1 Worker-0 Trial-0 Trial-2 Trial-3 Trial-0 Worker-1 Trial-1 Trial-0 Trial-3 Trial-4 Trial-5 t Start new trial on Rung 0 Promotion to Rung 1 Start new trial on Rung 0 .5.2 Asynchronoussuccessivehalving(ASHA)withtwoworkers.
import logging from d2l import torch as d2l logging.
basic Config(level=logging.
INFO) import matplotlib.
pyplot as plt from syne_tune import Stopping Criterion, Tuner from syne_tune.
backend.
python_backend import Python Backend from syne_tune.
config_space import loguniform, randint from syne_tune.
experiments import load_experiment from syne_tune.
optimizer.
baselines import ASHA INFO: root: Sage Maker Backend is not imported since dependencies are missing.
Youâ£ â†©! can install them with pip install 'syne-tune[extra]' AWS dependencies are not imported since dependencies are missing.
You canâ£ â†©! install them with pip install 'syne-tune[aws]' or (for everything) pip install 'syne-tune[extra]' (continuesonnextpage) 869 Asynchronous Successive Halving (continuedfrompreviouspage) AWS dependencies are not imported since dependencies are missing.
You canâ£ â†©! install them with pip install 'syne-tune[aws]' or (for everything) pip install 'syne-tune[extra]' INFO: root: Ray Tune schedulers and searchers are not imported sinceâ£ â†©! dependencies are missing.
You can install them with pip install 'syne-tune[raytune]' or (for everything) pip install 'syne-tune[extra]' 19.5.1 Objective Function Wewilluse Syne Tunewiththesameobjectivefunctionasin Section19.3.
def hpo_objective_lenet_synetune(learning_rate, batch_size, max_epochs): from syne_tune import Reporter from d2l import torch as d2l model = d2l.
Le Net(lr=learning_rate, num_classes=10) trainer = d2l.
HPOTrainer(max_epochs=1, num_gpus=1) data = d2l.
Fashion MNIST(batch_size=batch_size) model.
apply_init([next(iter(data.
get_dataloader(True)))[0]], d2l.
init_cnn) report = Reporter() for epoch in range(1, max_epochs + 1): if epoch == 1: # Initialize the state of Trainer trainer.
fit(model=model, data=data) else: trainer.
fit_epoch() validation_error = trainer.
validation_error().
cpu().
detach().
numpy() report(epoch=epoch, validation_error=float(validation_error)) Wewillalsousethesameconfigurationspaceasbefore: min_number_of_epochs = 2 max_number_of_epochs = 10 eta = 2 config_space = { "learning_rate": loguniform(1e-2, 1), "batch_size": randint(32, 256), "max_epochs": max_number_of_epochs, } initial_config = { "learning_rate": 0.1, "batch_size": 128, } 19.5.2 Asynchronous Scheduler 870 Hyperparameter Optimization First, wedefinethenumberofworkersthatevaluatetrialsconcurrently.
Wealsoneedto specify how long we want to run random search, by defining an upper limit on the total wall-clocktime.
n_workers = 2 # Needs to be <= the number of available GPUs max_wallclock_time = 12 * 60 # 12 minutes Thecodeforrunning ASHAisasimplevariationofwhatwedidforasynchronousrandom search.
mode = "min" metric = "validation_error" resource_attr = "epoch" scheduler = ASHA( config_space, metric=metric, mode=mode, points_to_evaluate=[initial_config], max_resource_attr="max_epochs", resource_attr=resource_attr, grace_period=min_number_of_epochs, reduction_factor=eta, ) INFO: syne_tune.
optimizer.
schedulers.
fifo: max_resource_level = 10, as inferredâ£ â†©! from config_space INFO: syne_tune.
optimizer.
schedulers.
fifo: Master random_seed = 3140976097 Here, metricandresource_attrspecifythekeynamesusedwiththereportcallback, andmax_resource_attrdenoteswhichinputtotheobjectivefunctioncorrespondstoğ‘Ÿ .
max Moreover, grace_period providesğ‘Ÿ , and reduction_factor is ğœ‚.
We can run Syne min Tuneasbefore(thiswilltakeabout12minutes): trial_backend = Python Backend( tune_function=hpo_objective_lenet_synetune, config_space=config_space, ) stop_criterion = Stopping Criterion(max_wallclock_time=max_wallclock_time) tuner = Tuner( trial_backend=trial_backend, scheduler=scheduler, stop_criterion=stop_criterion, n_workers=n_workers, print_update_interval=int(max_wallclock_time * 0.6), ) tuner.
run() 871 Asynchronous Successive Halving INFO: syne_tune.
tuner: results of trials will be saved on /home/ci/syne-tune/ â†©! python-entrypoint-2023-08-18-20-01-52-046 INFO: root: Detected 4 GPUs INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.1 --batch_size 128 --max_epochs 10 --tune_function_rootâ£ â†©!/home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/tune_function -- â†©! tune_function_hash e03d187e043d2a17cae636d6af164015 --st_checkpoint_dir / â†©! home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/0/checkpoints INFO: syne_tune.
tuner:(trial 0) - scheduled config {'learning_rate': 0.1, â†©!'batch_size': 128, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.44639554136672527 --batch_size 196 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!1/checkpoints INFO: syne_tune.
tuner:(trial 1) - scheduled config {'learning_rate': 0.
â†©!44639554136672527, 'batch_size': 196, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.011548051321691994 --batch_size 254 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!2/checkpoints INFO: syne_tune.
tuner:(trial 2) - scheduled config {'learning_rate': 0.
â†©!011548051321691994, 'batch_size': 254, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.14942487313193167 --batch_size 132 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!3/checkpoints INFO: syne_tune.
tuner:(trial 3) - scheduled config {'learning_rate': 0.
â†©!14942487313193167, 'batch_size': 132, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 1 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.06317157191455719 --batch_size 242 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!4/checkpoints INFO: syne_tune.
tuner:(trial 4) - scheduled config {'learning_rate': 0.
â†©!06317157191455719, 'batch_size': 242, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.48801815412811467 --batch_size 41 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!5/checkpoints INFO: syne_tune.
tuner:(trial 5) - scheduled config {'learning_rate': 0.
(continuesonnextpage) 872 Hyperparameter Optimization (continuedfrompreviouspage) â†©!48801815412811467, 'batch_size': 41, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.5904067586747807 --batch_size 244 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!6/checkpoints INFO: syne_tune.
tuner:(trial 6) - scheduled config {'learning_rate': 0.
â†©!5904067586747807, 'batch_size': 244, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.08812857364095393 --batch_size 148 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!7/checkpoints INFO: syne_tune.
tuner:(trial 7) - scheduled config {'learning_rate': 0.
â†©!08812857364095393, 'batch_size': 148, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.012271314788363914 --batch_size 235 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!8/checkpoints INFO: syne_tune.
tuner:(trial 8) - scheduled config {'learning_rate': 0.
â†©!012271314788363914, 'batch_size': 235, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 5 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.08845692598296777 --batch_size 236 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!9/checkpoints INFO: syne_tune.
tuner:(trial 9) - scheduled config {'learning_rate': 0.
â†©!08845692598296777, 'batch_size': 236, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.0825770880068151 --batch_size 75 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©! tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!10/checkpoints INFO: syne_tune.
tuner:(trial 10) - scheduled config {'learning_rate': 0.
â†©!0825770880068151, 'batch_size': 75, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.20235201406823256 --batch_size 65 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!11/checkpoints INFO: syne_tune.
tuner:(trial 11) - scheduled config {'learning_rate': 0.
(continuesonnextpage) 873 Asynchronous Successive Halving (continuedfrompreviouspage) â†©!20235201406823256, 'batch_size': 65, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.3359885631737537 --batch_size 58 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©! tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!12/checkpoints INFO: syne_tune.
tuner:(trial 12) - scheduled config {'learning_rate': 0.
â†©!3359885631737537, 'batch_size': 58, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.7892434579795236 --batch_size 89 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©! tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!13/checkpoints INFO: syne_tune.
tuner:(trial 13) - scheduled config {'learning_rate': 0.
â†©!7892434579795236, 'batch_size': 89, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.1233786579597858 --batch_size 176 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!14/checkpoints INFO: syne_tune.
tuner:(trial 14) - scheduled config {'learning_rate': 0.
â†©!1233786579597858, 'batch_size': 176, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 13 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.13707981127012328 --batch_size 141 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!15/checkpoints INFO: syne_tune.
tuner:(trial 15) - scheduled config {'learning_rate': 0.
â†©!13707981127012328, 'batch_size': 141, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.02913976299993913 --batch_size 116 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!16/checkpoints INFO: syne_tune.
tuner:(trial 16) - scheduled config {'learning_rate': 0.
â†©!02913976299993913, 'batch_size': 116, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.033362897489792855 --batch_size 154 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!17/checkpoints INFO: syne_tune.
tuner:(trial 17) - scheduled config {'learning_rate': 0.
(continuesonnextpage) 874 Hyperparameter Optimization (continuedfrompreviouspage) â†©!033362897489792855, 'batch_size': 154, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.29442952580755816 --batch_size 210 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!18/checkpoints INFO: syne_tune.
tuner:(trial 18) - scheduled config {'learning_rate': 0.
â†©!29442952580755816, 'batch_size': 210, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.10214259921521483 --batch_size 239 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!19/checkpoints INFO: syne_tune.
tuner:(trial 19) - scheduled config {'learning_rate': 0.
â†©!10214259921521483, 'batch_size': 239, 'max_epochs': 10} INFO: syne_tune.
tuner: tuning status (last metric is reported) trial_id status iter learning_rate batch_size max_epochs epoch â£ â†©! validation_error worker-time 0 Stopped 4 0.100000 128 10 4.0 â£ â†©! 0.430578 29.093798 1 Completed 10 0.446396 196 10 10.0 â£ â†©! 0.205652 72.747496 2 Stopped 2 0.011548 254 10 2.0 â£ â†©! 0.900570 13.729115 3 Stopped 8 0.149425 132 10 8.0 â£ â†©! 0.259171 58.980305 4 Stopped 4 0.063172 242 10 4.0 â£ â†©! 0.900579 27.773950 5 Completed 10 0.488018 41 10 10.0 â£ â†©! 0.140488 113.171314 6 Stopped 10 0.590407 244 10 10.0 â£ â†©! 0.193776 70.364757 7 Stopped 2 0.088129 148 10 2.0 â£ â†©! 0.899955 14.169738 8 Stopped 2 0.012271 235 10 2.0 â£ â†©! 0.899840 13.434274 9 Stopped 2 0.088457 236 10 2.0 â£ â†©! 0.899801 13.034437 10 Stopped 4 0.082577 75 10 4.0 â£ â†©! 0.385970 35.426524 11 Stopped 4 0.202352 65 10 4.0 â£ â†©! 0.543102 34.653495 12 Stopped 10 0.335989 58 10 10.0 â£ â†©! 0.149558 90.924182 13 Completed 10 0.789243 89 10 10.0 â£ â†©! 0.144887 77.365970 14 Stopped 2 0.123379 176 10 2.0 â£ â†©! 0.899987 12.422906 15 Stopped 2 0.137080 141 10 2.0 â£ â†©! 0.899983 13.395153 16 Stopped 4 0.029140 116 10 4.0 â£ (continuesonnextpage) 875 Asynchronous Successive Halving (continuedfrompreviouspage) â†©! 0.900532 27.834111 17 Stopped 2 0.033363 154 10 2.0 â£ â†©! 0.899996 13.407285 18 In Progress 1 0.294430 210 10 1.0 â£ â†©! 0.899878 6.126259 19 In Progress 0 0.102143 239 10 - â£ â†©! - - 2 trials running, 18 finished (3 until the end), 437.07s wallclock-time INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.02846298236356246 --batch_size 115 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!20/checkpoints INFO: syne_tune.
tuner:(trial 20) - scheduled config {'learning_rate': 0.
â†©!02846298236356246, 'batch_size': 115, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.037703019195187606 --batch_size 91 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!21/checkpoints INFO: syne_tune.
tuner:(trial 21) - scheduled config {'learning_rate': 0.
â†©!037703019195187606, 'batch_size': 91, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.0741039859356903 --batch_size 192 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!22/checkpoints INFO: syne_tune.
tuner:(trial 22) - scheduled config {'learning_rate': 0.
â†©!0741039859356903, 'batch_size': 192, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.3032613031191755 --batch_size 252 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!23/checkpoints INFO: syne_tune.
tuner:(trial 23) - scheduled config {'learning_rate': 0.
â†©!3032613031191755, 'batch_size': 252, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.019823425532533637 --batch_size 252 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!24/checkpoints INFO: syne_tune.
tuner:(trial 24) - scheduled config {'learning_rate': 0.
â†©!019823425532533637, 'batch_size': 252, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ (continuesonnextpage) 876 Hyperparameter Optimization (continuedfrompreviouspage) â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.8203370335228594 --batch_size 77 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©! tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!25/checkpoints INFO: syne_tune.
tuner:(trial 25) - scheduled config {'learning_rate': 0.
â†©!8203370335228594, 'batch_size': 77, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.2960420911378594 --batch_size 104 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!26/checkpoints INFO: syne_tune.
tuner:(trial 26) - scheduled config {'learning_rate': 0.
â†©!2960420911378594, 'batch_size': 104, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.2993874715754653 --batch_size 192 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!27/checkpoints INFO: syne_tune.
tuner:(trial 27) - scheduled config {'learning_rate': 0.
â†©!2993874715754653, 'batch_size': 192, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.08056711961080017 --batch_size 36 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!28/checkpoints INFO: syne_tune.
tuner:(trial 28) - scheduled config {'learning_rate': 0.
â†©!08056711961080017, 'batch_size': 36, 'max_epochs': 10} INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.26868380288030347 --batch_size 151 --max_epochs 10 -- â†©! tune_function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52- â†©!046/tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!29/checkpoints INFO: syne_tune.
tuner:(trial 29) - scheduled config {'learning_rate': 0.
â†©!26868380288030347, 'batch_size': 151, 'max_epochs': 10} INFO: syne_tune.
tuner: Trial trial_id 29 completed.
INFO: root: running subprocess with command: /usr/bin/python /home/ci/.
local/lib/ â†©! python3.8/site-packages/syne_tune/backend/python_backend/python_entrypoint.
â†©! py --learning_rate 0.9197404791177789 --batch_size 66 --max_epochs 10 --tune_ â†©! function_root /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©! tune_function --tune_function_hash e03d187e043d2a17cae636d6af164015 --st_ â†©! checkpoint_dir /home/ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046/ â†©!30/checkpoints INFO: syne_tune.
tuner:(trial 30) - scheduled config {'learning_rate': 0.
â†©!9197404791177789, 'batch_size': 66, 'max_epochs': 10} INFO: syne_tune.
stopping_criterion: reaching max wallclock time (720), stoppingâ£ (continuesonnextpage) 877 Asynchronous Successive Halving (continuedfrompreviouspage) â†©! there.
INFO: syne_tune.
tuner: Stopping trials that may still be running.
INFO: syne_tune.
tuner: Tuning finished, results of trials can be found on /home/ â†©! ci/syne-tune/python-entrypoint-2023-08-18-20-01-52-046 -------------------- Resource summary (last result is reported): trial_id status iter learning_rate batch_size max_epochs epoch â£ â†©! validation_error worker-time 0 Stopped 4 0.100000 128 10 4 â£ â†©! 0.430578 29.093798 1 Completed 10 0.446396 196 10 10 â£ â†©! 0.205652 72.747496 2 Stopped 2 0.011548 254 10 2 â£ â†©! 0.900570 13.729115 3 Stopped 8 0.149425 132 10 8 â£ â†©! 0.259171 58.980305 4 Stopped 4 0.063172 242 10 4 â£ â†©! 0.900579 27.773950 5 Completed 10 0.488018 41 10 10 â£ â†©! 0.140488 113.171314 6 Stopped 10 0.590407 244 10 10 â£ â†©! 0.193776 70.364757 7 Stopped 2 0.088129 148 10 2 â£ â†©! 0.899955 14.169738 8 Stopped 2 0.012271 235 10 2 â£ â†©! 0.899840 13.434274 9 Stopped 2 0.088457 236 10 2 â£ â†©! 0.899801 13.034437 10 Stopped 4 0.082577 75 10 4 â£ â†©! 0.385970 35.426524 11 Stopped 4 0.202352 65 10 4 â£ â†©! 0.543102 34.653495 12 Stopped 10 0.335989 58 10 10 â£ â†©! 0.149558 90.924182 13 Completed 10 0.789243 89 10 10 â£ â†©! 0.144887 77.365970 14 Stopped 2 0.123379 176 10 2 â£ â†©! 0.899987 12.422906 15 Stopped 2 0.137080 141 10 2 â£ â†©! 0.899983 13.395153 16 Stopped 4 0.029140 116 10 4 â£ â†©! 0.900532 27.834111 17 Stopped 2 0.033363 154 10 2 â£ â†©! 0.899996 13.407285 18 Stopped 8 0.294430 210 10 8 â£ â†©! 0.241193 52.089688 19 Stopped 2 0.102143 239 10 2 â£ â†©! 0.900002 12.487762 20 Stopped 2 0.028463 115 10 2 â£ â†©! 0.899995 14.100359 21 Stopped 2 0.037703 91 10 2 â£ â†©! 0.900026 14.664848 22 Stopped 2 0.074104 192 10 2 â£ â†©! 0.901730 13.312770 23 Stopped 2 0.303261 252 10 2 â£ (continuesonnextpage) 878 Hyperparameter Optimization (continuedfrompreviouspage) â†©! 0.900009 12.725821 24 Stopped 2 0.019823 252 10 2 â£ â†©! 0.899917 12.533380 25 Stopped 10 0.820337 77 10 10 â£ â†©! 0.196842 81.816103 26 Stopped 10 0.296042 104 10 10 â£ â†©! 0.198453 81.121330 27 Stopped 4 0.299387 192 10 4 â£ â†©! 0.336183 24.610689 28 In Progress 9 0.080567 36 10 9 â£ â†©! 0.203052 104.303746 29 Completed 10 0.268684 151 10 10 â£ â†©! 0.222814 68.217289 30 In Progress 1 0.919740 66 10 1 â£ â†©! 0.900037 10.070776 2 trials running, 29 finished (4 until the end), 723.70s wallclock-time validation_error: best 0.1404876708984375 for trial-id 5 -------------------- Note that we are running a variant of ASHA where underperforming trials are stopped early.
Thisisdifferenttoourimplementationin Section19.4.1, whereeachtrainingjobis startedwithafixedmax_epochs.
Inthelattercase, awell-performingtrialwhichreaches thefull10epochs, firstneedstotrain1, then2, then4, then8epochs, eachtimestarting fromscratch.
Thistypeofpause-and-resumeschedulingcanbeimplementedefficientlyby checkpointingthetrainingstateaftereachepoch, butweavoidthisextracomplexityhere.
Aftertheexperimenthasfinished, wecanretrieveandplotresults.
d2l.
set_figsize() e = load_experiment(tuner.
name) e.
plot() WARNING: matplotlib.
legend: No artists with labels found to put in legend.
Noteâ£ â†©! that artists whose label start with an underscore are ignored when legend()â£ â†©! is called with no argument.
19.5.3 Visualizethe Optimization Process 879 Asynchronous Successive Halving Oncemore, wevisualizethelearningcurvesofeverytrial(eachcolorintheplotrepresents a trial).
Compare this to asynchronous random search in Section 19.3.
As we have seen forsuccessivehalvingin Section19.4, mostofthetrialsarestoppedat1or2epochs(ğ‘Ÿ min orğœ‚ ğ‘Ÿ ).
However, trialsdonotstopatthesamepoint, becausetheyrequiredifferent min amount of time per epoch.
If we ran standard successive halving instead of ASHA, we wouldneedtosynchronizeourworkers, beforewecanpromoteconfigurationstothenext runglevel.
d2l.
set_figsize([6, 2.5]) results = e.
results for trial_id in results.
trial_id.
unique(): df = results[results["trial_id"] == trial_id] d2l.
plt.
plot( df["st_tuner_time"], df["validation_error"], marker="o" ) d2l.
plt.
xlabel("wall-clock time") d2l.
plt.
ylabel("objective function") Text(0, 0.5, 'objective function') 19.5.4 Summary Compared to random search, successive halving is not quite as trivial to run in an asyn- chronousdistributedsetting.
Toavoidsynchronisationpoints, wepromoteconfigurations as quickly as possible to the next rung level, even if this means promoting some wrong ones.
In practice, this usually does not hurt much, and the gains of asynchronous versus synchronousschedulingareusuallymuchhigherthanthelossofthesuboptimaldecision making.
Discussions273.
273 20 Generative Adversarial Networks 20.1 Generative Adversarial Networks Throughout most of this book, we have talked about how to make predictions.
In some formoranother, weuseddeepneuralnetworkstolearnmappingsfromdataexamplesto labels.
Thiskindoflearningiscalleddiscriminativelearning, asin, weâ€™dliketobeable todiscriminatebetweenphotosofcatsandphotosofdogs.
Classifiersandregressorsare both examples of discriminative learning.
And neural networks trained by backpropaga- tionhaveupendedeverythingwethoughtweknewaboutdiscriminativelearningonlarge complicateddatasets.
Classificationaccuraciesonhigh-resimageshavegonefromuseless tohuman-level(withsomecaveats)injust5-6years.
Wewillspareyouanotherspielabout alltheotherdiscriminativetaskswheredeepneuralnetworksdoastoundinglywell.
Butthereismoretomachinelearningthanjustsolvingdiscriminativetasks.
Forexample, given a large dataset, without any labels, we might want to learn a model that concisely captures the characteristics of this data.
Given such a model, we could sample synthetic dataexamplesthatresemblethedistributionofthetrainingdata.
Forexample, givenalarge corpusofphotographsoffaces, wemightwanttobeabletogenerateanewphotorealistic image that looks like it might plausibly have come from the same dataset.
This kind of learningiscalledgenerativemodeling.
Untilrecently, wehadnomethodthatcouldsynthesizenovelphotorealisticimages.
Butthe success of deep neural networks for discriminative learning opened up new possibilities.
One big trend over the last three years has been the application of discriminative deep nets to overcome challenges in problems that we do not generally think of as supervised learningproblems.
Therecurrentneuralnetworklanguagemodelsareoneexampleofusing adiscriminativenetwork(trainedtopredictthenextcharacter)thatoncetrainedcanactas agenerativemodel.
In2014, abreakthroughpaperintroduced Generativeadversarialnetworks(GANs)(Good- fellowetal.,2014), aclevernewwaytoleveragethepowerofdiscriminativemodelstoget goodgenerativemodels.
Attheirheart, GANsrelyontheideathatadatageneratorisgood ifwecannottellfakedataapartfromrealdata.
Instatistics, thisiscalledatwo-sampletest weredrawnfromthesamedistribution.
Themaindifferencebetweenmoststatisticspapers 880 881 Generative Adversarial Networks and GANsisthatthelatterusethisideainaconstructiveway.
Inotherwords, ratherthan justtrainingamodeltosayâ€œhey, thesetwodatasetsdonotlookliketheycamefromthe samedistributionâ€, theyusethetwo-sampletest274 toprovidetrainingsignalstoagener- 274 ativemodel.
Thisallowsustoimprovethedatageneratoruntilitgeneratessomethingthat resemblestherealdata.
Attheveryleast, itneedstofooltheclassifierevenifourclassifier isastateoftheartdeepneuralnetwork.
t .1.1 Generative Adversarial Networks The GAN architecture is illustrated in .1.1.
As you can see, there are two pieces in GAN architecture - first off, we need a device (say, a deep network but it really could be anything, such as a game rendering engine) that might potentially be able to generate datathatlooksjustliketherealthing.
Ifwearedealingwithimages, thisneedstogenerate images.
If we are dealing with speech, it needs to generate audio sequences, and so on.
Wecallthisthegeneratornetwork.
Thesecondcomponentisthediscriminatornetwork.
It attemptstodistinguishfakeandrealdatafromeachother.
Bothnetworksareincompetition witheachother.
Thegeneratornetworkattemptstofoolthediscriminatornetwork.
Atthat point, thediscriminatornetworkadaptstothenewfakedata.
Thisinformation, inturnis usedtoimprovethegeneratornetwork, andsoon.
Thediscriminatorisabinaryclassifiertodistinguishiftheinputğ‘¥isreal(fromrealdata)or fake(fromthegenerator).
Typically, thediscriminatoroutputsascalarpredictionğ‘œ 2Rfor inputx, suchasusingafullyconnectedlayerwithhiddensize1, andthenappliessigmoid function to obtain the predicted probability ğ·â€xâ€ = 1 â€1 â€š ğ‘’ ğ‘œâ€.
Assume the label ğ‘¦ for the true data is 1 and 0 for the fake data.
We train the discriminator to minimize the cross-entropyloss, i.
e., minf ğ‘¦logğ·â€xâ€ â€1 ğ‘¦â€logâ€1 ğ·â€xâ€â€g, (20.1.1) ğ· Forthegenerator, itfirstdrawssomeparameterz2Rğ‘‘ fromasourceofrandomness, e.
g., anormaldistributionz Nâ€0,1â€.
Weoftencallzasthelatentvariable.
Itthenapplies a function to generate x0 = ğºâ€zâ€.
The goal of the generator is to fool the discriminator to classify x0 = ğºâ€zâ€ as true data, i.
e., we want ğ·â€ğºâ€zâ€â€ 1.
In other words, for a givendiscriminatorğ·, weupdatetheparametersofthegeneratorğºtomaximizethecross- entropylosswhenğ‘¦ =0, i.
e., maxf â€1 ğ‘¦â€logâ€1 ğ·â€ğºâ€zâ€â€â€g =maxf logâ€1 ğ·â€ğºâ€zâ€â€â€g.
(20.1.2) ğº ğº If the generator does a perfect job, then ğ·â€x0â€ 1, so the above loss is near 0, which 882 Generative Adversarial Networks resultsinthegradientsthataretoosmalltomakegoodprogressforthediscriminator.
So commonly, weminimizethefollowingloss: minf ğ‘¦logâ€ğ·â€ğºâ€zâ€â€â€g =minf logâ€ğ·â€ğºâ€zâ€â€â€g, (20.1.3) ğº ğº whichisjustfeedingx0 =ğºâ€zâ€intothediscriminatorbutgivinglabelğ‘¦ =1.
To sum up, ğ· and ğº are playing a â€œminimaxâ€ game with the comprehensive objective function: minmaxf ğ¸ ğ‘¥ Data logğ·â€xâ€ ğ¸ ğ‘§ Noise logâ€1 ğ·â€ğºâ€zâ€â€â€g.
(20.1.4) ğ· ğº Manyofthe GANsapplicationsareinthecontextofimages.
Asademonstrationpurpose, we are going to content ourselves with fitting a much simpler distribution first.
We will illustratewhathappensifweuse GANstobuildtheworldâ€™smostinefficientestimatorof parametersfora Gaussian.
Letâ€™sgetstarted.
%matplotlib inline import torch from torch import nn from d2l import torch as d2l 20.1.1 Generate Someâ€œRealâ€Data Sincethisisgoingtobetheworldâ€™slamestexample, wesimplygeneratedatadrawnfrom a Gaussian.
X = torch.
normal(0.0, 1, (1000, 2)) A = torch.
tensor([[1, 2], [-0.1, 0.5]]) b = torch.
tensor([1, 2]) data = torch.
matmul(X, A) + b Letâ€™sseewhatwegot.
Thisshouldbea Gaussianshiftedinsomeratherarbitrarywaywith meanğ‘andcovariancematrix ğ´ğ‘‡ğ´.
d2l.
set_figsize() â†©! numpy()); print(f'The covariance matrix is\n{torch.
matmul(A.
T, A)}') The covariance matrix is tensor([[1.0100, 1.9500], [1.9500, 4.2500]]) batch_size = 8 data_iter = d2l.
load_array((data,), batch_size) 883 Generative Adversarial Networks 20.1.2 Generator Ourgeneratornetworkwillbethesimplestnetworkpossible-asinglelayerlinearmodel.
Thisissincewewillbedrivingthatlinearnetworkwitha Gaussiandatagenerator.
Hence, itliterallyonlyneedstolearntheparameterstofakethingsperfectly.
net_G = nn.
Sequential(nn.
Linear(2, 2)) 20.1.3 Discriminator For the discriminator we will be a bit more discriminating: we will use an MLP with 3 layerstomakethingsabitmoreinteresting.
net_D = nn.
Sequential( nn.
Linear(2, 5), nn.
Tanh(), nn.
Linear(5, 3), nn.
Tanh(), nn.
Linear(3, 1)) 20.1.4 Training Firstwedefineafunctiontoupdatethediscriminator.
#@save def update_D(X, Z, net_D, net_G, loss, trainer_D): """Update discriminator.""" batch_size = X.
shape[0] ones = torch.
ones((batch_size,), device=X.
device) zeros = torch.
zeros((batch_size,), device=X.
device) trainer_D.
zero_grad() real_Y = net_D(X) fake_X = net_G(Z) # Do not need to compute gradient for `net_G`, detach it from # computing gradients.
fake_Y = net_D(fake_X.
detach()) loss_D = (loss(real_Y, ones.
reshape(real_Y.
shape)) + loss(fake_Y, zeros.
reshape(fake_Y.
shape))) / 2 loss_D.
backward() trainer_D.
step() return loss_D 884 Generative Adversarial Networks The generator is updated similarly.
Here we reuse the cross-entropy loss but change the labelofthefakedatafrom0to1.
#@save def update_G(Z, net_D, net_G, loss, trainer_G): """Update generator.""" batch_size = Z.
shape[0] ones = torch.
ones((batch_size,), device=Z.
device) trainer_G.
zero_grad() # We could reuse `fake_X` from `update_D` to save computation fake_X = net_G(Z) # Recomputing `fake_Y` is needed since `net_D` is changed fake_Y = net_D(fake_X) loss_G = loss(fake_Y, ones.
reshape(fake_Y.
shape)) loss_G.
backward() trainer_G.
step() return loss_G Both the discriminator and the generator performs a binary logistic regression with the cross-entropyloss.
Weuse Adamtosmooththetrainingprocess.
Ineachiteration, wefirst update the discriminator and then the generator.
We visualize both losses and generated examples.
def train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G, latent_dim, data): loss = nn.
BCEWith Logits Loss(reduction='sum') for w in net_D.
parameters(): nn.
init.
normal_(w, 0, 0.02) for w in net_G.
parameters(): nn.
init.
normal_(w, 0, 0.02) trainer_D = torch.
optim.
Adam(net_D.
parameters(), lr=lr_D) trainer_G = torch.
optim.
Adam(net_G.
parameters(), lr=lr_G) animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[1, num_epochs], nrows=2, figsize=(5, 5), legend=['discriminator', 'generator']) animator.
fig.
subplots_adjust(hspace=0.3) for epoch in range(num_epochs): # Train one epoch timer = d2l.
Timer() metric = d2l.
Accumulator(3) # loss_D, loss_G, num_examples for (X,) in data_iter: batch_size = X.
shape[0] Z = torch.
normal(0, 1, size=(batch_size, latent_dim)) metric.
add(update_D(X, Z, net_D, net_G, loss, trainer_D), update_G(Z, net_D, net_G, loss, trainer_G), batch_size) # Visualize generated examples Z = torch.
normal(0, 1, size=(100, latent_dim)) fake_X = net_G(Z).
detach().
numpy() animator.
axes[1].
cla() animator.
axes[1].
scatter(data[:, 0], data[:, 1]) animator.
axes[1].
scatter(fake_X[:, 0], fake_X[:, 1]) animator.
axes[1].
legend(['real', 'generated']) # Show the losses loss_D, loss_G = metric[0]/metric[2], metric[1]/metric[2] (continuesonnextpage) 885 Generative Adversarial Networks (continuedfrompreviouspage) animator.
add(epoch + 1, (loss_D, loss_G)) print(f'loss_D {loss_D:.3f}, loss_G {loss_G:.3f}, ' f'{metric[2] / timer.
stop():.1f} examples/sec') Nowwespecifythehyperparameterstofitthe Gaussiandistribution.
lr_D, lr_G, latent_dim, num_epochs = 0.05, 0.005, 2, 20 train(net_D, net_G, data_iter, num_epochs, lr_D, lr_G, latent_dim, data[:100].
detach().
numpy()) loss_D 0.693, loss_G 0.693, 1020.0 examples/sec 20.1.5 Summary Generativeadversarialnetworks(GANs)composesoftwodeepnetworks, thegenerator andthediscriminator.
Thegeneratorgeneratestheimageasmuchclosertothetrueimageaspossibletofool thediscriminator, viamaximizingthecross-entropyloss, i.
e., maxlogâ€ğ·â€x0â€â€.
The discriminator tries to distinguish the generated images from the true images, via minimizingthecross-entropyloss, i.
e., min ğ‘¦logğ·â€xâ€ â€1 ğ‘¦â€logâ€1 ğ·â€xâ€â€.
20.1.6 Exercises Doesanequilibriumexistwherethegeneratorwins, i.
e.
thediscriminatorendsupunable 275 todistinguishthetwodistributionsonfinitesamples? Discussions275.
886 Generative Adversarial Networks 20.2 Deep Convolutional Generative Adversarial Networks In Section20.1, weintroducedthebasicideasbehindhow GANswork.
Weshowedthat they can draw samples from some simple, easy-to-sample distribution, like a uniform or normaldistribution, andtransformthemintosamplesthatappeartomatchthedistribution ofsomedataset.
Andwhileourexampleofmatchinga2DGaussiandistributiongotthe pointacross, itisnotespeciallyexciting.
Inthissection, wewilldemonstratehowyoucanuse GANstogeneratephotorealisticim- ages.
Wewillbebasingourmodelsonthedeepconvolutional GANs(DCGAN)introduced in Radfordetal.
(2015).
Wewillborrowtheconvolutionalarchitecturethathaveproven sosuccessfulfordiscriminativecomputervisionproblemsandshowhowvia GANs, they canbeleveragedtogeneratephotorealisticimages.
import warnings import torch import torchvision from torch import nn from d2l import torch as d2l 20.2.1 The Pokemon Dataset Thedatasetwewilluseisacollectionof Pokemonspritesobtainedfrompokemondb276.
276 Firstdownload, extractandloadthisdataset.
#@save d2l.
DATA_HUB['pokemon'] = (d2l.
DATA_URL + 'pokemon.
zip', 'c065c0e2593b8b161a2d7873e42418bf6a21106c') data_dir = d2l.
download_extract('pokemon') pokemon = torchvision.
datasets.
Image Folder(data_dir) â†©! com/pokemon.
zip...
We resize each image into 64 64.
The To Tensor transformation will project the pixel valueintoÂ»0,1â€¦, whileourgeneratorwillusethetanhfunctiontoobtainoutputsinÂ» 1,1â€¦.
Therefore we normalize the data with 0.5 mean and 0.5 standard deviation to match the valuerange.
batch_size = 256 transformer = torchvision.
transforms.
Compose([ torchvision.
transforms.
Resize((64, 64)), (continuesonnextpage) 887 Deep Convolutional Generative Adversarial Networks (continuedfrompreviouspage) torchvision.
transforms.
To Tensor(), torchvision.
transforms.
Normalize(0.5, 0.5) ]) pokemon.
transform = transformer data_iter = torch.
utils.
data.
Data Loader( pokemon, batch_size=batch_size, shuffle=True, num_workers=d2l.
get_dataloader_workers()) Letâ€™svisualizethefirst20images.
warnings.
filterwarnings('ignore') d2l.
set_figsize((4, 4)) for X, y in data_iter: imgs = X[:20,:,:,:].
permute(0, 2, 3, 1)/2+0.5 d2l.
show_images(imgs, num_rows=4, num_cols=5) break 20.2.2 The Generator Thegeneratorneedstomapthenoisevariablez 2 Rğ‘‘ , alength-ğ‘‘ vector, toa RGBimage withwidthandheighttobe64 64.
In Section14.11weintroducedthefullyconvolutional networkthatusestransposedconvolutionlayer(referto Section14.10)toenlargeinputsize.
The basic block of the generator contains a transposed convolution layer followed by the batchnormalizationand Re LUactivation.
class G_block(nn.
Module): def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2, padding=1, **kwargs): (continuesonnextpage) 888 Generative Adversarial Networks (continuedfrompreviouspage) super(G_block, self).__init__(**kwargs) self.
conv2d_trans = nn.
Conv Transpose2d(in_channels, out_channels, kernel_size, strides, padding, bias=False) self.
batch_norm = nn.
Batch Norm2d(out_channels) self.
activation = nn.
Re LU() def forward(self, X): return self.
activation(self.
batch_norm(self.
conv2d_trans(X))) In default, the transposed convolution layer uses a ğ‘˜ â„ = ğ‘˜ ğ‘¤ = 4 kernel, a ğ‘  â„ = ğ‘  ğ‘¤ = 2 strides, andağ‘ â„ = ğ‘ ğ‘¤ =1padding.
Withainputshapeofğ‘›0 â„ ğ‘›0 ğ‘¤ =16 16, thegenerator blockwilldoubleinputâ€™swidthandheight.
ğ‘›0 â„ ğ‘›0 ğ‘¤ = Â»â€ğ‘› â„ ğ‘˜ â„ â€ğ‘› â„ 1â€â€ğ‘˜ â„ ğ‘  â„ â€ 2ğ‘ â„ â€¦ Â»â€ğ‘› ğ‘¤ ğ‘˜ ğ‘¤ â€ğ‘› ğ‘¤ 1â€â€ğ‘˜ ğ‘¤ ğ‘  ğ‘¤ â€ 2ğ‘ ğ‘¤ â€¦ = Â»â€ğ‘˜ â„ â€šğ‘  â„ â€ğ‘› â„ 1â€ 2ğ‘ â„ â€¦ Â»â€ğ‘˜ ğ‘¤ â€šğ‘  ğ‘¤ â€ğ‘› ğ‘¤ 1â€ 2ğ‘ ğ‘¤ â€¦ = Â»â€4â€š2 â€16 1â€ 2 1â€¦ Â»â€4â€š2 â€16 1â€ 2 1â€¦ =32 32.
(20.2.1) x = torch.
zeros((2, 3, 16, 16)) g_blk = G_block(20) g_blk(x).
shape torch.
Size([2, 20, 32, 32]) Ifchangingthetransposedconvolutionlayertoa4 4kernel,1 1stridesandzeropadding.
Withainputsizeof1 1, theoutputwillhaveitswidthandheightincreasedby3respec- tively.
x = torch.
zeros((2, 3, 1, 1)) g_blk = G_block(20, strides=1, padding=0) g_blk(x).
shape torch.
Size([2, 20, 4, 4]) Thegeneratorconsistsoffourbasicblocksthatincreaseinputâ€™sbothwidthandheightfrom 1to32.
Atthesametime, itfirstprojectsthelatentvariableinto64 8channels, andthen halve the channels each time.
At last, a transposed convolution layer is used to generate the output.
It further doubles the width and height to match the desired 64 64 shape, andreducesthechannelsizeto3.
Thetanhactivationfunctionisappliedtoprojectoutput valuesintotheâ€ 1,1â€range.
n_G = 64 net_G = nn.
Sequential( (continuesonnextpage) 889 Deep Convolutional Generative Adversarial Networks (continuedfrompreviouspage) G_block(in_channels=100, out_channels=n_G*8, strides=1, padding=0), # Output: (64 * 8, 4, 4) G_block(in_channels=n_G*8, out_channels=n_G*4), # Output: (64 * 4, 8, 8) G_block(in_channels=n_G*4, out_channels=n_G*2), # Output: (64 * 2, 16, 16) G_block(in_channels=n_G*2, out_channels=n_G), # Output: (64, 32, 32) nn.
Conv Transpose2d(in_channels=n_G, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False), nn.
Tanh()) # Output: (3, 64, 64) Generatea100dimensionallatentvariabletoverifythegeneratorâ€™soutputshape.
x = torch.
zeros((1, 100, 1, 1)) net_G(x).
shape torch.
Size([1, 3, 64, 64]) 20.2.3 Discriminator The discriminator is a normal convolutional network network except that it uses a leaky Re LUasitsactivationfunction.
Givenğ›¼ 2 Â»0,1â€¦, itsdefinitionis ( ğ‘¥ ifğ‘¥ >0 leaky Re LUâ€ğ‘¥â€ = .
(20.2.2) ğ›¼ğ‘¥ otherwise As it can be seen, it is normal Re LU if ğ›¼ = 0, and an identity function if ğ›¼ = 1.
For ğ›¼ 2 â€0,1â€, leaky Re LUisanonlinearfunctionthatgiveanon-zerooutputforanegative input.
Itaimstofixtheâ€œdying Re LUâ€problemthataneuronmightalwaysoutputanegative valueandthereforecannotmakeanyprogresssincethegradientof Re LUis0.
alphas = [0, .2, .4, .6, .8, 1] x = torch.
arange(-2, 1, 0.1) Y = [nn.
Leaky Re LU(alpha)(x).
detach().
numpy() for alpha in alphas] d2l.
plot(x.
detach().
numpy(), Y, 'x', 'y', alphas) Thebasicblockofthediscriminatorisaconvolutionlayerfollowedbyabatchnormalization layerandaleaky Re LUactivation.
Thehyperparametersoftheconvolutionlayeraresimilar tothetransposeconvolutionlayerinthegeneratorblock.
890 Generative Adversarial Networks class D_block(nn.
Module): def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2, padding=1, alpha=0.2, **kwargs): super(D_block, self).__init__(**kwargs) self.
conv2d = nn.
Conv2d(in_channels, out_channels, kernel_size, strides, padding, bias=False) self.
batch_norm = nn.
Batch Norm2d(out_channels) self.
activation = nn.
Leaky Re LU(alpha, inplace=True) def forward(self, X): return self.
activation(self.
batch_norm(self.
conv2d(X))) A basic block with default settings will halve the width and height of the inputs, as we demonstratedin Section7.3.
Forexample, givenainputshapeğ‘› â„ =ğ‘› ğ‘¤ =16, withakernel shape ğ‘˜ â„ = ğ‘˜ ğ‘¤ = 4, astrideshape ğ‘  â„ = ğ‘  ğ‘¤ = 2, andapaddingshape ğ‘ â„ = ğ‘ ğ‘¤ = 1, the outputshapewillbe: ğ‘›0 â„ ğ‘›0 ğ‘¤ = bâ€ğ‘› â„ ğ‘˜ â„ â€š2ğ‘ â„ â€šğ‘  â„ â€ ğ‘  â„ c bâ€ğ‘› ğ‘¤ ğ‘˜ ğ‘¤ â€š2ğ‘ ğ‘¤ â€šğ‘  ğ‘¤ â€ ğ‘  ğ‘¤ c = bâ€16 4â€š2 1â€š2â€ 2c bâ€16 4â€š2 1â€š2â€ 2c (20.2.3) =8 8.
x = torch.
zeros((2, 3, 16, 16)) d_blk = D_block(20) d_blk(x).
shape torch.
Size([2, 20, 8, 8]) Thediscriminatorisamirrorofthegenerator.
n_D = 64 net_D = nn.
Sequential( D_block(n_D), # Output: (64, 32, 32) D_block(in_channels=n_D, out_channels=n_D*2), # Output: (64 * 2, 16, 16) D_block(in_channels=n_D*2, out_channels=n_D*4), # Output: (64 * 4, 8, 8) D_block(in_channels=n_D*4, out_channels=n_D*8), # Output: (64 * 8, 4, 4) nn.
Conv2d(in_channels=n_D*8, out_channels=1, kernel_size=4, bias=False)) # Output: (1, 1, 1) Itusesaconvolutionlayerwithoutputchannel1asthelastlayertoobtainasingleprediction value.
x = torch.
zeros((1, 3, 64, 64)) net_D(x).
shape torch.
Size([1, 1, 1, 1]) 20.2.4 Training 891 Deep Convolutional Generative Adversarial Networks Comparedtothebasic GANin Section20.1, weusethesamelearningrateforbothgen- eratoranddiscriminatorsincetheyaresimilartoeachother.
Inaddition, wechange ğ›½ in 1 Adam(Section12.10)from0.9to0.5.
Itdecreasesthesmoothnessofthemomentum, the exponentiallyweightedmovingaverageofpastgradients, totakecareoftherapidchanging gradientsbecausethegeneratorandthediscriminatorfightwitheachother.
Besides, the randomgeneratednoise Z, isa4-Dtensorandweareusing GPUtoacceleratethecompu- tation.
def train(net_D, net_G, data_iter, num_epochs, lr, latent_dim, device=d2l.
try_gpu()): loss = nn.
BCEWith Logits Loss(reduction='sum') for w in net_D.
parameters(): nn.
init.
normal_(w, 0, 0.02) for w in net_G.
parameters(): nn.
init.
normal_(w, 0, 0.02) net_D, net_G = net_D.
to(device), net_G.
to(device) trainer_hp = {'lr': lr, 'betas': [0.5,0.999]} trainer_D = torch.
optim.
Adam(net_D.
parameters(), **trainer_hp) trainer_G = torch.
optim.
Adam(net_G.
parameters(), **trainer_hp) animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[1, num_epochs], nrows=2, figsize=(5, 5), legend=['discriminator', 'generator']) animator.
fig.
subplots_adjust(hspace=0.3) for epoch in range(1, num_epochs + 1): # Train one epoch timer = d2l.
Timer() metric = d2l.
Accumulator(3) # loss_D, loss_G, num_examples for X, _ in data_iter: batch_size = X.
shape[0] Z = torch.
normal(0, 1, size=(batch_size, latent_dim, 1, 1)) X, Z = X.
to(device), Z.
to(device) metric.
add(d2l.
update_D(X, Z, net_D, net_G, loss, trainer_D), d2l.
update_G(Z, net_D, net_G, loss, trainer_G), batch_size) # Show generated examples Z = torch.
normal(0, 1, size=(21, latent_dim, 1, 1), device=device) # Normalize the synthetic data to N(0, 1) fake_x = net_G(Z).
permute(0, 2, 3, 1) / 2 + 0.5 imgs = torch.
cat( [torch.
cat([ fake_x[i * 7 + j].
cpu().
detach() for j in range(7)], dim=1) for i in range(len(fake_x)//7)], dim=0) animator.
axes[1].
cla() animator.
axes[1].
imshow(imgs) # Show the losses loss_D, loss_G = metric[0] / metric[2], metric[1] / metric[2] animator.
add(epoch, (loss_D, loss_G)) print(f'loss_D {loss_D:.3f}, loss_G {loss_G:.3f}, ' f'{metric[2] / timer.
stop():.1f} examples/sec on {str(device)}') Wetrainthemodelwithasmallnumberofepochsjustfordemonstration.
Forbetterper- formance, thevariablenum_epochscanbesettoalargernumber.
892 Generative Adversarial Networks latent_dim, lr, num_epochs = 100, 0.005, 20 train(net_D, net_G, data_iter, num_epochs, lr, latent_dim) loss_D 0.023, loss_G 7.359, 2292.7 examples/sec on cuda:0 20.2.5 Summary DCGANarchitecturehasfourconvolutionallayersforthe Discriminatorandfourâ€œfractionally- stridedâ€convolutionallayersforthe Generator.
The Discriminatorisa4-layerstridedconvolutionswithbatchnormalization(exceptits inputlayer)andleaky Re LUactivations.
Leaky Re LUisanonlinearfunctionthatgiveanon-zerooutputforanegativeinput.
It aimstofixtheâ€œdying Re LUâ€problemandhelpsthegradientsfloweasierthroughthe architecture.
20.2.6 Exercises 1.
Whatwillhappenifweusestandard Re LUactivationratherthanleaky Re LU? 2.
Apply DCGANon Fashion-MNISTandseewhichcategoryworkswellandwhichdoes not.
Discussions277.
277 21 Recommender Systems Shuai Zhang(Amazon), Aston Zhang(Amazon), and Yi Tay(Google) Recommender systems are widely employed in industry and are ubiquitous in our daily lives.
Thesesystemsareutilizedinanumberofareassuchasonlineshoppingsites(e.
g., amazon.
com), music/movie services site (e.
g., Netflix and Spotify), mobile application stores(e.
g., IOSappstoreandgoogleplay), onlineadvertising, justtonameafew.
The major goal of recommender systems is to help users discover relevant items such as moviestowatch, texttoreadorproductstobuy, soastocreateadelightfuluserexperience.
Moreover, recommendersystemsareamongthemostpowerfulmachinelearningsystems thatonlineretailersimplementinordertodriveincrementalrevenue.
Recommendersys- temsarereplacementsofsearchenginesbyreducingtheeffortsinproactivesearchesand surprisinguserswithofferstheyneversearchedfor.
Manycompaniesmanagedtoposition themselves ahead of their competitors with the help of more effective recommender sys- tems.
As such, recommender systems are central to not only our everyday lives but also highlyindispensableinsomeindustries.
Inthischapter, wewillcoverthefundamentalsandadvancementsofrecommendersystems, alongwithexploringsomecommonfundamentaltechniquesforbuildingrecommendersys- temswithdifferentdatasourcesavailableandtheirimplementations.
Specifically, youwill learnhowtopredicttheratingausermightgivetoaprospectiveitem, howtogeneratea recommendationlistofitemsandhowtopredicttheclick-throughratefromabundantfea- tures.
Thesetasksarecommonplaceinreal-worldapplications.
Bystudyingthischapter, youwillgethands-onexperiencepertainingtosolvingrealworldrecommendationprob- lemswithnotonlyclassicalmethodsbutthemoreadvanceddeeplearningbasedmodels aswell.
21.1 Overview of Recommender Systems Inthelastdecade, the Internethasevolvedintoaplatformforlarge-scaleonlineservices, whichprofoundlychangedthewaywecommunicate, readnews, buyproducts, andwatch movies.
Inthemeanwhile, theunprecedentednumberofitems(weusethetermitemtorefer tomovies, news, books, and products.) offeredonline requiresasystemthatcan helpus discoveritemsthatwepreferred.
Recommendersystemsarethereforepowerfulinformation 893 894 Recommender Systems filtering tools that can facilitate personalized services and provide tailored experience to individualusers.
Inshort, recommendersystemsplayapivotalroleinutilizingthewealth of data available to make choices manageable.
Nowadays, recommender systems are at thecoreofanumberofonlineservicesproviderssuchas Amazon, Netflix, and You Tube.
Recalltheexampleof Deeplearningbooksrecommendedby Amazonin.3.3.
The benefitsofemployingrecommendersystemsaretwo-folds: Ontheonehand, itcanlargely reduce usersâ€™ effort in finding items and alleviate the issue of information overload.
On the other hand, it can add business value to online service providers and is an important source of revenue.
This chapter will introduce the fundamental concepts, classic models andrecentadvanceswithdeeplearninginthefieldofrecommendersystems, togetherwith implementedexamples.
t .1.1 Illustrationofthe Recommendation Process 21.1.1 Collaborative Filtering Westartthejourneywiththeimportantconceptinrecommendersystemsâ€”collaborative filtering (CF), which was first coined by the Tapestry system (Goldberg et al., 1992), re- ferringtoâ€œpeoplecollaboratetohelponeanotherperformthefilteringprocessinorderto handlethelargeamountsofemailandmessagespostedtonewsgroupsâ€.
Thistermhasbeen enrichedwithmoresenses.
Inabroadsense, itistheprocessoffilteringforinformationor patternsusingtechniquesinvolvingcollaborationamongmultipleusers, agents, anddata sources.
CFhasmanyformsandnumerous CFmethodsproposedsinceitsadvent.
Overall, CFtechniquescanbecategorizedinto: memory-based CF, model-based CF, and their hybrid (Su and Khoshgoftaar, 2009).
Representative memory-based CF techniques are nearest neighbor-based CF such as user-based CF and item-based CF (Sarwar et al., 2001).
Latentfactormodelssuchasmatrixfactorizationareexamplesofmodel-based CF.
Memory-based CFhaslimitationsindealingwithsparseandlarge-scaledatasinceitcom- putesthesimilarityvaluesbasedoncommonitems.
Model-basedmethodsbecomemore popular with its better capability in dealing with sparsity and scalability.
Many model- based CFapproachescanbeextendedwithneuralnetworks, leadingtomoreflexibleand scalablemodelswiththecomputationaccelerationindeeplearning(Zhangetal., 2019).
In general, CF only uses the user-item interaction data to make predictions and recom- mendations.
Besides CF, content-basedandcontext-basedrecommendersystemsarealso usefulinincorporatingthecontentdescriptionsofitems/usersandcontextualsignalssuch 895 Overviewof Recommender Systems astimestampsandlocations.
Obviously, wemayneedtoadjustthemodeltypes/structures whendifferentinputdataisavailable.
21.1.2 Explicit Feedbackand Implicit Feedback Tolearnthepreferenceofusers, thesystemshallcollectfeedbackfromthem.
Thefeedback can be either explicit or implicit (Hu et al., 2008).
For example, IMDb278 collects star 278 ratings ranging from one to ten stars for movies.
You Tube provides the thumbs-up and thumbs-down buttons for users to show their preferences.
It is apparent that gathering explicitfeedbackrequiresuserstoindicatetheirinterestsproactively.
Nonetheless, explicit feedbackisnotalwaysreadilyavailableasmanyusersmaybereluctanttorateproducts.
Relativelyspeaking, implicitfeedbackisoftenreadilyavailablesinceitismainlyconcerned withmodelingimplicitbehaviorsuchasuserclicks.
Assuch, manyrecommendersystems arecenteredonimplicitfeedbackwhichindirectlyreflectsuserâ€™sopinionthroughobserving user behavior.
There are diverse forms of implicit feedback including purchase history, browsinghistory, watchesandevenmousemovements.
Forexample, auserthatpurchased manybooksbythesameauthorprobablylikesthatauthor.
Notethatimplicitfeedbackis inherentlynoisy.
Wecanonlyguesstheirpreferencesandtruemotives.
Auserwatcheda moviedoesnotnecessarilyindicateapositiveviewofthatmovie.
21.1.3 Recommendation Tasks A number of recommendation tasks have been investigated in the past decades.
Based onthedomainofapplications, therearemoviesrecommendation, newsrecommendations, point-of-interestrecommendation(Yeetal.,2011)andsoforth.
Itisalsopossibletodif- ferentiatethetasksbasedonthetypesoffeedbackandinputdata, forexample, therating predictiontaskaimstopredicttheexplicitratings.
Top-ğ‘›recommendation(itemranking) ranksallitemsforeachuserpersonallybasedontheimplicitfeedback.
Iftime-stampinfor- mationisalsoincluded, wecanbuild sequence-awarerecommendation(Quadrana etal., 2018).
Anotherpopulartaskiscalledclick-throughrateprediction, whichisalsobasedon implicitfeedback, butvariouscategoricalfeaturescanbeutilized.
Recommendingfornew usersandrecommendingnewitemstoexistingusersarecalledcold-startrecommendation (Scheinetal.,2002).
21.1.4 Summary Recommendersystemsareimportantforindividualusersandindustries.
Collaborative filteringisakeyconceptinrecommendation.
Therearetwotypesoffeedbacks: implicitfeedbackandexplicitfeedback.
Anumberof recommendationtaskshavebeenexploredduringthelastdecade.
21.1.5 Exercises 1.
Canyouexplainhowrecommendersystemsinfluenceyourdailylife? 2.
Whatinterestingrecommendationtasksdoyouthinkcanbeinvestigated? 896 Recommender Systems Discussions279.
279 Mathematics for Deep A Learning Brent Werness(Amazon), Rachel Hu(Amazon), andauthorsofthisbook One of the wonderful parts of modern deep learning is the fact that much of it can be understood and used without a full understanding of the mathematics below it.
This is a signthatthefieldismaturing.
Justasmostsoftwaredevelopersnolongerneedtoworry aboutthetheoryofcomputablefunctions, neithershoulddeeplearningpractitionersneed toworryaboutthetheoreticalfoundationsofmaximumlikelihoodlearning.
But, wearenotquitethereyet.
In practice, you will sometimes need to understand how architectural choices influence gradientflow, ortheimplicitassumptionsyoumakebytrainingwithacertainlossfunction.
You might need to know what in the world entropy measures, and how it can help you understandexactlywhatbits-per-charactermeansinyourmodel.
Theseallrequiredeeper mathematicalunderstanding.
Thisappendixaimstoprovideyouthemathematicalbackgroundyouneedtounderstand the core theory of modern deep learning, but it is not exhaustive.
We will begin with examininglinearalgebraingreaterdepth.
Wedevelopageometricunderstandingofallthe commonlinearalgebraicobjectsandoperationsthatwillenableustovisualizetheeffects ofvarioustransformationsonourdata.
Akeyelementisthedevelopmentofthebasicsof eigen-decompositions.
Wenextdevelopthetheoryofdifferentialcalculustothepointthatwecanfullyunderstand whythegradientisthedirectionofsteepestdescent, andwhyback-propagationtakesthe formitdoes.
Integralcalculusisthendiscussedtothedegreeneededtosupportournext topic, probabilitytheory.
Problemsencounteredinpracticefrequentlyarenotcertain, andthusweneedalanguageto speakaboutuncertainthings.
Wereviewthetheoryofrandomvariablesandthemostcom- monlyencountereddistributionssowemaydiscussmodelsprobabilistically.
Thisprovides thefoundationforthenaive Bayesclassifier, aprobabilisticclassificationtechnique.
Closely related to probability theory is the study of statistics.
While statistics is far too largeafieldtodojusticeinashortsection, wewillintroducefundamentalconceptsthatall machinelearningpractitionersshouldbeawareof, inparticular: evaluatingandcomparing estimators, conductinghypothesistests, andconstructingconfidenceintervals.
Last, weturntothetopicofinformationtheory, whichisthemathematicalstudyofinfor- 897 898 Mathematicsfor Deep Learning mationstorageandtransmission.
Thisprovidesthecorelanguagebywhichwemaydiscuss quantitativelyhowmuchinformationamodelholdsonadomainofdiscourse.
Takentogether, theseformthecoreofthemathematicalconceptsneededtobegindownthe pathtowardsadeepunderstandingofdeeplearning.
A.1 Geometry and Linear Algebraic Operations In Section2.3, weencounteredthebasicsoflinearalgebraandsawhowitcouldbeused toexpresscommonoperationsfortransformingourdata.
Linearalgebraisoneofthekey mathematicalpillarsunderlyingmuchoftheworkthatwedoindeeplearningandinma- chinelearningmorebroadly.
While Section2.3containedenoughmachinerytocommu- nicate the mechanics of modern deep learning models, there is a lot more to the subject.
In this section, we will go deeper, highlighting some geometric interpretations of linear algebraoperations, andintroducingafewfundamentalconcepts, includingofeigenvalues andeigenvectors.
A.1.1 Geometryof Vectors First, we need to discuss the two common geometric interpretations of vectors, as either points or directions in space.
Fundamentally, a vector is a list of numbers such as the Pythonlistbelow.
v = [1, 7, 0, 1] Mathematiciansmostoftenwritethisaseitheracolumnorrowvector, whichistosayeither as 2 3 617 6 7 x= 6 6 77 7 , (A.1) 607 6 7 415 or x > = 1 7 0 1 .
(A.2) These often have different interpretations, where data examples are column vectors and weightsusedtoformweightedsumsarerowvectors.
However, itcanbebeneficialtobe flexible.
Aswehavedescribedin Section2.3, thoughasinglevectorâ€™sdefaultorientationis acolumnvector, foranymatrixrepresentingatabulardataset, treatingeachdataexample asarowvectorinthematrixismoreconventional.
Givenavector, thefirstinterpretationthatweshouldgiveitisasapointinspace.
Intwo orthreedimensions, wecanvisualizethesepointsbyusingthecomponentsofthevectors 899 Geometryand Linear Algebraic Operations todefinethelocationofthepointsinspacecomparedtoafixedreferencecalledtheorigin.
Thiscanbeseenin Fig.
A.1.
t Fig.
A.1 Anillustrationofvisualizingvectorsaspointsintheplane.
Thefirstcomponentofthe vectorgivesthex-coordinate, thesecondcomponentgivesthey-coordinate.
Higher dimensionsareanalogous, althoughmuchhardertovisualize.
Thisgeometricpointofviewallowsustoconsidertheproblemonamoreabstractlevel.
No longerfacedwithsomeinsurmountableseemingproblemlikeclassifyingpicturesaseither catsordogs, wecanstartconsideringtasksabstractlyascollectionsofpointsinspaceand picturingthetaskasdiscoveringhowtoseparatetwodistinctclustersofpoints.
Inparallel, thereisasecondpointofviewthatpeopleoftentakeofvectors: asdirections inspace.
Notonlycanwethinkofthevectorv= Â»3,2â€¦> asthelocation3unitstotheright and2unitsupfromtheorigin, wecanalsothinkofitasthedirectionitselftotake3steps totherightand2stepsup.
Inthisway, weconsiderallthevectorsinfigure Fig.
A.2the same.
t Fig.
A.2 Anyvectorcanbevisualizedasanarrowintheplane.
Inthiscase, everyvectordrawnisa representationofthevectorâ€3,2â€> .
Oneofthebenefitsofthisshiftisthatwecanmakevisualsenseoftheactofvectoraddition.
Inparticular, wefollowthedirectionsgivenbyonevector, andthenfollowthedirections givenbytheother, asisseenin Fig.
A.3.
Vectorsubtractionhas asimilar interpretation.
Byconsidering theidentity that u = vâ€š â€u vâ€, weseethatthevectoru visthedirectionthattakesusfromthepointvtothe pointu.
A.1.2 Dot Productsand Angles 900 Mathematicsfor Deep Learning t Fig.
A.3 Wecanvisualizevectoradditionbyfirstfollowingonevector, andthenanother.
Aswesawin Section2.3, ifwetaketwocolumnvectorsuandv, wecanformtheirdot productbycomputing: u > v= ğ‘¢ ğ‘– ğ‘£ ğ‘– .
(A.3) ğ‘– Because (A.3) is symmetric, we will mirror the notation of classical multiplication and write u v=u > v=v > u, (A.4) tohighlightthefactthatexchangingtheorderofthevectorswillyieldthesameanswer.
The dot product (A.3) also admits a geometric interpretation: it is closely related to the anglebetweentwovectors.
Considertheangleshownin Fig.
A.4.
t Fig.
A.4 Betweenanytwovectorsintheplanethereisawelldefinedangleğœƒ.
Wewillseethis angleisintimatelytiedtothedotproduct.
Tostart, letâ€™sconsidertwospecificvectors: v= â€ğ‘Ÿ,0â€ andw= â€ğ‘ cosâ€ğœƒâ€,ğ‘ sinâ€ğœƒâ€â€.
(A.5) The vector v is length ğ‘Ÿ and runs parallel to the ğ‘¥-axis, and the vector w is of length ğ‘  andatangleğœƒ withtheğ‘¥-axis.
Ifwecomputethedotproductofthesetwovectors, wesee that v w=ğ‘Ÿğ‘ cosâ€ğœƒâ€ = kvkkwkcosâ€ğœƒâ€.
(A.6) Withsomesimplealgebraicmanipulation, wecanrearrangetermstoobtain v w ğœƒ =arccos .
(A.7) kvkkwk 901 Geometryand Linear Algebraic Operations In short, for these two specific vectors, the dot product combined with the norms tell us the angle between the two vectors.
This same fact is true in general.
We will not derive the expression here, however, if we consider writing kv wk2 in two ways: one with the dot product, and the other geometrically using the law of cosines, we can obtain the fullrelationship.
Indeed, foranytwovectorsvandw, theanglebetweenthetwovectors is v w ğœƒ =arccos .
(A.8) kvkkwk Thisisaniceresultsincenothinginthecomputationreferencestwo-dimensions.
Indeed, wecanusethisinthreeorthreemilliondimensionswithoutissue.
Asasimpleexample, letâ€™sseehowtocomputetheanglebetweenapairofvectors: %matplotlib inline import torch import torchvision from IPython import display from torchvision import transforms from d2l import torch as d2l def angle(v, w): return torch.
acos(v.
dot(w) / (torch.
norm(v) * torch.
norm(w))) angle(torch.
tensor([0, 1, 2], dtype=torch.
float32), torch.
tensor([2.0, 3, 4])) tensor(0.4190) Wewillnotuseitrightnow, butitisusefultoknowthatwewillrefertovectorsforwhich the angle is ğœ‹ 2 (or equivalently 90 ) as being orthogonal.
By examining the equation above, weseethatthishappenswhenğœƒ =ğœ‹ 2, whichisthesamethingascosâ€ğœƒâ€ =0.
The onlywaythiscanhappenisifthedotproductitselfiszero, andtwovectorsareorthogonal ifandonlyifv w=0.
Thiswillprovetobeahelpfulformulawhenunderstandingobjects geometrically.
Itisreasonabletoask: whyiscomputingtheangleuseful? Theanswercomesinthekind of invariance we expect data to have.
Consider an image, and a duplicate image, where everypixelvalueisthesamebut10%thebrightness.
Thevaluesoftheindividualpixels are in general far from the original values.
Thus, if one computed the distance between the original image and the darker one, the distance can be large.
However, for most ML applications, thecontentisthesameâ€”itisstillanimageofacatasfarasacat/dogclassifier isconcerned.
However, ifweconsidertheangle, itisnothardtoseethatforanyvectorv, theanglebetweenv and0.1 v iszero.
Thiscorrespondstothefactthatscalingvectors keepsthesamedirectionandjustchangesthelength.
Theangleconsidersthedarkerimage identical.
Examples like this are everywhere.
In text, we might want the topic being discussed to not change if we write twice as long of document that says the same thing.
For some 902 Mathematicsfor Deep Learning encoding(suchascountingthenumberofoccurrencesofwordsinsomevocabulary), this corresponds to a doubling of the vector encoding the document, so again wecan use the angle.
Cosine Similarity In MLcontextswheretheangleisemployedtomeasuretheclosenessoftwovectors, prac- titionersadoptthetermcosinesimilaritytorefertotheportion v w cosâ€ğœƒâ€ = .
(A.9) kvkkwk Thecosinetakesamaximumvalueof1whenthetwovectorspointinthesamedirection, aminimumvalueof 1whentheypointinoppositedirections, andavalueof0whenthe twovectorsareorthogonal.
Notethatifthecomponentsofhigh-dimensionalvectorsare sampledrandomlywithmean0, theircosinewillnearlyalwaysbecloseto0.
A.1.3 Hyperplanes Inadditiontoworkingwithvectors, anotherkeyobjectthatyoumustunderstandtogofar inlinearalgebraisthehyperplane, ageneralizationtohigherdimensionsofaline(twodi- mensions)orofaplane(threedimensions).
Inanğ‘‘-dimensionalvectorspace, ahyperplane hasğ‘‘ 1dimensionsanddividesthespaceintotwohalf-spaces.
Letâ€™sstartwithanexample.
Supposethatwehaveacolumnvectorw = Â»2,1â€¦> .
Wewant toknow,â€œwhatarethepointsvwithw v=1?â€ Byrecallingtheconnectionbetweendot productsandanglesabove(A.8), wecanseethatthisisequivalentto 1 1 kvkkwkcosâ€ğœƒâ€ =1 () kvkcosâ€ğœƒâ€ = = p .
(A.10) kwk 5 t Fig.
A.5 Recallingtrigonometry, weseetheformulakvkcosâ€ğœƒâ€isthelengthoftheprojectionof thevectorvontothedirectionofw Ifweconsiderthegeometricmeaningofthisexpression, weseethatthisisequivalentto sayingthatthelengthoftheprojectionofv ontothedirectionofw isexactly1 kwk, as isshownin Fig.
A.5.
Thesetofallpointswherethisistrueisalineatrightanglestothe vectorw.
Ifwewanted, wecouldfindtheequationforthislineandseethatitis2ğ‘¥â€šğ‘¦ =1 orequivalentlyğ‘¦ =1 2ğ‘¥.
903 Geometryand Linear Algebraic Operations If we now look at what happens when we ask about the set of points with w v > 1 or w v < 1, wecanseethatthesearecaseswheretheprojectionsarelongerorshorterthan 1 kwk, respectively.
Thus, thosetwoinequalitiesdefineeithersideoftheline.
Inthisway, wehavefoundawaytocutourspaceintotwohalves, whereallthepointsononesidehave dotproductbelowathreshold, andtheothersideaboveasweseein Fig.
A.6.
t Fig.
A.6 Ifwenowconsidertheinequalityversionoftheexpression, weseethatourhyperplane(in thiscase: justaline)separatesthespaceintotwohalves.
Thestoryinhigherdimensionismuchthesame.
Ifwenowtakew = Â»1,2,3â€¦> andask aboutthepointsinthreedimensionswithw v=1, weobtainaplaneatrightanglestothe givenvectorw.
Thetwoinequalitiesagaindefinethetwosidesoftheplaneasisshownin Fig.
A.7.
t Fig.
A.7 Hyperplanesinanydimensionseparatethespaceintotwohalves.
While our ability to visualize runs out at this point, nothing stops us from doing this in tens, hundreds, orbillionsofdimensions.
Thisoccursoftenwhenthinkingaboutmachine learned models.
For instance, we can understand linear classification models like those from Section4.1, asmethodstofindhyperplanesthatseparatethedifferenttargetclasses.
Inthiscontext, suchhyperplanesareoftenreferredtoasdecisionplanes.
Themajorityof deep learned classification models end with a linear layer fed into a softmax, so one can interprettheroleofthedeepneuralnetworktobetofindanon-linearembeddingsuchthat thetargetclassescanbeseparatedcleanlybyhyperplanes.
To give a hand-built example, notice that we can produce a reasonable model to classify tinyimagesoft-shirtsandtrousersfromthe Fashion-MNISTdataset(seenin Section4.2) by just taking the vector between their means to define the decision plane and eyeball a crudethreshold.
Firstwewillloadthedataandcomputetheaverages.
# Load in the dataset trans = [] (continuesonnextpage) 904 Mathematicsfor Deep Learning (continuedfrompreviouspage) trans.
append(transforms.
To Tensor()) trans = transforms.
Compose(trans) train = torchvision.
datasets.
Fashion MNIST(root="../data", transform=trans, train=True, download=True) test = torchvision.
datasets.
Fashion MNIST(root="../data", transform=trans, train=False, download=True) X_train_0 = torch.
stack( [x[0] * 256 for x in train if x[1] == 0]).
type(torch.
float32) X_train_1 = torch.
stack( [x[0] * 256 for x in train if x[1] == 1]).
type(torch.
float32) X_test = torch.
stack( [x[0] * 256 for x in test if x[1] == 0 or x[1] == 1]).
type(torch.
float32) y_test = torch.
stack([torch.
tensor(x[1]) for x in test if x[1] == 0 or x[1] == 1]).
type(torch.
float32) # Compute averages ave_0 = torch.
mean(X_train_0, axis=0) ave_1 = torch.
mean(X_train_1, axis=0) Itcanbeinformativetoexaminetheseaveragesindetail, soletâ€™splotwhattheylooklike.
Inthiscase, weseethattheaverageindeedresemblesablurryimageofat-shirt.
# Plot average t-shirt d2l.
set_figsize() d2l.
plt.
imshow(ave_0.
reshape(28, 28).
tolist(), cmap='Greys') d2l.
plt.
show() Inthesecondcase, weagainseethattheaverageresemblesablurryimageoftrousers.
# Plot average trousers d2l.
plt.
imshow(ave_1.
reshape(28, 28).
tolist(), cmap='Greys') d2l.
plt.
show() Inafullymachinelearnedsolution, wewouldlearnthethresholdfromthedataset.
Inthis case, Isimplyeyeballedathresholdthatlookedgoodonthetrainingdatabyhand.
# Print test set accuracy with eyeballed threshold w = (ave_1 - ave_0).
T (continuesonnextpage) 905 Geometryand Linear Algebraic Operations (continuedfrompreviouspage) # '@' is Matrix Multiplication operator in pytorch.
predictions = X_test.
reshape(2000, -1) @ (w.
flatten()) > -1500000 # Accuracy â†©! float64) tensor(0.7870, dtype=torch.
float64) A.1.4 Geometryof Linear Transformations Through Section2.3andtheabovediscussions, wehaveasolidunderstandingofthegeom- etryofvectors, lengths, andangles.
However, thereisoneimportantobjectwehaveomitted discussing, andthatisageometricunderstandingoflineartransformationsrepresentedby matrices.
Fullyinternalizingwhatmatricescandototransformdatabetweentwopoten- tiallydifferenthighdimensionalspacestakessignificantpractice, andisbeyondthescope ofthisappendix.
However, wecanstartbuildingupintuitionintwodimensions.
Supposethatwehavesomematrix: ğ‘ ğ‘ A= .
(A.11) ğ‘ ğ‘‘ Ifwewanttoapplythistoanarbitraryvectorv= Â»ğ‘¥,ğ‘¦â€¦> , wemultiplyandseethat ğ‘ ğ‘ ğ‘¥ Av= ğ‘ ğ‘‘ ğ‘¦ ğ‘ğ‘¥â€šğ‘ğ‘¦ = ğ‘ğ‘¥â€šğ‘‘ğ‘¦ (A.12) ğ‘ ğ‘ =ğ‘¥ â€šğ‘¦ ğ‘ ğ‘‘ 1 0 =ğ‘¥ A â€šğ‘¦ A .
0 1 Thismayseemlikeanoddcomputation, wheresomethingclearbecamesomewhatimpen- etrable.
However, ittellsusthatwecanwritethewaythatamatrixtransformsanyvector 906 Mathematicsfor Deep Learning intermsofhowittransformstwospecificvectors: Â»1,0â€¦> and Â»0,1â€¦> .
Thisisworthcon- sideringforamoment.
Wehaveessentiallyreducedaninfiniteproblem(whathappensto any pair of real numbers) to a finite one (what happens to these specific vectors).
These vectorsareanexampleabasis, wherewecanwriteanyvectorinourspaceasaweighted sumofthesebasisvectors.
Letâ€™sdrawwhathappenswhenweusethespecificmatrix 1 2 A= .
(A.13) 1 3 Ifwelookatthespecificvectorv = Â»2, 1â€¦> , weseethisis2 Â»1,0â€¦>â€š 1 Â»0,1â€¦> , and thusweknowthatthematrixğ´willsendthisto2â€AÂ»1,0â€¦>â€â€š 1â€AÂ»0,1â€¦â€> =2Â»1, 1â€¦> Â»2,3â€¦> = Â»0, 5â€¦> .
Ifwefollowthislogicthroughcarefully, saybyconsideringthegrid of all integer pairs of points, we see that what happens is that the matrix multiplication canskew, rotate, andscalethegrid, butthegridstructuremustremainasyouseein Fig.
A.8.
t Fig.
A.8 Thematrix Aactingonthegivenbasisvectors.
Noticehowtheentiregridistransported alongwithit.
This is the most important intuitive point to internalize about linear transformations rep- resentedbymatrices.
Matricesareincapableofdistortingsomepartsofspacedifferently thanothers.
Alltheycandoistaketheoriginalcoordinatesonourspaceandskew, rotate, andscalethem.
Somedistortionscanbesevere.
Forinstancethematrix 2 1 B= , (A.14) 4 2 compressestheentiretwo-dimensionalplanedowntoasingleline.
Identifyingandworking with such transformations are the topic of a later section, but geometrically we can see that this is fundamentally different from the types of transformations we saw above.
For instance, theresultfrommatrix Acanbeâ€œbentbackâ€totheoriginalgrid.
Theresultsfrom matrix Bcannotbecausewewillneverknowwherethevector Â»1,2â€¦> camefromâ€”wasit Â»1,1â€¦> or Â»0, 1â€¦> ? Whilethispicturewasfora2 2matrix, nothingpreventsusfromtakingthelessonslearned intohigherdimensions.
IfwetakesimilarbasisvectorslikeÂ»1,0,...,0â€¦andseewhereour matrixsendsthem, wecanstarttogetafeelingforhowthematrixmultiplicationdistorts theentirespaceinwhateverdimensionspacewearedealingwith.
907 Geometryand Linear Algebraic Operations A.1.5 Linear Dependence Consideragainthematrix 2 1 B= .
(A.15) 4 2 Thiscompressestheentireplanedowntoliveonthesinglelineğ‘¦ =2ğ‘¥.
Thequestionnow arises: istheresomewaywecandetectthisjustlookingatthematrixitself? Theansweris thatindeedwecan.
Letâ€™stakeb = Â»2,4â€¦> andb = Â» 1, 2â€¦> bethetwocolumnsof B.
1 2 Rememberthatwecanwriteeverythingtransformedbythematrix Basaweightedsumof thecolumnsofthematrix: likeğ‘ b â€šğ‘ b .
Wecallthisalinearcombination.
Thefact 1 1 2 2 thatb = 2 b meansthatwecanwriteanylinearcombinationofthosetwocolumns 1 2 entirelyintermsofsayb since 2 ğ‘ b â€šğ‘ b = 2ğ‘ b â€šğ‘ b = â€ğ‘ 2ğ‘ â€b .
(A.16) 1 1 2 2 1 2 2 2 2 1 2 Thismeansthatoneofthecolumnsis, inasense, redundantbecauseitdoesnotdefinea uniquedirectioninspace.
Thisshouldnotsurpriseustoomuchsincewealreadysawthat this matrix collapses the entire plane down into a single line.
Moreover, we see that the lineardependenceb = 2 b capturesthis.
Tomakethismoresymmetricalbetweenthe 1 2 twovectors, wewillwritethisas b â€š2 b =0.
(A.17) 1 2 Ingeneral, wewillsaythatacollectionofvectorsv 1 ,..., vğ‘˜arelinearlydependentifthere existcoefficientsğ‘ 1 ,...,ğ‘ ğ‘˜ notallequaltozerosothat ğ‘˜ ğ‘ ğ‘–v i =0.
(A.18) ğ‘–=1 Inthiscase, wecansolveforoneofthevectorsintermsofsomecombinationoftheothers, andeffectivelyrenderitredundant.
Thus, alineardependenceinthecolumnsofamatrix is a witness to the fact that our matrix is compressing the space down to some lower di- mension.
Ifthereisnolineardependencewesaythevectorsarelinearlyindependent.
If thecolumnsofamatrixarelinearlyindependent, nocompressionoccursandtheoperation canbeundone.
A.1.6 Rank Ifwehaveageneralğ‘› ğ‘šmatrix, itisreasonabletoaskwhatdimensionspacethematrix mapsinto.
Aconceptknownastherank willbeouranswer.
Intheprevioussection, we notedthatalineardependencebearswitnesstocompressionofspaceintoalowerdimension and so we will be able to use this to define the notion of rank.
In particular, the rank of amatrix Aisthelargestnumberoflinearlyindependentcolumnsamongstallsubsetsof columns.
Forexample, thematrix 2 4 B= , (A.19) 1 2 908 Mathematicsfor Deep Learning hasrankâ€ğµâ€ =1, sincethetwocolumnsarelinearlydependent, buteithercolumnbyitself isnotlinearlydependent.
Foramorechallengingexample, wecanconsider 2 6 1 3 0 1 0 3 7 C= 6 6 6 1 0 1 1 1 7 7 7 , (A.20) 6 0 3 1 0 17 6 7 4 2 3 1 2 1 5 andshowthat Chasranktwosince, forinstance, thefirsttwocolumnsarelinearlyinde- pendent, howeveranyofthefourcollectionsofthreecolumnsaredependent.
Thisprocedure, asdescribed, isveryinefficient.
Itrequireslookingateverysubsetofthe columnsofourgivenmatrix, andthusispotentiallyexponentialinthenumberofcolumns.
Later we will see a more computationally efficient way to compute the rank of a matrix, but for now, this is sufficient to see that the concept is well defined and understand the meaning.
A.1.7 Invertibility Wehaveseenabovethatmultiplicationbyamatrixwithlinearlydependentcolumnscannot beundone, i.
e., thereisnoinverseoperationthatcanalwaysrecovertheinput.
However, multiplication by a full-rank matrix (i.
e., some A that is ğ‘› ğ‘› matrix with rank ğ‘›), we shouldalwaysbeabletoundoit.
Considerthematrix 2 61 0 0 3 7 6 60 1 0 7 7 I= 6 6 6 .
.
.
.
.
.
.
7 7 7 .
(A.21) 6 7 40 0 15 which is the matrix with ones along the diagonal, and zeros elsewhere.
We call this the identity matrix.
It is the matrix which leaves our data unchanged when applied.
To find a matrix which undoes what our matrix A has done, we want to find a matrix A 1 such that A 1A=AA 1 =I.
(A.22) If we look at this as a system, we have ğ‘› ğ‘› unknowns (the entries of A 1) and ğ‘› ğ‘› equations(theequalitythatneedstoholdbetweeneveryentryoftheproduct A 1Aand every entry of I) so we should generically expect a solution to exist.
Indeed, in the next sectionwewillseeaquantitycalledthedeterminant, whichhasthepropertythataslongas thedeterminantisnotzero, wecanfindasolution.
Wecallsuchamatrix A 1 theinverse matrix.
Asanexample, if Aisthegeneral2 2matrix ğ‘ ğ‘ A= , (A.23) ğ‘ ğ‘‘ thenwecanseethattheinverseis 1 ğ‘‘ ğ‘ .
(A.24) ğ‘ğ‘‘ ğ‘ğ‘ ğ‘ ğ‘ 909 Geometryand Linear Algebraic Operations Wecantesttoseethisbyseeingthatmultiplyingbytheinversegivenbytheformulaabove worksinpractice.
M = torch.
tensor([[1, 2], [1, 4]], dtype=torch.
float32) M_inv = torch.
tensor([[2, -1], [-0.5, 0.5]]) M_inv @ M tensor([[1., 0.], [0., 1.]]) Numerical Issues Whiletheinverseofamatrixisusefulintheory, wemustsaythatmostofthetimewedo notwishtousethematrixinversetosolveaprobleminpractice.
Ingeneral, therearefar morenumericallystablealgorithmsforsolvinglinearequationslike Ax=b, (A.25) thancomputingtheinverseandmultiplyingtoget x=A 1b.
(A.26) Justasdivisionbyasmallnumbercanleadtonumericalinstability, socaninversionofa matrixwhichisclosetohavinglowrank.
Moreover, itiscommonthatthematrix Aissparse, whichistosaythatitcontainsonlya smallnumberofnon-zerovalues.
Ifweweretoexploreexamples, wewouldseethatthis doesnotmeantheinverseissparse.
Evenif Awasa1millionby1millionmatrixwithonly 5millionnon-zeroentries(andthusweneedonlystorethose5million), theinversewill typicallyhavealmosteveryentrynon-negative, requiringustostoreall1M2 entriesâ€”that is1trillionentries! Whilewedonothavetimetodiveallthewayintothethornynumericalissuesfrequently encounteredwhenworkingwithlinearalgebra, wewanttoprovideyouwithsomeintuition aboutwhentoproceedwithcaution, andgenerallyavoidinginversioninpracticeisagood ruleofthumb.
A.1.8 Determinant The geometric view of linear algebra gives an intuitive way to interpret a fundamental quantityknownasthedeterminant.
Considerthegridimagefrombefore, butnowwitha highlightedregion(Fig.
A.9).
Lookatthehighlightedsquare.
Thisisasquarewithedgesgivenby â€0,1â€ and â€1,0â€ and thusithasareaone.
After Atransformsthissquare, weseethatitbecomesaparallelogram.
Thereisnoreasonthisparallelogramshouldhavethesameareathatwestartedwith, and 910 Mathematicsfor Deep Learning t Fig.
A.9 Thematrix Aagaindistortingthegrid.
Thistime, Iwanttodrawparticularattentionto whathappenstothehighlightedsquare.
indeedinthespecificcaseshownhereof 1 2 A= , (A.27) 1 3 itisanexerciseincoordinategeometrytocomputetheareaofthisparallelogramandobtain thattheareais5.
Ingeneral, ifwehaveamatrix ğ‘ ğ‘ A= , (A.28) ğ‘ ğ‘‘ wecanseewithsomecomputationthattheareaoftheresultingparallelogramisğ‘ğ‘‘ ğ‘ğ‘.
Thisareaisreferredtoasthedeterminant.
Letâ€™scheckthisquicklywithsomeexamplecode.
torch.
det(torch.
tensor([[1, -1], [2, 3]], dtype=torch.
float32)) tensor(5.) The eagle-eyed amongst us will notice that this expression can be zero or even negative.
Forthenegativeterm, thisisamatterofconventiontakengenerallyinmathematics: ifthe matrixflipsthefigure, wesaytheareaisnegated.
Letâ€™sseenowthatwhenthedeterminant iszero, welearnmore.
Letâ€™sconsider 2 4 B= .
(A.29) 1 2 Ifwecomputethedeterminantofthismatrix, weget2 â€ 2â€ 4 â€ 1â€ = 0.
Givenour understandingabove, thismakessense.
Bcompressesthesquarefromtheoriginalimage downtoalinesegment, whichhaszeroarea.
Andindeed, beingcompressedintoalower dimensionalspaceistheonlywaytohavezeroareaafterthetransformation.
Thuswesee the following result is true: a matrix ğ´ is invertible if and only if the determinant is not equaltozero.
911 Geometryand Linear Algebraic Operations As a final comment, imagine that we have any figure drawn on the plane.
Thinking like computerscientists, wecandecomposethatfigureintoacollectionoflittlesquaressothat theareaofthefigureisinessencejustthenumberofsquaresinthedecomposition.
Ifwe nowtransformthatfigurebyamatrix, wesendeachofthesesquarestoparallelograms, each oneofwhichhasareagivenbythedeterminant.
Weseethatforanyfigure, thedeterminant givesthe(signed)numberthatamatrixscalestheareaofanyfigure.
Computingdeterminantsforlargermatricescanbelaborious, buttheintuitionisthesame.
Thedeterminantremainsthefactorthatğ‘› ğ‘›matricesscaleğ‘›-dimensionalvolumes.
A.1.9 Tensorsand Common Linear Algebra Operations In Section 2.3 the concept of tensors was introduced.
In this section, we will dive more deeply into tensor contractions (the tensor equivalent of matrix multiplication), and see howitcanprovideaunifiedviewonanumberofmatrixandvectoroperations.
With matrices and vectors we knew how to multiply them to transform data.
We need to have a similar definition for tensors if they are to be useful to us.
Think about matrix multiplication: C=AB, (A.30) orequivalently ğ‘ ğ‘–,ğ‘— = ğ‘ ğ‘–,ğ‘˜ ğ‘ ğ‘˜,ğ‘— .
(A.31) ğ‘˜ Thispatternisonewecanrepeatfortensors.
Fortensors, thereisnoonecaseofwhatto sumoverthatcanbeuniversallychosen, soweneedspecifyexactlywhichindiceswewant tosumover.
Forinstancewecouldconsider ğ‘¦ ğ‘–ğ‘™ = ğ‘¥ ğ‘–ğ‘—ğ‘˜ğ‘™ ğ‘ ğ‘—ğ‘˜ .
(A.32) ğ‘—ğ‘˜ Such a transformation is called a tensor contraction.
It can represent a far more flexible familyoftransformationsthatmatrixmultiplicationalone.
Asaoften-usednotationalsimplification, wecannoticethatthesumisoverexactlythose indicesthatoccurmorethanonceintheexpression, thuspeopleoftenworkwith Einstein notation, wherethesummationisimplicitlytakenoverallrepeatedindices.
Thisgivesthe compactexpression: ğ‘¦ ğ‘–ğ‘™ =ğ‘¥ ğ‘–ğ‘—ğ‘˜ğ‘™ ğ‘ ğ‘—ğ‘˜ .
(A.33) Common Examplesfrom Linear Algebra Letâ€™sseehowmanyofthelinearalgebraicdefinitionswehaveseenbeforecanbeexpressed inthiscompressedtensornotation: Ë v w= ğ‘– ğ‘£ ğ‘– ğ‘¤ ğ‘– Ë kvk2 2 = ğ‘– ğ‘£ ğ‘– ğ‘£ ğ‘– 912 Mathematicsfor Deep Learning Ë â€Avâ€ ğ‘– = ğ‘— ğ‘ ğ‘–ğ‘— ğ‘£ ğ‘— Ë â€ABâ€ ğ‘–ğ‘˜ = ğ‘— ğ‘ ğ‘–ğ‘— ğ‘ ğ‘—ğ‘˜ Ë trâ€Aâ€ = ğ‘– ğ‘ ğ‘–ğ‘– In this way, we can replace a myriad of specialized notations with short tensor expres- sions.
Expressingin Code Tensorsmayflexiblybeoperatedonincodeaswell.
Asseenin Section2.3, wecancreate tensorsasisshownbelow.
# Define tensors B = torch.
tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]) A = torch.
tensor([[1, 2], [3, 4]]) v = torch.
tensor([1, 2]) # Print out the shapes A.
shape, B.
shape, v.
shape (torch.
Size([2, 2]), torch.
Size([2, 2, 3]), torch.
Size([2])) Einsteinsummationhasbeenimplementeddirectly.
Theindicesthatoccursinthe Einstein summationcanbepassedasastring, followedbythetensorsthatarebeingactedupon.
For instance, toimplementmatrixmultiplication, wecanconsiderthe Einsteinsummationseen above(Av=ğ‘ ğ‘–ğ‘— ğ‘£ ğ‘—)andstripouttheindicesthemselvestogettheimplementation: # Reimplement matrix multiplication torch.
einsum("ij, j -> i", A, v), A@v (tensor([ 5, 11]), tensor([ 5, 11])) Thisisahighlyflexiblenotation.
Forinstanceifwewanttocomputewhatwouldbetradi- tionallywrittenas ğ‘ ğ‘˜ğ‘™ = bğ‘–ğ‘—ğ‘˜ağ‘–ğ‘™ ğ‘£ ğ‘— .
(A.34) ğ‘–ğ‘— itcanbeimplementedvia Einsteinsummationas: torch.
einsum("ijk, il, j -> kl", B, A, v) tensor([[ 90, 126], [102, 144], [114, 162]]) 913 Geometryand Linear Algebraic Operations Thisnotationisreadableandefficientforhumans, howeverbulkyifforwhateverreasonwe needtogenerateatensorcontractionprogrammatically.
Forthisreason, einsumprovides analternativenotationbyprovidingintegerindicesforeachtensor.
Forexample, thesame tensorcontractioncanalsobewrittenas: # Py Torch does not support this type of notation.
Either notation allows for concise and efficient representation of tensor contractions in code.
A.1.10 Summary Vectorscanbeinterpretedgeometricallyaseitherpointsordirectionsinspace.
Dotproductsdefinethenotionofangletoarbitrarilyhigh-dimensionalspaces.
Hyperplanesarehigh-dimensionalgeneralizationsoflinesandplanes.
Theycanbeused todefinedecisionplanesthatareoftenusedasthelaststepinaclassificationtask.
Matrixmultiplicationcanbegeometricallyinterpretedasuniformdistortionsoftheun- derlyingcoordinates.
Theyrepresentaveryrestricted, butmathematicallyclean, way totransformvectors.
Lineardependenceisawaytotellwhenacollectionofvectorsareinalowerdimensional spacethanwewouldexpect(sayyouhave3vectorslivingina2-dimensionalspace).
The rank of a matrix is the size of the largest subset of its columns that are linearly independent.
Whenamatrixâ€™sinverseisdefined, matrixinversionallowsustofindanothermatrixthat undoestheactionofthefirst.
Matrixinversionisusefulintheory, butrequirescarein practiceowingtonumericalinstability.
Determinantsallowustomeasurehowmuchamatrixexpandsorcontractsaspace.
A nonzero determinant implies an invertible (non-singular) matrix and a zero-valued determinantmeansthatthematrixisnon-invertible(singular).
Tensor contractions and Einstein summation provide for a neat and clean notation for expressingmanyofthecomputationsthatareseeninmachinelearning.
A.1.11 Exercises 1.
Whatistheanglebetween 2 3 2 3 6 1 7 637 6 7 6 7 ğ‘£fi 1 = 6 6 6 0 1 7 7 7 , ğ‘£fi 2 = 6 6 6 1 0 7 7 7 ? (A.35) 6 7 6 7 4 2 5 415 1 2 1 2 2.
Trueorfalse: and areinversesofoneanother? 0 1 0 1 914 Mathematicsfor Deep Learning 3.
Suppose that we draw a shape in the plane with area 100m2.
What is the area after transformingthefigurebythematrix 2 3 .
(A.36) 1 2 4.
Whichofthefollowingsetsofvectorsarelinearlyindependent? 8>>><' 1 â€œ ' 2 â€œ '3â€œ 9>>>= >>> : â€º â€º Â« 0 1 fi fi â€¹ ,â€º â€º Â« 1 1 fi fi â€¹ ,â€º â€º Â« 1 1 fi fi â€¹ >>> ; 8>>><'3â€œ '1â€œ '0â€œ 9>>>= >>> : â€º â€º Â« 1 1 fi fi â€¹ ,â€º â€º Â« 1 1 fi fi â€¹ ,â€º â€º Â« 0 0 fi fi â€¹ >>> ; 8>>><'1â€œ ' 0 â€œ '1â€œ 9>>>= >>> : â€º â€º Â« 1 0 fi fi â€¹ ,â€º â€º Â« 1 1 fi fi â€¹ ,â€º â€º Â« 0 1 fi fi â€¹ >>> ; ğ‘ 5.
Supposethatyouhaveamatrixwrittenas ğ´ = ğ‘ ğ‘ forsomechoiceofvalues ğ‘‘ ğ‘,ğ‘,ğ‘, andğ‘‘.
Trueorfalse: thedeterminantofsuchamatrixisalways0? 1 0 6.
Thevectorsğ‘’ = andğ‘’ = areorthogonal.
Whatistheconditiononamatrix ğ´ 1 0 2 1 sothat ğ´ğ‘’ and ğ´ğ‘’ areorthogonal? 1 2 7.
Howcanyouwritetrâ€A4â€in Einsteinnotationforanarbitrarymatrix ğ´? 280 Discussions280.
A.2 Eigendecompositions Eigenvaluesareoftenoneofthemostusefulnotionswewillencounterwhenstudyinglinear algebra, however, asabeginner, itiseasytooverlooktheirimportance.
Below, weintroduce eigendecompositionandtrytoconveysomesenseofjustwhyitissoimportant.
Supposethatwehaveamatrix ğ´withthefollowingentries: 2 0 A= .
(A.1) 0 1 Ifweapply ğ´toanyvectorv = Â»ğ‘¥,ğ‘¦â€¦> , weobtainavector Av = Â»2ğ‘¥, ğ‘¦â€¦> .
Thishasan intuitiveinterpretation: stretchthevectortobetwiceaswideintheğ‘¥-direction, andthen flipitintheğ‘¦-direction.
915 Eigendecompositions However, therearesomevectorsforwhichsomethingremainsunchanged.
NamelyÂ»1,0â€¦> gets sent to Â»2,0â€¦> and Â»0,1â€¦> gets sent to Â»0, 1â€¦> .
These vectors are still in the same line, and the only modification is that the matrix stretches them by a factor of 2 and 1 respectively.
Wecallsuchvectorseigenvectorsandthefactortheyarestretchedbyeigen- values.
Ingeneral, ifwecanfindanumberğœ†andavectorvsuchthat Av=ğœ†v.
(A.2) Wesaythatvisaneigenvectorfor ğ´andğœ†isaneigenvalue.
A.2.1 Finding Eigenvalues Letâ€™s figure out how to find them.
By subtracting off the ğœ†v from both sides, and then factoringoutthevector, weseetheaboveisequivalentto: â€A ğœ†Iâ€v=0.
(A.3) For (A.3) to happen, we see that â€A ğœ†Iâ€ must compress some direction down to zero, henceitisnotinvertible, andthusthedeterminantiszero.
Thus, wecanfindtheeigenvalues by finding for what ğœ† is detâ€A ğœ†Iâ€ = 0.
Once we find the eigenvalues, we can solve Av=ğœ†vtofindtheassociatedeigenvector(s).
An Example Letâ€™sseethiswithamorechallengingmatrix 2 1 A= .
(A.4) 2 3 If we consider detâ€A ğœ†Iâ€ = 0, we see this is equivalent to the polynomial equation 0 = â€2 ğœ†â€â€3 ğœ†â€ 2 = â€4 ğœ†â€â€1 ğœ†â€.
Thus, twoeigenvaluesare4and1.
Tofindthe associatedvectors, wethenneedtosolve 2 1 ğ‘¥ ğ‘¥ 2 1 ğ‘¥ 4ğ‘¥ = and = .
(A.5) 2 3 ğ‘¦ ğ‘¦ 2 3 ğ‘¦ 4ğ‘¦ Wecansolvethiswiththevectors Â»1, 1â€¦> and Â»1,2â€¦> respectively.
Wecancheckthisincodeusingthebuilt-innumpy.
linalg.
eigroutine.
%matplotlib inline import torch from IPython import display from d2l import torch as d2l torch.
linalg.
eig(torch.
tensor([[2, 1], [2, 3]], dtype=torch.
float64)) 916 Mathematicsfor Deep Learning torch.
return_types.
linalg_eig( eigenvectors=tensor([[-0.7071+0.
j, -0.4472+0.
j], Notethatnumpynormalizestheeigenvectorstobeoflengthone, whereaswetookoursto beofarbitrarylength.
Additionally, thechoiceofsignisarbitrary.
However, thevectors computedareparalleltotheoneswefoundbyhandwiththesameeigenvalues.
A.2.2 Decomposing Matrices Letâ€™scontinuethepreviousexampleonestepfurther.
Let 1 1 W= , (A.6) 1 2 bethematrixwherethecolumnsaretheeigenvectorsofthematrix A.
Let 1 0 ğšº = , (A.7) 0 4 bethematrixwiththeassociatedeigenvaluesonthediagonal.
Thenthedefinitionofeigen- valuesandeigenvectorstellsusthat AW=Wğšº.
(A.8) Thematrixğ‘Š isinvertible, sowemaymultiplybothsidesbyğ‘Š 1ontheright, weseethat wemaywrite A=WğšºW 1.
(A.9) Inthenextsectionwewillseesomeniceconsequencesofthis, butfornowweneedonly knowthatsuchadecompositionwillexistaslongaswecanfindafullcollectionoflinearly independenteigenvectors(sothatğ‘Š isinvertible).
A.2.3 Operationson Eigendecompositions Onenicethingabouteigendecompositions(A.9)isthatwecanwritemanyoperationswe usually encounter cleanly in terms of the eigendecomposition.
As a first example, con- sider: z ğ‘› } tim | e s { z ğ‘› } tim | e s { z ğ‘› } tim | e { s (A.10) A ğ‘› =A A= â€WğšºW 1â€ â€WğšºW 1â€ =Wğšº ğšºW 1 =Wğšºğ‘› W 1.
Thistellsusthatforanypositivepowerofamatrix, theeigendecompositionisobtainedby justraisingtheeigenvaluestothesamepower.
Thesamecanbeshownfornegativepowers, soifwewanttoinvertamatrixweneedonlyconsider A 1 =Wğšº 1W 1, (A.11) 917 Eigendecompositions orinotherwords, justinverteacheigenvalue.
Thiswillworkaslongaseacheigenvalueis non-zero, soweseethatinvertibleisthesameashavingnozeroeigenvalues.
Indeed, additionalworkcanshowthatifğœ† 1 ,...,ğœ† ğ‘› aretheeigenvaluesofamatrix, then thedeterminantofthatmatrixis detâ€Aâ€ =ğœ† 1 ğœ† ğ‘› , (A.12) ortheproductofalltheeigenvalues.
Thismakessenseintuitivelybecausewhateverstretch- ing Wdoes,ğ‘Š 1 undoesit, sointheendtheonlystretchingthathappensisbymultipli- cation by the diagonal matrix ğšº, which stretchesvolumes by the product of the diagonal elements.
Finally, recallthattherankwasthemaximumnumberoflinearlyindependentcolumnsof yourmatrix.
Byexaminingtheeigendecompositionclosely, wecanseethattherankisthe sameasthenumberofnon-zeroeigenvaluesof A.
The examples could continue, but hopefully the point is clear: eigendecomposition can simplify many linear-algebraic computations and is a fundamental operation underlying manynumericalalgorithmsandmuchoftheanalysisthatwedoinlinearalgebra.
A.2.4 Eigendecompositionsof Symmetric Matrices It is not always possible to find enough linearly independent eigenvectors for the above processtowork.
Forinstancethematrix 1 1 A= , (A.13) 0 1 hasonlyasingleeigenvector, namely â€1,0â€> .
Tohandlesuchmatrices, werequiremore advancedtechniquesthanwecancover(suchasthe Jordan Normal Form, or Singular Value Decomposition).
We will often need to restrict our attention to those matrices where we canguaranteetheexistenceofafullsetofeigenvectors.
Themostcommonlyencounteredfamilyarethesymmetricmatrices, whicharethosema- triceswhere A = A> .
Inthiscase, wemaytakeğ‘Š tobeanorthogonalmatrixâ€”amatrix whose columns are all length one vectors that are at right angles to one another, where W> =W 1â€”andalltheeigenvalueswillbereal.
Thus, inthisspecialcase, wecanwrite (A.9)as A=WğšºW >.
(A.14) A.2.5 Gershgorin Circle Theorem Eigenvaluesareoftendifficulttoreasonwithintuitively.
Ifpresentedanarbitrarymatrix, thereislittlethatcanbesaidaboutwhattheeigenvaluesarewithoutcomputingthem.
There is, however, onetheoremthatcanmakeiteasytoapproximatewellifthelargestvaluesare onthediagonal.
Ë Let A = â€ğ‘ ğ‘–ğ‘— â€ be any square matrix (ğ‘› ğ‘›).
We will define ğ‘Ÿ ğ‘– = ğ‘—â‰ ğ‘– jğ‘ ğ‘–ğ‘— j.
Let D ğ‘– 918 Mathematicsfor Deep Learning representthediscinthecomplexplanewithcenterğ‘ ğ‘–ğ‘– radiusğ‘Ÿ ğ‘–.
Then, everyeigenvalueof Aiscontainedinoneofthe D ğ‘–.
Thiscanbeabittounpack, soletâ€™slookatanexample.
Considerthematrix: 2 61.0 0.1 0.1 0.1 3 7 A= 6 6 6 0.1 3.0 0.2 0.3 7 7 7 .
(A.15) 60.1 0.2 5.0 0.57 6 7 40.1 0.3 0.5 9.05 1 2 3 4 eigenvalues are real.
This means that all of our eigenvalues will be in one of the ranges of Â»ğ‘ ğ‘Ÿ ,ğ‘ â€šğ‘Ÿ â€¦ = Â»0.7,1.3â€¦, (A.16) 11 1 11 1 Â»ğ‘ ğ‘Ÿ ,ğ‘ â€šğ‘Ÿ â€¦ = Â»2.4,3.6â€¦, (A.17) 22 2 22 2 Â»ğ‘ ğ‘Ÿ ,ğ‘ â€šğ‘Ÿ â€¦ = Â»4.2,5.8â€¦, (A.18) 33 3 33 3 Â»ğ‘ ğ‘Ÿ ,ğ‘ â€šğ‘Ÿ â€¦ = Â»8.1,9.9â€¦.
(A.19) 44 4 44 4 Performingthenumericalcomputationshowsthattheeigenvaluesareapproximately0.99, 2.97,4.95,9.08, allcomfortablyinsidetherangesprovided.
[0.1, 3.0, 0.2, 0.3], [0.1, 0.2, 5.0, 0.5], [0.1, 0.3, 0.5, 9.0]]) v, _ = torch.
linalg.
eig(A) v Inthisway, eigenvaluescanbeapproximated, andtheapproximationswillbefairlyaccurate inthecasethatthediagonalissignificantlylargerthanalltheotherelements.
Itisasmallthing, butwithacomplexandsubtletopiclikeeigendecomposition, itisgood togetanyintuitivegraspwecan.
A.2.6 AUseful Application: The Growthof Iterated Maps Nowthatweunderstandwhateigenvectorsareinprinciple, letâ€™sseehowtheycanbeused toprovideadeepunderstandingofaproblemcentraltoneuralnetworkbehavior: proper weightinitialization.
919 Eigendecompositions Eigenvectorsas Long Term Behavior Thefullmathematicalinvestigationoftheinitializationofdeepneuralnetworksisbeyond thescopeofthetext, butwecanseeatoyversionheretounderstandhoweigenvaluescan helpusseehowthesemodelswork.
Asweknow, neuralnetworksoperatebyinterspersing layers of linear transformations with non-linear operations.
For simplicity here, we will assumethatthereisnonon-linearity, andthatthetransformationisasinglerepeatedmatrix operation ğ´, sothattheoutputofourmodelis vğ‘œğ‘¢ğ‘¡ =A A Avğ‘–ğ‘› =A ğ‘ vğ‘–ğ‘› .
(A.20) Whenthesemodelsareinitialized, ğ´istakentobearandommatrixwith Gaussianentries, soletâ€™smakeoneofthose.
Tobeconcrete, westartwithameanzero, varianceone Gaussian distributed5 5matrix.
torch.
manual_seed(42) k = 5 A = torch.
randn(k, k, dtype=torch.
float64) A Behavioron Random Data For simplicity in our toy model, we will assume that the data vector we feed in vğ‘–ğ‘› is a randomfivedimensional Gaussianvector.
Letâ€™sthinkaboutwhatwewanttohavehappen.
Forcontext, letsthinkofageneric MLproblem, wherewearetryingtoturninputdata, like animage, intoaprediction, liketheprobabilitytheimageisapictureofacat.
Ifrepeated applicationof Astretchesarandomvectorouttobeverylong, thensmallchangesininput willbeamplifiedintolargechangesinoutputâ€”tinymodificationsoftheinputimagewould leadtovastlydifferentpredictions.
Thisdoesnotseemright! Ontheflipside, if Ashrinksrandomvectorstobeshorter, thenafterrunningthroughmany layers, thevectorwillessentiallyshrinktonothing, andtheoutputwillnotdependonthe input.
Thisisalsoclearlynotrighteither! Weneedtowalkthenarrowlinebetweengrowthanddecaytomakesurethatouroutput changesdependingonourinput, butnotmuch! Letâ€™sseewhathappenswhenwerepeatedlymultiplyourmatrix Aagainstarandominput vector, andkeeptrackofthenorm.
920 Mathematicsfor Deep Learning # Calculate the sequence of norms after repeatedly applying `A` v_in = torch.
randn(k, 1, dtype=torch.
float64) norm_list = [torch.
norm(v_in).
item()] for i in range(1, 100): v_in = A @ v_in norm_list.
append(torch.
norm(v_in).
item()) d2l.
plot(torch.
arange(0, 100), norm_list, 'Iteration', 'Value') Thenormisgrowinguncontrollably! Indeedifwetakethelistofquotients, wewillseea pattern.
# Compute the scaling factor of the norms norm_ratio_list = [] for i in range(1, 100): norm_ratio_list.
append(norm_list[i]/norm_list[i - 1]) d2l.
plot(torch.
arange(1, 100), norm_ratio_list, 'Iteration', 'Ratio') Ifwelook at the lastportion of the abovecomputation, wesee thatthe random vectoris stretchedbyafactorof1.974459321485[...], wheretheportionattheendshiftsalittle, butthestretchingfactorisstable.
921 Eigendecompositions Relating Backto Eigenvectors We have seen that eigenvectors and eigenvalues correspond to the amount something is stretched, butthatwasforspecificvectors, andspecificstretches.
Letâ€™stakealookatwhat theyarefor A.
Abitofacaveathere: itturnsoutthattoseethemall, wewillneedtogo tocomplexnumbers.
Youcanthinkoftheseasstretchesandrotations.
Bytakingthenorm ofthecomplexnumber(squarerootofthesumsofsquaresofrealandimaginaryparts)we canmeasurethatstretchingfactor.
Letâ€™salsosortthem.
# Compute the eigenvalues eigs = torch.
linalg.
eig(A).
eigenvalues.
tolist() norm_eigs = [torch.
abs(torch.
tensor(x)) for x in eigs] norm_eigs.
sort() print(f'norms of eigenvalues: {norm_eigs}') norms of eigenvalues: [tensor(0.3490), tensor(1.1296), tensor(1.1296),â£ â†©! tensor(1.1828), tensor(2.4532)] An Observation Weseesomethingabitunexpectedhappeninghere: thatnumberweidentifiedbeforeforthe longtermstretchingofourmatrix Aappliedtoarandomvectorisexactly(accuratetothir- teendecimalplaces!) thelargesteigenvalueof A.
Thisisclearlynotacoincidence! But, ifwenowthinkaboutwhatishappeninggeometrically, thisstartstomakesense.
Con- siderarandomvector.
Thisrandomvectorpointsalittleineverydirection, soinparticular, it points at least a little bit in the same direction as the eigenvector of A associated with the largest eigenvalue.
This is so important that it is called the principle eigenvalue and principleeigenvector.
Afterapplying A, ourrandomvectorgetsstretchedineverypossi- ble direction, as is associated with every possible eigenvector, but it is stretched most of allinthedirectionassociatedwiththisprincipleeigenvector.
Whatthismeansisthatafter applyin ğ´, ourrandomvectorislonger, andpointsinadirectionclosertobeingaligned withtheprincipleeigenvector.
Afterapplyingthematrixmanytimes, thealignmentwith the principle eigenvector becomes closer and closer until, for all practical purposes, our randomvectorhasbeentransformedintotheprincipleeigenvector! Indeedthisalgorithm isthebasisforwhatisknownasthepoweriterationforfindingthelargesteigenvalueand eigenvectorofamatrix.
Fordetailssee, forexample,(Goluband Van Loan,1996).
Fixingthe Normalization Now, from above discussions, we concluded that we do not want a random vector to be stretched or squished at all, we would like random vectors to stay about the same size throughouttheentireprocess.
Todoso, wenowrescaleourmatrixbythisprincipleeigen- valuesothatthelargesteigenvalueisinsteadnowjustone.
Letâ€™sseewhathappensinthis case.
922 Mathematicsfor Deep Learning # Rescale the matrix `A` A /= norm_eigs[-1] # Do the same experiment again v_in = torch.
randn(k, 1, dtype=torch.
float64) norm_list = [torch.
norm(v_in).
item()] for i in range(1, 100): v_in = A @ v_in norm_list.
append(torch.
norm(v_in).
item()) d2l.
plot(torch.
arange(0, 100), norm_list, 'Iteration', 'Value') Wecanalsoplottheratiobetweenconsecutivenormsasbeforeandseethatindeeditsta- bilizes.
# Also plot the ratio norm_ratio_list = [] for i in range(1, 100): norm_ratio_list.
append(norm_list[i]/norm_list[i-1]) d2l.
plot(torch.
arange(1, 100), norm_ratio_list, 'Iteration', 'Ratio') A.2.7 Discussion We now see exactly what we hoped for! After normalizing the matrices by the principal eigenvalue, weseethattherandomdatadoesnotexplodeasbefore, butrathereventually equilibrates to a specific value.
It would be nice to be able to do these things from first 923 Eigendecompositions principles, anditturnsoutthatifwelookdeeplyatthemathematicsofit, wecanseethat thelargesteigenvalueofalargerando p mmatrixwithindpependentmeanzero, varianceone Gaussianentriesisonaverageabout ğ‘›, orinourcase 5 2.2, duetoafascinatingfact knownasthecircularlaw(Ginibre,1965).
Therelationshipbetweentheeigenvalues(and a related object called singular values) of random matrices has been shown to havedeep connectionstoproperinitializationofneuralnetworksaswasdiscussedin Penningtonet al.
(2017)andsubsequentworks.
A.2.8 Summary Eigenvectorsarevectorswhicharestretchedbyamatrixwithoutchangingdirection.
Eigenvaluesaretheamountthattheeigenvectorsarestretchedbytheapplicationofthe matrix.
The eigendecomposition of a matrix can allow for many operations to be reduced to operationsontheeigenvalues.
The Gershgorin Circle Theoremcanprovideapproximatevaluesfortheeigenvaluesof amatrix.
Thebehaviorofiteratedmatrixpowersdependsprimarilyonthesizeofthelargesteigen- value.
Thisunderstandinghasmanyapplicationsinthetheoryofneuralnetworkini- tialization.
A.2.9 Exercises 1.
Whataretheeigenvaluesandeigenvectorsof 2 1 A= ? (A.21) 1 2 2.
Whataretheeigenvaluesandeigenvectorsofthefollowingmatrix, andwhatisstrange aboutthisexamplecomparedtothepreviousone? 2 1 A= .
(A.22) 0 2 3.
Without computing the eigenvalues, is it possible that the smallest eigenvalue of the followingmatrixislessthat0.5? Note: thisproblemcanbedoneinyourhead.
2 63.0 0.1 0.3 1.0 3 7 A= 6 6 6 0.1 1.0 0.1 0.2 7 7 7 .
(A.23) 60.3 0.1 5.0 0.07 6 7 281 41.0 0.2 0.0 1.85 Discussions281.
924 Mathematicsfor Deep Learning A.3 Single Variable Calculus In Section 2.4, we saw the basic elements of differential calculus.
This section takes a deeperdiveintothefundamentalsofcalculusandhowwecanunderstandandapplyitin thecontextofmachinelearning.
A.3.1 Differential Calculus Differentialcalculusisfundamentallythestudyofhowfunctionsbehaveundersmallchanges.
Toseewhythisissocoretodeeplearning, letâ€™sconsideranexample.
Supposethatwehaveadeepneuralnetworkwheretheweightsare, forconvenience, con- catenatedintoasinglevectorw= â€ğ‘¤ 1 ,...,ğ‘¤ ğ‘› â€.
Givenatrainingdataset, weconsiderthe lossofourneuralnetworkonthisdataset, whichwewillwriteas Lâ€wâ€.
Thisfunctionisextraordinarilycomplex, encodingtheperformanceofallpossiblemodels ofthegivenarchitectureonthisdataset, soitisnearlyimpossibletotellwhatsetofweights wwillminimizetheloss.
Thus, inpractice, weoftenstartbyinitializingourweightsran- domly, andtheniterativelytakesmallstepsinthedirectionwhichmakesthelossdecrease asrapidlyaspossible.
The question then becomes something that on the surface is no easier: how do we find the direction which makes the weights decrease as quickly as possible? To dig into this, letâ€™sfirstexaminethecasewithonlyasingleweight: ğ¿â€wâ€ = ğ¿â€ğ‘¥â€ forasinglerealvalue ğ‘¥.
Letâ€™stakeğ‘¥ andtrytounderstandwhathappenswhenwechangeitbyasmallamountto ğ‘¥â€šğœ–.
Ifyouwishtobeconcrete, thinkanumberlikeğœ– =0.0000001.
Tohelpusvisualize whathappens, letâ€™sgraphanexamplefunction, ğ‘“â€ğ‘¥â€ =sinâ€ğ‘¥ğ‘¥â€, overthe Â»0,3â€¦.
%matplotlib inline import torch from IPython import display from d2l import torch as d2l torch.
pi = torch.
acos(torch.
zeros(1)).
item() * 2 # Define pi in torch # Plot a function in a normal range x_big = torch.
arange(0.01, 3.01, 0.01) ys = torch.
sin(x_big**x_big) d2l.
plot(x_big, ys, 'x', 'f(x)') Atthislargescale, thefunctionâ€™sbehaviorisnotsimple.
However, ifwereduceourrangeto somethingsmallerlike Â»1.75,2.25â€¦, weseethatthegraphbecomesmuchsimpler.
# Plot a the same function in a tiny range x_med = torch.
arange(1.75, 2.25, 0.001) (continuesonnextpage) 925 Single Variable Calculus (continuedfrompreviouspage) ys = torch.
sin(x_med**x_med) d2l.
plot(x_med, ys, 'x', 'f(x)') Takingthistoanextreme, ifwezoomintoatinysegment, thebehaviorbecomesfarsimpler: itisjustastraightline.
# Plot a the same function in a tiny range x_small = torch.
arange(2.0, 2.01, 0.0001) ys = torch.
sin(x_small**x_small) d2l.
plot(x_small, ys, 'x', 'f(x)') Thisisthekeyobservationofsinglevariablecalculus: thebehavioroffamiliarfunctions canbemodeledbyalineinasmallenoughrange.
Thismeansthatformostfunctions, it isreasonabletoexpectthatasweshifttheğ‘¥valueofthefunctionbyalittlebit, theoutput ğ‘“â€ğ‘¥â€willalsobeshiftedbyalittlebit.
Theonlyquestionweneedtoansweris,â€œHowlarge 926 Mathematicsfor Deep Learning isthechangeintheoutputcomparedtothechangeintheinput? Isithalfaslarge? Twice aslarge?â€ Thus, wecanconsidertheratioofthechangeintheoutputofafunctionforasmallchange intheinputofthefunction.
Wecanwritethisformallyas ğ¿â€ğ‘¥â€šğœ–â€ ğ¿â€ğ‘¥â€ ğ¿â€ğ‘¥â€šğœ–â€ ğ¿â€ğ‘¥â€ = .
(A.1) â€ğ‘¥â€šğœ–â€ ğ‘¥ ğœ– Thisisalreadyenoughtostarttoplayaroundwithincode.
Forinstance, supposethatwe knowthat ğ¿â€ğ‘¥â€ = ğ‘¥2 â€š1701â€ğ‘¥ 4â€3, thenwecanseehowlargethisvalueisatthepoint ğ‘¥ =4asfollows.
# Define our function def L(x): return x**2 + 1701*(x-4)**3 # Print the difference divided by epsilon for several epsilon for epsilon in [0.1, 0.001, 0.0001, 0.00001]: print(f'epsilon = {epsilon:.5f} -> {(L(4+epsilon) - L(4)) / epsilon:.5f}') epsilon = 0.10000 -> 25.11000 epsilon = 0.00100 -> 8.00270 epsilon = 0.00010 -> 8.00012 epsilon = 0.00001 -> 8.00001 Now, ifweareobservant, wewillnoticethattheoutputofthisnumberissuspiciouslyclose to8.
Indeed, ifwedecreaseğœ–, wewillseevaluebecomesprogressivelycloserto8.
Thuswe mayconclude, correctly, thatthevalueweseek(thedegreeachangeintheinputchanges theoutput)shouldbe8atthepointğ‘¥ =4.
Thewaythatamathematicianencodesthisfact is ğ¿â€4â€šğœ–â€ ğ¿â€4â€ lim =8.
(A.2) ğœ–!0 ğœ– Asabitofahistoricaldigression: inthefirstfewdecadesofneuralnetworkresearch, sci- entistsusedthisalgorithm(themethodoffinitedifferences)toevaluatehowalossfunction changedundersmallperturbation: justchangetheweightsandseehowthelosschanged.
Thisiscomputationallyinefficient, requiringtwoevaluationsofthelossfunctiontoseehow asinglechangeofonevariableinfluencedtheloss.
Ifwetriedtodothiswithevenapal- tryfewthousandparameters, itwouldrequireseveralthousandevaluationsofthenetwork over the entire dataset! It was not solved until 1986 that the backpropagation algorithm introducedin Rumelhartetal.
(1988)providedawaytocalculatehowanychangeofthe weightstogetherwouldchangethelossinthesamecomputationtimeasasingleprediction ofthenetworkoverthedataset.
Backinourexample, thisvalue8isdifferentfordifferentvaluesofğ‘¥, soitmakessenseto defineitasafunctionofğ‘¥.
Moreformally, thisvaluedependentrateofchangeisreferred toasthederivativewhichiswrittenas ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€ â€ğ‘¥â€ = lim .
(A.3) ğ‘‘ğ‘¥ ğœ–!0 ğœ– 927 Single Variable Calculus Differenttextswillusedifferentnotationsforthederivative.
Forinstance, allofthebelow notationsindicatethesamething: ğ‘‘ğ‘“ ğ‘‘ ğ‘‘ğ‘¥ = ğ‘‘ğ‘¥ ğ‘“ = ğ‘“0 =r ğ‘¥ ğ‘“ = ğ· ğ‘¥ ğ‘“ = ğ‘“ ğ‘¥ .
(A.4) Mostauthorswillpickasinglenotationandstickwithit, howevereventhatisnotguaran- ğ‘‘ğ‘“ teed.
Itisbesttobefamiliarwithallofthese.
Wewillusethenotation throughoutthis ğ‘‘ğ‘¥ text, unlesswewanttotakethederivativeofacomplexexpression, inwhichcasewewill use ğ‘‘ ğ‘“ towriteexpressionslike ğ‘‘ğ‘¥ ğ‘‘ ğ‘¥2â€š1 ğ‘¥4â€šcos .
(A.5) ğ‘‘ğ‘¥ 2ğ‘¥ 1 Oftentimes, itisintuitivelyusefultounravelthedefinitionofderivative(A.3)againtosee howafunctionchangeswhenwemakeasmallchangeofğ‘¥: ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€ â€ğ‘¥â€ = lim =) â€ğ‘¥â€ ğ‘‘ğ‘¥ ğœ–!0 ğœ– ğ‘‘ğ‘¥ ğœ– ğ‘‘ğ‘“ =) ğœ– â€ğ‘¥â€ ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€ (A.6) ğ‘‘ğ‘¥ ğ‘‘ğ‘“ =) ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€â€šğœ– â€ğ‘¥â€.
ğ‘‘ğ‘¥ Thelastequationisworthexplicitlycallingout.
Ittellsusthatifyoutakeanyfunctionand changetheinputbyasmallamount, theoutputwouldchangebythatsmallamountscaled bythederivative.
Inthisway, wecanunderstandthederivativeasthescalingfactorthattellsushowlargeof changewegetintheoutputfromachangeintheinput.
A.3.2 Rulesof Calculus We now turn to the task of understanding how to compute the derivative of an explicit function.
Afullformaltreatmentofcalculuswouldderiveeverythingfromfirstprinciples.
We will not indulge in this temptation here, but rather provide an understanding of the commonrulesencountered.
Common Derivatives Aswasseenin Section2.4, whencomputingderivativesonecanoftentimesuseaseriesof rulestoreducethecomputationtoafewcorefunctions.
Werepeatthemhereforeaseof reference.
Derivativeofconstants.
ğ‘‘ ğ‘ =0.
ğ‘‘ğ‘¥ Derivativeoflinearfunctions.
ğ‘‘ â€ğ‘ğ‘¥â€ =ğ‘.
ğ‘‘ğ‘¥ Powerrule.
ğ‘‘ ğ‘¥ğ‘› =ğ‘›ğ‘¥ğ‘› 1.
ğ‘‘ğ‘¥ Derivativeofexponentials.
ğ‘‘ ğ‘’ğ‘¥ =ğ‘’ğ‘¥ .
ğ‘‘ğ‘¥ Derivativeofthelogarithm.
ğ‘‘ logâ€ğ‘¥â€ = 1.
ğ‘‘ğ‘¥ ğ‘¥ 928 Mathematicsfor Deep Learning Derivative Rules Ifeveryderivativeneededtobeseparatelycomputedandstoredinatable, differentialcal- culus would be near impossible.
It is a gift of mathematics that we can generalize the above derivatives and compute more complex derivatives like finding the derivative of ğ‘“â€ğ‘¥â€ = log 1â€šâ€ğ‘¥ 1â€10 .
As was mentioned in Section 2.4, the key to doing so is to codify what happens when we take functions and combine them in various ways, most importantly: sums, products, andcompositions.
Sumrule.
ğ‘‘ â€ğ‘”â€ğ‘¥â€â€šâ„â€ğ‘¥â€â€ = ğ‘‘ğ‘”â€ğ‘¥â€â€š ğ‘‘â„â€ğ‘¥â€.
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Productrule.
ğ‘‘ â€ğ‘”â€ğ‘¥â€ â„â€ğ‘¥â€â€ =ğ‘”â€ğ‘¥â€ğ‘‘â„â€ğ‘¥â€â€š ğ‘‘ğ‘”â€ğ‘¥â€â„â€ğ‘¥â€.
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Chainrule.
ğ‘‘ ğ‘”â€â„â€ğ‘¥â€â€ = ğ‘‘ğ‘”â€â„â€ğ‘¥â€â€ ğ‘‘â„â€ğ‘¥â€.
ğ‘‘ğ‘¥ ğ‘‘â„ ğ‘‘ğ‘¥ Letâ€™s see how we may use (A.6) to understand these rules.
For the sum rule, consider followingchainofreasoning: ğ‘“â€ğ‘¥â€šğœ–â€ =ğ‘”â€ğ‘¥â€šğœ–â€â€šâ„â€ğ‘¥â€šğœ–â€ ğ‘‘ğ‘” ğ‘‘â„ ğ‘”â€ğ‘¥â€â€šğœ– â€ğ‘¥â€â€šâ„â€ğ‘¥â€â€šğœ– â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘” ğ‘‘â„ (A.7) =ğ‘”â€ğ‘¥â€â€šâ„â€ğ‘¥â€â€šğœ– â€ğ‘¥â€â€š â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘” ğ‘‘â„ = ğ‘“â€ğ‘¥â€â€šğœ– â€ğ‘¥â€â€š â€ğ‘¥â€ .
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Bycomparingthisresultwiththefactthat ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€â€šğœ–ğ‘‘ğ‘“â€ğ‘¥â€, weseethat ğ‘‘ğ‘“â€ğ‘¥â€ = ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘”â€ğ‘¥â€â€šğ‘‘â„â€ğ‘¥â€asdesired.
Theintuitionhereis: whenwechangetheinputğ‘¥,ğ‘”andâ„jointly ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ contributetothechangeoftheoutputby ğ‘‘ğ‘”â€ğ‘¥â€and ğ‘‘â„â€ğ‘¥â€.
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ The product is more subtle, and will require a new observation about how to work with theseexpressions.
Wewillbeginasbeforeusing(A.6): ğ‘“â€ğ‘¥â€šğœ–â€ =ğ‘”â€ğ‘¥â€šğœ–â€ â„â€ğ‘¥â€šğœ–â€ ğ‘‘ğ‘” ğ‘‘â„ ğ‘”â€ğ‘¥â€â€šğœ– â€ğ‘¥â€ â„â€ğ‘¥â€â€šğœ– â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘â„ ğ‘‘ğ‘” ğ‘‘ğ‘” ğ‘‘â„ (A.8) =ğ‘”â€ğ‘¥â€ â„â€ğ‘¥â€â€šğœ– ğ‘”â€ğ‘¥â€ â€ğ‘¥â€â€š â€ğ‘¥â€â„â€ğ‘¥â€ â€šğœ–2 â€ğ‘¥â€ â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘â„ ğ‘‘ğ‘” ğ‘‘ğ‘” ğ‘‘â„ = ğ‘“â€ğ‘¥â€â€šğœ– ğ‘”â€ğ‘¥â€ â€ğ‘¥â€â€š â€ğ‘¥â€â„â€ğ‘¥â€ â€šğœ–2 â€ğ‘¥â€ â€ğ‘¥â€.
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ This resembles the computation done above, and indeed we see our answer ( ğ‘‘ğ‘“â€ğ‘¥â€ = ğ‘‘ğ‘¥ ğ‘”â€ğ‘¥â€ğ‘‘â„â€ğ‘¥â€ â€š ğ‘‘ğ‘”â€ğ‘¥â€â„â€ğ‘¥â€) sitting next to ğœ–, but there is the issue of that term of size ğœ–2.
ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Wewillrefertothisasahigher-orderterm, sincethepowerofğœ–2ishigherthanthepower of ğœ–1.
We will see in a later section that we will sometimes want to keep track of these, however for now observe that if ğœ– = 0.0000001, then ğœ–2 = 0.0000000000001, which is vastly smaller.
As we send ğœ– ! 0, we may safely ignore the higher order terms.
As a generalconventioninthisappendix, wewilluseâ€œ â€todenotethatthetwotermsareequal 929 Single Variable Calculus up to higher order terms.
However, if we wish to be more formal we may examine the differencequotient ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€ ğ‘‘â„ ğ‘‘ğ‘” ğ‘‘ğ‘” ğ‘‘â„ =ğ‘”â€ğ‘¥â€ â€ğ‘¥â€â€š â€ğ‘¥â€â„â€ğ‘¥â€â€šğœ– â€ğ‘¥â€ â€ğ‘¥â€, (A.9) ğœ– ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ andseethataswesendğœ– !0, therighthandtermgoestozeroaswell.
Finally, withthechainrule, wecanagainprogressasbeforeusing(A.6)andseethat ğ‘“â€ğ‘¥â€šğœ–â€ =ğ‘”â€â„â€ğ‘¥â€šğœ–â€â€ ğ‘‘â„ ğ‘” â„â€ğ‘¥â€â€šğœ– â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘â„ ğ‘‘ğ‘” (A.10) ğ‘”â€â„â€ğ‘¥â€â€â€šğœ– â€ğ‘¥â€ â€â„â€ğ‘¥â€â€ ğ‘‘ğ‘¥ ğ‘‘â„ ğ‘‘ğ‘” ğ‘‘â„ = ğ‘“â€ğ‘¥â€â€šğœ– â€â„â€ğ‘¥â€â€ â€ğ‘¥â€, ğ‘‘â„ ğ‘‘ğ‘¥ whereinthesecondlineweviewthefunction ğ‘” ashavingitsinput(â„â€ğ‘¥â€)shiftedbythe tinyquantityğœ–ğ‘‘â„â€ğ‘¥â€.
ğ‘‘ğ‘¥ These rule provide us with a flexible set of tools to compute essentially any expression desired.
Forinstance, ğ‘‘ h i 1 ğ‘‘ log 1â€šâ€ğ‘¥ 1â€10 = 1â€šâ€ğ‘¥ 1â€10 1â€šâ€ğ‘¥ 1â€10 ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ 1 ğ‘‘ ğ‘‘ = 1â€šâ€ğ‘¥ 1â€10 Â»1â€¦â€š Â»â€ğ‘¥ 1â€10â€¦ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ 1 ğ‘‘ = 1â€šâ€ğ‘¥ 1â€10 0â€š10â€ğ‘¥ 1â€9 Â»ğ‘¥ 1â€¦ (A.11) ğ‘‘ğ‘¥ 1 =10 1â€šâ€ğ‘¥ 1â€10 â€ğ‘¥ 1â€9 10â€ğ‘¥ 1â€9 = .
1â€šâ€ğ‘¥ 1â€10 Whereeachlinehasusedthefollowingrules: 1.
Thechainruleandderivativeoflogarithm.
2.
Thesumrule.
3.
Thederivativeofconstants, chainrule, andpowerrule.
4.
Thesumrule, derivativeoflinearfunctions, derivativeofconstants.
Twothingsshouldbeclearafterdoingthisexample: 1.
Anyfunctionwecanwritedownusingsums, products, constants, powers, exponentials, andlogarithmscanhaveitsderivatecomputedmechanicallybyfollowingtheserules.
2.
Havingahumanfollowtheserulescanbetediousanderrorprone! Thankfully, thesetwofactstogetherhinttowardsawayforward: thisisaperfectcandidate 930 Mathematicsfor Deep Learning formechanization! Indeedbackpropagation, whichwewillrevisitlaterinthissection, is exactlythat.
Linear Approximation Whenworkingwithderivatives, itisoftenusefultogeometricallyinterprettheapproxima- tionusedabove.
Inparticular, notethattheequation ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¥â€â€šğœ– â€ğ‘¥â€, (A.12) ğ‘‘ğ‘¥ approximates the value of ğ‘“ by a line which passes through the point â€ğ‘¥, ğ‘“â€ğ‘¥â€â€ and has slope ğ‘‘ğ‘“â€ğ‘¥â€.
In this way we say that the derivative gives a linear approximation to the ğ‘‘ğ‘¥ function ğ‘“, asillustratedbelow: # Compute sin xs = torch.
arange(-torch.
pi, torch.
pi, 0.01) plots = [torch.
sin(xs)] # Compute some linear approximations.
Use d(sin(x))/dx = cos(x) for x0 in [-1.5, 0.0, 2.0]: plots.
append(torch.
sin(torch.
tensor(x0)) + (xs - x0) * torch.
cos(torch.
tensor(x0))) d2l.
plot(xs, plots, 'x', 'f(x)', ylim=[-1.5, 1.5]) Higher Order Derivatives Letâ€™s now do something that may on the surface seem strange.
Take a function ğ‘“ and computethederivative ğ‘‘ğ‘“ .
Thisgivesustherateofchangeof ğ‘“ atanypoint.
ğ‘‘ğ‘¥ ğ‘‘ğ‘“ However, thederivative, ğ‘‘ğ‘¥ , canbeviewedasa fun ctionitself, sonothingstopsusfrom ğ‘‘ğ‘“ ğ‘‘2ğ‘“ ğ‘‘ğ‘“ ğ‘‘ğ‘“ computingthederivativeof toget = .
Wewillcallthisthesecondderiva- ğ‘‘ğ‘¥ ğ‘‘ğ‘¥2 ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ tiveof ğ‘“.
Thisfunctionistherateofchangeoftherateofchangeof ğ‘“, orinotherwords, howtherateofchangeischanging.
Wemayapplythederivativeanynumberoftimesto obtain what is called the ğ‘›-th derivative.
To keep the notation clean, we will denote the 931 Single Variable Calculus ğ‘›-thderivativeas ğ‘‘ğ‘›ğ‘“ ğ‘‘ ğ‘› ğ‘“â€ğ‘›â€â€ğ‘¥â€ = = ğ‘“.
(A.13) ğ‘‘ğ‘¥ğ‘› ğ‘‘ğ‘¥ Letâ€™strytounderstandwhythisisausefulnotion.
Below, wevisualize ğ‘“â€2â€â€ğ‘¥â€, ğ‘“â€1â€â€ğ‘¥â€, and ğ‘“â€ğ‘¥â€.
First, considerthecasethatthesecondderivative ğ‘“â€2â€â€ğ‘¥â€isapositiveconstant.
Thismeans thattheslopeofthefirstderivativeispositive.
Asaresult, thefirstderivative ğ‘“â€1â€â€ğ‘¥â€may startoutnegative, becomeszeroatapoint, andthenbecomespositiveintheend.
Thistells ustheslopeofouroriginalfunction ğ‘“ andtherefore, thefunction ğ‘“ itselfdecreases, flattens out, thenincreases.
Inotherwords, thefunction ğ‘“ curvesup, andhasasingleminimumas isshownin Fig.
A.1.
t Fig.
A.1 Ifweassumethesecondderivativeisapositiveconstant, thenthefistderivativein increasing, whichimpliesthefunctionitselfhasaminimum.
Second, ifthesecondderivativeisanegativeconstant, thatmeansthatthefirstderivative is decreasing.
This implies the first derivative may start out positive, becomes zero at a point, andthenbecomesnegative.
Hence, thefunction ğ‘“ itselfincreases, flattensout, then decreases.
In other words, the function ğ‘“ curves down, and has a single maximum as is shownin Fig.
A.2.
t Fig.
A.2 Ifweassumethesecondderivativeisanegativeconstant, thenthefistderivativein decreasing, whichimpliesthefunctionitselfhasamaximum.
Third, ifthesecondderivativeisaalwayszero, thenthefirstderivativewillneverchangeâ€” itisconstant! Thismeansthat ğ‘“ increases(ordecreases)atafixedrate, and ğ‘“ isitselfa straightlineasisshownin Fig.
A.3.
Tosummarize, thesecondderivativecanbeinterpretedasdescribingthewaythatthefunc- tion ğ‘“ curves.
Apositivesecondderivativeleadstoaupwardscurve, whileanegativesec- ondderivativemeansthat ğ‘“ curvesdownwards, andazerosecondderivativemeansthat ğ‘“ doesnotcurveatall.
932 Mathematicsfor Deep Learning t Fig.
A.3 Ifweassumethesecondderivativeiszero, thenthefistderivativeisconstant, which impliesthefunctionitselfisastraightline.
Letâ€™stakethisonestepfurther.
Considerthefunctionğ‘”â€ğ‘¥â€ = ğ‘ğ‘¥2 â€šğ‘ğ‘¥ â€šğ‘.
Wecanthen computethat ğ‘‘ğ‘” â€ğ‘¥â€ =2ğ‘ğ‘¥â€šğ‘ ğ‘‘ğ‘¥ (A.14) ğ‘‘2ğ‘” â€ğ‘¥â€ =2ğ‘.
ğ‘‘ğ‘¥2 Ifwehavesomeoriginalfunction ğ‘“â€ğ‘¥â€ inmind, wemaycomputethefirsttwoderivatives and find the values for ğ‘,ğ‘, and ğ‘ that make them match this computation.
Similarly to the previous section where we saw that the first derivative gave the best approximation withastraightline, thisconstructionprovidesthebestapproximationbyaquadratic.
Letâ€™s visualizethisfor ğ‘“â€ğ‘¥â€ =sinâ€ğ‘¥â€.
# Compute sin xs = torch.
arange(-torch.
pi, torch.
pi, 0.01) plots = [torch.
sin(xs)] # Compute some quadratic approximations.
Use d(sin(x)) / dx = cos(x) for x0 in [-1.5, 0.0, 2.0]: plots.
append(torch.
sin(torch.
tensor(x0)) + (xs - x0) * torch.
cos(torch.
tensor(x0)) - (xs - x0)**2 * torch.
sin(torch.
tensor(x0)) / 2) d2l.
plot(xs, plots, 'x', 'f(x)', ylim=[-1.5, 1.5]) Wewillextendthisideatotheideaofa Taylorseriesinthenextsection.
933 Single Variable Calculus Taylor Series The Taylorseriesprovidesamethodtoappr oximatethefunction ğ‘“â€ğ‘¥â€ifwearegiven values 0 0 0 0 0 ideawillbetofindadegreeğ‘›polynomialthatmatchesallthegivenderivativesatğ‘¥ .
0 Wesawthecaseofğ‘›=2intheprevioussectionandalittlealgebrashowsthisis 1ğ‘‘2ğ‘“ ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€ â€ğ‘¥ â€â€ğ‘¥ ğ‘¥ â€2â€š â€ğ‘¥ â€â€ğ‘¥ ğ‘¥ â€â€š ğ‘“â€ğ‘¥ â€.
(A.15) 2 ğ‘‘ğ‘¥2 0 0 ğ‘‘ğ‘¥ 0 0 0 Aswecanseeabove, thedenominatorof2istheretocanceloutthe2wegetwhenwetake two derivatives of ğ‘¥2, while the other terms are all zero.
Same logic applies for the first derivativeandthevalueitself.
Ifwepushthelogicfurthertoğ‘›=3, wewillconcludethat ğ‘‘3ğ‘“â€ğ‘¥ â€ ğ‘‘2ğ‘“â€ğ‘¥ â€ ğ‘‘ğ‘“ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥3 0 â€ğ‘¥ ğ‘¥ â€3â€š ğ‘‘ğ‘¥2 0 â€ğ‘¥ ğ‘¥ â€2â€š â€ğ‘¥ â€â€ğ‘¥ ğ‘¥ â€â€š ğ‘“â€ğ‘¥ â€.
(A.16) 6 0 2 0 ğ‘‘ğ‘¥ 0 0 0 wherethe6=3 2=3! comesfromtheconstantwegetinfrontifwetakethreederivatives ofğ‘¥3.
Furthermore, wecangetadegreeğ‘›polynomialby ğ‘› ğ‘“â€ğ‘–â€â€ğ‘¥ â€ ğ‘ƒ ğ‘› â€ğ‘¥â€ = ğ‘–! 0 â€ğ‘¥ ğ‘¥ 0 â€ğ‘–.
(A.17) ğ‘–=0 wherethenotation ğ‘‘ğ‘›ğ‘“ ğ‘‘ ğ‘› ğ‘“â€ğ‘›â€â€ğ‘¥â€ = = ğ‘“.
(A.18) ğ‘‘ğ‘¥ğ‘› ğ‘‘ğ‘¥ Indeed,ğ‘ƒ ğ‘› â€ğ‘¥â€canbeviewedasthebestğ‘›-thdegreepolynomialapproximationtoourfunc- tion ğ‘“â€ğ‘¥â€.
Whilewearenot goingtodiveallthewayinto theerrorof theaboveapproximations, it isworthmentioningtheinfinitelimit.
Inthiscase, forwellbehavedfunctions(knownas realanalyticfunctions)likecosâ€ğ‘¥â€orğ‘’ğ‘¥ , wecanwriteouttheinfinitenumberoftermsand approximatetheexactlysamefunction 1 ğ‘“â€ğ‘›â€â€ğ‘¥ â€ ğ‘“â€ğ‘¥â€ = 0 â€ğ‘¥ ğ‘¥ â€ğ‘›.
(A.19) ğ‘›! 0 ğ‘›=0 Take ğ‘“â€ğ‘¥â€ =ğ‘’ğ‘¥ asamexample.
Sinceğ‘’ğ‘¥ isitsownderivative, weknowthat ğ‘“â€ğ‘›â€â€ğ‘¥â€ =ğ‘’ğ‘¥ .
Therefore,ğ‘’ğ‘¥ canbereconstructedbytakingthe Taylorseriesatğ‘¥ =0, i.
e., 0 1 ğ‘¥ğ‘› ğ‘¥2 ğ‘¥3 ğ‘’ğ‘¥ = =1â€šğ‘¥â€š â€š â€š .
(A.20) ğ‘›! 2 6 ğ‘›=0 Letâ€™s see how this works in code and observe how increasing the degree of the Taylor approximationbringsusclosertothedesiredfunctionğ‘’ğ‘¥ .
934 Mathematicsfor Deep Learning # Compute the exponential function xs = torch.
arange(0, 3, 0.01) ys = torch.
exp(xs) # Compute a few Taylor series approximations P1 = 1 + xs P2 = 1 + xs + xs**2 / 2 P5 = 1 + xs + xs**2 / 2 + xs**3 / 6 + xs**4 / 24 + xs**5 / 120 d2l.
plot(xs, [ys, P1, P2, P5], 'x', 'f(x)', legend=[ "Exponential", "Degree 1 Taylor Series", "Degree 2 Taylor Series", "Degree 5 Taylor Series"]) Taylorserieshavetwoprimaryapplications: 1.
Theoretical applications: Often when we try to understand a too complex function, using Taylorseriesenablesustoturnitintoapolynomialthatwecanworkwithdirectly.
2.
Numericalapplications: Somefunctionslikeğ‘’ğ‘¥ orcosâ€ğ‘¥â€ aredifficultformachinesto compute.
Theycanstoretablesofvaluesatafixedprecision(andthisisoftendone), but itstillleavesopenquestionslikeâ€œWhatisthe1000-thdigitofcosâ€1â€?â€ Taylorseries areoftenhelpfultoanswersuchquestions.
A.3.3 Summary Derivativescanbeusedtoexpresshowfunctionschangewhenwechangetheinputbya smallamount.
Elementaryderivativescanbecombinedusingderivativerulestocreatearbitrarilycom- plexderivatives.
Derivativescan be iterated to getsecond or higher order derivatives.
Eachincrease in orderprovidesmorefinegrainedinformationonthebehaviorofthefunction.
Usinginformationinthederivativesofasingledataexample, wecanapproximatewell behavedfunctionsbypolynomialsobtainedfromthe Taylorseries.
A.3.4 Exercises 1.
Whatisthederivativeofğ‘¥3 4ğ‘¥â€š1? 935 Multivariable Calculus 2.
Whatisthederivativeoflogâ€1â€? ğ‘¥ 3.
Trueor False: If ğ‘“0â€ğ‘¥â€ =0then ğ‘“ hasamaximumorminimumatğ‘¥? 4.
Whereistheminimumof ğ‘“â€ğ‘¥â€ =ğ‘¥logâ€ğ‘¥â€forğ‘¥ 0(whereweassumethat ğ‘“ takesthe limitingvalueof0at ğ‘“â€0â€)? Discussions282.
282 A.4 Multivariable Calculus Now that we have a fairly strong understanding of derivatives of a function of a single variable, letâ€™sreturntoouroriginalquestionwherewewereconsideringalossfunctionof potentiallybillionsofweights.
A.4.1 Higher-Dimensional Differentiation What Section A.3 tells us is that if we change a single one of these billions of weights leaving every other one fixed, we know what will happen! This is nothing more than a functionofasinglevariable, sowecanwrite ğ‘‘ 1 Wewillcallthederivativeinonevariablewhilefixingtheothervariablesthepartialderiva- ğœ• tive, andwewillusethenotation forthederivativein(A.1).
ğœ•ğ‘¤ 1 Now, letâ€™stakethisandchangeğ‘¤ alittlebittoğ‘¤ â€šğœ– : 2 2 2 ğœ• 1 1 2 2 ğ‘ 1 2 2 ğ‘ 1ğœ•ğ‘¤ 1 2 2 ğ‘ ğ‘ 1 ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 1 2 ğ‘ ğœ• â€šğœ– ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 2ğœ•ğ‘¤ 1 2 ğ‘ 2 ğœ• â€šğœ– ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 1ğœ•ğ‘¤ 1 2 ğ‘ 1 ğœ• ğœ• â€šğœ– ğœ– ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 1 2ğœ•ğ‘¤ ğœ•ğ‘¤ 1 2 ğ‘ 2 1 ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 1 2 ğ‘ ğœ• â€šğœ– ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€ 2ğœ•ğ‘¤ 1 2 ğ‘ 2 ğœ• â€šğœ– ğ¿â€ğ‘¤ ,ğ‘¤ ,...,ğ‘¤ â€.
1ğœ•ğ‘¤ 1 2 ğ‘ 1 (A.2) Wehaveagainusedtheideathatğœ– ğœ– isahigherordertermthatwecandiscardinthesame 1 2 936 Mathematicsfor Deep Learning way we could discard ğœ–2 in the previous section, along with what we saw in (A.1).
By continuinginthismanner, wemaywritethat ğœ• 1 1 2 2 ğ‘ ğ‘ 1 2 ğ‘ ğ‘–ğœ•ğ‘¤ 1 2 ğ‘ ğ‘– ğ‘– (A.3) Thismaylooklikeamess, butwecanmakethismorefamiliarbynotingthatthesumon therightlooksexactlylikeadotproduct, soifwelet ğœ•ğ¿ ğœ•ğ¿ > 1 ğ‘ then ğ¿â€wâ€šğâ€ ğ¿â€wâ€â€šğ r ğ¿â€wâ€.
(A.5) w Wewillcallthevectorr ğ¿thegradientofğ¿.
w Equation(A.5)isworthponderingforamoment.
Ithasexactlytheformatthatweencoun- tered in one dimension, just we have converted everything to vectors and dot products.
It allows us to tell approximately how the function ğ¿ will change given any perturbation to the input.
As we will see in the next section, this will provide us with an important toolinunderstandinggeometricallyhowwecanlearnusinginformationcontainedinthe gradient.
Butfirst, letâ€™sseethisapproximationatworkwithanexample.
Supposethatweareworking withthefunction ğ‘’ğ‘¥ ğ‘’ğ‘¦ ğ‘“â€ğ‘¥,ğ‘¦â€ =logâ€ğ‘’ğ‘¥ â€šğ‘’ğ‘¦â€withgradientrğ‘“â€ğ‘¥,ğ‘¦â€ = , .
(A.6) ğ‘’ğ‘¥ â€šğ‘’ğ‘¦ ğ‘’ğ‘¥ â€šğ‘’ğ‘¦ Ifwelookatapointlikeâ€0, logâ€2â€â€, weseethat 1 2 ğ‘“â€ğ‘¥,ğ‘¦â€ =logâ€3â€withgradientrğ‘“â€ğ‘¥,ğ‘¦â€ = , .
(A.7) 3 3 Thus, if we want to approximate ğ‘“ at â€ğœ– , logâ€2â€ â€š ğœ– â€, we see that we should have the 1 2 specificinstanceof(A.5): 1 2 ğ‘“â€ğœ– , logâ€2â€â€šğœ– â€ logâ€3â€â€š ğœ– â€š ğœ– .
(A.8) 1 2 1 2 3 3 Wecantestthisincodetoseehowgoodtheapproximationis.
%matplotlib inline import numpy as np import torch from IPython import display from mpl_toolkits import mplot3d from d2l import torch as d2l def f(x, y): (continuesonnextpage) 937 Multivariable Calculus (continuedfrompreviouspage) return torch.
log(torch.
exp(x) + torch.
exp(y)) def grad_f(x, y): return torch.
tensor([torch.
exp(x) / (torch.
exp(x) + torch.
exp(y)), torch.
exp(y) / (torch.
exp(x) + torch.
exp(y))]) epsilon = torch.
tensor([0.01, -0.03]) grad_approx = f(torch.
tensor([0.]), torch.
log( torch.
tensor([2.]))) + epsilon.
dot( true_value = f(torch.
tensor([0.]) + epsilon[0], torch.
log( torch.
tensor([2.])) + epsilon[1]) f'approximation: {grad_approx}, true Value: {true_value}' 'approximation: tensor([1.0819]), true Value: tensor([1.0821])' A.4.2 Geometryof Gradientsand Gradient Descent Considertheexpressionfrom(A.5)again: ğ¿â€wâ€šğâ€ ğ¿â€wâ€â€šğ r ğ¿â€wâ€.
(A.9) w Letâ€™ssupposethat Iwanttousethistohelpminimizeourlossğ¿.
Letâ€™sunderstandgeomet- ricallythealgorithmofgradientdescentfirstdescribedin Section2.5.
Whatwewilldois thefollowing: 1.
Startwitharandomchoicefortheinitialparametersw.
2.
Findthedirectionvthatmakesğ¿decreasethemostrapidlyatw.
3.
Takeasmallstepinthatdirection: w! wâ€šğœ–v.
4.
Repeat.
Theonlythingwedonotknowexactlyhowtodoistocomputethevectorvinthesecond step.
Wewillcallsuchadirectionthedirectionofsteepestdescent.
Usingthegeometric understandingofdotproductsfrom Section A.1, weseethatwecanrewrite(A.5)as ğ¿â€wâ€švâ€ ğ¿â€wâ€â€šv r ğ¿â€wâ€ = ğ¿â€wâ€â€škr ğ¿â€wâ€kcosâ€ğœƒâ€.
(A.10) w w Notethatwehavetakenourdirectiontohavelengthoneforconvenience, andused ğœƒ for the angle between v and r ğ¿â€wâ€.
If we want to find the direction that decreases ğ¿ as w rapidlyaspossible, wewanttomakethisexpressionasnegativeaspossible.
Theonlyway thedirectionwepickentersintothisequationisthroughcosâ€ğœƒâ€, andthuswewishtomake thiscosineasnegativeaspossible.
Now, recallingtheshapeofcosine, wecanmakethisas negativeaspossiblebymakingcosâ€ğœƒâ€ = 1orequivalentlymakingtheanglebetweenthe gradientandourchosendirectiontobe ğœ‹ radians, orequivalently180degrees.
Theonly waytoachievethisistoheadintheexactoppositedirection: pickv topointintheexact oppositedirectiontor ğ¿â€wâ€! w This brings us to one of the most important mathematical concepts in machine learning: 938 Mathematicsfor Deep Learning the direction of steepest decent points in the direction of r ğ¿â€wâ€.
Thus our informal w algorithmcanberewrittenasfollows.
1.
Startwitharandomchoicefortheinitialparametersw.
2.
Computer ğ¿â€wâ€.
w 3.
Takeasmallstepintheoppositeofthatdirection: w w ğœ–r ğ¿â€wâ€.
w 4.
Repeat.
Thisbasicalgorithmhasbeenmodifiedandadaptedmanywaysbymanyresearchers, but thecoreconceptremainsthesameinallofthem.
Usethegradienttofindthedirectionthat decreasesthelossasrapidlyaspossible, andupdatetheparameterstotakeastepinthat direction.
A.4.3 ANoteon Mathematical Optimization Throughoutthisbook, wefocussquarelyonnumericaloptimizationtechniquesfortheprac- ticalreasonthatallfunctionsweencounterinthedeeplearningsettingaretoocomplexto minimizeexplicitly.
However, itisausefulexercisetoconsiderwhatthegeometricunderstandingweobtained abovetellsusaboutoptimizingfunctionsdirectly.
Supposethatwewishtofindthevalueofx whichminimizessomefunction ğ¿â€xâ€.
Letâ€™s 0 supposethatmoreoversomeonegivesusavalueandtellsusthatitisthevaluethatmini- mizesğ¿.
Isthereanythingwecanchecktoseeiftheiranswerisevenplausible? Againconsider(A.5): ğ¿â€x â€šğâ€ ğ¿â€x â€â€šğ r ğ¿â€x â€.
(A.11) 0 0 x 0 Ifthegradientisnotzero, weknowthatwecantakeastepinthedirection ğœ–r ğ¿â€x â€ to x 0 find a value of ğ¿ that is smaller.
Thus, if we truly are at a minimum, this cannot be the case! Wecanconcludethatifx isaminimum, thenr ğ¿â€x â€ = 0.
Wecallpointswith 0 x 0 r ğ¿â€x â€ =0criticalpoints.
x 0 Thisisnice, becauseinsomeraresettings, wecanexplicitlyfindallthepointswherethe gradientiszero, andfindtheonewiththesmallestvalue.
Foraconcreteexample, considerthefunction ğ‘“â€ğ‘¥â€ =3ğ‘¥4 4ğ‘¥3 12ğ‘¥2.
(A.12) Thisfunctionhasderivative ğ‘‘ğ‘“ =12ğ‘¥3 12ğ‘¥2 24ğ‘¥ =12ğ‘¥â€ğ‘¥ 2â€â€ğ‘¥â€š1â€.
(A.13) ğ‘‘ğ‘¥ The only possible location of minima are at ğ‘¥ = 1,0,2, where the function takes the values 5,0, 32 respectively, and thus we can conclude that we minimize our function whenğ‘¥ =2.
Aquickplotconfirmsthis.
939 Multivariable Calculus x = torch.
arange(-2, 3, 0.01) f = (3 * x**4) - (4 * x**3) - (12 * x**2) d2l.
plot(x, f, 'x', 'f(x)') Thishighlightsanimportantfacttoknowwhenworkingeithertheoreticallyornumerically: theonlypossiblepointswherewecanminimize(ormaximize)afunctionwillhavegradient equaltozero, however, noteverypointwithgradientzeroisthetrueglobalminimum(or maximum).
A.4.4 Multivariate Chain Rule Letâ€™ssupposethatwehaveafunctionoffourvariables(ğ‘¤,ğ‘¥,ğ‘¦, andğ‘§)whichwecanmake bycomposingmanyterms: ğ‘“â€ğ‘¢,ğ‘£â€ = â€ğ‘¢â€šğ‘£â€2 ğ‘¢â€ğ‘,ğ‘â€ = â€ğ‘â€šğ‘â€2, ğ‘£â€ğ‘,ğ‘â€ = â€ğ‘ ğ‘â€2, (A.14) ğ‘â€ğ‘¤,ğ‘¥,ğ‘¦,ğ‘§â€ = â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2, ğ‘â€ğ‘¤,ğ‘¥,ğ‘¦,ğ‘§â€ = â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2.
Such chains of equations are common when working with neural networks, so trying to understandhowtocomputegradientsofsuchfunctionsiskey.
Wecanstarttoseevisual hintsofthisconnectionin Fig.
A.1ifwetakealookatwhatvariablesdirectlyrelatetoone another.
t Fig.
A.1 Thefunctionrelationsabovewherenodesrepresentvaluesandedgesshowfunctional dependence.
Nothingstopsusfromjustcomposingeverythingfrom(A.14)andwritingoutthat 2 2 2 ğ‘“â€ğ‘¤,ğ‘¥,ğ‘¦,ğ‘§â€ = â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2â€šâ€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2 â€š â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2 â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2 .
(A.15) 940 Mathematicsfor Deep Learning Wemaythentakethederivativebyjustusingsinglevariablederivatives, butifwedidthat we would quickly find ourself swamped with terms, many of which are repeats! Indeed, onecanseethat, forinstance: ğœ•ğ‘“ =2 2â€2â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€ 2â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€â€ â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2 â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2 â€š ğœ•ğ‘¤ 2â€2â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€â€š2â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€â€ â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2â€šâ€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2 2 2 â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2 â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2 â€š â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2â€šâ€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2 .
(A.16) ğœ•ğ‘“ Ifwethenalsowantedtocompute , wewouldendupwithasimilarequationagainwith ğœ•ğ‘¥ manyrepeatedterms, andmanyshared repeatedtermsbetweenthetwoderivatives.
This representsamassivequantityofwastedwork, andifweneededtocomputederivativesthis way, thewholedeeplearningrevolutionwouldhavestalledoutbeforeitbegan! Letâ€™sbreakuptheproblem.
Wewillstartbytryingtounderstandhow ğ‘“ changeswhenwe change ğ‘, essentially assuming that ğ‘¤,ğ‘¥,ğ‘¦, and ğ‘§ all do not exist.
We will reason as we didbackwhenweworkedwiththegradientforthefirsttime.
Letâ€™stakeğ‘andaddasmall amountğœ– toit.
ğ‘“â€ğ‘¢â€ğ‘â€šğœ–,ğ‘â€,ğ‘£â€ğ‘â€šğœ–,ğ‘â€â€ ğœ•ğ‘¢ ğœ•ğ‘£ ğ‘“ ğ‘¢â€ğ‘,ğ‘â€â€šğœ– â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€šğœ– â€ğ‘,ğ‘â€ ğœ•ğ‘ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘£ ğ‘“â€ğ‘¢â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€â€šğœ– â€ğ‘¢â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€ â€ğ‘,ğ‘â€â€š â€ğ‘¢â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€ â€ğ‘,ğ‘â€ .
ğœ•ğ‘¢ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘ (A.17) Thefirstlinefollowsfromthedefinitionofpartialderivative, andthesecondfollowsfrom thedefinitionofgradient.
Itisnotationallyburdensometotrackexactlywhereweevaluate everyderivative, asintheexpression ğœ•ğ‘“â€ğ‘¢â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€, soweoftenabbreviatethisto ğœ•ğ‘¢ themuchmorememorable ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘£ = â€š .
(A.18) ğœ•ğ‘ ğœ•ğ‘¢ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘ It is useful to think about the meaning of the process.
We are trying to understand how a function of the form ğ‘“â€ğ‘¢â€ğ‘,ğ‘â€,ğ‘£â€ğ‘,ğ‘â€â€ changes its value with a change in ğ‘.
There are two pathways this can occur: there is the pathway where ğ‘ ! ğ‘¢ ! ğ‘“ and where ğ‘ ! ğ‘£ ! ğ‘“.
Wecancomputebothofthesecontributionsviathechainrule: ğœ•ğ‘¤ ğœ•ğ‘¢ and ğœ•ğ‘¢ ğœ•ğ‘¥ ğœ•ğ‘¤ ğœ•ğ‘£ respectively, andaddedup.
ğœ•ğ‘£ ğœ•ğ‘¥ Imaginewehaveadifferentnetworkoffunctionswherethefunctionsontherightdepend onthosethatareconnectedtoontheleftasisshownin Fig.
A.2.
t Fig.
A.2 Anothermoresubtleexampleofthechainrule.
941 Multivariable Calculus Tocomputesomethinglike ğœ•ğ‘“ , weneedtosumoverall(inthiscase3)pathsfrom ğ‘¦ to ğ‘“ ğœ•ğ‘¦ giving ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘ ğœ•ğ‘£ = â€š â€š .
(A.19) ğœ•ğ‘¦ ğœ•ğ‘ ğœ•ğ‘¢ ğœ•ğ‘¦ ğœ•ğ‘¢ ğœ•ğ‘¦ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘¦ Understandingthechainruleinthiswaywillpaygreatdividendswhentryingtounderstand howgradientsflowthroughnetworks, andwhyvariousarchitecturalchoiceslikethosein LSTMs(Section10.1)orresiduallayers(Section8.6)canhelpshapethelearningprocess bycontrollinggradientflow.
A.4.5 The Backpropagation Algorithm Letâ€™sreturntotheexampleof(A.14)theprevioussectionwhere ğ‘“â€ğ‘¢,ğ‘£â€ = â€ğ‘¢â€šğ‘£â€2 ğ‘¢â€ğ‘,ğ‘â€ = â€ğ‘â€šğ‘â€2, ğ‘£â€ğ‘,ğ‘â€ = â€ğ‘ ğ‘â€2, (A.20) ğ‘â€ğ‘¤,ğ‘¥,ğ‘¦,ğ‘§â€ = â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€2, ğ‘â€ğ‘¤,ğ‘¥,ğ‘¦,ğ‘§â€ = â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€2.
ğœ•ğ‘“ Ifwewanttocomputesay wemayapplythemulti-variatechainruletosee: ğœ•ğ‘¤ ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘£ = â€š , ğœ•ğ‘¤ ğœ•ğ‘¢ ğœ•ğ‘¤ ğœ•ğ‘£ ğœ•ğ‘¤ ğœ•ğ‘¢ ğœ•ğ‘¢ ğœ•ğ‘ ğœ•ğ‘¢ ğœ•ğ‘ = â€š , (A.21) ğœ•ğ‘¤ ğœ•ğ‘ğœ•ğ‘¤ ğœ•ğ‘ğœ•ğ‘¤ ğœ•ğ‘£ ğœ•ğ‘£ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘ = â€š .
ğœ•ğ‘¤ ğœ•ğ‘ğœ•ğ‘¤ ğœ•ğ‘ğœ•ğ‘¤ ğœ•ğ‘“ Letâ€™s try using this decomposition to compute .
Notice that all we need here are the ğœ•ğ‘¤ varioussinglesteppartials: ğœ•ğ‘“ ğœ•ğ‘“ =2â€ğ‘¢â€šğ‘£â€, =2â€ğ‘¢â€šğ‘£â€, ğœ•ğ‘¢ ğœ•ğ‘£ ğœ•ğ‘¢ ğœ•ğ‘¢ =2â€ğ‘â€šğ‘â€, =2â€ğ‘â€šğ‘â€, ğœ•ğ‘ ğœ•ğ‘ (A.22) ğœ•ğ‘£ ğœ•ğ‘£ =2â€ğ‘ ğ‘â€, = 2â€ğ‘ ğ‘â€, ğœ•ğ‘ ğœ•ğ‘ ğœ•ğ‘ ğœ•ğ‘ =2â€ğ‘¤â€šğ‘¥â€šğ‘¦â€šğ‘§â€, =2â€ğ‘¤â€šğ‘¥ ğ‘¦ ğ‘§â€.
ğœ•ğ‘¤ ğœ•ğ‘¤ Ifwewritethisoutintocodethisbecomesafairlymanageableexpression.
# Compute the value of the function from inputs to outputs w, x, y, z = -1, 0, -2, 1 a, b = (w + x + y + z)**2, (w + x - y - z)**2 u, v = (a + b)**2, (a - b)**2 f = (u + v)**2 print(f' f at {w}, {x}, {y}, {z} is {f}') # Compute the single step partials df_du, df_dv = 2*(u + v), 2*(u + v) (continuesonnextpage) 942 Mathematicsfor Deep Learning (continuedfrompreviouspage) du_da, du_db, dv_da, dv_db = 2*(a + b), 2*(a + b), 2*(a - b), -2*(a - b) da_dw, db_dw = 2*(w + x + y + z), 2*(w + x - y - z) # Compute the final result from inputs to outputs du_dw, dv_dw = du_da*da_dw + du_db*db_dw, dv_da*da_dw + dv_db*db_dw df_dw = df_du*du_dw + df_dv*dv_dw print(f'df/dw at {w}, {x}, {y}, {z} is {df_dw}') f at -1, 0, -2, 1 is 1024 df/dw at -1, 0, -2, 1 is -4096 ğœ•ğ‘“ However, note that this still does not make it easy to compute something like .
The ğœ•ğ‘¥ reasonforthatisthewaywechosetoapplythechainrule.
Ifwelookatwhatwedidabove, wealwayskeptğœ•ğ‘¤ inthedenominatorwhenwecould.
Inthisway, wechosetoapplythe chainruleseeinghowğ‘¤changedeveryothervariable.
Ifthatiswhatwewanted, thiswould beagoodidea.
However, thinkbacktoourmotivationfromdeeplearning: wewanttosee howeveryparameterchangestheloss.
Inessence, wewanttoapplythechainrulekeeping ğœ•ğ‘“ inthenumeratorwheneverwecan! Tobemoreexplicit, notethatwecanwrite ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘ = â€š , ğœ•ğ‘¤ ğœ•ğ‘ ğœ•ğ‘¤ ğœ•ğ‘ ğœ•ğ‘¤ ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘£ = â€š , (A.23) ğœ•ğ‘ ğœ•ğ‘¢ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘¢ ğœ•ğ‘“ ğœ•ğ‘£ = â€š .
ğœ•ğ‘ ğœ•ğ‘¢ ğœ•ğ‘ ğœ•ğ‘£ ğœ•ğ‘ Notethatthisapplicationofthechainrulehasusexplicitlycompute ğœ•ğ‘“, ğœ•ğ‘“, ğœ•ğ‘“, ğœ•ğ‘“, and ğœ•ğ‘“ .
ğœ•ğ‘¢ ğœ•ğ‘£ ğœ•ğ‘ ğœ•ğ‘ ğœ•ğ‘¤ Nothingstopsusfromalsoincludingtheequations: ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘ = â€š , ğœ•ğ‘¥ ğœ•ğ‘ ğœ•ğ‘¥ ğœ•ğ‘ ğœ•ğ‘¥ ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘ = â€š , (A.24) ğœ•ğ‘¦ ğœ•ğ‘ ğœ•ğ‘¦ ğœ•ğ‘ ğœ•ğ‘¦ ğœ•ğ‘“ ğœ•ğ‘“ ğœ•ğ‘ ğœ•ğ‘“ ğœ•ğ‘ = â€š .
ğœ•ğ‘§ ğœ•ğ‘ ğœ•ğ‘§ ğœ•ğ‘ ğœ•ğ‘§ andthenkeepingtrackofhow ğ‘“ changeswhenwechangeanynodeintheentirenetwork.
Letâ€™simplementit.
# Compute the value of the function from inputs to outputs w, x, y, z = -1, 0, -2, 1 a, b = (w + x + y + z)**2, (w + x - y - z)**2 u, v = (a + b)**2, (a - b)**2 f = (u + v)**2 print(f'f at {w}, {x}, {y}, {z} is {f}') # Compute the derivative using the decomposition above (continuesonnextpage) 943 Multivariable Calculus (continuedfrompreviouspage) # First compute the single step partials df_du, df_dv = 2*(u + v), 2*(u + v) du_da, du_db, dv_da, dv_db = 2*(a + b), 2*(a + b), 2*(a - b), -2*(a - b) da_dw, db_dw = 2*(w + x + y + z), 2*(w + x - y - z) da_dx, db_dx = 2*(w + x + y + z), 2*(w + x - y - z) da_dy, db_dy = 2*(w + x + y + z), -2*(w + x - y - z) da_dz, db_dz = 2*(w + x + y + z), -2*(w + x - y - z) # Now compute how f changes when we change any value from output to input df_da, df_db = df_du*du_da + df_dv*dv_da, df_du*du_db + df_dv*dv_db df_dw, df_dx = df_da*da_dw + df_db*db_dw, df_da*da_dx + df_db*db_dx df_dy, df_dz = df_da*da_dy + df_db*db_dy, df_da*da_dz + df_db*db_dz print(f'df/dw at {w}, {x}, {y}, {z} is {df_dw}') print(f'df/dx at {w}, {x}, {y}, {z} is {df_dx}') print(f'df/dy at {w}, {x}, {y}, {z} is {df_dy}') print(f'df/dz at {w}, {x}, {y}, {z} is {df_dz}') f at -1, 0, -2, 1 is 1024 df/dw at -1, 0, -2, 1 is -4096 df/dx at -1, 0, -2, 1 is -4096 df/dy at -1, 0, -2, 1 is -4096 df/dz at -1, 0, -2, 1 is -4096 Thefactthatwecomputederivativesfrom ğ‘“ backtowardstheinputsratherthanfromthe inputsforwardtotheoutputs(aswedidinthefirstcodesnippetabove)iswhatgivesthis algorithmitsname: backpropagation.
Notethattherearetwosteps: 1.
Computethevalue ofthefunction, andthesinglesteppartialsfromfronttoback.
Whilenotdoneabove, this canbecombinedintoasingleforwardpass.
2.
Computethegradientof ğ‘“ frombackto front.
Wecallthisthebackwardspass.
Thisispreciselywhateverydeeplearningalgorithmimplementstoallowthecomputation ofthegradientofthelosswithrespecttoeveryweightinthenetworkatonepass.
Itisan astonishingfactthatwehavesuchadecomposition.
Toseehowtoencapsulatedthis, letâ€™stakeaquicklookatthisexample.
# Initialize as ndarrays, then attach gradients w = torch.
tensor([-1.], requires_grad=True) x = torch.
tensor([0.], requires_grad=True) y = torch.
tensor([-2.], requires_grad=True) z = torch.
tensor([1.], requires_grad=True) # Do the computation like usual, tracking gradients a, b = (w + x + y + z)**2, (w + x - y - z)**2 u, v = (a + b)**2, (a - b)**2 f = (u + v)**2 # Execute backward pass f.
backward() (continuesonnextpage) 944 Mathematicsfor Deep Learning (continuedfrompreviouspage) Allofwhatwedidabovecanbedoneautomaticallybycallingf.
backwards().
A.4.6 Hessians Aswithsinglevariablecalculus, itisusefultoconsiderhigher-orderderivativesinorder togetahandleonhowwecanobtainabetterapproximationtoafunctionthanusingthe gradientalone.
Thereisoneimmediateproblemoneencounterswhenworkingwithhigherorderderiva- tivesoffunctionsofseveralvariables, andthatistherearealargenumberofthem.
Ifwe haveafunction ğ‘“â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘› â€ofğ‘›variables, thenwecantakeğ‘›2manysecondderivatives, namelyforanychoiceofğ‘–and ğ‘—: ğ‘‘2ğ‘“ ğ‘‘ ğ‘‘ = ğ‘“ .
(A.25) ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘– ğ‘— ğ‘– ğ‘— Thisistraditionallyassembledintoamatrixcalledthe Hessian: 2 6 ğ‘‘2ğ‘“ ğ‘‘2ğ‘“ 3 7 6 7 6 ğ‘‘2ğ‘“ ğ‘‘2ğ‘“ 7 4ğ‘‘ğ‘¥ğ‘›ğ‘‘ğ‘¥ 1 ğ‘‘ğ‘¥ğ‘›ğ‘‘ğ‘¥ğ‘› 5 Not every entry of this matrix is independent.
Indeed, we can show that as long as both mixed partials (partial derivatives with respect to more than one variable) exist and are continuous, wecansaythatforanyğ‘–, and ğ‘—, ğ‘‘2ğ‘“ ğ‘‘2ğ‘“ = .
(A.27) ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘– ğ‘— ğ‘— ğ‘– Thisfollowsbyconsideringfirstperturbingafunctioninthedirectionofğ‘¥ ğ‘–, andthenper- turbingitinğ‘¥ ğ‘— andthencomparingtheresultofthatwithwhathappensifweperturbfirst ğ‘¥ ğ‘— andthenğ‘¥ ğ‘–, withtheknowledgethatbothoftheseordersleadtothesamefinalchange intheoutputof ğ‘“.
As with single variables, we can use these derivatives to get a far better idea of how the 945 Multivariable Calculus functionbehavesnearapoint.
Inparticular, wecanuseittofindthebestfittingquadratic nearapointx , aswesawinasinglevariable.
0 Letâ€™sseeanexample.
Supposethat ğ‘“â€ğ‘¥ ,ğ‘¥ â€ =ğ‘â€šğ‘ ğ‘¥ â€šğ‘ ğ‘¥ â€šğ‘ ğ‘¥2â€šğ‘ ğ‘¥ ğ‘¥ â€šğ‘ ğ‘¥2.
1 2 1 1 2 2 11 1 12 1 2 22 2 This is the general form for a quadratic in two variables.
If we look at the value of the function, itsgradient, andits Hessian(A.26), allatthepointzero: ğ‘“â€0,0â€ =ğ‘, ğ‘ rğ‘“â€0,0â€ = 1 , ğ‘ (A.28) 2 2ğ‘ ğ‘ Hğ‘“â€0,0â€ = 11 12 , ğ‘ 2ğ‘ 12 22 wecangetouroriginalpolynomialbackbysaying 1 ğ‘“â€xâ€ = ğ‘“â€0â€â€šrğ‘“â€0â€ xâ€š x > Hğ‘“â€0â€x.
(A.29) 2 Ingeneral, ifwecomputedthisexpansionanypointx , weseethat 0 1 ğ‘“â€xâ€ = ğ‘“â€x â€â€šrğ‘“â€x â€ â€x x â€â€š â€x x â€> Hğ‘“â€x â€â€x x â€.
(A.30) 0 0 0 0 0 0 2 Thisworksforanydimensionalinput, andprovidesthebestapproximatingquadratictoany functionatapoint.
Togiveanexample, letâ€™splotthefunction ğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘¥ğ‘’ ğ‘¥2 ğ‘¦2.
(A.31) Onecancomputethatthegradientand Hessianare rğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘’ ğ‘¥2 ğ‘¦2 1 2ğ‘¥2 and Hğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘’ ğ‘¥2 ğ‘¦2 4ğ‘¥3 6ğ‘¥ 4ğ‘¥2ğ‘¦ 2ğ‘¦ .
2ğ‘¥ğ‘¦ 4ğ‘¥2ğ‘¦ 2ğ‘¦ 4ğ‘¥ğ‘¦2 2ğ‘¥ (A.32) Andthus, withalittlealgebra, seethattheapproximatingquadraticat Â» 1,0â€¦> is ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘’ 1 1 â€ğ‘¥â€š1â€â€šâ€ğ‘¥â€š1â€2â€šğ‘¦2 .
(A.33) # Construct grid and compute function x, y = torch.
meshgrid(torch.
linspace(-2, 2, 101), torch.
linspace(-2, 2, 101)) z = x*torch.
exp(- x**2 - y**2) # Compute approximating quadratic with gradient and Hessian at (1, 0) w = torch.
exp(torch.
tensor([-1.]))*(-1 - (x + 1) + 2 * (x + 1)**2 + 2 * y**2) # Plot function ax = d2l.
plt.
figure().
add_subplot(111, projection='3d') ax.
plot_wireframe(x.
numpy(), y.
numpy(), z.
numpy(), **{'rstride': 10, 'cstride': 10}) ax.
plot_wireframe(x.
numpy(), y.
numpy(), w.
numpy(), **{'rstride': 10, 'cstride': 10}, color='purple') (continuesonnextpage) 946 Mathematicsfor Deep Learning (continuedfrompreviouspage) d2l.
plt.
xlabel('x') d2l.
plt.
ylabel('y') d2l.
set_figsize() ax.
set_xlim(-2, 2) ax.
set_ylim(-2, 2) ax.
set_zlim(-1, 1) ax.
dist = 12 Thisformsthebasisfor Newtonâ€™s Algorithmdiscussedin Section12.3, whereweperform numericaloptimizationiterativelyfindingthebestfittingquadratic, andthenexactlymini- mizingthatquadratic.
A.4.7 ALittle Matrix Calculus Derivatives of functions involving matrices turn out to be particularly nice.
This section canbecomenotationallyheavy, somaybeskippedinafirstreading, butitisusefultoknow howderivativesoffunctionsinvolvingcommonmatrixoperationsareoftenmuchcleaner thanonemightinitiallyanticipate, particularlygivenhowcentralmatrixoperationsareto deeplearningapplications.
Letâ€™sbeginwithanexample.
Supposethatwehavesomefixedcolumnvector ğœ·, andwe wanttotaketheproductfunction ğ‘“â€xâ€ = ğœ·> x, andunderstandhowthedotproductchanges whenwechangex.
Abitofnotationthatwillbeusefulwhenworkingwithmatrixderivativesin MLiscalled the denominator layout matrix derivative where we assemble our partial derivatives into theshapeofwhatevervector, matrix, ortensorisinthedenominatorofthedifferential.
In thiscase, wewillwrite 2 ğ‘‘ğ‘“ 3 6 7 ğ‘‘ğ‘“ = 6 6 6 ğ‘‘ .
.
.
ğ‘¥ 17 7 7 , (A.34) ğ‘‘x 6 7 6 ğ‘‘ğ‘“ 7 4ğ‘‘ğ‘¥ğ‘› 5 wherewematchedtheshapeofthecolumnvectorx.
Ifwewriteoutourfunctionintocomponentsthisis ğ‘› ğ‘“â€xâ€ = ğ›½ ğ‘– ğ‘¥ ğ‘– = ğ›½ 1 ğ‘¥ 1 â€š â€šğ›½ ğ‘› ğ‘¥ ğ‘› .
(A.35) ğ‘–=1 947 Multivariable Calculus Ifwenowtakethepartialderivativewithrespecttosayğ›½ , notethateverythingiszerobut 1 thefirstterm, whichisjustğ‘¥ multipliedby ğ›½ , soweobtainthat 1 1 ğ‘‘ğ‘“ = ğ›½ , (A.36) ğ‘‘ğ‘¥ 1 1 ormoregenerallythat ğ‘‘ğ‘“ ğ‘‘ğ‘¥ = ğ›½ ğ‘– .
(A.37) ğ‘– Wecannowreassemblethisintoamatrixtosee Thisillustratesafewfactorsaboutmatrixcalculusthatwewilloftencounterthroughout thissection: First, Thecomputationswillgetratherinvolved.
Second, The final results are much cleaner than the intermediate process, and will al- wayslooksimilartothesinglevariablecase.
Inthiscase, notethat ğ‘‘ â€ğ‘ğ‘¥â€ = ğ‘ and ğ‘‘ğ‘¥ ğ‘‘ â€ğœ·> xâ€ = ğœ·arebothsimilar.
ğ‘‘x Third, transposescanoftenappearseeminglyfromnowhere.
Thecorereasonforthisis the convention that we match the shape of the denominator, thus when we multiply matrices, wewill needto taketransposesto matchbacktothe shapeof theoriginal term.
Tokeepbuildingintuition, letâ€™stryacomputationthatisalittleharder.
Supposethatwe haveacolumnvectorx, andasquarematrix ğ´andwewanttocompute ğ‘‘ â€x >ğ´xâ€.
(A.39) ğ‘‘x Todrivetowardseasiertomanipulatenotation, letâ€™sconsiderthisproblemusing Einstein notation.
Inthiscasewecanwritethefunctionas x >ğ´x=ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— .
(A.40) Tocomputeourderivative, weneedtounderstandforeveryğ‘˜, whatisthevalueof ğ‘‘ ğ‘‘ ğ‘‘ğ‘¥ â€x >ğ´xâ€ = ğ‘‘ğ‘¥ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— .
(A.41) ğ‘˜ ğ‘˜ Bytheproductrule, thisis ğ‘‘ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— = ğ‘‘ğ‘¥ ğ‘–ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— â€šğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘—ğ‘‘ğ‘¥ ğ‘— .
(A.42) ğ‘˜ ğ‘˜ ğ‘˜ For a term like ğ‘‘ğ‘¥ğ‘–, it is not hard to see that this is one whenğ‘– = ğ‘˜ and zero otherwise.
ğ‘‘ğ‘¥ğ‘˜ Thismeansthateverytermwhereğ‘– and ğ‘˜ aredifferentvanishfromthissum, sotheonly 948 Mathematicsfor Deep Learning termsthatremaininthatfirstsumaretheoneswhereğ‘– = ğ‘˜.
Thesamereasoningholdsfor thesecondtermwhereweneed ğ‘— = ğ‘˜.
Thisgives ğ‘‘ ğ‘‘ğ‘¥ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— =ğ‘ ğ‘˜ğ‘— ğ‘¥ ğ‘— â€šğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘˜ .
(A.43) ğ‘˜ Now, thenamesoftheindicesin Einsteinnotationarearbitraryâ€”thefactthatğ‘– and ğ‘— are differentisimmaterialtothiscomputationatthispoint, sowecanre-indexsothattheyboth useğ‘–toseethat ğ‘‘ ğ‘‘ğ‘¥ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— =ğ‘ ğ‘˜ğ‘– ğ‘¥ ğ‘– â€šğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘˜ = â€ğ‘ ğ‘˜ğ‘– â€šğ‘ ğ‘–ğ‘˜ â€ğ‘¥ ğ‘– .
(A.44) ğ‘˜ Now, hereiswherewestarttoneedsomepracticetogofurther.
Letâ€™stryandidentifythis outcomeintermsofmatrixoperations.
ğ‘ ğ‘˜ğ‘– â€šğ‘ ğ‘–ğ‘˜ istheğ‘˜,ğ‘–-thcomponentof Aâ€šA> .
This gives ğ‘‘ ğ‘‘ğ‘¥ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— = Â»Aâ€šA >â€¦ ğ‘˜ğ‘– ğ‘¥ ğ‘– .
(A.45) ğ‘˜ Similarly, this term is now the product of the matrix Aâ€šA> by the vector x, so we see that ğ‘‘ ğ‘‘ ğ‘‘x â€x >ğ´xâ€ ğ‘˜ = ğ‘‘ğ‘¥ ğ‘˜ ğ‘¥ ğ‘– ğ‘ ğ‘–ğ‘— ğ‘¥ ğ‘— = Â»â€Aâ€šA >â€xâ€¦ ğ‘˜ .
(A.46) Thus, weseethattheğ‘˜-thentryofthedesiredderivativefrom(A.39)isjusttheğ‘˜-thentry ofthevectorontheright, andthusthetwoarethesame.
Thusyields ğ‘‘ â€x >ğ´xâ€ = â€Aâ€šA >â€x.
(A.47) ğ‘‘x Thisrequiredsignificantlymoreworkthanourlastone, butthefinalresultissmall.
More thanthat, considerthefollowingcomputationfortraditionalsinglevariablederivatives: ğ‘‘ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ â€ğ‘¥ğ‘ğ‘¥â€ = ğ‘ğ‘¥â€šğ‘¥ğ‘ = â€ğ‘â€šğ‘â€ğ‘¥.
(A.48) ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ ğ‘‘ğ‘¥ Equivalently ğ‘‘ â€ğ‘ğ‘¥2â€ = 2ğ‘ğ‘¥ = â€ğ‘â€šğ‘â€ğ‘¥.
Again, wegetaresultthatlooksratherlikethe ğ‘‘ğ‘¥ singlevariableresultbutwithatransposetossedin.
At this point, the pattern should be looking rather suspicious, so letâ€™s try to figure out why.
When we take matrix derivatives like this, letâ€™s first assume that the expression we getwillbeanothermatrixexpression: anexpressionwecanwriteitintermsofproducts andsumsofmatricesandtheirtransposes.
Ifsuchanexpressionexists, itwillneedtobe trueforallmatrices.
Inparticular, itwillneedtobetrueof1 1matrices, inwhichcase thematrixproductisjusttheproductofthenumbers, thematrixsumisjustthesum, and thetransposedoesnothingatall! Inotherwords, whateverexpressionwegetmustmatch thesinglevariableexpression.
Thismeansthat, withsomepractice, onecanoftenguess matrixderivativesjustbyknowingwhattheassociatedsinglevariableexpressionmustlook like! Letâ€™strythisout.
Supposethat Xisağ‘› ğ‘šmatrix, Uisanğ‘› ğ‘Ÿ and Visanğ‘Ÿ ğ‘š.
Letâ€™s trytocompute ğ‘‘ k X UVk2 =? (A.49) ğ‘‘V 2 949 Multivariable Calculus Thiscomputationisimportantinanareacalledmatrixfactorization.
Forus, however, itis justaderivativetocompute.
Letâ€™strytoimaginewhatthiswouldbefor1 1matrices.
In thatcase, wegettheexpression ğ‘‘ â€ğ‘¥ ğ‘¢ğ‘£â€2 = 2â€ğ‘¥ ğ‘¢ğ‘£â€ğ‘¢, (A.50) ğ‘‘ğ‘£ where, thederivativeisratherstandard.
Ifwetrytoconvertthisbackintoamatrixexpres- sionweget ğ‘‘ k X UVk2 = 2â€X UVâ€U.
(A.51) ğ‘‘V 2 However, ifwelookatthisitdoesnotquitework.
Recallthat Xisğ‘› ğ‘š, asis UV, sothe matrix2â€X UVâ€isğ‘› ğ‘š.
Ontheotherhand Uisğ‘› ğ‘Ÿ, andwecannotmultiplyağ‘› ğ‘š andağ‘› ğ‘Ÿ matrixsincethedimensionsdonotmatch! Wewanttoget ğ‘‘ , whichisthesameshapeas V, whichisğ‘Ÿ ğ‘š.
Sosomehowweneed ğ‘‘V to take a ğ‘› ğ‘š matrix and a ğ‘› ğ‘Ÿ matrix, multiply them together (perhaps with some transposes)togetağ‘Ÿ ğ‘š.
Wecandothisbymultiplyingğ‘ˆ> byâ€X UVâ€.
Thus, wecan guessthesolutionto(A.49)is ğ‘‘ k X UVk2 = 2U >â€X UVâ€.
(A.52) ğ‘‘V 2 To show that this works, we would be remiss to not provide a detailed computation.
If wealreadybelievethatthisrule-of-thumbworks, feelfreetoskippastthisderivation.
To compute ğ‘‘ k X UVk2, (A.53) ğ‘‘V 2 wemustfindforeveryğ‘, andğ‘ ! 2 ğ‘‘ ğ‘‘ ğ‘‘ğ‘£ k X UVk2 2 = ğ‘‘ğ‘£ ğ‘¥ ğ‘–ğ‘— ğ‘¢ ğ‘–ğ‘˜ ğ‘£ ğ‘˜ğ‘— .
(A.54) ğ‘ğ‘ ğ‘ğ‘ ğ‘–,ğ‘— ğ‘˜ ğ‘‘ Recalling that all entries of X and U are constants as far as is concerned, we may ğ‘‘ğ‘£ğ‘ğ‘ pushthederivativeinsidethesum, andapplythechainruletothesquaretoget ! ! ğ‘‘ ğ‘‘ğ‘£ ğ‘˜ğ‘— ğ‘‘ğ‘£ k X UVk2 2 = 2 ğ‘¥ ğ‘–ğ‘— ğ‘¢ ğ‘–ğ‘˜ ğ‘£ ğ‘˜ğ‘— ğ‘¢ ğ‘–ğ‘˜ğ‘‘ğ‘£ .
(A.55) ğ‘ğ‘ ğ‘ğ‘ ğ‘–,ğ‘— ğ‘˜ ğ‘˜ As in the previous derivation, we may note that ğ‘‘ğ‘£ğ‘˜ğ‘— is only non-zero if the ğ‘˜ = ğ‘ and ğ‘‘ğ‘£ğ‘ğ‘ ğ‘— = ğ‘.
Ifeitherofthoseconditionsdonothold, theterminthesumiszero, andwemay freelydiscardit.
Weseethat ! ğ‘‘ ğ‘‘ğ‘£ k X UVk2 2 = 2 ğ‘¥ ğ‘–ğ‘ ğ‘¢ ğ‘–ğ‘˜ ğ‘£ ğ‘˜ğ‘ ğ‘¢ ğ‘–ğ‘ .
(A.56) ğ‘ğ‘ ğ‘– ğ‘˜ An important subtlety here is that the requirement that ğ‘˜ = ğ‘ does not occur inside the 950 Mathematicsfor Deep Learning innersum sincethat ğ‘˜ isa dummyvariable whichwearesumming overinside the inner term.
Foranotationallycleanerexample, considerwhy ! ! 2 ğ‘‘ ğ‘‘ğ‘¥ ğ‘¥ ğ‘– =2 ğ‘¥ ğ‘– .
(A.57) 1 ğ‘– ğ‘– Fromthispoint, wemaystartidentifyingcomponentsofthesum.
First, ğ‘¢ ğ‘–ğ‘˜ ğ‘£ ğ‘˜ğ‘ = Â»UVâ€¦ ğ‘–ğ‘ .
(A.58) ğ‘˜ Sotheentireexpressionintheinsideofthesumis ğ‘¥ ğ‘–ğ‘ ğ‘¢ ğ‘–ğ‘˜ ğ‘£ ğ‘˜ğ‘ = Â»X UVâ€¦ ğ‘–ğ‘ .
(A.59) ğ‘˜ Thismeanswemaynowwriteourderivativeas ğ‘‘ ğ‘‘ğ‘£ k X UVk2 2 = 2 Â»X UVâ€¦ ğ‘–ğ‘ ğ‘¢ ğ‘–ğ‘ .
(A.60) ğ‘ğ‘ ğ‘– Wewantthistolookliketheğ‘,ğ‘elementofamatrixsowecanusethetechniqueasinthe previousexampletoarriveatamatrixexpression, whichmeansthatweneedtoexchange theorderoftheindicesonğ‘¢ ğ‘–ğ‘.
Ifwenoticethatğ‘¢ ğ‘–ğ‘ = Â»U>â€¦ ğ‘ğ‘–, wecanthenwrite ğ‘‘ ğ‘‘ğ‘£ k X UVk2 2 = 2 Â»U >â€¦ ğ‘ğ‘– Â»X UVâ€¦ ğ‘–ğ‘ .
(A.61) ğ‘ğ‘ ğ‘– Thisisamatrixproduct, andthuswecanconcludethat ğ‘‘ ğ‘‘ğ‘£ k X UVk2 2 = 2Â»U >â€X UVâ€â€¦ ğ‘ğ‘ .
(A.62) ğ‘ğ‘ andthuswemaywritethesolutionto(A.49) ğ‘‘ k X UVk2 = 2U >â€X UVâ€.
(A.63) ğ‘‘V 2 Thismatchesthesolutionweguessedabove! It is reasonable to ask at this point, â€œWhy can I not just write down matrix versions of all the calculus rules I have learned? It is clear this is still mechanical.
Why do we not justgetitoverwith!â€ Andindeedtherearesuchrulesand(Petersenand Pedersen,2008) provides an excellent summary.
However, due to the plethora of ways matrix operations canbecombinedcomparedtosinglevalues, therearemanymorematrixderivativerules thansinglevariableones.
Itisoftenthecasethatitisbesttoworkwiththeindices, orleave ituptoautomaticdifferentiationwhenappropriate.
A.4.8 Summary Inhigherdimensions, wecandefinegradientswhichservethesamepurposeasderiva- tivesinonedimension.
Theseallowustoseehowamulti-variablefunctionchanges whenwemakeanarbitrarysmallchangetotheinputs.
951 Integral Calculus The backpropagation algorithm can be seen to be a method of organizing the multi- variablechainruletoallowfortheefficientcomputationofmanypartialderivatives.
Matrixcalculusallowsustowritethederivativesofmatrixexpressionsinconciseways.
A.4.9 Exercises 1.
Givenacolumnvectorğœ·, computethederivativesofboth ğ‘“â€xâ€ = ğœ·> xandğ‘”â€xâ€ =x>ğœ·.
Whydoyougetthesameanswer? 2.
Letvbeanğ‘›dimensionvector.
Whatis ğœ• kvk ? ğœ•v 2 3.
Letğ¿â€ğ‘¥,ğ‘¦â€ =logâ€ğ‘’ğ‘¥ â€šğ‘’ğ‘¦â€.
Computethegradient.
Whatisthesumofthecomponents ofthegradient? 4.
Let ğ‘“â€ğ‘¥,ğ‘¦â€ = ğ‘¥2ğ‘¦ â€šğ‘¥ğ‘¦2.
Show that the only critical point is â€0,0â€.
By considering ğ‘“â€ğ‘¥,ğ‘¥â€, determineifâ€0,0â€isamaximum, minimum, orneither.
5.
Supposethatweareminimizingafunction ğ‘“â€xâ€ =ğ‘”â€xâ€â€šâ„â€xâ€.
Howcanwegeomet- ricallyinterprettheconditionofrğ‘“ =0intermsofğ‘”andâ„? Discussions283.
283 A.5 Integral Calculus Differentiationonlymakesuphalfofthecontentofatraditionalcalculuseducation.
The other pillar, integration, starts out seeming a rather disjoint question, â€œWhat is the area underneaththiscurve?â€ Whileseeminglyunrelated, integrationistightlyintertwinedwith thedifferentiationviawhatisknownasthefundamentaltheoremofcalculus.
Atthelevelofmachinelearningwediscussinthisbook, wewillnotneedadeepunderstand- ingofintegration.
However, wewillprovideabriefintroductiontolaythegroundworkfor anyfurtherapplicationswewillencounterlateron.
A.5.1 Geometric Interpretation Supposethatwehaveafunction ğ‘“â€ğ‘¥â€.
Forsimplicity, letâ€™sassumethat ğ‘“â€ğ‘¥â€isnon-negative (never takes a value less than zero).
What we want to try and understand is: what is the areacontainedbetween ğ‘“â€ğ‘¥â€andtheğ‘¥-axis? %matplotlib inline import torch from IPython import display from mpl_toolkits import mplot3d from d2l import torch as d2l (continuesonnextpage) 952 Mathematicsfor Deep Learning (continuedfrompreviouspage) x = torch.
arange(-2, 2, 0.01) f = torch.
exp(-x**2) d2l.
set_figsize() d2l.
plt.
plot(x, f, color='black') d2l.
plt.
fill_between(x.
tolist(), f.
tolist()) d2l.
plt.
show() Inmostcases, thisareawillbeinfiniteorundefined(considertheareaunder ğ‘“â€ğ‘¥â€ = ğ‘¥2), sopeoplewilloftentalkabouttheareabetweenapairofends, sayğ‘andğ‘.
x = torch.
arange(-2, 2, 0.01) f = torch.
exp(-x**2) d2l.
set_figsize() d2l.
plt.
plot(x, f, color='black') d2l.
plt.
fill_between(x.
tolist()[50:250], f.
tolist()[50:250]) d2l.
plt.
show() Wewilldenotethisareabytheintegralsymbolbelow: â€ ğ‘ Areaâ€Aâ€ = ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.1) ğ‘ Ë Theinnervariableisadummyvariable, muchliketheindexofasumina , andsothis canbeequivalentlywrittenwithanyinnervaluewelike: â€ â€ ğ‘ ğ‘ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥ = ğ‘“â€ğ‘§â€ ğ‘‘ğ‘§.
(A.2) ğ‘ ğ‘ 953 Integral Calculus There is a traditional way to try and understand how we might try to approximate such integrals: we can imagine taking the region in-between ğ‘ and ğ‘ and chopping it into ğ‘ verticalslices.
Ifğ‘ islarge, wecanapproximatetheareaofeachslicebyarectangle, and thenadduptheareastogetthetotalareaunderthecurve.
Letâ€™stakealookatanexample doingthisincode.
Wewillseehowtogetthetruevalueinalatersection.
epsilon = 0.05 a = 0 b = 2 x = torch.
arange(a, b, epsilon) f = x / (1 + x**2) approx = torch.
sum(epsilon*f) true = torch.
log(torch.
tensor([5.])) / 2 d2l.
set_figsize() d2l.
plt.
bar(x, f, width=epsilon, align='edge') d2l.
plt.
plot(x, f, color='black') d2l.
plt.
ylim([0, 1]) d2l.
plt.
show() f'approximation: {approx}, truth: {true}' 'approximation: 0.7944855690002441, truth: tensor([0.8047])' Theissueisthatwhileitcanbedonenumerically, wecandothisapproachanalyticallyfor onlythesimplestfunctionslike â€ ğ‘ ğ‘¥ ğ‘‘ğ‘¥.
(A.3) ğ‘ Anythingsomewhatmorecomplexlikeourexamplefromthecodeabove â€ ğ‘ ğ‘¥ ğ‘‘ğ‘¥.
(A.4) ğ‘ 1â€šğ‘¥2 isbeyondwhatwecansolvewithsuchadirectmethod.
Wewillinsteadtakeadifferentapproach.
Wewillworkintuitivelywiththenotionofthe area, andlearnthemaincomputationaltoolusedtofindintegrals: thefundamentaltheorem ofcalculus.
Thiswillbethebasisforourstudyofintegration.
954 Mathematicsfor Deep Learning A.5.2 The Fundamental Theoremof Calculus Todivedeeperintothetheoryofintegration, letâ€™sintroduceafunction â€ ğ‘¥ ğ¹â€ğ‘¥â€ = ğ‘“â€ğ‘¦â€ğ‘‘ğ‘¦.
(A.5) 0 Thisfunctionmeasurestheareabetween0andğ‘¥ dependingonhowwechangeğ‘¥.
Notice thatthisiseverythingweneedsince â€ ğ‘ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥ = ğ¹â€ğ‘â€ ğ¹â€ğ‘â€.
(A.6) ğ‘ Thisisamathematicalencodingofthefactthatwecanmeasuretheareaouttothefarend- pointandthensubtractofftheareatothenearendpointasindicatedin Fig.
A.1.
t Fig.
A.1 Visualizingwhywemayreducetheproblemofcomputingtheareaunderacurvebetween twopointstocomputingtheareatotheleftofapoint.
Thus, we can figure out what the integral over any interval is by figuring out what ğ¹â€ğ‘¥â€ is.
Todoso, letâ€™sconsideranexperiment.
Asweoftendoincalculus, letâ€™simaginewhathap- penswhenweshiftthevaluebyatinybit.
Fromthecommentabove, weknowthat â€ ğ‘¥â€šğœ– ğ¹â€ğ‘¥â€šğœ–â€ ğ¹â€ğ‘¥â€ = ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦.
(A.7) ğ‘¥ Thistellsusthatthefunctionchangesbytheareaunderatinysliverofafunction.
Thisisthepointatwhichwemakeanapproximation.
Ifwelookatatinysliverofarealike this, itlookslikethisareaisclosetotherectangularareawithheightthevalueof ğ‘“â€ğ‘¥â€and thebasewidthğœ–.
Indeed, onecanshowthatasğœ– ! 0thisapproximationbecomesbetter andbetter.
Thuswecanconclude: ğ¹â€ğ‘¥â€šğœ–â€ ğ¹â€ğ‘¥â€ ğœ–ğ‘“â€ğ‘¥â€.
(A.8) However, wecannownotice: thisisexactlythepatternweexpectifwewerecomputing thederivativeofğ¹! Thusweseethefollowingrathersurprisingfact: ğ‘‘ğ¹ â€ğ‘¥â€ = ğ‘“â€ğ‘¥â€.
(A.9) ğ‘‘ğ‘¥ Thisisthefundamentaltheoremofcalculus.
Wemaywriteitinexpandedformas â€ ğ‘‘ ğ‘¥ ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¥â€.
(A.10) ğ‘‘ğ‘¥ 0 It takes the concept of finding areas (a priori rather hard), and reduces it to a statement derivatives (something much more completely understood).
One last comment that we 955 Integral Calculus mustmakeisthatthisdoesnottellusexactlywhatğ¹â€ğ‘¥â€is.
Indeedğ¹â€ğ‘¥â€â€šğ¶foranyğ¶has thesamederivative.
Thisisafact-of-lifeinthetheoryofintegration.
Thankfully, notice thatwhenworkingwithdefiniteintegrals, theconstantsdropout, andthusareirrelevantto theoutcome.
â€ ğ‘ ğ‘“â€ğ‘¥â€ ğ‘‘ğ‘¥ = â€ğ¹â€ğ‘â€â€šğ¶â€ â€ğ¹â€ğ‘â€â€šğ¶â€ = ğ¹â€ğ‘â€ ğ¹â€ğ‘â€.
(A.11) ğ‘ Thismayseemlikeabstractnon-sense, butletâ€™stakeamomenttoappreciatethatithasgiven usawholenewperspectiveoncomputingintegrals.
Ourgoalisno-longertodosomesort ofchop-and-sumprocesstotryandrecoverthearea, ratherweneedonlyfindafunction whose derivative is the function we have! This is incredible since we can now list many rather difficult integrals by just reversing the table from Section A.3.2.
For instance, we knowthatthederivativeofğ‘¥ğ‘› isğ‘›ğ‘¥ğ‘› 1.
Thus, wecansayusingthefundamentaltheorem (A.10)that â€ ğ‘¥ ğ‘›ğ‘¦ğ‘› 1 ğ‘‘ğ‘¦ =ğ‘¥ğ‘› 0 ğ‘› =ğ‘¥ğ‘›.
(A.12) 0 Similarly, weknowthatthederivativeofğ‘’ğ‘¥ isitself, sothatmeans â€ ğ‘¥ ğ‘’ğ‘¥ ğ‘‘ğ‘¥ =ğ‘’ğ‘¥ ğ‘’0 =ğ‘’ğ‘¥ 1.
(A.13) 0 Inthisway, wecandeveloptheentiretheoryofintegrationleveragingideasfromdifferential calculusfreely.
Everyintegrationrulederivesfromthisonefact.
A.5.3 Changeof Variables Just as with differentiation, there are a number of rules which make the computation of integralsmoretractable.
Infact, everyruleofdifferentialcalculus(liketheproductrule, sumrule, andchainrule)hasacorrespondingruleforintegralcalculus(integrationbyparts, linearityofintegration, andthechangeofvariablesformularespectively).
Inthissection, wewilldiveintowhatisarguablythemostimportantfromthelist: thechangeofvariables formula.
First, supposethatwehaveafunctionwhichisitselfanintegral: â€ ğ‘¥ ğ¹â€ğ‘¥â€ = ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦.
(A.14) 0 Letâ€™s suppose that we want to know how this function looks when we compose it with anothertoobtainğ¹â€ğ‘¢â€ğ‘¥â€â€.
Bythechainrule, weknow ğ‘‘ ğ‘‘ğ¹ ğ‘‘ğ‘¢ ğ¹â€ğ‘¢â€ğ‘¥â€â€ = â€ğ‘¢â€ğ‘¥â€â€ .
(A.15) ğ‘‘ğ‘¥ ğ‘‘ğ‘¢ ğ‘‘ğ‘¥ We can turn this into a statement about integration by using the fundamental theorem (A.10)asabove.
Thisgives â€ ğ‘¥ ğ‘‘ğ¹ ğ‘‘ğ‘¢ ğ¹â€ğ‘¢â€ğ‘¥â€â€ ğ¹â€ğ‘¢â€0â€â€ = â€ğ‘¢â€ğ‘¦â€â€ ğ‘‘ğ‘¦.
(A.16) ğ‘‘ğ‘¢ ğ‘‘ğ‘¦ 0 956 Mathematicsfor Deep Learning Recalling that ğ¹ is itself an integral gives that the left hand side may be rewritten to be â€ â€ ğ‘¢â€ğ‘¥â€ ğ‘¥ ğ‘‘ğ¹ ğ‘‘ğ‘¢ ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦ = â€ğ‘¢â€ğ‘¦â€â€ ğ‘‘ğ‘¦.
(A.17) ğ‘‘ğ‘¢ ğ‘‘ğ‘¦ ğ‘¢â€0â€ 0 Similarly, recalling that ğ¹ is an integral allows us to recognize that ğ‘‘ğ¹ = ğ‘“ using the ğ‘‘ğ‘¥ fundamentaltheorem(A.10), andthuswemayconclude â€ â€ ğ‘¢â€ğ‘¥â€ ğ‘¥ ğ‘‘ğ‘¢ ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¢â€ğ‘¦â€â€ ğ‘‘ğ‘¦.
(A.18) ğ‘‘ğ‘¦ ğ‘¢â€0â€ 0 Thisisthechangeofvariablesformula.
Foramoreintuitivederivation, considerwhathappenswhenwetakeanintegralof ğ‘“â€ğ‘¢â€ğ‘¥â€â€ between ğ‘¥ and ğ‘¥ â€šğœ–.
For a small ğœ–, this integral is approximately ğœ–ğ‘“â€ğ‘¢â€ğ‘¥â€â€, the area of the associated rectangle.
Now, letâ€™s compare this with the integral of ğ‘“â€ğ‘¦â€ from ğ‘¢â€ğ‘¥â€ to ğ‘¢â€ğ‘¥â€šğœ–â€.
Weknowthatğ‘¢â€ğ‘¥â€šğœ–â€ ğ‘¢â€ğ‘¥â€â€šğœ–ğ‘‘ğ‘¢â€ğ‘¥â€, sotheareaofthisrectangleisapprox- ğ‘‘ğ‘¥ imatelyğœ–ğ‘‘ğ‘¢â€ğ‘¥â€ğ‘“â€ğ‘¢â€ğ‘¥â€â€.
Thus, tomaketheareaofthesetworectanglestoagree, weneed ğ‘‘ğ‘¥ tomultiplythefirstoneby ğ‘‘ğ‘¢â€ğ‘¥â€asisillustratedin Fig.
A.2.
ğ‘‘ğ‘¥ t Fig.
A.2 Visualizingthetransformationofasinglethinrectangleunderthechangeofvariables.
Thistellsusthat â€ â€ ğ‘¥â€šğœ– ğ‘‘ğ‘¢ ğ‘¢â€ğ‘¥â€šğœ–â€ ğ‘“â€ğ‘¢â€ğ‘¦â€â€ â€ğ‘¦â€ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¦â€ ğ‘‘ğ‘¦.
(A.19) ğ‘‘ğ‘¦ ğ‘¥ ğ‘¢â€ğ‘¥â€ Thisisthechangeofvariablesformulaexpressedforasinglesmallrectangle.
If ğ‘¢â€ğ‘¥â€ and ğ‘“â€ğ‘¥â€ are properly chosen, this can allow for the computation of incredibly complexintegrals.
Forinstance, ifweevenchose ğ‘“â€ğ‘¦â€ =1andğ‘¢â€ğ‘¥â€ =ğ‘’ ğ‘¥2 (whichmeans ğ‘‘ğ‘¢â€ğ‘¥â€ = 2ğ‘¥ğ‘’ ğ‘¥2), thiscanshowforinstancethat ğ‘‘ğ‘¥ â€ â€ ğ‘’ 1 1 ğ‘’ 1 1= 1 ğ‘‘ğ‘¦ = 2 ğ‘¦ğ‘’ ğ‘¦2 ğ‘‘ğ‘¦, (A.20) ğ‘’ 0 0 andthusbyrearrangingthat â€ 1 1 ğ‘’ 1 ğ‘¦ğ‘’ ğ‘¦2 ğ‘‘ğ‘¦ = .
(A.21) 2 0 A.5.4 ACommenton Sign Conventions 957 Integral Calculus Keen-eyedreaderswillobservesomethingstrangeaboutthecomputationsabove.
Namely, computationslike â€ ğ‘’ 1 1 ğ‘‘ğ‘¦ =ğ‘’ 1 1<0, (A.22) ğ‘’ 0 canproducenegativenumbers.
Whenthinkingaboutareas, itcanbestrangetoseeaneg- ativevalue, andsoitisworthdiggingintowhattheconventionis.
Mathematicianstakethenotionofsignedareas.
Thismanifestsitselfintwoways.
First, if weconsiderafunction ğ‘“â€ğ‘¥â€ whichissometimeslessthanzero, thentheareawillalsobe negative.
Soforinstance â€ 1 â€ 1â€ ğ‘‘ğ‘¥ = 1.
(A.23) 0 Similarly, integralswhichprogressfromrighttoleft, ratherthanlefttorightarealsotaken tobenegativeareas â€ 1 1 ğ‘‘ğ‘¥ = 1.
(A.24) 0 The standard area (from left to right of a positive function) is always positive.
Anything obtainedbyflippingit(sayflippingovertheğ‘¥-axistogettheintegralofanegativenumber, or flipping over the ğ‘¦-axis to get an integral in the wrong order) will produce a negative area.
Andindeed, flippingtwicewillgiveapairofnegativesignsthatcancelouttohave positivearea â€ 1 â€ 1â€ ğ‘‘ğ‘¥ =1.
(A.25) 0 Ifthisdiscussionsoundsfamiliar, itis! In Section A.1wediscussedhowthedeterminant representedthesignedareainmuchthesameway.
A.5.5 Multiple Integrals Insomecases, wewillneedtoworkinhigherdimensions.
Forinstance, supposethatwe have a function of two variables, like ğ‘“â€ğ‘¥,ğ‘¦â€ and we want to know the volume under ğ‘“ whenğ‘¥rangesover Â»ğ‘,ğ‘â€¦ andğ‘¦rangesover Â»ğ‘,ğ‘‘â€¦.
# Construct grid and compute function x, y = torch.
meshgrid(torch.
linspace(-2, 2, 101), torch.
linspace(-2, 2, 101)) z = torch.
exp(- x**2 - y**2) # Plot function ax = d2l.
plt.
figure().
add_subplot(111, projection='3d') ax.
plot_wireframe(x, y, z) d2l.
plt.
xlabel('x') d2l.
plt.
ylabel('y') d2l.
plt.
xticks([-2, -1, 0, 1, 2]) d2l.
plt.
yticks([-2, -1, 0, 1, 2]) d2l.
set_figsize() (continuesonnextpage) 958 Mathematicsfor Deep Learning (continuedfrompreviouspage) ax.
set_xlim(-2, 2) ax.
set_ylim(-2, 2) ax.
set_zlim(0, 1) ax.
dist = 12 Wewritethisas â€ ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.26) Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ Supposethatwewishtocomputethisintegral.
Myclaimisthatwecandothisbyiteratively computingfirsttheintegralinğ‘¥andthenshiftingtotheintegralinğ‘¦, thatistosay â€ â€ â€ ğ‘‘ ğ‘ ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.27) Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ ğ‘ ğ‘ Letâ€™sseewhythisis.
Considerthefigureabovewherewehavesplitthefunctionintoğœ– ğœ– squareswhichwewill indexwithintegercoordinatesğ‘–, ğ‘—.
Inthiscase, ourintegralisapproximately ğœ–2ğ‘“â€ğœ–ğ‘–,ğœ–ğ‘—â€.
(A.28) ğ‘–,ğ‘— Once we discretize the problem, we may add up the values on these squares in whatever orderwelike, andnotworryaboutchangingthevalues.
Thisisillustratedin Fig.
A.3.
In particular, wecansaythat ! ğœ– ğœ–ğ‘“â€ğœ–ğ‘–,ğœ–ğ‘—â€ .
(A.29) ğ‘— ğ‘– t Fig.
A.3 Illustratinghowtodecomposeasumovermanysquaresasasumoverfirstthecolumns (1), thenaddingthecolumnsumstogether(2).
959 Integral Calculus Thesumontheinsideispreciselythediscretizationoftheintegral â€ ğ‘ ğºâ€ğœ–ğ‘—â€ = ğ‘“â€ğ‘¥,ğœ–ğ‘—â€ ğ‘‘ğ‘¥.
(A.30) ğ‘ Finally, noticethatifwecombinethesetwoexpressionsweget â€ â€ ğ‘‘ ğœ–ğºâ€ğœ–ğ‘—â€ ğºâ€ğ‘¦â€ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.31) ğ‘— ğ‘ Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ Thusputtingitalltogether, wehavethat â€ â€ â€ ğ‘‘ ğ‘ ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.32) Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ ğ‘ ğ‘ Noticethat, oncediscretized, allwedidwasrearrangetheorderinwhichweaddedalist ofnumbers.
Thismaymakeitseemlikeitisnothing, howeverthisresult(called Fubiniâ€™s Theorem) is not always true! For the type of mathematics encountered when doing ma- chinelearning(continuousfunctions), thereisnoconcern, howeveritispossibletocreate exampleswhereitfails(forexamplethefunction ğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘¥ğ‘¦â€ğ‘¥2 ğ‘¦2â€ â€ğ‘¥2â€šğ‘¦2â€3overthe rectangle Â»0,2â€¦ Â»0,1â€¦).
Notethatthechoicetodotheintegralinğ‘¥first, andthentheintegralinğ‘¦wasarbitrary.
We couldhaveequallywellchosentodoğ‘¦firstandthenğ‘¥tosee â€ â€ â€ ğ‘ ğ‘‘ ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦ = ğ‘“â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¦ ğ‘‘ğ‘¥.
(A.33) Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ ğ‘ ğ‘ Oftentimes, wewillcondensedowntovectornotation, andsaythatforğ‘ˆ = Â»ğ‘,ğ‘â€¦ Â»ğ‘,ğ‘‘â€¦ thisis â€ ğ‘“â€xâ€ ğ‘‘x.
(A.34) ğ‘ˆ A.5.6 Changeof Variablesin Multiple Integrals Aswithsinglevariablesin(A.18), theabilitytochangevariablesinsideahigherdimen- sionalintegralisakeytool.
Letâ€™ssummarizetheresultwithoutderivation.
Weneedafunctionthatreparametrizesourdomainofintegration.
Wecantakethistobe ğœ™: Rğ‘› ! Rğ‘› , thatisanyfunctionwhichtakesinğ‘›realvariablesandreturnsanotherğ‘›.
To keeptheexpressionsclean, wewillassumethatğœ™isinjectivewhichistosayitneverfolds overitself(ğœ™â€xâ€ = ğœ™â€yâ€ =) x=y).
Inthiscase, wecansaythat â€ â€ ğ‘“â€xâ€ ğ‘‘x= ğ‘“â€ğœ™â€xâ€â€jdetâ€ğ·ğœ™â€xâ€â€j ğ‘‘x.
(A.35) ğœ™â€ğ‘ˆâ€ ğ‘ˆ whereğ·ğœ™isthe Jacobianofğœ™, whichisthematrixofpartialderivativesofğ“= â€ğœ™ 1 â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘› â€,...,ğœ™ ğ‘› â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘› â€â€, 2 6 ğœ•ğœ™ 1 ğœ•ğœ™ 1 3 7 6 7 6ğœ•ğœ™ğ‘› ğœ•ğœ™ğ‘›7 4ğœ•ğ‘¥ 1 ğœ•ğ‘¥ğ‘› 5 960 Mathematicsfor Deep Learning Lookingclosely, weseethatthisissimilartothesinglevariablechainrule(A.18), except we have replaced the term ğ‘‘ğ‘¢â€ğ‘¥â€ with jdetâ€ğ·ğœ™â€xâ€â€j.
Letâ€™s see how we can to interpret ğ‘‘ğ‘¥ thisterm.
Recallthatthe ğ‘‘ğ‘¢â€ğ‘¥â€ termexistedtosayhowmuchwestretchedourğ‘¥-axisby ğ‘‘ğ‘¥ applyingğ‘¢.
Thesameprocessinhigherdimensionsistodeterminehowmuchwestretch thearea(orvolume, orhyper-volume)ofalittlesquare(orlittlehyper-cube)byapplyingğ“.
If ğ“wasthemultiplicationbyamatrix, thenweknowhowthedeterminantalreadygives theanswer.
With some work, one can show that the Jacobian provides the best approximation to a multivariablefunctionğ“atapointbyamatrixinthesamewaywecouldapproximateby linesorplaneswithderivativesandgradients.
Thusthedeterminantofthe Jacobianexactly mirrorsthescalingfactorweidentifiedinonedimension.
Ittakessomeworktofillinthedetailstothis, sodonotworryiftheyarenotclearnow.
Letâ€™sseeatleastoneexamplewewillmakeuseoflateron.
Considertheintegral â€ â€ 1 1 ğ‘’ ğ‘¥2 ğ‘¦2 ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.37) 1 1 Playingwiththisintegraldirectlywillgetusno-where, butifwechangevariables, wecan make significant progress.
If we let ğ“â€ğ‘Ÿ,ğœƒâ€ = â€ğ‘Ÿcosâ€ğœƒâ€,ğ‘Ÿsinâ€ğœƒâ€â€ (which is to say that ğ‘¥ = ğ‘Ÿcosâ€ğœƒâ€, ğ‘¦ = ğ‘Ÿsinâ€ğœƒâ€), thenwecanapplythechangeofvariableformulatoseethat thisisthesamethingas â€ â€ 1 2ğœ‹ ğ‘’ ğ‘Ÿ2 jdetâ€ğ·Å’â€xâ€â€j ğ‘‘ğœƒ ğ‘‘ğ‘Ÿ, (A.38) 0 0 where jdetâ€ğ·Å’â€xâ€â€j = det cosâ€ğœƒâ€ ğ‘Ÿsinâ€ğœƒâ€ =ğ‘Ÿâ€cos2â€ğœƒâ€â€šsin2â€ğœƒâ€â€ =ğ‘Ÿ.
(A.39) sinâ€ğœƒâ€ ğ‘Ÿcosâ€ğœƒâ€ Thus, theintegralis â€ â€ â€ 1 2ğœ‹ 1 ğ‘Ÿğ‘’ ğ‘Ÿ2 ğ‘‘ğœƒ ğ‘‘ğ‘Ÿ =2ğœ‹ ğ‘Ÿğ‘’ ğ‘Ÿ2 ğ‘‘ğ‘Ÿ =ğœ‹, (A.40) 0 0 0 wherethefinalequalityfollowsbythesamecomputationthatweusedinsection Section A.5.3.
We will meet this integral again when we study continuous random variables in Section A.6.
A.5.7 Summary Thetheoryofintegrationallowsustoanswerquestionsaboutareasorvolumes.
Thefundamentaltheoremofcalculusallowsustoleverageknowledgeaboutderivatives tocomputeareasviatheobservationthatthederivativeoftheareauptosomepoint isgivenbythevalueofthefunctionbeingintegrated.
Integralsinhigherdimensionscanbecomputedbyiteratingsinglevariableintegrals.
961 Random Variables A.5.8 Exercises fl 1.
Whatis 2 1 ğ‘‘ğ‘¥? 1 ğ‘¥ flp ğœ‹ 2.
Usethechangeofvariablesformulatointegrate ğ‘¥sinâ€ğ‘¥2â€ ğ‘‘ğ‘¥.
0 fl 3.
Whatis ğ‘¥ğ‘¦ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦? Â»0,1â€¦2 fl fl 4.
Usethechangeofvariablesformulatocompute 2 1ğ‘¥ğ‘¦â€ğ‘¥2 ğ‘¦2â€ â€ğ‘¥2 â€š ğ‘¦2â€3 ğ‘‘ğ‘¦ ğ‘‘ğ‘¥ fl fl 0 0 and 1 2 ğ‘“â€ğ‘¥,ğ‘¦â€ =ğ‘¥ğ‘¦â€ğ‘¥2 ğ‘¦2â€ â€ğ‘¥2â€šğ‘¦2â€3 ğ‘‘ğ‘¥ ğ‘‘ğ‘¦toseetheyaredifferent.
0 0 Discussions284.
284 A.6 Random Variables In Section2.6wesawthebasicsofhowtoworkwithdiscreterandomvariables, whichin ourcaserefertothoserandomvariableswhichtakeeitherafinitesetofpossiblevalues, or theintegers.
Inthissection, wedevelopthetheoryofcontinuousrandomvariables, which arerandomvariableswhichcantakeonanyrealvalue.
A.6.1 Continuous Random Variables Continuous random variables are a significantly more subtle topic than discrete random variables.
A fair analogy to make is that the technical jump is comparable to the jump betweenaddinglistsofnumbersandintegratingfunctions.
Assuch, wewillneedtotake sometimetodevelopthetheory.
From Discreteto Continuous Tounderstandtheadditionaltechnicalchallengesencounteredwhenworkingwithcontin- uousrandomvariables, letâ€™sperformathoughtexperiment.
Supposethatwearethrowing adartatthedartboard, andwewanttoknowtheprobabilitythatithitsexactly2cmfrom thecenteroftheboard.
Tostartwith, weimaginemeasuringasingledigitofaccuracy, thatistosaywithbinsfor 0cm,1cm,2cm, andsoon.
Wethrowsay100dartsatthedartboard, andif20ofthemfall intothebinfor2cmweconcludethat20%ofthedartswethrowhittheboard2cmaway fromthecenter.
However, whenwelookcloser, thisdoesnotmatchourquestion! Wewantedexactequality, whereasthesebinsholdallthatfellbetweensay1.5cmand2.5cm.
Undeterred, we continue further.
We measure even more precisely, say 1.9cm, 2.0cm, 2.1cm, andnowseethatperhaps3ofthe100dartshittheboardinthe2.0cmbucket.
Thus weconcludetheprobabilityis3%.
962 Mathematicsfor Deep Learning However, thisdoesnotsolveanything! Wehavejustpushedtheissuedownonedigitfurther.
Letâ€™s abstract a bit.
Imagine we know the probability that the first ğ‘˜ digits match with fairly reasonable to assume that the ğ‘˜ â€š1th digit is essentially a random choice from the setf0,1,2,...,9g.
Atleast, wecannotconceiveofaphysicallymeaningfulprocesswhich wouldforcethenumberofmicrometersawayformthecentertoprefertoendina7vsa 3.
What this means is that in essence each additional digit of accuracy we require should decreaseprobabilityofmatchingbyafactorof10.
Orputanotherway, wewouldexpect that Thevalueğ‘essentiallyencodeswhathappenswiththefirstfewdigits, andthe10 ğ‘˜ handles therest.
Noticethatifweknowthepositionaccurateto ğ‘˜ = 4digitsafterthedecimal, thatmeans weknowthevaluefallswithintheintervalsay Â»1.99995,2.00005â€¦ whichisanintervalof length 2.00005 1.99995 = 10 4.
Thus, if we call the length of this interval ğœ–, we can say ğ‘ƒâ€distanceisinanğœ–-sizedintervalaround2â€ ğœ– ğ‘.
(A.2) Letâ€™s take this one final step further.
We have been thinking about the point 2 the entire time, butneverthinkingaboutotherpoints.
Nothingisdifferenttherefundamentally, but it is the case that the value ğ‘ will likely be different.
We would at least hope that a dart throwerwasmorelikelytohitapointnearthecenter, like2cmratherthan20cm.
Thus, the value ğ‘ isnotfixed, butrathershoulddependonthepointğ‘¥.
Thistellsusthatweshould expect ğ‘ƒâ€distanceisinanğœ–-sizedintervalaroundğ‘¥â€ ğœ– ğ‘â€ğ‘¥â€.
(A.3) Indeed,(A.3)preciselydefinestheprobabilitydensityfunction.
Itisafunctionğ‘â€ğ‘¥â€which encodestherelativeprobabilityofhittingnearonepointvs.
another.
Letâ€™svisualizewhat suchafunctionmightlooklike.
%matplotlib inline import torch from IPython import display from d2l import torch as d2l torch.
pi = torch.
acos(torch.
zeros(1)).
item() * 2 # Define pi in torch # Plot the probability density function for some random variable x = torch.
arange(-5, 5, 0.01) d2l.
plot(x, p, 'x', 'Density') 963 Random Variables Thelocationswherethefunctionvalueislargeindicatesregionswherewearemorelikely to find the random value.
The low portions are areas where we are unlikely to find the randomvalue.
Probability Density Functions Letâ€™snowinvestigatethisfurther.
Wehavealreadyseenwhataprobabilitydensityfunction is intuitively for a random variable ğ‘‹, namely the density function is a function ğ‘â€ğ‘¥â€ so that ğ‘ƒâ€ğ‘‹ isinanğœ–-sizedintervalaroundğ‘¥â€ ğœ– ğ‘â€ğ‘¥â€.
(A.4) Butwhatdoesthisimplyforthepropertiesof ğ‘â€ğ‘¥â€? First, probabilitiesarenevernegative, thusweshouldexpectthat ğ‘â€ğ‘¥â€ 0aswell.
Second, letâ€™simaginethatwesliceupthe Rintoaninfinitenumberofsliceswhichareğœ– wide, saywithslicesâ€ğœ– ğ‘–,ğœ– â€ğ‘–â€š1â€â€¦.
Foreachofthese, weknowfrom(A.4)theprobability isapproximately ğ‘ƒâ€ğ‘‹ isinanğœ–-sizedintervalaroundğ‘¥â€ ğœ– ğ‘â€ğœ– ğ‘–â€, (A.5) sosummedoverallofthemitshouldbe ğ‘ƒâ€ğ‘‹ 2Râ€ ğœ– ğ‘â€ğœ– ğ‘–â€.
(A.6) ğ‘– Thisisnothingmorethantheapproximationofanintegraldiscussedin Section A.5, thus wecansaythat â€ 1 ğ‘ƒâ€ğ‘‹ 2Râ€ = ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.7) 1 Weknowthat ğ‘ƒâ€ğ‘‹ 2 Râ€ = 1, sincethe random variablemusttakeon some number, we canconcludethatforanydensity â€ 1 ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ =1.
(A.8) 1 Indeed, diggingintothisfurthershowsthatforanyğ‘, andğ‘, weseethat â€ ğ‘ ğ‘ƒâ€ğ‘‹ 2 â€ğ‘,ğ‘â€¦â€ = ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.9) ğ‘ 964 Mathematicsfor Deep Learning We may approximate this in code by using the same discrete approximation methods as before.
Inthiscasewecanapproximatetheprobabilityoffallingintheblueregion.
# Approximate probability using numerical integration epsilon = 0.01 x = torch.
arange(-5, 5, 0.01) d2l.
set_figsize() d2l.
plt.
plot(x, p, color='black') d2l.
plt.
fill_between(x.
tolist()[300:800], p.
tolist()[300:800]) d2l.
plt.
show() f'approximate Probability: {torch.
sum(epsilon*p[300:800])}' 'approximate Probability: 0.773617148399353' It turns out that these two properties describe exactly the space of possible probability densityfunctions(orp.
d.
f.â€™sforthecommonlyencounteredabbreviation).
Theyarenon- negativefunctions ğ‘â€ğ‘¥â€ 0suchthat â€ 1 ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ =1.
(A.10) 1 Weinterpretthisfunctionbyusingintegrationtoobtaintheprobabilityourrandomvariable isinaspecificinterval: â€ ğ‘ ğ‘ƒâ€ğ‘‹ 2 â€ğ‘,ğ‘â€¦â€ = ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.11) ğ‘ In Section A.8wewillseeanumberofcommondistributions, butletâ€™scontinueworking intheabstract.
Cumulative Distribution Functions Intheprevioussection, wesawthenotionofthep.
d.
f.
Inpractice, thisisacommonlyen- counteredmethodtodiscusscontinuousrandomvariables, butithasonesignificantpitfall: thatthevaluesofthep.
d.
f.
arenotthemselvesprobabilities, butratherafunctionthatwe must integrate to yield probabilities.
There is nothing wrong with a density being larger 965 Random Variables than10, aslongasitisnotlargerthan10formorethananintervaloflength1 10.
This canbecounter-intuitive, sopeopleoftenalsothinkintermsofthecumulativedistribution function, orc.
d.
f., whichisaprobability.
Inparticular, byusing (A.11), wedefinethec.
d.
f.
forarandomvariable ğ‘‹ withdensity ğ‘â€ğ‘¥â€by â€ ğ‘¥ ğ¹â€ğ‘¥â€ = ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ = ğ‘ƒâ€ğ‘‹ ğ‘¥â€.
(A.12) 1 Letâ€™sobserveafewproperties.
ğ¹â€ğ‘¥â€ !0asğ‘¥ ! 1.
ğ¹â€ğ‘¥â€ !1asğ‘¥ !1.
ğ¹â€ğ‘¥â€isnon-decreasing(ğ‘¦ >ğ‘¥ =) ğ¹â€ğ‘¦â€ ğ¹â€ğ‘¥â€).
ğ¹â€ğ‘¥â€iscontinuous(hasnojumps)if ğ‘‹ isacontinuousrandomvariable.
Withthefourthbulletpoint, notethatthiswouldnotbetrueif ğ‘‹ werediscrete, saytaking thevalues0and1bothwithprobability1 2.
Inthatcase 8>>>< 0 ğ‘¥ <0, ğ¹â€ğ‘¥â€ = 1 ğ‘¥ <1, (A.13) >>> 2 :1 ğ‘¥ 1.
In this example, we see one of the benefits of working with the c.
d.
f., the ability to deal withcontinuousordiscreterandomvariablesinthesameframework, orindeedmixtures ofthetwo(flipacoin: ifheadsreturntherollofadie, iftailsreturnthedistanceofadart throwfromthecenterofadartboard).
Means Supposethatwearedealingwitharandomvariablesğ‘‹.
Thedistributionitselfcanbehard tointerpret.
Itisoftenusefultobeabletosummarizethebehaviorofarandomvariable concisely.
Numbersthathelpuscapturethebehaviorofarandomvariablearecalledsum- marystatistics.
Themostcommonlyencounteredonesarethemean, thevariance, andthe standarddeviation.
Themeanencodestheaveragevalueofarandomvariable.
Ifwehaveadiscreterandom variable ğ‘‹, whichtakesthevaluesğ‘¥ ğ‘– withprobabilities ğ‘ ğ‘–, thenthemeanisgivenbythe weightedaverage: sumthevaluestimestheprobabilitythattherandomvariabletakeson thatvalue: ğœ‡ ğ‘‹ = ğ¸Â»ğ‘‹â€¦ = ğ‘¥ ğ‘– ğ‘ ğ‘– .
(A.14) ğ‘– The way we should interpret the mean (albeit with caution) is that it tells us essentially wheretherandomvariabletendstobelocated.
Asaminimalisticexamplethatwewillexaminethroughoutthissection, letâ€™stake ğ‘‹ tobe 966 Mathematicsfor Deep Learning therandomvariablewhichtakesthevalueğ‘ 2withprobabilityğ‘,ğ‘â€š2withprobabilityğ‘ andğ‘withprobability1 2ğ‘.
Wecancomputeusing(A.14)that, foranypossiblechoice ofğ‘and ğ‘, themeanis ğœ‡ ğ‘‹ = ğ¸Â»ğ‘‹â€¦ = ğ‘¥ ğ‘– ğ‘ ğ‘– = â€ğ‘ 2â€ğ‘â€šğ‘â€1 2ğ‘â€â€šâ€ğ‘â€š2â€ğ‘ =ğ‘.
(A.15) ğ‘– Thusweseethatthemeanisğ‘.
Thismatchestheintuitionsinceğ‘ isthelocationaround whichwecenteredourrandomvariable.
Becausetheyarehelpful, letâ€™ssummarizeafewproperties.
Foranyrandomvariable ğ‘‹ andnumbersğ‘andğ‘, wehavethatğœ‡ ğ‘ğ‘‹â€šğ‘ =ğ‘ğœ‡ ğ‘‹ â€šğ‘.
Ifwehavetworandomvariables ğ‘‹ andğ‘Œ, wehaveğœ‡ ğ‘‹â€šğ‘Œ = ğœ‡ ğ‘‹ â€šğœ‡ ğ‘Œ.
Meansareusefulforunderstandingtheaveragebehaviorofarandomvariable, howeverthe meanisnotsufficienttoevenhaveafullintuitiveunderstanding.
Makingaprofitof$10 $1 persaleisverydifferentfrommaking$10 $15persaledespitehavingthesameaverage value.
Thesecondonehasamuchlargerdegreeoffluctuation, andthusrepresentsamuch largerrisk.
Thus, tounderstandthebehaviorofarandomvariable, wewillneedatminimum onemoremeasure: somemeasureofhowwidelyarandomvariablefluctuates.
Variances Thisleadsustoconsiderthevarianceofarandomvariable.
Thisisaquantitativemeasure of how far a random variable deviates from the mean.
Consider the expression ğ‘‹ ğœ‡ ğ‘‹.
This is the deviation of the random variable from its mean.
This value can be positive ornegative, soweneedtodosomethingtomakeitpositivesothatwearemeasuringthe magnitudeofthedeviation.
A reasonable thing to try is to look at jğ‘‹ ğœ‡ ğ‘‹ j, and indeed this leads to a useful quan- tity called the mean absolute deviation, however due to connections with other areas of mathematicsandstatistics, peopleoftenuseadifferentsolution.
Inparticular, theylookatâ€ğ‘‹ ğœ‡ ğ‘‹ â€2.
Ifwelookatthetypicalsizeofthisquantitybytaking themean, wearriveatthevariance ğœ ğ‘‹ 2 =Varâ€ğ‘‹â€ = ğ¸ â€ğ‘‹ ğœ‡ ğ‘‹ â€2 = ğ¸Â»ğ‘‹2â€¦ ğœ‡2 ğ‘‹ .
(A.16) Thelastequalityin(A.16)holdsbyexpandingoutthedefinitioninthemiddle, andapplying thepropertiesofexpectation.
Letâ€™slookatourexamplewhereğ‘‹ istherandomvariablewhichtakesthevalueğ‘ 2with probability ğ‘,ğ‘â€š2withprobab ility ğ‘andğ‘withprobability1 2ğ‘.
Inthiscaseğœ‡ ğ‘‹ =ğ‘, soallweneedtocomputeisğ¸ ğ‘‹2 .
Thiscanreadilybedone: ğ¸ ğ‘‹2 = â€ğ‘ 2â€2ğ‘â€šğ‘2â€1 2ğ‘â€â€šâ€ğ‘â€š2â€2ğ‘ =ğ‘2â€š8ğ‘.
(A.17) Thus, weseethatby(A.16)ourvarianceis ğœ2 =Varâ€ğ‘‹â€ = ğ¸Â»ğ‘‹2â€¦ ğœ‡2 =ğ‘2â€š8ğ‘ ğ‘2 =8ğ‘.
(A.18) ğ‘‹ ğ‘‹ 967 Random Variables Thisresultagainmakessense.
Thelargest ğ‘ canbeis1 2whichcorrespondstopicking ğ‘ 2 or ğ‘ â€š2 with a coin flip.
The variance of this being 4 corresponds to the fact that bothğ‘ 2andğ‘â€š2are2unitsawayfromthemean, and22 = 4.
Ontheotherendofthe spectrum, if ğ‘ =0, thisrandomvariablealwaystakesthevalue0andsoithasnovariance atall.
Wewilllistafewpropertiesofvariancebelow: Foranyrandomvariableğ‘‹, Varâ€ğ‘‹â€ 0, with Varâ€ğ‘‹â€ =0ifandonlyifğ‘‹ isaconstant.
Foranyrandomvariableğ‘‹andnumbersğ‘andğ‘, wehavethat Varâ€ğ‘ğ‘‹â€šğ‘â€ =ğ‘2Varâ€ğ‘‹â€.
Ifwehavetwoindependentrandomvariablesğ‘‹ andğ‘Œ, wehave Varâ€ğ‘‹â€šğ‘Œâ€ =Varâ€ğ‘‹â€â€š Varâ€ğ‘Œâ€.
Wheninterpretingthesevalues, therecanbeabitofahiccup.
Inparticular, letâ€™stryimag- iningwhathappensifwekeeptrackofunitsthroughthiscomputation.
Supposethatweare workingwiththestarratingassignedtoaproductonthewebpage.
Thenğ‘,ğ‘ 2, andğ‘â€š2 are all measured in units of stars.
Similarly, the mean ğœ‡ ğ‘‹ is then also measured in stars (beingaweightedaverage).
However, ifwegettothevariance, weimmediatelyencounter anissue, whichiswewanttolookat â€ğ‘‹ ğœ‡ ğ‘‹ â€2, whichisinunitsofsquaredstars.
This meansthatthevarianceitselfisnotcomparabletotheoriginalmeasurements.
Tomakeit interpretable, wewillneedtoreturntoouroriginalunits.
Standard Deviations Thissummarystatisticscanalwaysbededucedfromthevariancebytakingthesquareroot! Thuswedefinethestandarddeviationtobe p ğœ ğ‘‹ = Varâ€ğ‘‹â€.
(A.19) p Inourexample, thismeanswenowhavethestandarddeviationisğœ ğ‘‹ = 2 2ğ‘.
Ifweare dealingwithunitsofstarsforourreviewexample,ğœ ğ‘‹ isagaininunitsofstars.
Thepropertieswehadforthevariancecanberestatedforthestandarddeviation.
Foranyrandomvariable ğ‘‹,ğœ ğ‘‹ 0.
Foranyrandomvariable ğ‘‹ andnumbersğ‘andğ‘, wehavethatğœ ğ‘ğ‘‹â€šğ‘ = jğ‘jğœ ğ‘‹ q Ifwehavetwoindependentrandomvariables ğ‘‹ andğ‘Œ, wehaveğœ ğ‘‹â€šğ‘Œ = ğœ ğ‘‹ 2 â€šğœ ğ‘Œ 2.
Itisnaturalatthismomenttoask,â€œIfthestandarddeviationisintheunitsofouroriginal random variable, does it represent something we can draw with regards to that random variable?â€ Theanswerisaresoundingyes! Indeedmuchlikethemeantoldusthetypical locationofourrandomvariable, thestandarddeviationgivesthetypicalrangeofvariation of that random variable.
We can make this rigorous with what is known as Chebyshevâ€™s inequality: 1 ğ‘ƒâ€ğ‘‹ âˆ‰ Â»ğœ‡ ğ‘‹ ğ›¼ğœ ğ‘‹ ,ğœ‡ ğ‘‹ â€šğ›¼ğœ ğ‘‹ â€¦â€ ğ›¼2 .
(A.20) 968 Mathematicsfor Deep Learning Ortostateitverballyinthecaseofğ›¼ =10,99%ofthesamplesfromanyrandomvariable fallwithin10standarddeviationsofthemean.
Thisgivesanimmediateinterpretationto ourstandardsummarystatistics.
Toseehowthisstatementisrathersubtle, letâ€™stakealookatourrunningexampleagain where ğ‘‹ istherandomvariablewhichtakesthevalueğ‘ 2withprobability ğ‘,ğ‘â€š2with probability ğ‘anpdğ‘withprobability1 2ğ‘.
Wesawthatthemeanwasğ‘andthestandard deviationwas2 2ğ‘.
Thismeans, ifwetake Chebyshevâ€™sinequality(A.20)with ğ›¼ = 2, weseethattheexpressionis p p 1 ğ‘ƒ ğ‘‹ âˆ‰ Â»ğ‘ 4 2ğ‘,ğ‘â€š4 2ğ‘â€¦ .
(A.21) 4 Thismeansthat75%ofthetime, thisrandomvariablewillfallwithinthisintervalforany valueof ğ‘.
Now, noticethatas ğ‘ ! 0, thisintervalalsoconvergestothesinglepoint ğ‘.
Butweknowthatourrandomvariabletakesthevaluesğ‘ 2,ğ‘, andğ‘â€š2onlysoeventually wecanbecertainğ‘ 2andğ‘â€š2willfalloutsidetheintervapl! Thequestionis, atwhat ğ‘ doesthathappen.
Sowewanttosolve: forwhat ğ‘doesğ‘â€š4 2ğ‘ =ğ‘â€š2, whichissolved whenğ‘ =1 8, whichisexactlythefirstğ‘whereitcouldpossiblyhappenwithoutviolating our claim that no more than 1 4 of samples from the distribution would fall outside the interval(1 8totheleft, and1 8totheright).
Letâ€™svisualizethis.
Wewillshowtheprobabilityofgettingthethreevaluesasthreevertical barswithheightproportionaltotheprobability.
Theintervalwillbedrawnasahorizontal lineinthemiddle.
Thefirstplotshowswhathappensfor ğ‘ >1 8wheretheintervalsafely containsallpoints.
# Define a helper to plot these figures def plot_chebyshev(a, p): d2l.
set_figsize() d2l.
plt.
stem([a-2, a, a+2], [p, 1-2*p, p], use_line_collection=True) d2l.
plt.
xlim([-4, 4]) d2l.
plt.
xlabel('x') d2l.
plt.
hlines(0.5, a - 4 * torch.
sqrt(2 * p), a + 4 * torch.
sqrt(2 * p), 'black', lw=4) d2l.
plt.
title(f'p = {p:.3f}') d2l.
plt.
show() # Plot interval when p > 1/8 plot_chebyshev(0.0, torch.
tensor(0.2)) Thesecondshowsthatat ğ‘ =1 8, theintervalexactlytouchesthetwopoints.
Thisshows that the inequality is sharp, since no smaller interval could be taken while keeping the inequalitytrue.
969 Random Variables # Plot interval when p = 1/8 plot_chebyshev(0.0, torch.
tensor(0.125)) Thethirdshowsthatforğ‘ <1 8theintervalonlycontainsthecenter.
Thisdoesnotinvali- datetheinequalitysinceweonlyneededtoensurethatnomorethan1 4oftheprobability fallsoutsidetheinterval, whichmeansthatonce ğ‘ <1 8, thetwopointsatğ‘ 2andğ‘â€š2 canbediscarded.
# Plot interval when p < 1/8 plot_chebyshev(0.0, torch.
tensor(0.05)) 970 Mathematicsfor Deep Learning Meansand Variancesinthe Continuum Thishasallbeenintermsofdiscreterandomvariables, butthecaseofcontinuousrandom variables is similar.
To intuitively understand how this works, imagine that we split the real number line into intervals of length ğœ– given by â€ğœ–ğ‘–,ğœ–â€ğ‘– â€š1â€â€¦.
Once we do this, our continuousrandomvariablehasbeenmadediscreteandwecanuse(A.14)saythat ğœ‡ ğ‘‹ â€ğœ–ğ‘–â€ğ‘ƒâ€ğ‘‹ 2 â€ğœ–ğ‘–,ğœ–â€ğ‘–â€š1â€â€¦â€ ğ‘– (A.22) â€ğœ–ğ‘–â€ğ‘ â€ğœ–ğ‘–â€ğœ–, ğ‘‹ ğ‘– where ğ‘ ğ‘‹ isthedensityof ğ‘‹.
Thisisanapproximationtotheintegralofğ‘¥ğ‘ ğ‘‹ â€ğ‘¥â€, sowe canconcludethat â€ 1 ğœ‡ ğ‘‹ = ğ‘¥ğ‘ ğ‘‹ â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.23) 1 Similarly, using(A.16)thevariancecanbewrittenas â€ â€ 1 1 2 ğœ ğ‘‹ 2 = ğ¸Â»ğ‘‹2â€¦ ğœ‡2 ğ‘‹ = ğ‘¥2ğ‘ ğ‘‹ â€ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘¥ğ‘ ğ‘‹ â€ğ‘¥â€ ğ‘‘ğ‘¥ .
(A.24) 1 1 Everythingstatedaboveaboutthemean, thevariance, andthestandarddeviationstillap- pliesinthiscase.
Forinstance, ifweconsidertherandomvariablewithdensity ( 1 ğ‘¥ 2 Â»0,1â€¦, ğ‘â€ğ‘¥â€ = (A.25) 0 otherwise.
wecancompute â€ â€ 1 1 1 ğœ‡ ğ‘‹ = ğ‘¥ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ = ğ‘¥ ğ‘‘ğ‘¥ = .
(A.26) 1 0 2 and â€ 1 1 2 1 1 1 ğœ2 = ğ‘¥2ğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥ = = .
(A.27) ğ‘‹ 1 2 3 4 12 Asawarning, letâ€™sexamineonemoreexample, knownasthe Cauchydistribution.
Thisis thedistributionwithp.
d.
f.
givenby 1 ğ‘â€ğ‘¥â€ = .
(A.28) 1â€šğ‘¥2 # Plot the Cauchy distribution p.
d.
f.
x = torch.
arange(-5, 5, 0.01) p = 1 / (1 + x**2) d2l.
plot(x, p, 'x', 'p.
d.
f.') This function looks innocent, and indeed consulting a table of integrals will show it has areaoneunderit, andthusitdefinesacontinuousrandomvariable.
971 Random Variables Toseewhatgoesastray, letâ€™strytocomputethevarianceofthis.
Thiswouldinvolveusing (A.16)computing â€ 1 ğ‘¥2 ğ‘‘ğ‘¥.
(A.29) 1 1â€šğ‘¥2 Thefunctionontheinsidelookslikethis: # Plot the integrand needed to compute the variance x = torch.
arange(-20, 20, 0.01) p = x**2 / (1 + x**2) d2l.
plot(x, p, 'x', 'integrand') Thisfunctionclearlyhasinfiniteareaunderitsinceitisessentiallytheconstantonewitha smalldipnearzero, andindeedwecouldshowthat â€ 1 ğ‘¥2 ğ‘‘ğ‘¥ =1.
(A.30) 1 1â€šğ‘¥2 Thismeansitdoesnothaveawell-definedfinitevariance.
However, lookingdeepershowsanevenmoredisturbingresult.
Letâ€™strytocomputethe meanusing(A.14).
Usingthechangeofvariablesformula, wesee â€ â€ 1 ğ‘¥ 1 1 1 ğœ‡ ğ‘‹ = 1 1â€šğ‘¥2 ğ‘‘ğ‘¥ = 2 1 ğ‘¢ ğ‘‘ğ‘¢.
(A.31) Theintegralinsideisthedefinitionofthelogarithm, sothisisinessencelogâ€1â€ = 1, so thereisnowell-definedaveragevalueeither! 972 Mathematicsfor Deep Learning Machinelearningscientistsdefinetheirmodelssothatwemostoftendonotneedtodeal with these issues, and will in the vast majority of cases deal with random variables with well-definedmeansandvariances.
However, everysooftenrandomvariableswithheavy tails(thatisthoserandomvariableswheretheprobabilitiesofgettinglargevaluesarelarge enoughtomakethingslikethemeanorvarianceundefined)arehelpfulinmodelingphysical systems, thusitisworthknowingthattheyexist.
Joint Density Functions Theaboveworkallassumesweareworkingwithasinglerealvaluedrandomvariable.
But what if we are dealing with two or more potentially highly correlated random variables? This circumstance is the norm in machine learning: imagine random variables like ğ‘… ğ‘–,ğ‘— whichencodetheredvalueofthepixelattheâ€ğ‘–, ğ‘—â€coordinateinanimage, orğ‘ƒ ğ‘¡ whichis arandomvariablegivenbyastockpriceattimeğ‘¡.
Nearbypixelstendtohavesimilarcolor, and nearby times tend to have similar prices.
We cannot treat them as separate random variables, andexpecttocreateasuccessfulmodel(wewillseein Section A.9amodelthat under-performsduetosuchanassumption).
Weneedtodevelopthemathematicallanguage tohandlethesecorrelatedcontinuousrandomvariables.
Thankfully, with the multiple integrals in Section A.5 we can develop such a language.
Supposethatwehave, forsimplicity, tworandomvariables ğ‘‹,ğ‘Œ whichcanbecorrelated.
Then, similartothecaseofasinglevariable, wecanaskthequestion: ğ‘ƒâ€ğ‘‹ isinanğœ–-sizedintervalaroundğ‘¥ andğ‘Œ isinanğœ–-sizedintervalaround ğ‘¦â€.
(A.32) Similarreasoningtothesinglevariablecaseshowsthatthisshouldbeapproximately ğ‘ƒâ€ğ‘‹ isinanğœ–-sizedintervalaroundğ‘¥ andğ‘Œ isinanğœ–-sizedintervalaround ğ‘¦â€ ğœ–2ğ‘â€ğ‘¥,ğ‘¦â€, (A.33) for some function ğ‘â€ğ‘¥,ğ‘¦â€.
This is referred to as the joint density of ğ‘‹ andğ‘Œ.
Similar propertiesaretrueforthisaswesawinthesinglevariablecase.
Namely: ğ‘â€ğ‘¥,ğ‘¦â€ 0; fl ğ‘â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦ =1; R2 fl ğ‘ƒâ€â€ğ‘‹,ğ‘Œâ€ 2 Dâ€ = ğ‘â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
D Inthisway, wecandealwithmultiple, potentiallycorrelatedrandomvariables.
Ifwewish toworkwithmorethantworandomvariables, wecanextendthemultivariatedensitytoas manycoordinatesasdesiredbyconsideringğ‘â€xâ€ = ğ‘â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘› â€.
Thesamepropertiesof beingnon-negative, andhavingtotalintegralofonestillhold.
Marginal Distributions When dealing with multiple variables, we oftentimes want to be able to ignore the rela- tionships and ask, â€œhow is this one variable distributed?â€ Such a distribution is called a marginaldistribution.
973 Random Variables To be concrete, letâ€™s suppose that we have two random variables ğ‘‹,ğ‘Œ with joint density givenby ğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€.
Wewillbeusingthesubscripttoindicatewhatrandomvariablesthe densityisfor.
Thequestionoffindingthemarginaldistributionistakingthisfunction, and usingittofind ğ‘ ğ‘‹ â€ğ‘¥â€.
Aswithmostthings, itisbesttoreturntotheintuitivepicturetofigureoutwhatshouldbe true.
Recallthatthedensityisthefunction ğ‘ ğ‘‹ sothat ğ‘ƒâ€ğ‘‹ 2 Â»ğ‘¥,ğ‘¥â€šğœ–â€¦â€ ğœ– ğ‘ ğ‘‹ â€ğ‘¥â€.
(A.34) Thereisnomentionofğ‘Œ, butifallwearegivenis ğ‘ ğ‘‹,ğ‘Œ, weneedtoincludeğ‘Œ somehow.
Wecanfirstobservethatthisisthesameas ğ‘ƒâ€ğ‘‹ 2 Â»ğ‘¥,ğ‘¥â€šğœ–â€¦, andğ‘Œ 2Râ€ ğœ– ğ‘ ğ‘‹ â€ğ‘¥â€.
(A.35) Ourdensitydoesnotdirectlytellusaboutwhathappensinthiscase, weneedtosplitinto smallintervalsinğ‘¦aswell, sowecanwritethisas ğœ– ğ‘ ğ‘‹ â€ğ‘¥â€ ğ‘ƒâ€ğ‘‹ 2 Â»ğ‘¥,ğ‘¥â€šğœ–â€¦, andğ‘Œ 2 Â»ğœ– ğ‘–,ğœ– â€ğ‘–â€š1â€â€¦â€ ğ‘– (A.36) ğœ–2ğ‘ â€ğ‘¥,ğœ– ğ‘–â€.
ğ‘‹,ğ‘Œ ğ‘– t Fig.
A.1 Bysummingalongthecolumnsofourarrayofprobabilities, weareabletoobtainthe marginaldistributionforjusttherandomvariablerepresentedalongthex-axis.
Thistellsustoaddupthevalueofthedensityalongaseriesofsquaresinalineasisshown in Fig.
A.1.
Indeed, aftercancelingonefactorofepsilonfrombothsides, andrecognizing thesumontherightistheintegraloverğ‘¦, wecanconcludethat ğ‘ â€ğ‘¥â€ ğœ–ğ‘ â€ğ‘¥,ğœ– ğ‘–â€ ğ‘‹ ğ‘‹,ğ‘Œ â€ğ‘– (A.37) 1 ğ‘ â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¦.
ğ‘‹,ğ‘Œ 1 Thuswesee â€ 1 ğ‘ ğ‘‹ â€ğ‘¥â€ = ğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¦.
(A.38) 1 Thistellsusthattogetamarginaldistribution, weintegrateoverthevariableswedonot 974 Mathematicsfor Deep Learning care about.
This process is often referred to as integrating out or marginalized out the unneededvariables.
Covariance When dealing with multiple random variables, there is one additional summary statistic whichishelpfultoknow: thecovariance.
Thismeasuresthedegreethattworandomvari- ablefluctuatetogether.
Suppose that we have two random variables ğ‘‹ andğ‘Œ, to begin with, letâ€™s suppose they arediscrete, takingonvalues â€ğ‘¥ ğ‘– ,ğ‘¦ ğ‘— â€ withprobability ğ‘ ğ‘–ğ‘—.
Inthiscase, thecovarianceis definedas ğœ ğ‘‹ğ‘Œ =Covâ€ğ‘‹,ğ‘Œâ€ = â€ğ‘¥ ğ‘– ğœ‡ ğ‘‹ â€â€ğ‘¦ ğ‘— ğœ‡ ğ‘Œ â€ğ‘ ğ‘–ğ‘— .= ğ¸Â»ğ‘‹ğ‘Œâ€¦ ğ¸Â»ğ‘‹â€¦ğ¸Â»ğ‘Œâ€¦.
(A.39) ğ‘–,ğ‘— Tothinkaboutthisintuitively: considerthefollowingpairofrandomvariables.
Suppose thatğ‘‹ takesthevalues1and3, andğ‘Œ takesthevalues 1and3.
Supposethatwehavethe followingprobabilities ğ‘ ğ‘ƒâ€ğ‘‹ =1andğ‘Œ = 1â€ = , 2 1 ğ‘ ğ‘ƒâ€ğ‘‹ =1andğ‘Œ =3â€ = , 2 (A.40) 1 ğ‘ ğ‘ƒâ€ğ‘‹ =3andğ‘Œ = 1â€ = , 2 ğ‘ ğ‘ƒâ€ğ‘‹ =3andğ‘Œ =3â€ = , 2 whereğ‘isaparameterinÂ»0,1â€¦wegettopick.
Noticethatifğ‘ =1thentheyarebothalways theirminimumormaximumvaluessimultaneously, andifğ‘ =0theyareguaranteedtotake their flipped values simultaneously (one is large when the other is small and vice versa).
If ğ‘ = 1 2, thenthefourpossibilitiesareallequallylikely, andneithershouldberelated.
Letâ€™scomputethecovariance.
First, note ğœ‡ ğ‘‹ = 2and ğœ‡ ğ‘Œ = 1, sowemaycomputeusing (A.39): Covâ€ğ‘‹,ğ‘Œâ€ = â€ğ‘¥ ğ‘– ğœ‡ ğ‘‹ â€â€ğ‘¦ ğ‘— ğœ‡ ğ‘Œ â€ğ‘ ğ‘–ğ‘— ğ‘–,ğ‘— ğ‘ 1 ğ‘ 1 ğ‘ ğ‘ = â€1 2â€â€ 1 1â€ â€šâ€1 2â€â€3 1â€ â€šâ€3 2â€â€ 1 1â€ â€šâ€3 2â€â€3 1â€ 2 2 2 2 =4ğ‘ 2.
(A.41) Whenğ‘ =1(thecasewheretheyarebothmaximallypositiveornegativeatthesametime) hasacovarianceof2.
When ğ‘ =0(thecasewheretheyareflipped)thecovarianceis 2.
Finally, when ğ‘ = 1 2(thecasewheretheyareunrelated), thecovarianceis0.
Thuswe seethatthecovariancemeasureshowthesetworandomvariablesarerelated.
A quick note on the covariance is that it only measures these linear relationships.
More complexrelationshipslikeğ‘‹ =ğ‘Œ2whereğ‘Œ israndomlychosenfromf 2, 1,0,1,2gwith 975 Random Variables equalprobabilitycanbemissed.
Indeedaquickcomputationshowsthattheserandomvari- ableshavecovariancezero, despiteonebeingadeterministicfunctionoftheother.
Forcontinuousrandomvariables, muchthesamestoryholds.
Atthispoint, wearepretty comfortablewithdoingthetransitionbetweendiscreteandcontinuous, sowewillprovide thecontinuousanalogueof(A.39)withoutanyderivation.
â€ ğœ ğ‘‹ğ‘Œ = â€ğ‘¥ ğœ‡ ğ‘‹ â€â€ğ‘¦ ğœ‡ ğ‘Œ â€ğ‘â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.42) R2 Forvisualization, letâ€™stakealookatacollectionofrandomvariableswithtunablecovari- ance.
# Plot a few random variables adjustable covariance covs = [-0.9, 0.0, 1.2] d2l.
plt.
figure(figsize=(12, 3)) for i in range(3): X = torch.
randn(500) Y = covs[i]*X + torch.
randn(500) d2l.
plt.
subplot(1, 4, i+1) d2l.
plt.
scatter(X.
numpy(), Y.
numpy()) d2l.
plt.
xlabel('X') d2l.
plt.
ylabel('Y') d2l.
plt.
title(f'cov = {covs[i]}') d2l.
plt.
show() Letâ€™sseesomepropertiesofcovariances: Foranyrandomvariable ğ‘‹, Covâ€ğ‘‹,ğ‘‹â€ =Varâ€ğ‘‹â€.
Foranyrandomvariablesğ‘‹,ğ‘Œandnumbersğ‘andğ‘, Covâ€ğ‘ğ‘‹â€šğ‘,ğ‘Œâ€ =Covâ€ğ‘‹,ğ‘ğ‘Œâ€šğ‘â€ = ğ‘Covâ€ğ‘‹,ğ‘Œâ€.
If ğ‘‹ andğ‘Œ areindependentthen Covâ€ğ‘‹,ğ‘Œâ€ =0.
Inaddition, wecanusethecovariancetoexpandarelationshipwesawbefore.
Recallthat is ğ‘‹ andğ‘Œ aretwoindependentrandomvariablesthen Varâ€ğ‘‹â€šğ‘Œâ€ =Varâ€ğ‘‹â€â€šVarâ€ğ‘Œâ€.
(A.43) 976 Mathematicsfor Deep Learning Withknowledgeofcovariances, wecanexpandthisrelationship.
Indeed, somealgebracan showthatingeneral, Varâ€ğ‘‹â€šğ‘Œâ€ =Varâ€ğ‘‹â€â€šVarâ€ğ‘Œâ€â€š2Covâ€ğ‘‹,ğ‘Œâ€.
(A.44) Thisallowsustogeneralizethevariancesummationruleforcorrelatedrandomvariables.
Correlation Aswedidinthecaseofmeansandvariances, letâ€™snowconsiderunits.
Ifğ‘‹ ismeasuredin oneunit(sayinches), andğ‘Œismeasuredinanother(saydollars), thecovarianceismeasured intheproductofthesetwounitsinches dollars.
Theseunitscanbehardtointerpret.
What wewilloftenwantinthiscaseisaunit-lessmeasurementofrelatedness.
Indeed, oftenwe do not care about exact quantitative correlation, but rather ask if the correlation is in the samedirection, andhowstrongtherelationshipis.
To see what makes sense, letâ€™s perform a thought experiment.
Suppose that we convert ourrandomvariablesininchesanddollarstobeininchesandcents.
Inthiscasetheran- dom variableğ‘Œ is multiplied by 100.
If we work through the definition, this means that Covâ€ğ‘‹,ğ‘Œâ€willbemultipliedby100.
Thusweseethatinthiscaseachangeofunitschange thecovariancebyafactorof100.
Thus, tofindourunit-invariantmeasureofcorrelation, wewillneed todivide bysomething elsethat alsogetsscaledby 100.
Indeed wehavea clearcandidate, thestandarddeviation! Indeedifwedefinethecorrelationcoeï¬€icient to be Covâ€ğ‘‹,ğ‘Œâ€ ğœŒâ€ğ‘‹,ğ‘Œâ€ = , (A.45) ğœ ğœ ğ‘‹ ğ‘Œ we see that this is a unit-less value.
A little mathematics can show that this number is between 1 and 1 with 1 meaning maximally positively correlated, whereas 1 means maximallynegativelycorrelated.
Returning to our explicit discrete example above, we can see that ğœ ğ‘‹ = 1 and ğœ ğ‘Œ = 2, sowecancomputethecorrelationbetweenthetworandomvariablesusing(A.45)tosee that 4ğ‘ 2 ğœŒâ€ğ‘‹,ğ‘Œâ€ = =2ğ‘ 1.
(A.46) 1 2 Thisnowrangesbetween 1and1withtheexpectedbehaviorof1meaningmostcorrelated, and 1meaningminimallycorrelated.
As another example, consider ğ‘‹ as any random variable, andğ‘Œ = ğ‘ğ‘‹ â€š ğ‘ as any linear deterministicfunctionof ğ‘‹.
Then, onecancomputethat ğœ ğ‘Œ =ğœ ğ‘ğ‘‹â€šğ‘ = jğ‘jğœ ğ‘‹ , (A.47) Covâ€ğ‘‹,ğ‘Œâ€ =Covâ€ğ‘‹,ğ‘ğ‘‹â€šğ‘â€ =ğ‘Covâ€ğ‘‹,ğ‘‹â€ =ğ‘Varâ€ğ‘‹â€, (A.48) andthusby(A.45)that ğ‘Varâ€ğ‘‹â€ ğ‘ ğœŒâ€ğ‘‹,ğ‘Œâ€ = = =signâ€ğ‘â€.
(A.49) jğ‘jğœ2 jğ‘j ğ‘‹ 977 Random Variables Thusweseethatthecorrelationisâ€š1foranyğ‘ > 0, and 1foranyğ‘ < 0illustratingthat correlation measures the degree and directionality the two random variables are related, notthescalethatthevariationtakes.
Letâ€™sagainplotacollectionofrandomvariableswithtunablecorrelation.
# Plot a few random variables adjustable correlations cors = [-0.9, 0.0, 1.0] d2l.
plt.
figure(figsize=(12, 3)) for i in range(3): X = torch.
randn(500) Y = cors[i] * X + torch.
sqrt(torch.
tensor(1) - cors[i]**2) * torch.
randn(500) d2l.
plt.
subplot(1, 4, i + 1) d2l.
plt.
scatter(X.
numpy(), Y.
numpy()) d2l.
plt.
xlabel('X') d2l.
plt.
ylabel('Y') d2l.
plt.
title(f'cor = {cors[i]}') d2l.
plt.
show() Letâ€™slistafewpropertiesofthecorrelationbelow.
Foranyrandomvariable ğ‘‹, ğœŒâ€ğ‘‹,ğ‘‹â€ =1.
Foranyrandomvariables ğ‘‹,ğ‘Œ andnumbers ğ‘ and ğ‘, ğœŒâ€ğ‘ğ‘‹ â€šğ‘,ğ‘Œâ€ = ğœŒâ€ğ‘‹,ğ‘ğ‘Œ â€šğ‘â€ = ğœŒâ€ğ‘‹,ğ‘Œâ€.
If ğ‘‹ andğ‘Œ areindependentwithnon-zerovariancethen ğœŒâ€ğ‘‹,ğ‘Œâ€ =0.
Asafinalnote, youmayfeellikesomeoftheseformulaearefamiliar.
Indeed, ifweexpand everythingoutassumingthatğœ‡ ğ‘‹ = ğœ‡ ğ‘Œ =0, weseethatthisis Ë ğ‘¥ ğ‘¦ ğ‘ ğ‘–,ğ‘— ğ‘– ğ‘– ğ‘–ğ‘— ğœŒâ€ğ‘‹,ğ‘Œâ€ = q Ë q Ë .
(A.50) ğ‘¥2ğ‘ ğ‘¦2ğ‘ ğ‘–,ğ‘— ğ‘– ğ‘–ğ‘— ğ‘–,ğ‘— ğ‘— ğ‘–ğ‘— Thislookslikeasumofaproductoftermsdividedbythesquarerootofsumsofterms.
Thisisexactlytheformulaforthecosineoftheanglebetweentwovectorsv, w withthe 978 Mathematicsfor Deep Learning differentcoordinatesweightedby ğ‘ ğ‘–ğ‘—: Ë cosâ€ğœƒâ€ = kv v k k w wk = q Ë ğ‘– ğ‘£ q ğ‘– ğ‘¤ Ë ğ‘– .
(A.51) ğ‘£2 ğ‘¤2 ğ‘– ğ‘– ğ‘– ğ‘– Indeed if we think of norms as being related to standard deviations, and correlations as being cosines of angles, much of the intuition we have from geometry can be applied to thinkingaboutrandomvariables.
A.6.2 Summary Continuousrandomvariablesarerandomvariablesthatcantakeonacontinuumofval- ues.
Theyhavesometechnicaldifficultiesthatmakethemmorechallengingtowork withcomparedtodiscreterandomvariables.
Theprobabilitydensityfunctionallowsustoworkwithcontinuousrandomvariablesby givingafunctionwheretheareaunderthecurveonsomeintervalgivestheprobability offindingasamplepointinthatinterval.
Thecumulativedistributionfunctionistheprobabilityofobservingtherandomvariable to be less than a given threshold.
It can provide a useful alternate viewpoint which unifiesdiscreteandcontinuousvariables.
Themeanistheaveragevalueofarandomvariable.
Thevarianceistheexpectedsquareofthedifferencebetweentherandomvariableand itsmean.
Thestandarddeviationisthesquarerootofthevariance.
Itcanbethoughtofasmea- suringtherangeofvaluestherandomvariablemaytake.
Chebyshevâ€™s inequality allows us to make this intuition rigorous by giving an explicit intervalthatcontainstherandomvariablemostofthetime.
Jointdensitiesallowustoworkwithcorrelatedrandomvariables.
Wemaymarginalize jointdensitiesbyintegratingoverunwantedrandomvariablestogetthedistribution ofthedesiredrandomvariable.
Thecovarianceandcorrelationcoefficientprovideawaytomeasureanylinearrelation- shipbetweentwocorrelatedrandomvariables.
A.6.3 Exercises 1.
Supposethatwehavetherandomvariablewithdensitygivenby ğ‘â€ğ‘¥â€ = 1 forğ‘¥ 1 ğ‘¥2 and ğ‘â€ğ‘¥â€ =0otherwise.
Whatisğ‘ƒâ€ğ‘‹ >2â€? 2.
The Laplacedistributionisarandomvariablewhosedensityisgivenbfly ğ‘â€ğ‘¥ = 1ğ‘’ jğ‘¥j .
Whatisthemeanandthestandarddeviationofthisfunction? Asahint, 1 ğ‘¥ğ‘’ ğ‘¥ 2 ğ‘‘ğ‘¥ =1 and fl 1 ğ‘¥2ğ‘’ ğ‘¥ ğ‘‘ğ‘¥ =2.
0 0 979 Maximum Likelihood 3.
Iwalkuptoyouonthestreetandsayâ€œIhavearandomvariablewithmean1, standard deviation2, and Iobserved25%ofmysamplestakingavaluelargerthan9.â€ Doyou believeme? Whyorwhynot? 4.
Supposethatyouhavetworandomvariablesğ‘‹,ğ‘Œ, withjointdensitygivenbyğ‘ ğ‘‹ğ‘Œ â€ğ‘¥,ğ‘¦â€ = 4ğ‘¥ğ‘¦forğ‘¥,ğ‘¦ 2 Â»0,1â€¦ and ğ‘ ğ‘‹ğ‘Œ â€ğ‘¥,ğ‘¦â€ =0otherwise.
Whatisthecovarianceof ğ‘‹ andğ‘Œ? Discussions285.
285 A.7 Maximum Likelihood Oneofthemostcommonlyencounteredwayofthinkinginmachinelearningisthemaxi- mumlikelihoodpointofview.
Thisistheconceptthatwhenworkingwithaprobabilistic model with unknown parameters, the parameters which make the data have the highest probabilityarethemostlikelyones.
A.7.1 The Maximum Likelihood Principle Thishas a Bayesianinterpretationwhichcanbe helpfulto thinkabout.
Suppose thatwe haveamodelwithparametersğœ½andacollectionofdataexamplesğ‘‹.
Forconcreteness, we canimaginethatğœ½isasinglevaluerepresentingtheprobabilitythatacoincomesupheads whenflipped, and ğ‘‹ isasequenceofindependentcoinflips.
Wewilllookatthisexample indepthlater.
If we want to find the most likely value for the parameters of our model, that means we wanttofind argmaxğ‘ƒâ€ğœ½ j ğ‘‹â€.
(A.1) By Bayesâ€™rule, thisisthesamethingas ğ‘ƒâ€ğ‘‹ j ğœ½â€ğ‘ƒâ€ğœ½â€ argmax .
(A.2) ğ‘ƒâ€ğ‘‹â€ The expression ğ‘ƒâ€ğ‘‹â€, a parameter agnostic probability of generating the data, does not dependonğœ½atall, andsocanbedroppedwithoutchangingthebestchoiceofğœ½.
Similarly, wemaynowpositthatwehavenopriorassumptiononwhichsetofparametersarebetter than any others, so we may declare that ğ‘ƒâ€ğœ½â€ does not depend on theta either! This, for instance, makessenseinourcoinflippingexamplewheretheprobabilityitcomesupheads couldbeanyvaluein Â»0,1â€¦ withoutanypriorbeliefitisfairornot(oftenreferredtoasan uninformativeprior).
Thusweseethatourapplicationof Bayesâ€™ruleshowsthatourbest choiceofğœ½ isthemaximumlikelihoodestimateforğœ½: ğœ½Ë† =argmaxğ‘ƒâ€ğ‘‹ j ğœ½â€.
(A.3) ğœ½ Asamatterofcommonterminology, theprobabilityofthedatagiventheparameters(ğ‘ƒâ€ğ‘‹ j ğœ½â€)isreferredtoasthelikelihood.
980 Mathematicsfor Deep Learning AConcrete Example Letâ€™sseehowthisworksinaconcreteexample.
Supposethatwehaveasingleparameterğœƒ representingtheprobabilitythatacoinflipisheads.
Thentheprobabilityofgettingatails is1 ğœƒ, andsoifourobserveddata ğ‘‹ isasequencewithğ‘› ğ» headsandğ‘› ğ‘‡ tails, wecan usethefactthatindependentprobabilitiesmultiplytoseethat ğ‘ƒâ€ğ‘‹ j ğœƒâ€ =ğœƒğ‘›ğ»â€1 ğœƒâ€ğ‘›ğ‘‡.
(A.4) Ifweflip13coinsandgetthesequenceâ€œHHHTHTTHHHHHTâ€, whichhasğ‘› ğ» = 9and ğ‘› ğ‘‡ =4, weseethatthisis ğ‘ƒâ€ğ‘‹ j ğœƒâ€ =ğœƒ9â€1 ğœƒâ€4.
(A.5) One nice thing about this example will be that we know the answer going in.
Indeed, if wesaidverbally,â€œIflipped13coins, and9cameupheads, whatisourbestguessforthe probabilitythatthecoincomesusheads?,â€everyonewouldcorrectlyguess9 13.
Whatthis maximumlikelihoodmethodwillgiveusisawaytogetthatnumberfromfirstprincipals inawaythatwillgeneralizetovastlymorecomplexsituations.
Forourexample, theplotofğ‘ƒâ€ğ‘‹ j ğœƒâ€isasfollows: %matplotlib inline import torch from d2l import torch as d2l theta = torch.
arange(0, 1, 0.001) p = theta**9 * (1 - theta)**4.
d2l.
plot(theta, p, 'theta', 'likelihood') isexactlythere, wecanturntocalculus.
Noticethatatthemaximum, thegradientofthe function is flat.
Thus, we could find the maximum likelihood estimate (A.1) by finding the values of ğœƒ where the derivative is zero, and finding the one that gives the highest 981 Maximum Likelihood probability.
Wecompute: ğ‘‘ 0= ğ‘ƒâ€ğ‘‹ j ğœƒâ€ ğ‘‘ğœƒ ğ‘‘ = ğœƒ9â€1 ğœƒâ€4 ğ‘‘ğœƒ (A.6) =9ğœƒ8â€1 ğœƒâ€4 4ğœƒ9â€1 ğœƒâ€3 =ğœƒ8â€1 ğœƒâ€3â€9 13ğœƒâ€.
Thishasthreesolutions: 0,1and9 13.
Thefirsttwoareclearlyminima, notmaximaas theyassignprobability0tooursequence.
Thefinalvaluedoesnotassignzeroprobability tooursequence, andthusmustbethemaximumlikelihoodestimateğœƒË†=9 13.
A.7.2 Numerical Optimizationandthe Negative Log-Likelihood Thepreviousexampleisnice, butwhatifwehavebillionsofparametersanddataexam- ples? First, noticethatifwemaketheassumptionthatallthedataexamplesareindependent, we cannolongerpracticallyconsiderthelikelihooditselfasitisaproductofmanyprobabili- ties.
Indeed, eachprobabilityisinÂ»0,1â€¦, saytypicallyofvalueabout1 2, andtheproductof â€1 2â€1000000000isfarbelowmachineprecision.
Wecannotworkwiththatdirectly.
However, recallthatthelogarithmturnsproductstosums, inwhichcase This number fits perfectly within even a single precision 32-bit float.
Thus, we should considerthelog-likelihood, whichis logâ€ğ‘ƒâ€ğ‘‹ j ğœ½â€â€.
(A.8) Sincethefunctionğ‘¥ 7! logâ€ğ‘¥â€ isincreasing, maximizingthelikelihoodisthesamething asmaximizingthelog-likelihood.
Indeedin Section A.9wewillseethisreasoningapplied whenworkingwiththespecificexampleofthenaive Bayesclassifier.
We often work with loss functions, where we wish to minimize the loss.
We may turn maximumlikelihoodintotheminimizationofalossbytaking logâ€ğ‘ƒâ€ğ‘‹ j ğœ½â€â€, whichis thenegativelog-likelihood.
Toillustratethis, considerthecoinflippingproblemfrombefore, andpretendthatwedo notknowtheclosedformsolution.
Wemaycomputethat logâ€ğ‘ƒâ€ğ‘‹ j ğœ½â€â€ = logâ€ğœƒğ‘›ğ»â€1 ğœƒâ€ğ‘›ğ‘‡â€ = â€ğ‘› ğ»logâ€ğœƒâ€â€šğ‘› ğ‘‡logâ€1 ğœƒâ€â€.
(A.9) Thiscanbewrittenintocode, andfreelyoptimizedevenforbillionsofcoinflips.
# Set up our data n_H = 8675309 n_T = 256245 (continuesonnextpage) 982 Mathematicsfor Deep Learning (continuedfrompreviouspage) # Initialize our paramteres theta = torch.
tensor(0.5, requires_grad=True) # Perform gradient descent lr = 1e-9 for iter in range(100): loss = -(n_H * torch.
log(theta) + n_T * torch.
log(1 - theta)) loss.
backward() with torch.
no_grad(): theta -= lr * theta.
grad theta.
grad.
zero_() # Check output theta, n_H / (n_H + n_T) (tensor(0.9713, requires_grad=True), 0.9713101437890875) Numericalconvenienceisnottheonlyreasonwhypeopleliketousenegativelog-likelihoods.
Thereareseveralotherreasonswhyitispreferable.
The second reason we consider the log-likelihood is the simplified application of calcu- lus rules.
As discussed above, due to independence assumptions, most probabilities we encounterinmachinelearningareproductsofindividualprobabilities.
ğ‘ƒâ€ğ‘‹ j ğœ½â€ = ğ‘â€ğ‘¥ 1 j ğœ½â€ ğ‘â€ğ‘¥ 2 j ğœ½â€ ğ‘â€ğ‘¥ ğ‘› j ğœ½â€.
(A.10) Thismeansthatifwedirectlyapplytheproductruletocomputeaderivativeweget ğœ• ğœ• ğœ•ğœ½ ğ‘ƒâ€ğ‘‹ j ğœ½â€ = ğœ•ğœ½ ğ‘ƒâ€ğ‘¥ 1 j ğœ½â€ ğ‘ƒâ€ğ‘¥ 2 j ğœ½â€ ğ‘ƒâ€ğ‘¥ ğ‘› j ğœ½â€ ğœ• â€šğ‘ƒâ€ğ‘¥ j ğœ½â€ ğ‘ƒâ€ğ‘¥ j ğœ½â€ ğ‘ƒâ€ğ‘¥ j ğœ½â€ 1 ğœ•ğœ½ 2 ğ‘› (A.11) .
.
.
ğœ• â€šğ‘ƒâ€ğ‘¥ j ğœ½â€ ğ‘ƒâ€ğ‘¥ j ğœ½â€ ğ‘ƒâ€ğ‘¥ j ğœ½â€ .
1 2 ğœ•ğœ½ ğ‘› Thisrequiresğ‘›â€ğ‘› 1â€ multiplications, alongwith â€ğ‘› 1â€ additions, soitisproportional to quadratic time in the inputs! Sufficient cleverness in grouping terms will reduce this to linear time, but it requires some thought.
For the negative log-likelihood we have in- stead logâ€ğ‘ƒâ€ğ‘‹ j ğœ½â€â€ = logâ€ğ‘ƒâ€ğ‘¥ 1 j ğœ½â€â€ logâ€ğ‘ƒâ€ğ‘¥ 2 j ğœ½â€â€ logâ€ğ‘ƒâ€ğ‘¥ ğ‘› j ğœ½â€â€, (A.12) whichthengives ğœ• 1 ğœ• 1 ğœ• ğœ•ğœ½ logâ€ğ‘ƒâ€ğ‘‹ j ğœ½â€â€ = ğ‘ƒâ€ğ‘¥ j ğœ½â€ ğœ•ğœ½ ğ‘ƒâ€ğ‘¥ 1 j ğœ½â€ â€š â€š ğ‘ƒâ€ğ‘¥ j ğœ½â€ ğœ•ğœ½ ğ‘ƒâ€ğ‘¥ ğ‘› j ğœ½â€ .
1 ğ‘› (A.13) 983 Maximum Likelihood Thisrequiresonlyğ‘›dividesandğ‘› 1sums, andthusislineartimeintheinputs.
The third and final reason to consider the negative log-likelihood is the relationship to information theory, which we will discuss in detail in Section A.11.
This is a rigorous mathematicaltheorywhichgivesawaytomeasurethedegreeofinformationorrandomness inarandomvariable.
Thekeyobjectofstudyinthatfieldistheentropywhichis ğ»â€ğ‘â€ = ğ‘ ğ‘–log 2 â€ğ‘ ğ‘– â€, (A.14) ğ‘– whichmeasurestherandomnessofasource.
Noticethatthisisnothingmorethantheav- erage logprobability, andthusifwetakeournegativelog-likelihoodanddividebythe numberofdataexamples, wegetarelativeofentropyknownascross-entropy.
Thistheoret- icalinterpretationalonewouldbesufficientlycompellingtomotivatereportingtheaverage negativelog-likelihoodoverthedatasetasawayofmeasuringmodelperformance.
A.7.3 Maximum Likelihoodfor Continuous Variables Everything that we have done so far assumes we are working with discrete random vari- ables, butwhatifwewanttoworkwithcontinuousones? Theshortsummaryisthatnothingatallchanges, exceptwereplacealltheinstancesofthe probabilitywiththeprobabilitydensity.
Recallingthatwewritedensitieswithlowercase ğ‘, thismeansthatforexamplewenowsay logâ€ğ‘â€ğ‘‹ j ğœ½â€â€ = logâ€ğ‘â€ğ‘¥ 1 j ğœ½â€â€ logâ€ğ‘â€ğ‘¥ 2 j ğœ½â€â€ logâ€ğ‘â€ğ‘¥ ğ‘› j ğœ½â€â€ = logâ€ğ‘â€ğ‘¥ ğ‘– j ğœƒâ€â€.
ğ‘– (A.15) Thequestionbecomes,â€œWhyisthis OK?â€Afterall, thereasonweintroduceddensitieswas becauseprobabilitiesofgettingspecificoutcomesthemselveswaszero, andthusisnotthe probabilityofgeneratingourdataforanysetofparameterszero? Indeed, thisisthecase, andunderstandingwhywecanshifttodensitiesisanexercisein tracingwhathappenstotheepsilons.
Letâ€™sfirstre-defineourgoal.
Supposethatforcontinuousrandomvariableswenolonger wanttocomputetheprobabilityofgettingexactlytherightvalue, butinsteadmatchingto withinsomerangeğœ–.
Forsimplicity, weassumeourdataisrepeatedobservationsğ‘¥ 1 ,...,ğ‘¥ ğ‘ ofidenticallydistributedrandomvariables ğ‘‹ 1 ,...,ğ‘‹ ğ‘.
Aswehaveseenpreviously, this canbewrittenas ğ‘ƒâ€ğ‘‹ 2 Â»ğ‘¥ ,ğ‘¥ â€šğœ–â€¦,ğ‘‹ 2 Â»ğ‘¥ ,ğ‘¥ â€šğœ–â€¦,...,ğ‘‹ 2 Â»ğ‘¥ ,ğ‘¥ â€šğœ–â€¦ j ğœ½â€ 1 1 1 2 2 2 ğ‘ ğ‘ ğ‘ (A.16) ğœ–ğ‘ğ‘â€ğ‘¥ j ğœ½â€ ğ‘â€ğ‘¥ j ğœ½â€ ğ‘â€ğ‘¥ j ğœ½â€.
1 2 ğ‘› Thus, ifwetakenegativelogarithmsofthisweobtain logâ€ğ‘ƒâ€ğ‘‹ 1 2 Â»ğ‘¥ 1 ,ğ‘¥ 1 â€šğœ–â€¦,ğ‘‹ 2 2 Â»ğ‘¥ 2 ,ğ‘¥ 2 â€šğœ–â€¦,...,ğ‘‹ ğ‘ 2 Â»ğ‘¥ ğ‘ ,ğ‘¥ ğ‘ â€šğœ–â€¦ j ğœ½â€â€ ğ‘logâ€ğœ–â€ logâ€ğ‘â€ğ‘¥ ğ‘– j ğœ½â€â€.
(A.17) ğ‘– Ifweexaminethisexpression, theonlyplacethattheğœ– occursisintheadditiveconstant 984 Mathematicsfor Deep Learning ğ‘logâ€ğœ–â€.
Thisdoesnotdependontheparametersğœ½atall, sotheoptimalchoiceofğœ½does notdependonourchoiceofğœ–! Ifwedemandfourdigitsorfour-hundred, thebestchoice of ğœ½ remains the same, thus we may freely drop the epsilon to see that what we want to optimizeis logâ€ğ‘â€ğ‘¥ ğ‘– j ğœ½â€â€.
(A.18) ğ‘– Thus, weseethatthemaximumlikelihoodpointofviewcanoperatewithcontinuousran- domvariablesaseasilyaswithdiscreteonesbyreplacingtheprobabilitieswithprobability densities.
A.7.4 Summary Themaximumlikelihoodprincipletellsusthatthebestfitmodelforagivendatasetis theonethatgeneratesthedatawiththehighestprobability.
Oftenpeopleworkwiththenegativelog-likelihoodinsteadforavarietyofreasons: nu- mericalstability, conversionofproductstosums(andtheresultingsimplificationof gradientcomputations), andtheoreticaltiestoinformationtheory.
While simplest to motivate in the discrete setting, it may be freely generalized to the continuoussettingaswellbymaximizingtheprobabilitydensityassignedtothedat- apoints.
A.7.5 Exercises 1.
Supposethatyouknowthatanon-negativerandomvariablehasdensityğ›¼ğ‘’ ğ›¼ğ‘¥ forsome value ğ›¼ > 0.
You obtain a single observation from the random variable which is the number3.
Whatisthemaximumlikelihoodestimateforğ›¼? 2.
Supposethatyouhaveadatasetofsamplesfğ‘¥ ğ‘– g ğ‘– ğ‘ =1 drawnfroma Gaussianwithunknown mean, butvariance1.
Whatisthemaximumlikelihoodestimateforthemean? 286 Discussions286.
A.8 Distributions Nowthatwehavelearnedhowtoworkwithprobabilityinboththediscreteandthecontin- uoussetting, letâ€™sgettoknowsomeofthecommondistributionsencountered.
Depending ontheareaofmachinelearning, wemayneedtobefamiliarwithvastlymoreofthese, or forsomeareasofdeeplearningpotentiallynoneatall.
Thisis, however, agoodbasiclist tobefamiliarwith.
Letâ€™sfirstimportsomecommonlibraries.
985 Distributions %matplotlib inline from math import erf, factorial import torch from IPython import display from d2l import torch as d2l torch.
pi = torch.
acos(torch.
zeros(1)) * 2 # Define pi in torch A.8.1 Bernoulli Thisisthesimplestrandomvariableusuallyencountered.
Thisrandomvariableencodesa coinflipwhichcomesup1withprobability ğ‘ and0withprobability1 ğ‘.
Ifwehavea randomvariable ğ‘‹ withthisdistribution, wewillwrite ğ‘‹ Bernoulliâ€ğ‘â€.
(A.1) Thecumulativedistributionfunctionis 8>>>< 0 ğ‘¥ <0, ğ¹â€ğ‘¥â€ = 1 ğ‘ 0 ğ‘¥ <1, (A.2) >>> :1 ğ‘¥ >=1.
Theprobabilitymassfunctionisplottedbelow.
p = 0.3 d2l.
set_figsize() d2l.
plt.
stem([0, 1], [1 - p, p], use_line_collection=True) d2l.
plt.
xlabel('x') d2l.
plt.
show() Now, letâ€™splotthecumulativedistributionfunction(A.2).
x = torch.
arange(-1, 2, 0.01) def F(x): return 0 if x < 0 else 1 if x > 1 else 1 - p (continuesonnextpage) 986 Mathematicsfor Deep Learning (continuedfrompreviouspage) If ğ‘‹ Bernoulliâ€ğ‘â€, then: ğœ‡ ğ‘‹ = ğ‘, ğœ2 = ğ‘â€1 ğ‘â€.
ğ‘‹ Wecansampleanarrayofarbitraryshapefroma Bernoullirandomvariableasfollows.
1*(torch.
rand(10, 10) < p) tensor([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0], [1, 1, 0, 0, 1, 1, 1, 1, 1, 0], [1, 0, 0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 1, 1, 1, 1, 0, 1, 0, 0]]) A.8.2 Discrete Uniform Thenextcommonlyencounteredrandomvariableisadiscreteuniform.
Forourdiscussion here, wewillassumethatitissupportedontheintegers f1,2,...,ğ‘›g, howeveranyother setofvaluescanbefreelychosen.
Themeaningoftheworduniforminthiscontextisthat everypossiblevalueisequallylikely.
Theprobabilityforeachvalueğ‘– 2 f1,2,3,...,ğ‘›gis ğ‘ ğ‘– = ğ‘› 1.
Wewilldenotearandomvariable ğ‘‹ withthisdistributionas ğ‘‹ ğ‘ˆâ€ğ‘›â€.
(A.3) 987 Distributions Thecumulativedistributionfunctionis 8>>>< 0 ğ‘¥ <1, ğ¹â€ğ‘¥â€ = ğ‘˜ ğ‘˜ ğ‘¥ < ğ‘˜ â€š1with1 ğ‘˜ < ğ‘›, (A.4) >>> ğ‘› :1 ğ‘¥ >=ğ‘›.
Letâ€™sfirstplottheprobabilitymassfunction.
n = 5 d2l.
plt.
stem([i+1 for i in range(n)], n*[1 / n], use_line_collection=True) d2l.
plt.
xlabel('x') d2l.
plt.
show() Now, letâ€™splotthecumulativedistributionfunction(A.4).
x = torch.
arange(-1, 6, 0.01) def F(x): return 0 if x < 1 else 1 if x > n else torch.
floor(x) / n If ğ‘‹ ğ‘ˆâ€ğ‘›â€, then: ğœ‡ ğ‘‹ = 1â€šğ‘› , 2 ğœ2 = ğ‘›2 1.
ğ‘‹ 12 988 Mathematicsfor Deep Learning We can sample an array of arbitrary shape from a discrete uniform random variable as follows.
torch.
randint(1, n, size=(10, 10)) tensor([[1, 4, 3, 2, 1, 1, 3, 1, 1, 4], [4, 1, 1, 4, 4, 1, 4, 3, 2, 4], [2, 4, 4, 1, 4, 2, 4, 3, 2, 1], [1, 2, 3, 1, 1, 4, 2, 4, 1, 3], [1, 2, 4, 1, 4, 3, 3, 2, 2, 1], [1, 2, 2, 4, 1, 3, 2, 4, 2, 3], [1, 2, 3, 4, 1, 3, 4, 1, 4, 3], [3, 1, 1, 4, 4, 1, 3, 1, 1, 2], [2, 2, 4, 3, 4, 2, 3, 4, 2, 4], [1, 4, 3, 3, 2, 3, 3, 4, 1, 3]]) A.8.3 Continuous Uniform Next, letâ€™sdiscussthecontinuousuniformdistribution.
Theideabehindthisrandomvari- ableisthatifweincreasetheğ‘›inthediscreteuniformdistribution, andthenscaleittofit within the interval Â»ğ‘,ğ‘â€¦, we will approach a continuous random variable that just picks an arbitrary value in Â»ğ‘,ğ‘â€¦ all with equal probability.
We will denote this distribution as ğ‘‹ ğ‘ˆâ€ğ‘,ğ‘â€.
(A.5) Theprobabilitydensityfunctionis ( 1 ğ‘¥ 2 Â»ğ‘,ğ‘â€¦, ğ‘â€ğ‘¥â€ = ğ‘ ğ‘ (A.6) 0 ğ‘¥ âˆ‰ Â»ğ‘,ğ‘â€¦.
Thecumulativedistributionfunctionis 8>>>< 0 ğ‘¥ < ğ‘, ğ¹â€ğ‘¥â€ = ğ‘¥ ğ‘ ğ‘¥ 2 Â»ğ‘,ğ‘â€¦, (A.7) >>> ğ‘ ğ‘ :1 ğ‘¥ >= ğ‘.
Letâ€™sfirstplottheprobabilitydensityfunction(A.6).
a, b = 1, 3 x = torch.
arange(0, 4, 0.01) p = (x > a).
type(torch.
float32)*(x < b).
type(torch.
float32)/(b-a) d2l.
plot(x, p, 'x', 'p.
d.
f.') Now, letâ€™splotthecumulativedistributionfunction(A.7).
989 Distributions def F(x): return 0 if x < a else 1 if x > b else (x - a) / (b - a) If ğ‘‹ ğ‘ˆâ€ğ‘,ğ‘â€, then: ğœ‡ ğ‘‹ = ğ‘â€šğ‘ , 2 ğœ2 = â€ğ‘ ğ‘â€2 .
ğ‘‹ 12 Wecansampleanarrayofarbitraryshapefromauniformrandomvariableasfollows.
Note thatitbydefaultsamplesfromağ‘ˆâ€0,1â€, soifwewantadifferentrangeweneedtoscale it.
(b - a) * torch.
rand(10, 10) + a â†©!3454, 2.4754], â†©!3860, 1.9090], â†©!4641, 2.8991], (continuesonnextpage) 990 Mathematicsfor Deep Learning (continuedfrompreviouspage) â†©!3354, 1.0130], â†©!3311, 2.6557], â†©!8165, 1.2806], â†©!4036, 2.1958], â†©!2235, 2.7038], â†©!9245, 1.7640], â†©!3818, 2.2087]]) A.8.4 Binomial Letâ€™smakethingsalittlemorecomplexandexaminethebinomialrandomvariable.
This randomvariableoriginatesfromperformingasequenceofğ‘›independentexperiments, each of which has probability ğ‘ of succeeding, and asking how many successes we expect to see.
Letâ€™sexpressthismathematically.
Eachexperimentisanindependentrandomvariable ğ‘‹ ğ‘– wherewewilluse1toencodesuccess, and0toencodefailure.
Sinceeachisanindependent coinflipwhichissuccessfulwithprobability ğ‘, wecansaythat ğ‘‹ ğ‘– Bernoulliâ€ğ‘â€.
Then, thebinomialrandomvariableis ğ‘› ğ‘‹ = ğ‘‹ ğ‘– .
(A.8) ğ‘–=1 Inthiscase, wewillwrite ğ‘‹ Binomialâ€ğ‘›,ğ‘â€.
(A.9) To get the cumulative distribution function, we need to notice that getting exactly ğ‘˜ suc- cessescanoccurin ğ‘› = ğ‘›! wayseachofwhichhasaprobabilityof ğ‘ğ‘˜â€1 ğ‘â€ğ‘› ğ‘˜ ğ‘˜ ğ‘˜!â€ğ‘› ğ‘˜â€! ofoccurring.
Thusthecumulativedistributionfunctionis 8>>>< 0 Ë ğ‘¥ <0, ğ¹â€ğ‘¥â€ = >>> ğ‘š ğ‘˜ ğ‘š ğ‘› ğ‘ğ‘šâ€1 ğ‘â€ğ‘› ğ‘š ğ‘˜ ğ‘¥ < ğ‘˜ â€š1with0 ğ‘˜ < ğ‘›, (A.10) :1 ğ‘¥ >=ğ‘›.
Letâ€™sfirstplottheprobabilitymassfunction.
991 Distributions n, p = 10, 0.2 # Compute binomial coefficient def binom(n, k): comb = 1 for i in range(min(k, n - k)): comb = comb * (n - i) // (i + 1) return comb pmf = torch.
tensor([p**i * (1-p)**(n - i) * binom(n, i) for i in range(n + 1)]) d2l.
plt.
stem([i for i in range(n + 1)], pmf, use_line_collection=True) d2l.
plt.
xlabel('x') d2l.
plt.
show() Now, letâ€™splotthecumulativedistributionfunction(A.10).
x = torch.
arange(-1, 11, 0.01) cmf = torch.
cumsum(pmf, dim=0) def F(x): return 0 if x < 0 else 1 if x > n else cmf[int(x)] If ğ‘‹ Binomialâ€ğ‘›,ğ‘â€, then: ğœ‡ ğ‘‹ =ğ‘›ğ‘, 992 Mathematicsfor Deep Learning ğœ2 =ğ‘›ğ‘â€1 ğ‘â€.
ğ‘‹ Thisfollowsfromthelinearityofexpectedvalueoverthesumofğ‘›Bernoullirandomvari- ables, andthefactthatthevarianceofthesumofindependentrandomvariablesisthesum ofthevariances.
Thiscanbesampledasfollows.
m = torch.
distributions.
binomial.
Binomial(n, p) m.
sample(sample_shape=(10, 10)) A.8.5 Poisson Letâ€™s now perform a thought experiment.
We are standing at a bus stop and we want to know how many buses will arrive in the next minute.
Letâ€™s start by considering ğ‘‹â€1â€ Bernoulliâ€ğ‘â€ whichissimplytheprobabilitythatabusarrivesintheoneminutewindow.
Forbusstopsfarfromanurbancenter, thismightbeaprettygoodapproximation.
Wemay neverseemorethanonebusinaminute.
However, ifweareinabusyarea, itispossibleorevenlikelythattwobuseswillarrive.
Wecanmodelthisbysplittingourrandomvariableintotwopartsforthefirst30seconds, orthesecond30seconds.
Inthiscasewecanwrite ğ‘‹â€2â€ ğ‘‹â€2â€ â€šğ‘‹â€2â€, (A.11) 1 2 where ğ‘‹â€2â€ is the total sum, and ğ‘‹â€2â€ Bernoulliâ€ğ‘ 2â€.
The total distribution is then ğ‘– ğ‘‹â€2â€ Binomialâ€2,ğ‘ 2â€.
Whystophere? Letâ€™scontinuetosplitthatminuteintoğ‘›parts.
Bythesamereasoningas above, weseethat ğ‘‹â€ğ‘›â€ Binomialâ€ğ‘›,ğ‘ ğ‘›â€.
(A.12) Considertheserandomvariables.
Bytheprevioussection, weknowthat(A.12)hasmean ğœ‡ ğ‘‹â€ğ‘›â€ = ğ‘›â€ğ‘ ğ‘›â€ = ğ‘, andvarianceğœ ğ‘‹ 2 â€ğ‘›â€ = ğ‘›â€ğ‘ ğ‘›â€â€1 â€ğ‘ ğ‘›â€â€ = ğ‘â€1 ğ‘ ğ‘›â€.
Ifwetake ğ‘›!1, wecanseethatthesenumbersstabilizetoğœ‡ ğ‘‹â€1â€ = ğ‘, andvarianceğœ ğ‘‹ 2 â€1â€ = ğ‘.
This indicatesthattherecouldbesomerandomvariablewecandefineinthisinfinitesubdivision limit.
Thisshouldnotcomeastoomuchofasurprise, sinceintherealworldwecanjustcount 993 Distributions thenumberofbusarrivals, howeveritisnicetoseethatourmathematicalmodeliswell defined.
Thisdiscussioncanbemadeformalasthelawofrareevents.
Followingthroughthisreasoningcarefully, wecanarriveatthefollowingmodel.
Wewill saythatğ‘‹ Poissonâ€ğœ†â€ifitisarandomvariablewhichtakesthevaluesf0,1,2,...
gwith probability ğœ†ğ‘˜ğ‘’ ğœ† ğ‘ ğ‘˜ = ğ‘˜! .
(A.13) The valueğœ† > 0 is known as the rate (or the shape parameter), and denotes the average numberofarrivalsweexpectinoneunitoftime.
Wemaysumthisprobabilitymassfunctiontogetthecumulativedistributionfunction.
( 0 ğ‘¥ <0, ğ¹â€ğ‘¥â€ = Ë (A.14) ğ‘’ ğœ† ğ‘˜ ğœ†ğ‘š ğ‘˜ ğ‘¥ < ğ‘˜ â€š1with0 ğ‘˜.
ğ‘š=0 ğ‘š! Letâ€™sfirstplottheprobabilitymassfunction(A.13).
lam = 5.0 xs = [i for i in range(20)] pmf = torch.
tensor([torch.
exp(torch.
tensor(-lam)) * lam**k / factorial(k) for k in xs]) d2l.
plt.
stem(xs, pmf, use_line_collection=True) d2l.
plt.
xlabel('x') d2l.
plt.
show() Now, letâ€™splotthecumulativedistributionfunction(A.14).
x = torch.
arange(-1, 21, 0.01) cmf = torch.
cumsum(pmf, dim=0) def F(x): return 0 if x < 0 else 1 if x > n else cmf[int(x)] As we saw above, the means and variances are particularly concise.
If ğ‘‹ Poissonâ€ğœ†â€, then: 994 Mathematicsfor Deep Learning ğœ‡ ğ‘‹ =ğœ†, ğœ2 =ğœ†.
ğ‘‹ Thiscanbesampledasfollows.
m = torch.
distributions.
poisson.
Poisson(lam) m.
sample((10, 10)) A.8.6 Gaussian Now Letâ€™s try a different, but related experiment.
Letâ€™s say we again are performing ğ‘› independent Bernoulliâ€ğ‘â€measurementsğ‘‹ ğ‘–.
Thedistributionofthesumoftheseisğ‘‹â€ğ‘›â€ Binomialâ€ğ‘›,ğ‘â€.
Ratherthantakingalimitasğ‘›increasesand ğ‘decreases, Letâ€™sfix ğ‘, and thensendğ‘› !1.
Inthiscase ğœ‡ ğ‘‹â€ğ‘›â€ = ğ‘›ğ‘ !1andğœ ğ‘‹ 2 â€ğ‘›â€ = ğ‘›ğ‘â€1 ğ‘â€ !1, sothereis noreasontothinkthislimitshouldbewelldefined.
However, notallhopeislost! Letâ€™sjustmakethemeanandvariancebewellbehavedby defining ğ‘‹â€ğ‘›â€ ğœ‡ ğ‘Œâ€ğ‘›â€ = ğ‘‹â€ğ‘›â€.
(A.15) ğœ ğ‘‹â€ğ‘›â€ Thiscanbeseentohavemeanzeroandvarianceone, andsoitisplausibletobelievethat itwillconvergetosomelimitingdistribution.
Ifweplotwhatthesedistributionslooklike, wewillbecomeevenmoreconvincedthatitwillwork.
995 Distributions p = 0.2 ns = [1, 10, 100, 1000] d2l.
plt.
figure(figsize=(10, 3)) for i in range(4): n = ns[i] pmf = torch.
tensor([p**i * (1-p)**(n-i) * binom(n, i) for i in range(n + 1)]) d2l.
plt.
subplot(1, 4, i + 1) d2l.
plt.
stem([(i - n*p)/torch.
sqrt(torch.
tensor(n*p*(1 - p))) for i in range(n + 1)], pmf, use_line_collection=True) d2l.
plt.
xlim([-4, 4]) d2l.
plt.
xlabel('x') d2l.
plt.
title("n = {}".
format(n)) d2l.
plt.
show() Onethingtonote: comparedtothe Poissoncase, wearenowdividingbythestandardde- viationwhichmeansthatwearesqueezingthepossibleoutcomesintosmallerandsmaller areas.
This is an indication that our limit will no longer be discrete, but rather continu- ous.
A derivation of what occurs is beyond the scope of this document, but the central limit theorem states that as ğ‘› ! 1, this will yield the Gaussian Distribution (or sometimes normaldistribution).
Moreexplicitly, foranyğ‘,ğ‘: lim ğ‘ƒâ€ğ‘Œâ€ğ‘›â€ 2 Â»ğ‘,ğ‘â€¦â€ = ğ‘ƒâ€Nâ€0,1â€ 2 Â»ğ‘,ğ‘â€¦â€, (A.16) ğ‘›!1 wherewesayarandomvariableisnormallydistributedwithgivenmean ğœ‡ andvariance ğœ2, written ğ‘‹ Nâ€ğœ‡,ğœ2â€if ğ‘‹ hasdensity ğ‘ ğ‘‹ â€ğ‘¥â€ = p 1 ğ‘’ â€ğ‘¥ 2 ğœ ğœ‡ 2 â€2 .
(A.17) 2ğœ‹ğœ2 Letâ€™sfirstplottheprobabilitydensityfunction(A.17).
mu, sigma = 0, 1 (continuesonnextpage) 996 Mathematicsfor Deep Learning (continuedfrompreviouspage) x = torch.
arange(-3, 3, 0.01) p = 1 / torch.
sqrt(2 * torch.
pi * sigma**2) * torch.
exp( -(x - mu)**2 / (2 * sigma**2)) d2l.
plot(x, p, 'x', 'p.
d.
f.') Now, letâ€™s plot the cumulative distribution function.
It is beyond the scope of this ap- pendix, but the Gaussian c.
d.
f.
does not have a closed-form formula in terms of more elementaryfunctions.
Wewilluseerfwhichprovidesawaytocomputethisintegralnu- merically.
def phi(x): Keen-eyedreaderswillrecognizesomeoftheseterms.
Indeed, weencounteredthisintegral in Section A.5.
Indeed weneed exactlythat computationto seethat this ğ‘ ğ‘‹ â€ğ‘¥â€ hastotal areaoneandisthusavaliddensity.
Ourchoiceofworkingwithcoinflipsmadecomputationsshorter, butnothingaboutthat choicewasfundamental.
Indeed, ifwetakeanycollectionofindependentidenticallydis- tributedrandomvariables ğ‘‹ ğ‘–, andform ğ‘ ğ‘‹â€ğ‘â€ = ğ‘‹ ğ‘– .
(A.18) ğ‘–=1 997 Distributions Then ğ‘‹â€ğ‘â€ ğœ‡ ğ‘‹â€ğ‘â€ (A.19) ğœ ğ‘‹â€ğ‘â€ willbeapproximately Gaussian.
Thereareadditionalrequirementsneededtomakeitwork, mostcommonlyğ¸Â»ğ‘‹4â€¦ <1, butthephilosophyisclear.
The central limit theorem is the reason why the Gaussian is fundamental to probability, statistics, and machine learning.
Whenever we can say that something we measured is a sumofmanysmallindependentcontributions, wecanassumethatthethingbeingmeasured willbecloseto Gaussian.
Therearemanymorefascinatingpropertiesof Gaussians, andwewouldliketodiscussone more here.
The Gaussian is what is known as a maximum entropy distribution.
We will get into entropy more deeply in Section A.11, however all we need to know at this point isthat it is ameasure of randomness.
In arigorous mathematical sense, wecanthink of the Gaussianasthemostrandomchoiceofrandomvariablewithfixedmeanandvariance.
Thus, ifweknowthatourrandomvariablehassomemeanandvariance, the Gaussianisin asensethemostconservativechoiceofdistributionwecanmake.
Toclosethesection, letâ€™srecallthatif ğ‘‹ Nâ€ğœ‡,ğœ2â€, then: ğœ‡ ğ‘‹ = ğœ‡, ğœ2 =ğœ2.
ğ‘‹ Wecansamplefromthe Gaussian(orstandardnormal)distributionasshownbelow.
torch.
normal(mu, sigma, size=(10, 10)) â†©!7313, -0.3038, 1.1935], â†©!0314, 0.3819, -1.7822], â†©!9052, -0.6411, -0.8949], â†©!0591, 0.8377, 0.5097], â†©!0253, -0.9182, 1.1536], â†©!9204, -0.5908, 0.9113], â†©!5744, -0.0668, 1.2074], (continuesonnextpage) 998 Mathematicsfor Deep Learning (continuedfrompreviouspage) â†©!5010, 0.6026, -0.7722], â†©!2663, 1.2275, 0.5993], â†©!8397, 0.0360, -0.7089]]) A.8.7 Exponential Family One shared property for all the distributions listed above is that they all belong to which isknownastheexponentialfamily.
Theexponentialfamilyisasetofdistributionswhose densitycanbeexpressedinthefollowingform: ğ‘â€x j ğœ¼â€ = â„â€xâ€ exp ğœ¼> ğ‘‡â€xâ€ ğ´â€ğœ¼â€ (A.20) Asthisdefinitioncanbealittlesubtle, letâ€™sexamineitclosely.
First, â„â€xâ€ isknownastheunderlyingmeasureorthebasemeasure.
Thiscanbeviewed asanoriginalchoiceofmeasurewearemodifyingwithourexponentialweight.
Second, we have the vector ğœ¼ = â€ğœ‚ 1 ,ğœ‚ 2 ,...,ğœ‚ ğ‘™ â€ 2 Rğ‘™ called the natural parameters or canonicalparameters.
Thesedefinehowthebasemeasurewillbemodified.
Thenatural parametersenterintothenewmeasurebytakingthedotproductoftheseparametersagainst some functionğ‘‡â€ â€ of x = â€ğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘› â€ 2 Rğ‘› and exponentiated.
The vectorğ‘‡â€xâ€ = â€ğ‘‡ 1 â€xâ€,ğ‘‡ 2 â€xâ€,...,ğ‘‡ ğ‘™ â€xâ€â€iscalledthesuï¬€icientstatisticsforğœ¼.
Thisnameisusedsincethe information represented byğ‘‡â€xâ€ is sufficient to calculate the probability density and no otherinformationfromthesamplexâ€™sarerequired.
Third, wehave ğ´â€ğœ¼â€, whichisreferredtoasthecumulantfunction, whichensuresthatthe abovedistribution(A.20)integratestoone, i.
e., â€ ğ´â€ğœ¼â€ =log â„â€xâ€ exp ğœ¼> ğ‘‡â€xâ€ ğ‘‘x .
(A.21) Tobeconcrete, letâ€™sconsiderthe Gaussian.
Assumingthatxisanunivariatevariable, we sawthatithadadensityof 1 â€ğ‘¥ ğœ‡â€2 ğ‘â€ğ‘¥ j ğœ‡,ğœâ€ = p exp 2ğœ‹ğœ2 2ğœ2 (A.22) 1 ğœ‡ 1 1 = p exp ğ‘¥ ğ‘¥2 ğœ‡2â€šlogâ€ğœâ€ .
2ğœ‹ ğœ2 2ğœ2 2ğœ2 Thismatchesthedefinitionoftheexponentialfamilywith: underlyingmeasure: â„â€ğ‘¥â€ = p1 , 2ğœ‹ ğœ‚ ğœ‡ naturalparameters: ğœ¼ = 1 = ğœ2 , ğœ‚ 1 2 2ğœ2 999 Naive Bayes ğ‘¥ suï¬€icientstatistics:ğ‘‡â€ğ‘¥â€ = , and ğ‘¥2 ğœ‚2 cumulantfunction: ğ´â€ğœ¼â€ = 1 ğœ‡2â€šlogâ€ğœâ€ = 1 1logâ€2ğœ‚ â€.
2ğœ2 4ğœ‚ 2 2 2 Itisworthnotingthattheexactchoiceofeachofabovetermsissomewhatarbitrary.
Indeed, theimportantfeatureisthatthedistributioncanbeexpressedinthisform, nottheexactform itself.
Aswealludetoin Section4.1.2, awidelyusedtechniqueistoassumethatthefinaloutput y follows an exponential family distribution.
The exponential family is a common and powerfulfamilyofdistributionsencounteredfrequentlyinmachinelearning.
A.8.8 Summary Bernoullirandomvariablescanbeusedtomodeleventswithayes/nooutcome.
Discreteuniformdistributionsmodelselectsfromafinitesetofpossibilities.
Continuousuniformdistributionsselectfromaninterval.
Binomialdistributionsmodelaseriesof Bernoullirandomvariables, andcountthenum- berofsuccesses.
Poissonrandomvariablesmodelthearrivalofrareevents.
Gaussian random variables model the result of adding a large number of independent randomvariablestogether.
Alltheabovedistributionsbelongtoexponentialfamily.
A.8.9 Exercises 1.
Whatisthestandarddeviationofarandomvariablethatisthedifference ğ‘‹ ğ‘Œ oftwo independentbinomialrandomvariables ğ‘‹,ğ‘Œ Binomialâ€16,1 2â€.
p 2.
If we take a Poisson random variable ğ‘‹ Poissonâ€ğœ†â€ and consider â€ğ‘‹ ğœ†â€ ğœ† as ğœ† ! 1, wecanshowthatthisbecomesapproximately Gaussian.
Whydoesthismake sense? 3.
Whatistheprobabilitymassfunctionforasumoftwodiscreteuniformrandomvariables onğ‘›elements? Discussions287.
287 A.9 Naive Bayes Throughouttheprevioussections, welearnedaboutthetheoryofprobabilityandrandom variables.
To put this theory to work, letâ€™s introduce the naive Bayes classifier.
This 1000 Mathematicsfor Deep Learning uses nothing but probabilistic fundamentals to allow us to perform classification of dig- its.
Learningisallaboutmakingassumptions.
Ifwewanttoclassifyanewdataexamplethatwe haveneverseenbeforewehavetomakesomeassumptionsaboutwhichdataexamplesare similartoeachother.
Thenaive Bayesclassifier, apopularandremarkablyclearalgorithm, assumesallfeaturesareindependentfromeachothertosimplifythecomputation.
Inthis section, wewillapplythismodeltorecognizecharactersinimages.
%matplotlib inline import math import torch import torchvision from d2l import torch as d2l d2l.
use_svg_display() A.9.1 Optical Character Recognition MNIST(Le Cunetal.,1998)isoneofwidelyuseddatasets.
Itcontains60,000imagesfor trainingand10,000imagesforvalidation.
Eachimagecontainsahandwrittendigitfrom0 to9.
Thetaskisclassifyingeachimageintothecorrespondingdigit.
Gluon provides a MNIST class in the data.
vision module to automatically retrieve the datasetfromthe Internet.
Subsequently, Gluonwillusethealready-downloadedlocalcopy.
Wespecifywhetherwearerequestingthetrainingsetorthetestsetbysettingthevalueof theparametertrainto Trueor False, respectively.
Eachimageisagrayscaleimagewith bothwidthandheightof28withshape(28,28,1).
Weuseacustomizedtransformationto removethelastchanneldimension.
Inaddition, thedatasetrepresentseachpixelbyanun- signed8-bitinteger.
Wequantizethemintobinaryfeaturestosimplifytheproblem.
data_transform = torchvision.
transforms.
Compose([ torchvision.
transforms.
To Tensor(), lambda x: torch.
floor(x * 255 / 128).
squeeze(dim=0) ]) mnist_train = torchvision.
datasets.
MNIST( root='./temp', train=True, transform=data_transform, download=True) mnist_test = torchvision.
datasets.
MNIST( root='./temp', train=False, transform=data_transform, download=True) Downloading http://yann.
lecun.
com/exdb/mnist/train-images-idx3-ubyte.
gz Downloading http://yann.
lecun.
com/exdb/mnist/train-images-idx3-ubyte.
gz to ./ â†©! temp/MNIST/raw/train-images-idx3-ubyte.
gz 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 9912422/9912422 [00:00<00:00, 115752065.81it/s] Extracting ./temp/MNIST/raw/train-images-idx3-ubyte.
gz to ./temp/MNIST/raw Downloading http://yann.
lecun.
com/exdb/mnist/train-labels-idx1-ubyte.
gz Downloading http://yann.
lecun.
com/exdb/mnist/train-labels-idx1-ubyte.
gz to ./ (continuesonnextpage) 1001 Naive Bayes (continuedfrompreviouspage) â†©! temp/MNIST/raw/train-labels-idx1-ubyte.
gz 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 28881/28881 [00:00<00:00, 5234904.66it/s] Extracting ./temp/MNIST/raw/train-labels-idx1-ubyte.
gz to ./temp/MNIST/raw Downloading http://yann.
lecun.
com/exdb/mnist/t10k-images-idx3-ubyte.
gz Downloading http://yann.
lecun.
com/exdb/mnist/t10k-images-idx3-ubyte.
gz to ./ â†©! temp/MNIST/raw/t10k-images-idx3-ubyte.
gz 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 1648877/1648877 [00:00<00:00, 43715298.68it/s]Extracting ./ â†©! temp/MNIST/raw/t10k-images-idx3-ubyte.
gz to ./temp/MNIST/raw Downloading http://yann.
lecun.
com/exdb/mnist/t10k-labels-idx1-ubyte.
gz Downloading http://yann.
lecun.
com/exdb/mnist/t10k-labels-idx1-ubyte.
gz to ./ â†©! temp/MNIST/raw/t10k-labels-idx1-ubyte.
gz 100%|ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿ï¿¿| 4542/4542 [00:00<00:00, 21501725.47it/s] Extracting ./temp/MNIST/raw/t10k-labels-idx1-ubyte.
gz to ./temp/MNIST/raw Wecanaccessaparticularexample, whichcontainstheimageandthecorrespondingla- bel.
image, label = mnist_train[2] image.
shape, label (torch.
Size([28, 28]), 4) Ourexample, storedhereinthevariableimage, correspondstoanimagewithaheightand widthof28pixels.
image.
shape, image.
dtype (torch.
Size([28, 28]), torch.
float32) Ourcodestoresthelabelofeachimageasascalar.
Itstypeisa32-bitinteger.
label, type(label) (4, int) Wecanalsoaccessmultipleexamplesatthesametime.
images = torch.
stack([mnist_train[i][0] for i in range(10, 38)], dim=0) labels = torch.
tensor([mnist_train[i][1] for i in range(10, 38)]) images.
shape, labels.
shape 1002 Mathematicsfor Deep Learning (torch.
Size([28, 28, 28]), torch.
Size([28])) Letâ€™svisualizetheseexamples.
d2l.
show_images(images, 2, 9); A.9.2 The Probabilistic Modelfor Classification Inaclassificationtask, wemapanexampleintoacategory.
Hereanexampleisagrayscale 28 28image, andacategoryisadigit.
(Referto Section4.1foramoredetailedexpla- nation.) Onenaturalwaytoexpresstheclassificationtaskisviatheprobabilisticquestion: whatisthemostlikelylabelgiventhefeatures(i.
e., imagepixels)? Denotebyx 2 Rğ‘‘ the featuresoftheexampleandğ‘¦ 2 Rthelabel.
Herefeaturesareimagepixels, wherewecan reshape a 2-dimensional image to a vector so that ğ‘‘ = 282 = 784, and labels are digits.
Theprobabilityofthelabelgiventhefeaturesis ğ‘â€ğ‘¦ j xâ€.
Ifweareabletocomputethese probabilities, whichare ğ‘â€ğ‘¦ j xâ€ for ğ‘¦ = 0,...,9inourexample, thentheclassifierwill outputthepredictionğ‘¦Ë† givenbytheexpression: ğ‘¦Ë† =argmaxğ‘â€ğ‘¦ j xâ€.
(A.1) Unfortunately, this requires that we estimate ğ‘â€ğ‘¦ j xâ€ for every value of x = ğ‘¥ 1 ,...,ğ‘¥ ğ‘‘.
Imaginethateachfeaturecouldtakeoneof2values.
Forexample, thefeatureğ‘¥ =1might 1 signifythatthewordappleappearsinagivendocumentandğ‘¥ = 0wouldsignifythatit 1 doesnot.
Ifwehad30suchbinaryfeatures, thatwouldmeanthatweneedtobeprepared toclassifyanyof230(over1billion!) possiblevaluesoftheinputvectorx.
Moreover, whereisthelearning? Ifweneedtoseeeverysinglepossibleexampleinorderto predictthecorrespondinglabelthenwearenotreallylearningapatternbutjustmemorizing thedataset.
A.9.3 The Naive Bayes Classifier Fortunately, bymakingsomeassumptionsaboutconditionalindependence, wecanintro- ducesomeinductivebiasandbuildamodelcapableofgeneralizingfromacomparatively modest selection of training examples.
To begin, letâ€™s use Bayes theorem, to express the classifieras ğ‘â€x j ğ‘¦â€ğ‘â€ğ‘¦â€ ğ‘¦Ë† =argmax ğ‘â€ğ‘¦ j xâ€ =argmax .
(A.2) ğ‘¦ ğ‘¦ ğ‘â€xâ€ 1003 Naive Bayes Notethatthedenominatoristhenormalizingtermğ‘â€xâ€whichdoesnotdependonthevalue ofthelabel ğ‘¦.
Asaresult, weonlyneedtoworryaboutcomparingthenumeratoracross differentvaluesof ğ‘¦.
Evenifcalculatingthedenominatorturnedouttobeintractable, we couldgetawaywithignoringit, solongaswecouldevaluatethenumerator.
Fortunately, evenifwewantedtorecoverthenormalizingconstant, wecould.
Wecanalwaysrecover Ë thenormalizationtermsince ğ‘¦ ğ‘â€ğ‘¦ j xâ€ =1.
Now, letâ€™sfocuson ğ‘â€x j ğ‘¦â€.
Usingthechainruleofprobability, wecanexpresstheterm ğ‘â€x j ğ‘¦â€as ğ‘‘ By itself, this expression does not get us any further.
We still must estimate roughly 2 parameters.
However, ifweassumethatthefeaturesareconditionallyindependentofeach other, giventhelabel, thensuddenlyweareinmuchbettershape, asthistermsimplifiesto Ë› ğ‘– ğ‘â€ğ‘¥ ğ‘– j ğ‘¦â€, givingusthepredictor ğ‘‘ ğ‘¦Ë† =argmax ğ‘¦ ğ‘â€ğ‘¥ ğ‘– j ğ‘¦â€ğ‘â€ğ‘¦â€.
(A.4) ğ‘–=1 Ifwecanestimate ğ‘â€ğ‘¥ ğ‘– =1 j ğ‘¦â€foreveryğ‘–andğ‘¦, andsaveitsvalueinğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘–,ğ‘¦â€¦, hereğ‘ƒ ğ‘¥ğ‘¦ isağ‘‘ ğ‘›matrixwithğ‘›beingthenumberofclassesandğ‘¦ 2 f1,...,ğ‘›g, thenwecanalso usethistoestimate ğ‘â€ğ‘¥ ğ‘– =0 j ğ‘¦â€, i.
e., ( ğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘–,ğ‘¦â€¦ forğ‘¡ ğ‘– =1; ğ‘â€ğ‘¥ ğ‘– =ğ‘¡ ğ‘– j ğ‘¦â€ = (A.5) 1 ğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘–,ğ‘¦â€¦ forğ‘¡ ğ‘– =0.
Inaddition, weestimate ğ‘â€ğ‘¦â€ forevery ğ‘¦ andsaveitin ğ‘ƒ ğ‘¦ Â»ğ‘¦â€¦, with ğ‘ƒ ğ‘¦ ağ‘›-lengthvector.
Then, foranynewexamplet= â€ğ‘¡ 1 ,ğ‘¡ 2 ,...,ğ‘¡ ğ‘‘ â€, wecouldcompute ğ‘‘ ğ‘¦Ë† =argmax ğ‘¦ ğ‘â€ğ‘¦â€ ğ‘â€ğ‘¥ ğ‘¡ =ğ‘¡ ğ‘– j ğ‘¦â€ ğ‘–=1 (A.6) ğ‘‘ =argmax ğ‘¦ ğ‘ƒ ğ‘¦ Â»ğ‘¦â€¦ ğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘–,ğ‘¦â€¦ğ‘¡ğ‘– 1 ğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘–,ğ‘¦â€¦ 1 ğ‘¡ğ‘– ğ‘–=1 for any ğ‘¦.
So our assumption of conditional independence has taken the complexity of ourmodelfromanexponentialdependenceonthenumberoffeatures Oâ€2 ğ‘‘ğ‘›â€ toalinear dependence, whichis Oâ€ğ‘‘ğ‘›â€.
A.9.4 Training Theproblemnowisthatwedonotknowğ‘ƒ ğ‘¥ğ‘¦ andğ‘ƒ ğ‘¦.
Soweneedtoestimatetheirvalues givensometrainingdatafirst.
Thisistrainingthemodel.
Estimating ğ‘ƒ ğ‘¦ isnottoohard.
Sinceweareonlydealingwith10classes, wemaycountthenumberofoccurrencesğ‘› ğ‘¦ for eachofthedigitsanddivideitbythetotalamountofdatağ‘›.
Forinstance, ifdigit8occurs ğ‘› = 5,800 times and we have a total of ğ‘› = 60,000 images, the probability estimate is 8 ğ‘â€ğ‘¦ =8â€ =0.0967.
1004 Mathematicsfor Deep Learning X = torch.
stack([mnist_train[i][0] for i in range(len(mnist_train))], dim=0) Y = torch.
tensor([mnist_train[i][1] for i in range(len(mnist_train))]) n_y = torch.
zeros(10) for y in range(10): n_y[y] = (Y == y).
sum() P_y = n_y / n_y.
sum() P_y 0.0992]) Now on to slightly more difficult things ğ‘ƒ ğ‘¥ğ‘¦.
Since we picked black and white images, ğ‘â€ğ‘¥ ğ‘– j ğ‘¦â€ denotestheprobabilitythatpixelğ‘–isswitchedonforclassğ‘¦.
Justlikebeforewe can go and count the number of times ğ‘› ğ‘–ğ‘¦ such that an event occurs and divide it by the totalnumberofoccurrencesofğ‘¦, i.
e.,ğ‘› ğ‘¦.
Butthereissomethingslightlytroubling: certain pixelsmayneverbeblack(e.
g., forwellcroppedimagesthecornerpixelsmightalwaysbe white).
Aconvenientwayforstatisticianstodealwiththisproblemistoaddpseudocounts toalloccurrences.
Hence, ratherthanğ‘› ğ‘–ğ‘¦ weuseğ‘› ğ‘–ğ‘¦ â€š1andinsteadofğ‘› ğ‘¦ weuseğ‘› ğ‘¦ â€š2 (sincetherearetwopossiblevaluespixelğ‘–cantake-itcaneitherbeblackorwhite).
This isalsocalled Laplace Smoothing.
Itmayseemad-hoc, howeveritcanbemotivatedfroma Bayesianpoint-of-viewbya Beta-binomialmodel.
n_x = torch.
zeros((10, 28, 28)) for y in range(10): n_x[y] = torch.
tensor(X.
numpy()[Y.
numpy() == y].
sum(axis=0)) P_xy = (n_x + 1) / (n_y + 2).
reshape(10, 1, 1) d2l.
show_images(P_xy, 2, 5); Byvisualizingthese10 28 28probabilities(foreachpixelforeachclass)wecouldget somemeanlookingdigits.
Nowwecanuse(A.6)topredictanewimage.
Givenx, thefollowingfunctionscomputes ğ‘â€x j ğ‘¦â€ğ‘â€ğ‘¦â€foreveryğ‘¦.
1005 Naive Bayes def bayes_pred(x): x = x.
unsqueeze(0) # (28, 28) -> (1, 28, 28) p_xy = P_xy * x + (1 - P_xy)*(1 - x) p_xy = p_xy.
reshape(10, -1).
prod(dim=1) # p(x|y) return p_xy * P_y image, label = mnist_test[0] bayes_pred(image) Thiswenthorriblywrong! Tofindoutwhy, letâ€™slookattheperpixelprobabilities.
They aretypicallynumbersbetween0.001and1.
Wearemultiplying784ofthem.
Atthispoint itisworthmentioningthatwearecalculatingthesenumbersonacomputer, hencewitha fixedrangefortheexponent.
Whathappensisthatweexperiencenumericalunderflow, i.
e., multiplyingallthesmallnumbersleadstosomethingevensmalleruntilitisroundeddown tozero.
Wediscussedthisasatheoreticalissuein Section A.7, butweseethephenomena clearlyhereinpractice.
As discussed in that section, we fix this by use the fact that logğ‘ğ‘ = logğ‘ â€šlogğ‘, i.
e., weswitchtosumminglogarithms.
Evenifbothğ‘andğ‘aresmallnumbers, thelogarithm valuesshouldbeinaproperrange.
a = 0.1 print('underflow:', a**784) print('logarithm is normal:', 784*math.
log(a)) underflow: 0.0 logarithm is normal: -1805.2267129073316 Sincethelogarithmisanincreasingfunction, wecanrewrite(A.6)as ğ‘‘ h i ğ‘¦Ë† =argmax ğ‘¦ logğ‘ƒ ğ‘¦ Â»ğ‘¦â€¦â€š ğ‘¡ ğ‘–logğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘¥ ğ‘– ,ğ‘¦â€¦â€šâ€1 ğ‘¡ ğ‘– â€logâ€1 ğ‘ƒ ğ‘¥ğ‘¦ Â»ğ‘¥ ğ‘– ,ğ‘¦â€¦â€ .
(A.7) ğ‘–=1 Wecanimplementthefollowingstableversion: log_P_xy = torch.
log(P_xy) log_P_xy_neg = torch.
log(1 - P_xy) log_P_y = torch.
log(P_y) def bayes_pred_stable(x): x = x.
unsqueeze(0) # (28, 28) -> (1, 28, 28) p_xy = log_P_xy * x + log_P_xy_neg * (1 - x) p_xy = p_xy.
reshape(10, -1).
sum(axis=1) # p(x|y) return p_xy + log_P_y py = bayes_pred_stable(image) py 1006 Mathematicsfor Deep Learning -292.5226, -114.6257, -220.3313, -163.1784]) Wemaynowcheckifthepredictioniscorrect.
py.
argmax(dim=0) == label tensor(True) Ifwenowpredictafewvalidationexamples, wecanseethe Bayesclassifierworkspretty well.
def predict(X): return [bayes_pred_stable(x).
argmax(dim=0).
type(torch.
int32).
item() for x in X] X = torch.
stack([mnist_test[i][0] for i in range(18)], dim=0) y = torch.
tensor([mnist_test[i][1] for i in range(18)]) preds = predict(X) d2l.
show_images(X, 2, 9, titles=[str(d) for d in preds]); Finally, letâ€™scomputetheoverallaccuracyoftheclassifier.
X = torch.
stack([mnist_test[i][0] for i in range(len(mnist_test))], dim=0) y = torch.
tensor([mnist_test[i][1] for i in range(len(mnist_test))]) preds = torch.
tensor(predict(X), dtype=torch.
int32) float((preds == y).
sum()) / len(y) # Validation accuracy 0.8427 Modern deep networks achieve error rates of less than 0.01.
The relatively poor perfor- mance is due to the incorrect statistical assumptions that we made in our model: we as- sumedthateachandeverypixelareindependentlygenerated, dependingonlyonthelabel.
Thisisclearlynothowhumanswritedigits, andthiswrongassumptionledtothedownfall ofouroverlynaive(Bayes)classifier.
A.9.5 Summary 1007 Statistics Using Bayesâ€™rule, aclassifiercanbemadebyassumingallobservedfeaturesareinde- pendent.
This classifier can be trained on a dataset by counting the number of occurrences of combinationsoflabelsandpixelvalues.
Thisclassifierwasthegoldstandardfordecadesfortaskssuchasspamdetection.
A.9.6 Exercises 1.
Consider the dataset Â»Â»0,0â€¦,Â»0,1â€¦,Â»1,0â€¦,Â»1,1â€¦â€¦ with labels given by the XOR of the two elements Â»0,1,1,0â€¦.
What are the probabilities for a Naive Bayes classifier built onthisdataset.
Doesitsuccessfullyclassifyourpoints? Ifnot, whatassumptionsare violated? 2.
Suppose that we did not use Laplace smoothing when estimating probabilities and a dataexamplearrivedattestingtimewhichcontainedavalueneverobservedintraining.
Whatwouldthemodeloutput? 3.
Thenaive Bayesclassifierisaspecificexampleofa Bayesiannetwork, wherethede- pendenceofrandomvariablesareencodedwithagraphstructure.
Whilethefulltheory is beyond the scope of this section (see Koller and Friedman (2009) for full details), explainwhyallowingexplicitdependencebetweenthetwoinputvariablesinthe XOR modelallowsforthecreationofasuccessfulclassifier.
288 Discussions288.
A.10 Statistics Undoubtedly, tobeatopdeeplearningpractitioner, theabilitytotrainthestate-of-the-art andhighaccuratemodelsiscrucial.
However, itisoftenunclearwhenimprovementsare significant, oronlytheresultofrandomfluctuationsinthetrainingprocess.
Tobeableto discussuncertaintyinestimatedvalues, wemustlearnsomestatistics.
Theearliestreferenceofstatisticscanbetracedbacktoan Arabscholar Al-Kindiinthe9th- century, whogaveadetaileddescriptionofhowtousestatisticsandfrequencyanalysisto decipherencryptedmessages.
After800years, themodernstatisticsarosefrom Germany in1700s, whentheresearchersfocusedonthedemographicandeconomicdatacollection andanalysis.
Today, statisticsisthesciencesubjectthatconcernsthecollection, processing, analysis, interpretationandvisualizationofdata.
Whatismore, thecoretheoryofstatistics hasbeenwidelyusedintheresearchwithinacademia, industry, andgovernment.
Morespecifically, statisticscanbedividedtodescriptivestatisticsandstatisticalinference.
Theformerfocusonsummarizingandillustratingthefeaturesofacollectionofobserved data, which is referred to as a sample.
The sample is drawn from a population, denotes 1008 Mathematicsfor Deep Learning thetotalsetofsimilarindividuals, items, oreventsofourexperimentinterests.
Contraryto descriptivestatistics, statisticalinferencefurtherdeducesthecharacteristicsofapopulation fromthegivensamples, basedontheassumptionsthatthesampledistributioncanreplicate thepopulationdistributionatsomedegree.
Youmaywonder: â€œWhatistheessentialdifferencebetweenmachinelearningandstatis- tics?â€ Fundamentallyspeaking, statisticsfocusesontheinferenceproblem.
Thistypeof problems includes modeling the relationship between the variables, such as causal infer- ence, andtestingthestatisticallysignificanceofmodelparameters, suchas A/Btesting.
In contrast, machinelearningemphasizesonmakingaccuratepredictions, withoutexplicitly programmingandunderstandingeachparameterâ€™sfunctionality.
Inthissection, wewillintroducethreetypesofstatisticsinferencemethods: evaluatingand comparingestimators, conductinghypothesistests, andconstructingconfidenceintervals.
These methods can help us infer the characteristics of a given population, i.
e., the true parameter ğœƒ.
For brevity, we assume that the true parameter ğœƒ of a given population is a scalarvalue.
Itisstraightforwardtoextendtothecasewhereğœƒ isavectororatensor, thus weomititinourdiscussion.
A.10.1 Evaluatingand Comparing Estimators Instatistics, anestimatorisafunctionofgivensamplesusedtoestimatethetrueparameter ğœƒ.
We will write ğœƒË† ğ‘› = ğ‘“Ë†â€ğ‘¥ 1 ,...,ğ‘¥ ğ‘› â€ for the estimate of ğœƒ after observing the samples {ğ‘¥ 1 ,ğ‘¥ 2 ,...,ğ‘¥ ğ‘›}.
Wehaveseensimpleexamplesofestimatorsbeforeinsection Section A.7.
Ifyouhavea numberofsamplesfroma Bernoullirandomvariable, thenthemaximumlikelihoodesti- matefortheprobabilitytherandomvariableisonecanbeobtainedbycountingthenumber ofonesobservedanddividingbythetotalnumberofsamples.
Similarly, anexerciseasked youtoshowthatthemaximumlikelihoodestimateofthemeanofa Gaussiangivenanum- berofsamplesisgivenbytheaveragevalueofallthesamples.
Theseestimatorswillalmost never give the true value of the parameter, but ideally for a large number of samples the estimatewillbeclose.
Asanexample, weshowbelowthetruedensityofa Gaussianrandomvariablewithmean zeroandvarianceone, alongwithacollectionsamplesfromthat Gaussian.
Weconstructed the ğ‘¦ coordinate so every point is visible and the relationship to the original density is clearer.
import torch from d2l import torch as d2l torch.
pi = torch.
acos(torch.
zeros(1)) * 2 #define pi in torch # Sample datapoints and create y coordinate epsilon = 0.1 torch.
manual_seed(8675309) xs = torch.
randn(size=(300,)) (continuesonnextpage) 1009 Statistics (continuedfrompreviouspage) ys = torch.
tensor( [torch.
sum(torch.
exp(-(xs[: i] - xs[i])**2 / (2 * epsilon**2))\ / torch.
sqrt(2*torch.
pi*epsilon**2)) / len(xs)\ for i in range(len(xs))]) # Compute true density xd = torch.
arange(torch.
min(xs), torch.
max(xs), 0.01) yd = torch.
exp(-xd**2/2) / torch.
sqrt(2 * torch.
pi) # Plot the results d2l.
plot(xd, yd, 'x', 'density') d2l.
plt.
scatter(xs, ys) d2l.
plt.
axvline(x=0) d2l.
plt.
axvline(x=torch.
mean(xs), linestyle='--', color='purple') d2l.
plt.
show() There can be many ways to compute an estimator of a parameter ğœƒË† ğ‘›.
In this section, we introducethreecommonmethodstoevaluateandcompareestimators: themeansquared error, thestandarddeviation, andstatisticalbias.
Mean Squared Error Perhapsthesimplestmetricusedtoevaluateestimatorsisthemeansquarederror(MSE) (orğ‘™ loss)estimatorwhichcanbedefinedas 2 MSEâ€ğœƒË† ğ‘› ,ğœƒâ€ = ğ¸Â»â€ğœƒË† ğ‘› ğœƒâ€2â€¦.
(A.1) Thisallowsustoquantifytheaveragesquareddeviationfromthetruevalue.
MSEisalways non-negative.
Ifyouhaveread Section3.1, youwillrecognizeitasthemostcommonlyused regressionlossfunction.
Asameasuretoevaluateanestimator, thecloseritsvaluetozero, theclosertheestimatorisclosetothetrueparameterğœƒ.
Statistical Bias The MSEprovidesanaturalmetric, butwecaneasilyimaginemultipledifferentphenom- enathatmightmakeitlarge.
Twofundamentallyimportantarefluctuationintheestimator 1010 Mathematicsfor Deep Learning duetorandomnessinthedataset, andsystematicerrorintheestimatorduetotheestimation procedure.
First, letâ€™smeasurethesystematicerror.
ForanestimatorğœƒË† ğ‘›, themathematicalillustration ofstatisticalbiascanbedefinedas biasâ€ğœƒË† ğ‘› â€ = ğ¸â€ğœƒË† ğ‘› ğœƒâ€ = ğ¸â€ğœƒË† ğ‘› â€ ğœƒ.
(A.2) Notethatwhenbiasâ€ğœƒË† ğ‘› â€ =0, theexpectationoftheestimatorğœƒË† ğ‘› isequaltothetruevalue of parameter.
In this case, we say ğœƒË† ğ‘› is an unbiased estimator.
In general, an unbiased estimatorisbetterthanabiasedestimatorsinceitsexpectationisthesameasthetruepa- rameter.
It is worth being aware, however, that biased estimators are frequently used in practice.
There are cases where unbiased estimators do not exist without further assumptions, or areintractabletocompute.
Thismayseemlikeasignificantflawinanestimator, however themajorityofestimatorsencounteredinpracticeareatleastasymptoticallyunbiasedin thesensethatthebiastends tozeroasthenumberof availablesamplestendstoinfinity: limğ‘›!1biasâ€ğœƒË† ğ‘› â€ =0.
Varianceand Standard Deviation Second, letâ€™smeasuretherandomnessintheestimator.
Recallfrom Section A.6, thestan- darddeviation(orstandarderror)isdefinedasthesquaredrootofthevariance.
Wemay measurethedegreeoffluctuationofanestimatorbymeasuringthestandarddeviationor varianceofthatestimator.
q q ğœ ğœƒË†ğ‘› = Varâ€ğœƒË† ğ‘› â€ = ğ¸Â»â€ğœƒË† ğ‘› ğ¸â€ğœƒË† ğ‘› â€â€2â€¦.
(A.3) Itisimportanttocompare(A.3)to(A.1).
Inthisequationwedonotcomparetothetrue population value ğœƒ, but instead to ğ¸â€ğœƒË† ğ‘› â€, the expected sample mean.
Thus we are not measuringhowfartheestimatortendstobefromthetruevalue, butinsteadwemeasuring thefluctuationoftheestimatoritself.
The Bias-Variance Trade-off Itisintuitivelyclearthatthesetwomaincomponentscontributetothemeansquarederror.
What is somewhat shocking is that we can show that this is actually a decomposition of themeansquarederrorintothesetwocontributionsplusathirdone.
Thatistosaythatwe canwritethemeansquarederrorasthesumofthesquareofthebias, thevarianceandthe 1011 Statistics irreducibleerror.
MSEâ€ğœƒË† ğ‘› ,ğœƒâ€ = ğ¸Â»â€ğœƒË† ğ‘› ğœƒâ€2â€¦ = ğ¸Â»â€ğœƒË† ğ‘› â€2â€¦â€šğ¸Â»ğœƒ2â€¦ 2ğ¸Â»ğœƒË† ğ‘› ğœƒâ€¦ =VarÂ»ğœƒË† ğ‘› â€¦â€šğ¸Â»ğœƒË† ğ‘› â€¦2â€šVarÂ»ğœƒâ€¦â€šğ¸Â»ğœƒâ€¦2 2ğ¸Â»ğœƒË† ğ‘› â€¦ğ¸Â»ğœƒâ€¦ (A.4) = â€ğ¸Â»ğœƒË† ğ‘› â€¦ ğ¸Â»ğœƒâ€¦â€2â€šVarÂ»ğœƒË† ğ‘› â€¦â€šVarÂ»ğœƒâ€¦ = â€ğ¸Â»ğœƒË† ğ‘› ğœƒâ€¦â€2â€šVarÂ»ğœƒË† ğ‘› â€¦â€šVarÂ»ğœƒâ€¦ = â€biasÂ»ğœƒË† ğ‘› â€¦â€2â€šVarâ€ğœƒË† ğ‘› â€â€šVarÂ»ğœƒâ€¦.
Werefertheaboveformulaasbias-variancetrade-off.
Themeansquarederrorcanbedi- videdintothreesourcesoferror: theerrorfromhighbias, theerrorfromhighvarianceand theirreducibleerror.
Thebiaserroriscommonlyseeninasimplemodel(suchasalinear regression model), which cannot extract high dimensional relations between the features andtheoutputs.
Ifamodelsuffersfromhighbiaserror, weoftensayitisunderfittingor lackofflexibiltyasintroducedin(Section3.6).
Thehighvarianceusuallyresultsfroma too complex model, which overfits the training data.
As a result, an overfitting model is sensitivetosmallfluctuationsinthedata.
Ifamodelsuffersfromhighvariance, weoften sayitisoverfittingandlackofgeneralizationasintroducedin(Section3.6).
Theirreducible erroristheresultfromnoiseintheğœƒ itself.
Evaluating Estimatorsin Code Sincethestandarddeviationofanestimatorhasbeenimplementingbysimplycallinga.
std()foratensora, wewillskipitbutimplementthestatisticalbiasandthemeansquared error.
# Statistical bias def stat_bias(true_theta, est_theta): return(torch.
mean(est_theta) - true_theta) # Mean squared error def mse(data, true_theta): return(torch.
mean(torch.
square(data - true_theta))) Toillustratetheequationofthebias-variancetrade-off, letâ€™ssimulateofnormaldistribution Nâ€ğœƒ,ğœ2â€ with 10,000 samples.
Here, we use a ğœƒ = 1 and ğœ = 4.
As the estimator is a functionofthegivensamples, hereweusethemeanofthesamplesasanestimatorfortrue ğœƒ inthisnormaldistribution Nâ€ğœƒ,ğœ2â€.
theta_true = 1 sigma = 4 sample_len = 10000 samples = torch.
normal(theta_true, sigma, size=(sample_len, 1)) theta_est = torch.
mean(samples) theta_est 1012 Mathematicsfor Deep Learning tensor(1.0170) Letâ€™svalidatethetrade-offequationbycalculatingthesummationofthesquaredbiasand thevarianceofourestimator.
First, calculatethe MSEofourestimator.
mse(samples, theta_true) tensor(16.0298) Next, wecalculate Varâ€ğœƒË† ğ‘› â€â€šÂ»biasâ€ğœƒË† ğ‘› â€â€¦2asbelow.
Asyoucansee, thetwovaluesagreeto numericalprecision.
bias = stat_bias(theta_true, theta_est) torch.
square(samples.
std(unbiased=False)) + torch.
square(bias) tensor(16.0298) A.10.2 Conducting Hypothesis Tests Themostcommonlyencounteredtopicinstatisticalinferenceishypothesistesting.
While hypothesis testing was popularized in the early 20th century, the first use can be traced back to John Arbuthnot in the 1700s.
John tracked 80-year birth records in London and concluded that more men were born than women each year.
Following that, the modern significancetestingistheintelligenceheritageby Karl Pearsonwhoinvented ğ‘-valueand Pearsonâ€™schi-squaredtest, William Gossetwhoisthefatherof Studentâ€™st-distribution, and Ronald Fisherwhoinitialedthenullhypothesisandthesignificancetest.
Ahypothesistestisawayofevaluatingsomeevidenceagainstthedefaultstatementabouta population.
Wereferthedefaultstatementasthenullhypothesisğ» , whichwetrytoreject 0 usingtheobserveddata.
Here, weuseğ» asastartingpointforthestatisticalsignificance 0 testing.
The alternative hypothesis ğ» ğ´ (or ğ» 1 ) is a statement that is contrary to the null hypothesis.
Anullhypothesisisoftenstatedinadeclarativeformwhichpositsarelation- shipbetweenvariables.
Itshouldreflectthebriefasexplicitaspossible, andbetestableby statisticstheory.
Imagine you are a chemist.
After spending thousands of hours in the lab, you develop a newmedicinewhichcandramaticallyimproveoneâ€™sabilitytounderstandmath.
Toshow its magic power, you need to test it.
Naturally, you may need some volunteers to take themedicineandseewhetheritcanhelpthemlearnmathematicsbetter.
Howdoyouget started? First, youwillneedcarefullyrandomselectedtwogroupsofvolunteers, sothatthereisno difference between their mathematical understanding ability measured by some metrics.
The two groups are commonly referred to as the test group and the control group.
The testgroup(ortreatmentgroup)isagroupofindividualswhowillexperiencethemedicine, 1013 Statistics while the control group represents the group of users who are set aside as a benchmark, i.
e., identical environment setups except taking this medicine.
In this way, the influence of all the variables are minimized, except the impact of the independent variable in the treatment.
Second, after a period of taking the medicine, you will need to measure the two groupsâ€™ mathematicalunderstandingbythesamemetrics, suchaslettingthevolunteersdothesame testsafterlearninganewmathematicalformula.
Then, youcancollecttheirperformance andcomparetheresults.
Inthiscase, ournullhypothesiswillbethatthereisnodifference betweenthetwogroups, andouralternatewillbethatthereis.
This is still not fully formal.
There are many details you have to think of carefully.
For example, whatisthesuitablemetricstotesttheirmathematicalunderstandingability? How many volunteers for your test so you can be confident to claim the effectiveness of your medicine? Howlongshouldyourunthetest? Howdoyoudecideifthereisadifference betweenthetwogroups? Doyoucareabouttheaverageperformanceonly, oralsotherange ofvariationofthescores? Andsoon.
Inthisway, hypothesistestingprovidesaframeworkforexperimentaldesignandreasoning about certainty in observed results.
If we can now show that the null hypothesis is very unlikelytobetrue, wemayrejectitwithconfidence.
Tocompletethestoryofhowtoworkwithhypothesistesting, weneedtonowintroduce someadditionalterminologyandmakesomeofourconceptsaboveformal.
Statistical Significance Thestatisticalsignificancemeasurestheprobabilityoferroneouslyrejectingthenullhy- pothesis,ğ» , whenitshouldnotberejected, i.
e., 0 statisticalsignificance =1 ğ›¼ =1 ğ‘ƒâ€rejectğ» j ğ» istrueâ€.
(A.5) 0 0 Itisalsoreferredtoasthetype Ierrororfalsepositive.
Theğ›¼, iscalledasthesignificance level and its commonly used value is 5%, i.
e., 1 ğ›¼ = 95%.
The significance level can be explained as the level of risk that we are willing to take, when we reject a true null hypothesis.
Fig.
A.1 shows the observationsâ€™ values and probability of a given normal distribution in a two-sample hypothesis test.
If the observation data example is located outsides the 95% threshold, it will be a very unlikely observation under the null hypothesis assump- tion.
Hence, theremightbesomethingwrongwiththenullhypothesisandwewillreject it.
Statistical Power Thestatisticalpower(orsensitivity)measurestheprobabilityofrejectthenullhypothesis, ğ» , whenitshouldberejected, i.
e., 0 statisticalpower =1 ğ›½=1 ğ‘ƒâ€failtorejectğ» j ğ» isfalseâ€.
(A.6) 0 0 1014 Mathematicsfor Deep Learning t Fig.
A.1 Statisticalsignificance.
Recall that a type I error is error caused by rejecting the null hypothesis when it is true, whereasatype IIerrorisresultedfromfailingtorejectthenullhypothesiswhenitisfalse.
A type II error is usually denoted as ğ›½, and hence the corresponding statistical power is 1 ğ›½.
Intuitively, statisticalpowercanbeinterpretedashowlikelyourtestwilldetectarealdis- crepancy of some minimum magnitude at a desired statistical significance level.
80% is a commonly used statistical power threshold.
The higher the statistical power, the more likelywearetodetecttruedifferences.
Oneofthemostcommonusesofstatisticalpowerisindeterminingthenumberofsamples needed.
Theprobabilityyourejectthenullhypothesiswhenitisfalsedependsonthedegree towhichitisfalse(knownastheeffectsize)andthenumberofsamplesyouhave.
Asyou mightexpect, smalleffectsizeswillrequireaverylargenumberofsamplestobedetectable withhighprobability.
Whilebeyondthescopeofthisbriefappendixtoderiveindetail, as anexample, wanttobeabletorejectanullhypothesisthatoursamplecamefromamean zerovarianceone Gaussian, andwebelievethatoursampleâ€™smeanisactuallyclosetoone, wecandosowithacceptableerrorrateswithasamplesizeofonly8.
However, ifwethink oursamplepopulationtruemeaniscloseto0.01, thenweâ€™dneedasamplesizeofnearly 80000todetectthedifference.
Wecanimaginethepowerasawaterfilter.
Inthisanalogy, ahighpowerhypothesistestis likeahighqualitywaterfiltrationsystemthatwillreduceharmfulsubstancesinthewater asmuchaspossible.
Ontheotherhand, asmallerdiscrepancyislikealowqualitywater filter, wheresomerelativesmallsubstancesmayeasilyescapefromthegaps.
Similarly, if thestatisticalpowerisnotofenoughhighpower, thenthetestmaynotcatchthesmaller discrepancy.
Test Statistic Ateststatisticğ‘‡â€ğ‘¥â€ isascalarwhichsummarizessomecharacteristicofthesampledata.
Thegoalofdefiningsuchastatisticisthatitshouldallowustodistinguishbetweendifferent distributionsandconductourhypothesistest.
Thinkingbacktoourchemistexample, ifwe wishtoshowthatonepopulationperformsbetterthantheother, itcouldbereasonableto 1015 Statistics take the mean as the test statistic.
Different choices of test statistic can lead to statistical testwithdrasticallydifferentstatisticalpower.
Often,ğ‘‡â€ğ‘‹â€ (thedistributionoftheteststatisticunderournullhypothesis)willfollow, at leastapproximately, acommonprobabilitydistributionsuchasanormaldistributionwhen consideredunderthenullhypothesis.
Ifwecanderiveexplicitlysuchadistribution, and thenmeasureourteststatisticonourdataset, wecansafelyrejectthenullhypothesisifour statisticisfaroutsidetherangethatwewouldexpect.
Makingthisquantitativeleadsusto thenotionof ğ‘-values.
ğ‘-value The ğ‘-value(ortheprobabilityvalue)istheprobabilitythatğ‘‡â€ğ‘‹â€isatleastasextremeas theobservedteststatisticğ‘‡â€ğ‘¥â€assumingthatthenullhypothesisistrue, i.
e., ğ‘-value= ğ‘ƒ ğ» â€ğ‘‡â€ğ‘‹â€ ğ‘‡â€ğ‘¥â€â€.
(A.7) 0 Iftheğ‘-valueissmallerthanorequaltoapredefinedandfixedstatisticalsignificancelevel ğ›¼, we may reject the null hypothesis.
Otherwise, we will conclude that we are lack of evidence to reject the null hypothesis.
For a given population distribution, the region of rejectionwillbetheintervalcontainedofallthepointswhichhasa ğ‘-valuesmallerthan thestatisticalsignificancelevelğ›¼.
One-side Testand Two-sided Test Normally there are two kinds of significance test: the one-sided test and the two-sided test.
Theone-sidedtest(orone-tailedtest)isapplicablewhenthenullhypothesisandthe alternativehypothesisonlyhaveonedirection.
Forexample, thenullhypothesismaystate that the true parameter ğœƒ is less than or equal to a value ğ‘.
The alternative hypothesis wouldbethatğœƒ isgreaterthanğ‘.
Thatis, theregionofrejectionisononlyonesideofthe samplingdistribution.
Contrarytotheone-sidedtest, thetwo-sidedtest(ortwo-tailedtest) isapplicablewhentheregionofrejectionisonbothsidesofthesamplingdistribution.
An exampleinthiscasemayhaveanullhypothesisstatethatthetrueparameterğœƒisequaltoa valueğ‘.
Thealternativehypothesiswouldbethatğœƒ isnotequaltoğ‘.
General Stepsof Hypothesis Testing Aftergettingfamiliarwiththeaboveconcepts, letâ€™sgothroughthegeneralstepsofhypoth- esistesting.
1.
Statethequestionandestablishanullhypothesesğ» .
0 2.
Setthestatisticalsignificancelevelğ›¼andastatisticalpower(1 ğ›½).
3.
Obtainsamples throughexperiments.
Thenumber of samplesneeded will dependon thestatisticalpower, andtheexpectedeffectsize.
4.
Calculatetheteststatisticandthe ğ‘-value.
1016 Mathematicsfor Deep Learning 5.
Make the decision to keep or reject the null hypothesis based on the ğ‘-value and the statisticalsignificancelevelğ›¼.
Toconductahypothesistest, westartbydefininganullhypothesisandalevelofriskthat wearewillingtotake.
Thenwecalculatetheteststatisticofthesample, takinganextreme value of the test statistic as evidence against the null hypothesis.
If the test statistic falls withintherejectregion, wemayrejectthenullhypothesisinfavorofthealternative.
Hypothesistestingisapplicableinavarietyofscenariossuchastheclinicaltrailsand A/B testing.
A.10.3 Constructing Confidence Intervals When estimatingthe value of a parameter ğœƒ, point estimators like ğœƒË† are of limited utility since they contain no notion of uncertainty.
Rather, it would be far better if we could produceanintervalthatwouldcontainthetrueparameter ğœƒ withhighprobability.
Ifyou were interested in such ideas a century ago, then you would have been excited to read â€œOutlineofa Theoryof Statistical Estimation Basedonthe Classical Theoryof Probabilityâ€ by Jerzy Neyman(Neyman,1937), whofirstintroducedtheconceptofconfidenceinterval in1937.
To be useful, a confidence interval should be as small as possible for a given degree of certainty.
Letâ€™sseehowtoderiveit.
Definition Mathematically, aconfidenceintervalforthetrueparameterğœƒ isanintervalğ¶ ğ‘› thatcom- putedfromthesampledatasuchthat ğ‘ƒ ğœƒ â€ğ¶ ğ‘› 3 ğœƒâ€ 1 ğ›¼,8ğœƒ.
(A.8) Hereğ›¼ 2 â€0,1â€, and1 ğ›¼iscalledtheconfidencelevelorcoverageoftheinterval.
Thisis thesameğ›¼asthesignificancelevelaswediscussedaboutabove.
Note that (A.8) is about variableğ¶ ğ‘›, not about the fixed ğœƒ.
To emphasize this, we write ğ‘ƒ ğœƒ â€ğ¶ ğ‘› 3 ğœƒâ€ratherthanğ‘ƒ ğœƒ â€ğœƒ 2ğ¶ ğ‘› â€.
Interpretation Itisverytemptingtointerpreta95%confidenceintervalasanintervalwhereyoucanbe 95%surethetrueparameterlies, howeverthisissadlynottrue.
Thetrueparameterisfixed, anditistheintervalthatisrandom.
Thusabetterinterpretationwouldbetosaythatifyou generatedalargenumberofconfidenceintervalsbythisprocedure,95%ofthegenerated intervalswouldcontainthetrueparameter.
Thismayseempedantic, butitcanhaverealimplicationsfortheinterpretationoftheresults.
Inparticular, wemaysatisfy(A.8)byconstructingintervalsthatwearealmostcertaindo notcontainthetruevalue, aslongasweonlydosorarelyenough.
Weclosethissectionby 1017 Statistics providingthreetemptingbutfalsestatements.
Anin-depthdiscussionofthesepointscan befoundin Moreyetal.
(2016).
Fallacy1.
Narrowconfidenceintervalsmeanwecanestimatetheparameterprecisely.
Fallacy2.
Thevaluesinsidetheconfidenceintervalaremorelikelytobethetruevalue thanthoseoutsidetheinterval.
Fallacy3.
Theprobabilitythataparticularobserved95%confidenceintervalcontains thetruevalueis95%.
Sufficedtosay, confidenceintervalsaresubtleobjects.
However, ifyoukeeptheinterpre- tationclear, theycanbepowerfultools.
AGaussian Example Letâ€™sdiscussthemostclassicalexample, theconfidenceintervalforthemeanofa Gaussian ofunknownmeanandvariance.
Supposewecollectğ‘›samplesfğ‘¥ ğ‘– g ğ‘– ğ‘› =1 fromour Gaussian Nâ€ğœ‡,ğœ2â€.
Wecancomputeestimatorsforthemeanandvariancebytaking ğ‘› ğ‘› 1 1 ğœ‡Ë†ğ‘› = ğ‘› ğ‘¥ ğ‘– andğœË†ğ‘› 2 = ğ‘› 1 â€ğ‘¥ ğ‘– ğœ‡Ë†â€2.
(A.9) ğ‘–=1 ğ‘–=1 Ifwenowconsidertherandomvariable ğ‘‡ = ğœ‡Ë†ğ‘› p ğœ‡ , (A.10) ğœË†ğ‘› ğ‘› we obtain a random variable following a well-known distribution called the Studentâ€™s t- distributiononğ‘› 1degreesoffreedom.
This distribution is very well studied, and it is known, for instance, that as ğ‘› ! 1, it is approximatelyastandard Gaussian, andthusbylookingupvaluesofthe Gaussianc.
d.
f.
in atable, wemayconcludethatthevalueofğ‘‡ isintheinterval Â» 1.96,1.96â€¦ atleast95% ofthetime.
Forfinitevaluesof ğ‘›, theintervalneedstobesomewhatlarger, butarewell knownandprecomputedintables.
Thus, wemayconcludethatforlargeğ‘›, ğ‘ƒ ğœ‡Ë†ğ‘› p ğœ‡ ğœË†ğ‘› ğ‘› p RearrangingthisbymultiplyingbothsidesbyğœË†ğ‘› ğ‘›andthenaddingğœ‡Ë†ğ‘›, weobtain ğ‘ƒ ğœ‡ 2 ğœ‡Ë†ğ‘› 1.96p ğœË†ğ‘›,ğœ‡Ë†ğ‘› â€š1.96p ğœË†ğ‘› 0.95.
(A.12) ğ‘› ğ‘› Thusweknowthatwehavefoundour95%confidenceinterval: ğœ‡Ë†ğ‘› 1.96p ğœË†ğ‘›,ğœ‡Ë†ğ‘› â€š1.96p ğœË†ğ‘› .
(A.13) ğ‘› ğ‘› It is safe to say that (A.13) is one of the most used formula in statistics.
Letâ€™s close our 1018 Mathematicsfor Deep Learning discussionofstatisticsbyimplementingit.
Forsimplicity, weassumeweareintheasymp- toticregime.
Smallvaluesofğ‘ shouldincludethecorrectvalueoft_starobtainedeither programmaticallyorfromağ‘¡-table.
# Py Torch uses Bessel's correction by default, which means the use of ddof=1 # instead of default ddof=0 in numpy.
We can use unbiased=False to imitate # ddof=0.
# Number of samples N = 1000 # Sample dataset samples = torch.
normal(0, 1, size=(N,)) # Lookup Students's t-distribution c.
d.
f.
t_star = 1.96 # Construct interval mu_hat = torch.
mean(samples) sigma_hat = samples.
std(unbiased=True) (mu_hat - t_star*sigma_hat/torch.
sqrt(torch.
tensor(N, dtype=torch.
float32)),\ mu_hat + t_star*sigma_hat/torch.
sqrt(torch.
tensor(N, dtype=torch.
float32))) (tensor(-0.0568), tensor(0.0704)) A.10.4 Summary Statisticsfocusesoninferenceproblems, whereasdeeplearningemphasizesonmaking accuratepredictionswithoutexplicitlyprogrammingandunderstanding.
Therearethreecommonstatisticsinferencemethods: evaluatingandcomparingestima- tors, conductinghypothesistests, andconstructingconfidenceintervals.
Therearethreemostcommonestimators: statisticalbias, standarddeviation, andmean squareerror.
Aconfidenceintervalisanestimatedrangeofatruepopulationparameterthatwecan constructbygiventhesamples.
Hypothesis testing is a way of evaluating some evidence against the default statement aboutapopulation.
A.10.5 Exercises 1.
Let ğ‘‹ 1 ,ğ‘‹ 2 ,...,ğ‘‹ ğ‘› i id Unifâ€0,ğœƒâ€, where â€œiidâ€ stands for independent and identically distributed.
Considerthefollowingestimatorsofğœƒ: ğœƒË†=maxfğ‘‹ 1 ,ğ‘‹ 2 ,...,ğ‘‹ ğ‘› g; (A.14) ğ‘› 2 ğœƒËœ=2ğ‘‹Â¯ ğ‘› = ğ‘› ğ‘‹ ğ‘– .
(A.15) ğ‘–=1 1019 Information Theory Findthestatisticalbias, standarddeviation, andmeansquareerrorofğœƒË†.
Findthestatisticalbias, standarddeviation, andmeansquareerrorofğœƒËœ.
Whichestimatorisbetter? 2.
Forourchemistexampleinintroduction, canyouderivethe5stepstoconductatwo- sidedhypothesistesting? Giventhestatisticalsignificancelevelğ›¼ = 0.05andthesta- tisticalpower1 ğ›½=0.8.
3.
Runtheconfidenceintervalcodewithğ‘ =2andğ›¼ =0.5for100independentlygener- ateddataset, andplottheresultingintervals(inthiscaset_star = 1.0).
Youwillsee severalveryshortintervalswhichareveryfarfromcontainingthetruemean0.
Does this contradict the interpretation of the confidence interval? Do you feel comfortable usingshortintervalstoindicatehighprecisionestimates? 289 Discussions289.
A.11 Information Theory Theuniverseisoverflowingwithinformation.
Informationprovidesacommonlanguage acrossdisciplinaryrifts: from Shakespeareâ€™s Sonnettoresearchersâ€™paperon Cornell Ar Xiv, from Van Goghâ€™sprinting Starry Nightto Beethovenâ€™smusic Symphony No.5, fromthe firstprogramminglanguage PlankalkÃ¼ltothestate-of-the-artmachinelearningalgorithms.
Everythingmustfollowtherulesofinformationtheory, nomattertheformat.
Withinfor- mationtheory, wecanmeasureandcomparehowmuchinformationispresentindifferent signals.
Inthissection, wewillinvestigatethefundamentalconceptsofinformationtheory andapplicationsofinformationtheoryinmachinelearning.
Beforewegetstarted, letâ€™soutlinetherelationshipbetweenmachinelearningandinforma- tiontheory.
Machinelearningaimstoextractinterestingsignalsfromdataandmakecritical predictions.
Ontheotherhand, informationtheorystudiesencoding, decoding, transmit- ting, andmanipulatinginformation.
Asaresult, informationtheoryprovidesfundamental languagefordiscussingtheinformationprocessinginmachinelearnedsystems.
Forexam- ple, manymachinelearningapplicationsusethecross-entropylossasdescribedin Section 4.1.
Thislosscanbedirectlyderivedfrominformationtheoreticconsiderations.
A.11.1 Information Letâ€™sstartwiththeâ€œsoulâ€ofinformationtheory: information.
Informationcanbeencoded inanythingwithaparticularsequenceofoneormoreencodingformats.
Supposethatwe task ourselves with trying to define a notion of information.
What could be our starting point? Considerthefollowingthoughtexperiment.
Wehaveafriendwithadeckofcards.
They 1020 Mathematicsfor Deep Learning willshufflethedeck, flipoversomecards, andtellusstatementsaboutthecards.
Wewill trytoassesstheinformationcontentofeachstatement.
First, theyflipoveracardandtellus,â€œIseeacard.â€ Thisprovidesuswithnoinformation atall.
Wewerealreadycertainthatthiswasthecasesowehopetheinformationshouldbe zero.
Next, they flip over a card and say, â€œI see a heart.â€ This provides us some information, butinrealitythereareonly4differentsuitsthatwerepossible, eachequallylikely, sowe arenotsurprisedbythisoutcome.
Wehopethatwhateverthemeasureofinformation, this eventshouldhavelowinformationcontent.
Next, they flip over a card and say, â€œThis is the 3 of spades.â€ This is more information.
Indeedtherewere52equallylikelypossibleoutcomes, andourfriendtolduswhichoneit was.
Thisshouldbeamediumamountofinformation.
Letâ€™stakethistothelogicalextreme.
Supposethatfinallytheyflipovereverycardfromthe deckandreadofftheentiresequenceoftheshuffleddeck.
Thereare52! differentorders tothedeck, againallequallylikely, soweneedalotofinformationtoknowwhichoneit is.
Anynotionofinformationwedevelopmustconformtothisintuition.
Indeed, inthenext sections we will learn how to compute that these events have 0bits, 2bits, 5.7bits, and 225.6bitsofinformationrespectively.
Ifwereadthroughthesethoughtexperiments, weseeanaturalidea.
Asastartingpoint, ratherthancaringabouttheknowledge, wemaybuildofftheideathatinformationrepre- sentsthedegreeofsurpriseortheabstractpossibilityoftheevent.
Forexample, ifwewant todescribeanunusualevent, weneedalotinformation.
Foracommonevent, wemaynot needmuchinformation.
In1948, Claude E.
Shannonpublished AMathematical Theoryof Communication(Shan- non, 1948)establishingthetheoryofinformation.
Inhisarticle, Shannonintroducedthe conceptofinformationentropyforthefirsttime.
Wewillbeginourjourneyhere.
Self-information Sinceinformationembodiestheabstractpossibilityofanevent, howdowemapthepos- sibility to the number of bits? Shannon introduced the terminology bit as the unit of in- formation, whichwasoriginallycreatedby John Tukey.
Sowhatisaâ€œbitâ€andwhydowe useittomeasureinformation? Historically, anantiquetransmittercanonlysendorreceive twotypesofcode: 0and1.
Indeed, binaryencodingisstillincommonuseonallmodern digital computers.
In this way, any information is encoded by a series of 0 and 1.
And hence, aseriesofbinarydigitsoflengthğ‘›containsğ‘›bitsofinformation.
Now, suppose that for any series of codes, each 0 or 1 occurs with a probability of 1.
2 Hence, anevent ğ‘‹ withaseriesofcodesoflengthğ‘›, occurswithaprobabilityof 1 .
At 2ğ‘› thesametime, aswementionedbefore, thisseriescontainsğ‘›bitsofinformation.
So, can 1021 Information Theory wegeneralizetoamathematicalfunctionwhichcantransfertheprobabilityğ‘tothenumber ofbits? Shannongavetheanswerbydefiningself-information ğ¼â€ğ‘‹â€ = log â€ğ‘â€, (A.1) 2 asthebitsofinformationwehavereceivedforthisevent ğ‘‹.
Notethatwewillalwaysuse base-2logarithmsinthissection.
Forthesakeofsimplicity, therestofthissectionwillomit 2 thecodeâ€œ0010â€hasaself-information 1 ğ¼â€â€0010â€â€ = logâ€ğ‘â€â€0010â€â€â€ = log =4bits.
(A.2) 24 We can calculate self information as shown below.
Before that, letâ€™s first import all the necessarypackagesinthissection.
import torch from torch.
nn import NLLLoss def nansum(x): # Define nansum, as pytorch does not offer it inbuilt.
return x[~torch.
isnan(x)].
sum() def self_information(p): return -torch.
log2(torch.
tensor(p)).
item() self_information(1 / 64) 6.0 A.11.2 Entropy As self-information only measures the information of a single discrete event, we need a moregeneralizedmeasureforanyrandomvariableofeitherdiscreteorcontinuousdistri- bution.
Motivating Entropy Letâ€™strytogetspecificaboutwhatwewant.
Thiswillbeaninformalstatementofwhatare knownastheaxiomsof Shannonentropy.
Itwillturnoutthatthefollowingcollectionof common-sensestatementsforceustoauniquedefinitionofinformation.
Aformalversion oftheseaxioms, alongwithseveralothersmaybefoundin CsiszÃ¡r(2008).
1.
Theinformationwegainbyobservingarandomvariabledoesnotdependonwhatwe calltheelements, orthepresenceofadditionalelementswhichhaveprobabilityzero.
2.
Theinformationwegainbyobservingtworandomvariablesisnomorethanthesum oftheinformationwegainbyobservingthemseparately.
Iftheyareindependent, then itisexactlythesum.
1022 Mathematicsfor Deep Learning 3.
Theinformationgainedwhenobserving(nearly)certaineventsis(nearly)zero.
While proving this fact is beyond the scope of our text, it is important to know that this uniquelydeterminestheformthatentropymusttake.
Theonlyambiguitythattheseallow isinthechoiceoffundamentalunits, whichismostoftennormalizedbymakingthechoice wesawbeforethattheinformationprovidedbyasinglefaircoinflipisonebit.
Definition Foranyrandomvariableğ‘‹ thatfollowsaprobabilitydistributionğ‘ƒwithaprobabilityden- amountofinformationthroughentropy(or Shannonentropy) ğ»â€ğ‘‹â€ = ğ¸ ğ‘¥ ğ‘ƒ Â»logğ‘â€ğ‘¥â€â€¦.
(A.3) Tobespecific, if ğ‘‹ isdiscrete, ğ»â€ğ‘‹â€ = ğ‘ ğ‘–logğ‘ ğ‘–, where ğ‘ ğ‘– = ğ‘ƒâ€ğ‘‹ ğ‘– â€.
(A.4) ğ‘– Otherwise, if ğ‘‹ iscontinuous, wealsoreferentropyasdifferentialentropy â€ ğ»â€ğ‘‹â€ = ğ‘â€ğ‘¥â€logğ‘â€ğ‘¥â€ ğ‘‘ğ‘¥.
(A.5) ğ‘¥ Wecandefineentropyasbelow.
def entropy(p): entropy = - p * torch.
log2(p) # Operator `nansum` will sum up the non-nan number out = nansum(entropy) return out tensor(1.6855) Interpretations You may be curious: in the entropy definition (A.3), why do we use an expectation of a negativelogarithm? Herearesomeintuitions.
First, whydoweusealogarithmfunctionlog? Supposethatğ‘â€ğ‘¥â€ = ğ‘“ 1 â€ğ‘¥â€ğ‘“ 2 â€ğ‘¥â€..., ğ‘“ ğ‘› â€ğ‘¥â€, whereeachcomponentfunction ğ‘“ ğ‘– â€ğ‘¥â€isindependentfromeachother.
Thismeansthateach ğ‘“ ğ‘– â€ğ‘¥â€contributesindependentlytothetotalinformationobtainedfrom ğ‘â€ğ‘¥â€.
Asdiscussed above, we want the entropy formula to be additive over independent random variables.
Luckily, logcannaturallyturnaproductofprobabilitydistributionstoasummationofthe individualterms.
Next, whydoweuseanegativelog? Intuitively, morefrequenteventsshouldcontainless 1023 Information Theory informationthanlesscommonevents, sinceweoftengainmoreinformationfromanun- usualcasethanfromanordinaryone.
However, logismonotonicallyincreasingwiththe probabilities, andindeednegativeforallvaluesinÂ»0,1â€¦.
Weneedtoconstructamonoton- ically decreasing relationship between the probability of events and their entropy, which willideallybealwayspositive(fornothingweobserveshouldforceustoforgetwhatwe haveknown).
Hence, weaddanegativesigninfrontoflogfunction.
Last, wheredoestheexpectationfunctioncomefrom? Considerarandomvariableğ‘‹.
We caninterprettheself-information( logâ€ğ‘â€)astheamountofsurprisewehaveatseeing a particular outcome.
Indeed, as the probability approaches zero, the surprise becomes infinite.
Similarly, we can interpret the entropy as the average amount of surprise from observing ğ‘‹.
For example, imagine that a slot machine system emits statistical indepen- thissystemequalstotheaverageself-informationfromobservingeachoutput, i.
e., ğ»â€ğ‘†â€ = ğ‘ ğ‘– ğ¼â€ğ‘  ğ‘– â€ = ğ‘ ğ‘– logğ‘ ğ‘– .
(A.6) ğ‘– ğ‘– Propertiesof Entropy Bytheaboveexamplesandinterpretations, wecanderivethefollowingpropertiesofen- tropy (A.3).
Here, we refer to ğ‘‹ as an event and ğ‘ƒ as the probability distribution of ğ‘‹.
ğ»â€ğ‘‹â€ 0foralldiscrete ğ‘‹ (entropycanbenegativeforcontinuous ğ‘‹).
ğ»â€ğ‘‹â€ = ğ¸ ğ‘¥ ğ‘ƒ Â»logğ‘â€ğ‘¥â€â€¦ ğ¸ ğ‘¥ ğ‘ƒ Â»logğ‘â€ğ‘¥â€â€¦, withequalityifandonlyifğ‘ƒ =ğ‘„.
(A.7) Alternatively, ğ»â€ğ‘‹â€ gives a lower bound of the average number of bits needed to encodesymbolsdrawnfromğ‘ƒ.
Ifğ‘‹ ğ‘ƒ, thenğ‘¥conveysthemaximumamountofinformationifitspreadsevenlyamong all possible outcomes.
Specifically, if the probability distribution ğ‘ƒ is discrete with ğ‘˜-classfğ‘ 1 ,...,ğ‘ ğ‘˜ g, then 1 ğ»â€ğ‘‹â€ logâ€ğ‘˜â€, withequalityifandonlyif ğ‘ ğ‘– = ğ‘˜ ,8ğ‘–.
(A.8) Ifğ‘ƒisacontinuousrandomvariable, thenthestorybecomesmuchmorecomplicated.
However, if we additionally impose that ğ‘ƒ is supported on a finite interval (with all valuesbetween0and1), thenğ‘ƒhasthehighestentropyifitistheuniformdistribution onthatinterval.
A.11.3 Mutual Information Previouslywedefinedentropyofasinglerandomvariable ğ‘‹, howabouttheentropyofa pair random variables â€ğ‘‹,ğ‘Œâ€? We can think of these techniques as trying to answer the 1024 Mathematicsfor Deep Learning followingtypeofquestion,â€œWhatinformationiscontainedin ğ‘‹ andğ‘Œ togethercompared toeachseparately? Isthereredundantinformation, orisitallunique?â€ Forthefollowingdiscussion, wealwaysuseâ€ğ‘‹,ğ‘Œâ€asapairofrandomvariablesthatfollows probabilitydistribution ğ‘ ğ‘‹ â€ğ‘¥â€and ğ‘ ğ‘Œ â€ğ‘¦â€, respectively.
Joint Entropy Similartoentropyofasinglerandomvariable(A.3), wedefinethejointentropyğ»â€ğ‘‹,ğ‘Œâ€ ofapairrandomvariablesâ€ğ‘‹,ğ‘Œâ€as ğ»â€ğ‘‹,ğ‘Œâ€ = ğ¸ â€ğ‘¥,ğ‘¦â€ ğ‘ƒ Â»logğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€â€¦.
(A.9) Precisely, ontheonehand, ifâ€ğ‘‹,ğ‘Œâ€isapairofdiscreterandomvariables, then ğ»â€ğ‘‹,ğ‘Œâ€ = ğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€logğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€.
(A.10) ğ‘¥ ğ‘¦ Ontheotherhand, if â€ğ‘‹,ğ‘Œâ€ isapairofcontinuousrandomvariables, thenwedefinethe differentialjointentropyas â€ ğ»â€ğ‘‹,ğ‘Œâ€ = ğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€ logğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.11) ğ‘¥,ğ‘¦ Wecanthinkof (A.9)astellingusthetotalrandomnessinthepairofrandomvariables.
Asapairofextremes, ifğ‘‹ =ğ‘Œ aretwoidenticalrandomvariables, thentheinformationin thepairisexactlytheinformationinoneandwehave ğ»â€ğ‘‹,ğ‘Œâ€ = ğ»â€ğ‘‹â€ = ğ»â€ğ‘Œâ€.
Onthe otherextreme, if ğ‘‹ andğ‘Œ areindependentthenğ»â€ğ‘‹,ğ‘Œâ€ = ğ»â€ğ‘‹â€â€šğ»â€ğ‘Œâ€.
Indeedwewill alwayshavethattheinformationcontainedinapairofrandomvariablesisnosmallerthan theentropyofeitherrandomvariableandnomorethanthesumofboth.
ğ»â€ğ‘‹â€,ğ»â€ğ‘Œâ€ ğ»â€ğ‘‹,ğ‘Œâ€ ğ»â€ğ‘‹â€â€šğ»â€ğ‘Œâ€.
(A.12) Letâ€™simplementjointentropyfromscratch.
def joint_entropy(p_xy): joint_ent = -p_xy * torch.
log2(p_xy) # Operator `nansum` will sum up the non-nan number out = nansum(joint_ent) return out tensor(1.6855) Noticethatthisisthesamecodeasbefore, butnowweinterpretitdifferentlyasworking onthejointdistributionofthetworandomvariables.
1025 Information Theory Conditional Entropy Thejointentropydefinedabovetheamountofinformationcontainedinapairofrandom variables.
Thisisuseful, butoftentimesitisnotwhatwecareabout.
Considerthesetting ofmachinelearning.
Letâ€™stakeğ‘‹tobetherandomvariable(orvectorofrandomvariables) thatdescribesthepixelvaluesofanimage, andğ‘Œ tobetherandomvariablewhichisthe classlabel.
ğ‘‹ shouldcontainsubstantialinformationâ€”anaturalimageisacomplexthing.
However, the information contained inğ‘Œ once the image has been show should be low.
Indeed, theimageofadigitshouldalreadycontaintheinformationaboutwhatdigititis unless the digit is illegible.
Thus, to continue to extend our vocabulary of information theory, we need to be able to reason about the information content in a random variable conditionalonanother.
Intheprobabilitytheory, wesawthedefinitionoftheconditionalprobabilitytomeasure the relationship between variables.
We now want to analogously define the conditional entropyğ»â€ğ‘Œ j ğ‘‹â€.
Wecanwritethisas ğ»â€ğ‘Œ j ğ‘‹â€ = ğ¸ â€ğ‘¥,ğ‘¦â€ ğ‘ƒ Â»logğ‘â€ğ‘¦ j ğ‘¥â€â€¦, (A.13) whereğ‘â€ğ‘¦ j ğ‘¥â€ = ğ‘ğ‘‹,ğ‘Œâ€ğ‘¥,ğ‘¦â€ istheconditionalprobability.
Specifically, ifâ€ğ‘‹,ğ‘Œâ€isapairof ğ‘ğ‘‹â€ğ‘¥â€ discreterandomvariables, then ğ»â€ğ‘Œ j ğ‘‹â€ = ğ‘â€ğ‘¥,ğ‘¦â€logğ‘â€ğ‘¦ j ğ‘¥â€.
(A.14) ğ‘¥ ğ‘¦ Ifâ€ğ‘‹,ğ‘Œâ€isapairofcontinuousrandomvariables, thenthedifferentialconditionalentropy issimilarlydefinedas â€ â€ ğ»â€ğ‘Œ j ğ‘‹â€ = ğ‘â€ğ‘¥,ğ‘¦â€ logğ‘â€ğ‘¦ j ğ‘¥â€ ğ‘‘ğ‘¥ ğ‘‘ğ‘¦.
(A.15) ğ‘¥ ğ‘¦ Itisnownaturaltoask, howdoestheconditionalentropy ğ»â€ğ‘Œ j ğ‘‹â€ relatetotheentropy ğ»â€ğ‘‹â€ and the joint entropy ğ»â€ğ‘‹,ğ‘Œâ€? Using the definitions above, we can express this cleanly: ğ»â€ğ‘Œ j ğ‘‹â€ = ğ»â€ğ‘‹,ğ‘Œâ€ ğ»â€ğ‘‹â€.
(A.16) Thishasanintuitiveinterpretation: theinformationinğ‘Œ given ğ‘‹ (ğ»â€ğ‘Œ j ğ‘‹â€)isthesame astheinformationinbothğ‘‹ andğ‘Œ together(ğ»â€ğ‘‹,ğ‘Œâ€)minustheinformationalreadycon- tainedin ğ‘‹.
Thisgivesustheinformationinğ‘Œ whichisnotalsorepresentedin ğ‘‹.
Now, letâ€™simplementconditionalentropy(A.13)fromscratch.
def conditional_entropy(p_xy, p_x): p_y_given_x = p_xy/p_x cond_ent = -p_xy * torch.
log2(p_y_given_x) # Operator `nansum` will sum up the non-nan number out = nansum(cond_ent) return out torch.
tensor([0.2, 0.8])) 1026 Mathematicsfor Deep Learning tensor(0.8635) Mutual Information Given the previous setting of random variables â€ğ‘‹,ğ‘Œâ€, you may wonder: â€œNow that we knowhowmuchinformationiscontainedinğ‘Œ butnotinğ‘‹, canwesimilarlyaskhowmuch information is shared between ğ‘‹ andğ‘Œ?â€ The answer will be the mutual information of â€ğ‘‹,ğ‘Œâ€, whichwewillwriteasğ¼â€ğ‘‹,ğ‘Œâ€.
Rather than diving straight into the formal definition, letâ€™s practice our intuition by first tryingtoderiveanexpressionforthemutualinformationentirelybasedontermswehave constructedbefore.
Wewishtofindtheinformationsharedbetweentworandomvariables.
Onewaywecouldtrytodothisistostartwithalltheinformationcontainedinbothğ‘‹ and ğ‘Œ together, andthenwetakeoffthepartsthatarenotshared.
Theinformationcontainedin bothğ‘‹andğ‘Œ togetheriswrittenasğ»â€ğ‘‹,ğ‘Œâ€.
Wewanttosubtractfromthistheinformation containedinğ‘‹ butnotinğ‘Œ, andtheinformationcontainedinğ‘Œ butnotinğ‘‹.
Aswesawin theprevioussection, thisisgivenbyğ»â€ğ‘‹ jğ‘Œâ€ andğ»â€ğ‘Œ j ğ‘‹â€ respectively.
Thus, wehave thatthemutualinformationshouldbe ğ¼â€ğ‘‹,ğ‘Œâ€ = ğ»â€ğ‘‹,ğ‘Œâ€ ğ»â€ğ‘Œ j ğ‘‹â€ ğ»â€ğ‘‹ jğ‘Œâ€.
(A.17) Indeed, thisisavaliddefinitionforthemutualinformation.
Ifweexpandoutthedefinitions ofthesetermsandcombinethem, alittlealgebrashowsthatthisisthesameas ğ‘ â€ğ‘¥,ğ‘¦â€ ğ¼â€ğ‘‹,ğ‘Œâ€ = ğ¸ ğ‘¥ ğ¸ ğ‘¦ ğ‘ ğ‘‹,ğ‘Œ â€ğ‘¥,ğ‘¦â€log ğ‘ ğ‘‹ â€ , ğ‘¥ ğ‘Œ â€ğ‘ â€ğ‘¦â€ .
(A.18) ğ‘‹ ğ‘Œ We can summarize all of these relationships in image Fig.
A.1.
It is an excellent test of intuitiontoseewhythefollowingstatementsareallalsoequivalenttoğ¼â€ğ‘‹,ğ‘Œâ€.
ğ»â€ğ‘‹â€ ğ»â€ğ‘‹ jğ‘Œâ€ ğ»â€ğ‘Œâ€ ğ»â€ğ‘Œ j ğ‘‹â€ ğ»â€ğ‘‹â€â€šğ»â€ğ‘Œâ€ ğ»â€ğ‘‹,ğ‘Œâ€ t Fig.
A.1 Mutualinformationâ€™srelationshipwithjointentropyandconditionalentropy.
In many ways we can think of the mutual information (A.18) as principled extension of correlation coefficient we saw in Section A.6.
This allows us to ask not only for linear 1027 Information Theory relationshipsbetweenvariables, butforthemaximuminformationsharedbetweenthetwo randomvariablesofanykind.
Now, letâ€™simplementmutualinformationfromscratch.
def mutual_information(p_xy, p_x, p_y): p = p_xy / (p_x * p_y) mutual = p_xy * torch.
log2(p) # Operator `nansum` will sum up the non-nan number out = nansum(mutual) return out tensor(0.7195) Propertiesof Mutual Information Ratherthanmemorizingthedefinitionofmutualinformation(A.18), youonlyneedtokeep inminditsnotableproperties: Mutualinformationissymmetric, i.
e.,ğ¼â€ğ‘‹,ğ‘Œâ€ = ğ¼â€ğ‘Œ,ğ‘‹â€.
Mutualinformationisnon-negative, i.
e.,ğ¼â€ğ‘‹,ğ‘Œâ€ 0.
ğ¼â€ğ‘‹,ğ‘Œâ€ = 0 if and only if ğ‘‹ andğ‘Œ are independent.
For example, if ğ‘‹ andğ‘Œ are in- dependent, thenknowingğ‘Œ doesnotgiveanyinformationabout ğ‘‹ andviceversa, so theirmutualinformationiszero.
Alternatively, ifğ‘‹ isaninvertiblefunctionofğ‘Œ, thenğ‘Œ andğ‘‹ shareallinformationand ğ¼â€ğ‘‹,ğ‘Œâ€ = ğ»â€ğ‘Œâ€ = ğ»â€ğ‘‹â€.
(A.19) Pointwise Mutual Information Whenweworkedwithentropyatthebeginningofthischapter, wewereabletoprovidean interpretationof logâ€ğ‘ ğ‘‹ â€ğ‘¥â€â€ashowsurprisedwewerewiththeparticularoutcome.
We maygiveasimilarinterpretationtothelogarithmicterminthemutualinformation, which isoftenreferredtoasthepointwisemutualinformation: ğ‘ â€ğ‘¥,ğ‘¦â€ pmiâ€ğ‘¥,ğ‘¦â€ =log ğ‘‹,ğ‘Œ .
(A.20) ğ‘ â€ğ‘¥â€ğ‘ â€ğ‘¦â€ ğ‘‹ ğ‘Œ Wecanthinkof (A.20)asmeasuringhowmuchmoreorlesslikelythespecificcombina- tionofoutcomesğ‘¥ and ğ‘¦ arecomparedtowhatwewouldexpectforindependentrandom outcomes.
Ifitislargeandpositive, thenthesetwospecificoutcomesoccurmuchmorefre- quentlythantheywouldcomparedtorandomchance(note: thedenominatorisğ‘ ğ‘‹ â€ğ‘¥â€ğ‘ ğ‘Œ â€ğ‘¦â€ whichistheprobabilityofthetwooutcomeswereindependent), whereasifitislargeand 1028 Mathematicsfor Deep Learning negativeitrepresentsthetwooutcomeshappeningfarlessthanwewouldexpectbyrandom chance.
This allows us to interpret the mutual information (A.18) as the average amount that we weresurprisedtoseetwooutcomesoccurringtogethercomparedtowhatwewouldexpect iftheywereindependent.
Applicationsof Mutual Information Mutualinformationmaybealittleabstractinitpuredefinition, sohowdoesitrelatedto machinelearning? Innaturallanguageprocessing, oneofthemostdifficultproblemsisthe ambiguity resolution, or the issue of the meaning of a word being unclear from context.
Forexample, recentlyaheadlineinthenewsreportedthatâ€œAmazonisonfireâ€.
Youmay wonderwhetherthecompany Amazonhasabuildingonfire, orthe Amazonrainforestis onfire.
Inthiscase, mutualinformationcanhelpusresolvethisambiguity.
Wefirstfindthegroup of words that each has a relatively large mutual information with the company Amazon, suchase-commerce, technology, andonline.
Second, wefindanothergroupofwordsthat each has a relatively large mutual information with the Amazon rain forest, such as rain, forest, and tropical.
When we need to disambiguate â€œAmazonâ€, we can compare which group has more occurrence in the context of the word Amazon.
In this case the article wouldgoontodescribetheforest, andmakethecontextclear.
A.11.4 Kullbackâ€“Leibler Divergence Aswhatwehavediscussedin Section2.3, wecanusenormstomeasuredistancebetween two points in space of any dimensionality.
We would like to be able to do a similar task withprobabilitydistributions.
Therearemanywaystogoaboutthis, butinformationtheory providesoneofthenicest.
Wenowexplorethe Kullbackâ€“Leibler(KL)divergence, which providesawaytomeasureiftwodistributionsareclosetogetherornot.
Definition Given a random variable ğ‘‹ that follows the probability distribution ğ‘ƒ with a p.
d.
f.
or a p.
m.
f.
ğ‘â€ğ‘¥â€.
Thenthe Kullbackâ€“Leibler(KL)divergence(orrelativeentropy)between ğ‘ƒ andğ‘„is ğ‘â€ğ‘¥â€ ğ· KL â€ğ‘ƒkğ‘„â€ = ğ¸ ğ‘¥ ğ‘ƒ log ğ‘â€ğ‘¥â€ .
(A.21) Aswiththepointwisemutualinformation(A.20), wecanagainprovideaninterpretationof thelogarithmicterm: log ğ‘â€ğ‘¥â€ = logâ€ğ‘â€ğ‘¥â€â€ â€ logâ€ğ‘â€ğ‘¥â€â€â€ willbelargeandpositive ğ‘â€ğ‘¥â€ ifweseeğ‘¥ farmoreoftenunder ğ‘ƒ thanwewouldexpectforğ‘„, andlargeandnegativeif weseetheoutcomefarlessthanexpected.
Inthisway, wecaninterpretitasourrelative surprise at observing the outcome compared to how surprised we would be observing it fromourreferencedistribution.
1029 Information Theory Letâ€™simplementthe KLdivergencefrom Scratch.
def kl_divergence(p, q): kl = p * torch.
log2(p / q) out = nansum(kl) return out.
abs().
item() KLDivergence Properties Letâ€™stakealookatsomepropertiesofthe KLdivergence(A.21).
KLdivergenceisnon-symmetric, i.
e., thereareğ‘ƒ,ğ‘„suchthat ğ· â€ğ‘ƒkğ‘„â€ â‰  ğ· â€ğ‘„kğ‘ƒâ€.
(A.22) KL KL KLdivergenceisnon-negative, i.
e., ğ· â€ğ‘ƒkğ‘„â€ 0.
(A.23) KL Notethattheequalityholdsonlywhenğ‘ƒ =ğ‘„.
Ifthereexistsanğ‘¥suchthat ğ‘â€ğ‘¥â€ >0andğ‘â€ğ‘¥â€ =0, thenğ· â€ğ‘ƒkğ‘„â€ =1.
KL Thereisacloserelationshipbetween KLdivergenceandmutualinformation.
Besides the relationship shown in Fig.
A.1, ğ¼â€ğ‘‹,ğ‘Œâ€ is also numerically equivalent with the followingterms: 1.
ğ· â€ğ‘ƒâ€ğ‘‹,ğ‘Œâ€ k ğ‘ƒâ€ğ‘‹â€ğ‘ƒâ€ğ‘Œâ€â€; KL 2.
ğ¸ ğ‘Œ fğ· KL â€ğ‘ƒâ€ğ‘‹ jğ‘Œâ€ k ğ‘ƒâ€ğ‘‹â€â€g; 3.
ğ¸ ğ‘‹ fğ· KL â€ğ‘ƒâ€ğ‘Œ j ğ‘‹â€ k ğ‘ƒâ€ğ‘Œâ€â€g.
For the first term, we interpret mutual information as the KL divergence between ğ‘ƒâ€ğ‘‹,ğ‘Œâ€ and the product of ğ‘ƒâ€ğ‘‹â€ and ğ‘ƒâ€ğ‘Œâ€, and thus is a measure of how differ- ent the joint distribution is from the distribution if they were independent.
For the secondterm, mutualinformationtellsustheaveragereductioninuncertaintyaboutğ‘Œ thatresultsfromlearningthevalueoftheğ‘‹â€™sdistribution.
Similarlytothethirdterm.
Example Letâ€™sgothroughatoyexampletoseethenon-symmetryexplicitly.
First, letâ€™s generate and sort three tensors of length 10,000: an objective tensor ğ‘ which followsanormaldistribution ğ‘â€0,1â€, andtwocandidatetensors ğ‘ and ğ‘ whichfollow 1 2 normaldistributionsğ‘â€ 1,1â€andğ‘â€1,1â€respectively.
1030 Mathematicsfor Deep Learning torch.
manual_seed(1) tensor_len = 10000 p = torch.
normal(0, 1, (tensor_len, )) q1 = torch.
normal(-1, 1, (tensor_len, )) q2 = torch.
normal(1, 1, (tensor_len, )) p = torch.
sort(p)[0] q1 = torch.
sort(q1)[0] q2 = torch.
sort(q2)[0] Sinceğ‘ andğ‘ aresymmetricwithrespecttothey-axis(i.
e.,ğ‘¥ = 0), weexpectasimilar 1 2 valueof KLdivergencebetweenğ· â€ğ‘kğ‘ â€andğ· â€ğ‘kğ‘ â€.
Asyoucanseebelow, there KL 1 KL 2 isonlyalessthan3%offbetweenğ· â€ğ‘kğ‘ â€andğ· â€ğ‘kğ‘ â€.
KL 1 KL 2 kl_pq1 = kl_divergence(p, q1) kl_pq2 = kl_divergence(p, q2) similar_percentage = abs(kl_pq1 - kl_pq2) / ((kl_pq1 + kl_pq2) / 2) * 100 kl_pq1, kl_pq2, similar_percentage (8582.0341796875, 8828.3095703125, 2.8290698237936858) Incontrast, youmayfindthat ğ· â€ğ‘ kğ‘â€ and ğ· â€ğ‘kğ‘ â€ areoffalot, witharound40% KL 2 KL 2 offasshownbelow.
kl_q2p = kl_divergence(q2, p) differ_percentage = abs(kl_q2p - kl_pq2) / ((kl_q2p + kl_pq2) / 2) * 100 kl_q2p, differ_percentage (14130.125, 46.18621024399691) A.11.5 Cross-Entropy Ifyouarecuriousaboutapplicationsofinformationtheoryindeeplearning, hereisaquick example.
We define the true distribution ğ‘ƒ with probability distribution ğ‘â€ğ‘¥â€, and the estimated distribution ğ‘„ with probability distribution ğ‘â€ğ‘¥â€, and we will use them in the restofthissection.
Say we need to solve a binary classification problem based on given ğ‘› data examples {ğ‘¥ 1 ,...,ğ‘¥ ğ‘›}.
Assume that we encode 1 and 0 as the positive and negative class label ğ‘¦ ğ‘– respectively, and our neural network is parametrized by ğœƒ.
If we aim to find a best ğœƒ so that ğ‘¦Ë†ğ‘– = ğ‘ ğœƒ â€ğ‘¦ ğ‘– j ğ‘¥ ğ‘– â€, itisnaturaltoapplythemaximumlog-likelihoodapproachaswas seenin Section A.7.
Tobespecific, fortruelabelsğ‘¦ ğ‘– andpredictionsğ‘¦Ë†ğ‘– = ğ‘ ğœƒ â€ğ‘¦ ğ‘– j ğ‘¥ ğ‘– â€, the probabilitytobeclassifiedaspositiveis ğœ‹ ğ‘– = ğ‘ ğœƒ â€ğ‘¦ ğ‘– = 1 j ğ‘¥ ğ‘– â€.
Hence, thelog-likelihood 1031 Information Theory functionwouldbe ğ‘™â€ğœƒâ€ =logğ¿â€ğœƒâ€ ğ‘› =log ğœ‹ ğ‘– ğ‘¦ğ‘–â€1 ğœ‹ ğ‘– â€1 ğ‘¦ğ‘– (A.24) ğ‘–=1 ğ‘› = ğ‘¦ ğ‘–logâ€ğœ‹ ğ‘– â€â€šâ€1 ğ‘¦ ğ‘– â€logâ€1 ğœ‹ ğ‘– â€.
ğ‘–=1 Maximizingthe log-likelihoodfunction ğ‘™â€ğœƒâ€ isidentical to minimizing ğ‘™â€ğœƒâ€, and hence wecanfindthebestğœƒfromhere.
Togeneralizetheabovelosstoanydistributions, wealso called ğ‘™â€ğœƒâ€thecross-entropyloss CEâ€ğ‘¦,ğ‘¦Ë†â€, whereğ‘¦followsthetruedistributionğ‘ƒandğ‘¦Ë† followstheestimateddistributionğ‘„.
Thiswasallderivedbyworkingfromthemaximumlikelihoodpointofview.
However, if welookcloselywecanseethattermslikelogâ€ğœ‹ ğ‘– â€haveenteredintoourcomputationwhich isasolidindicationthatwecanunderstandtheexpressionfromaninformationtheoretic pointofview.
Formal Definition Like KLdivergence, forarandomvariableğ‘‹, wecanalsomeasurethedivergencebetween theestimatingdistributionğ‘„andthetruedistributionğ‘ƒviacross-entropy, CEâ€ğ‘ƒ,ğ‘„â€ = ğ¸ ğ‘¥ ğ‘ƒ Â»logâ€ğ‘â€ğ‘¥â€â€â€¦.
(A.25) Byusingpropertiesofentropydiscussedabove, wecanalsointerpretitasthesummation oftheentropyğ»â€ğ‘ƒâ€andthe KLdivergencebetweenğ‘ƒandğ‘„, i.
e., CEâ€ğ‘ƒ,ğ‘„â€ = ğ»â€ğ‘ƒâ€â€šğ· â€ğ‘ƒkğ‘„â€.
(A.26) KL Wecanimplementthecross-entropylossasbelow.
def cross_entropy(y_hat, y): ce = -torch.
log(y_hat[range(len(y_hat)), y]) return ce.
mean() Nowdefinetwotensorsforthelabelsandpredictions, andcalculatethecross-entropyloss ofthem.
labels = torch.
tensor([0, 2]) cross_entropy(preds, labels) tensor(0.9486) 1032 Mathematicsfor Deep Learning Properties Asalludedinthebeginningofthissection, cross-entropy(A.25)canbeusedtodefinealoss functionintheoptimizationproblem.
Itturnsoutthatthefollowingareequivalent: 1.
Maximizingpredictiveprobabilityofğ‘„fordistributionğ‘ƒ,(i.
e.,ğ¸ ğ‘¥ ğ‘ƒ Â»logâ€ğ‘â€ğ‘¥â€â€â€¦); 2.
Minimizingcross-entropy CEâ€ğ‘ƒ,ğ‘„â€; 3.
Minimizingthe KLdivergenceğ· â€ğ‘ƒkğ‘„â€.
KL The definition of cross-entropy indirectly proves the equivalent relationship between ob- jective2andobjective3, aslongastheentropyoftruedatağ»â€ğ‘ƒâ€isconstant.
Cross-Entropyas An Objective Functionof Multi-class Classification If we dive deep into the classification objective function with cross-entropy loss CE, we willfindminimizing CEisequivalenttomaximizingthelog-likelihoodfunctionğ¿.
Tobeginwith, supposethatwearegivenadatasetwithğ‘›examples, anditcanbeclassified intoğ‘˜-classes.
Foreachdataexampleğ‘–, werepresentanyğ‘˜-classlabelyğ‘– = â€ğ‘¦ ğ‘–1 ,...,ğ‘¦ ğ‘–ğ‘˜ â€ by one-hot encoding.
To be specific, if the exampleğ‘– belongs to class ğ‘—, then we set the ğ‘—-thentryto1, andallothercomponentsto0, i.
e., ( 1 ğ‘— 2 ğ½; ğ‘¦ ğ‘–ğ‘— = (A.27) 0 otherwise.
Forinstance, ifamulti-classclassificationproblemcontainsthreeclassesğ´,ğµ, andğ¶, then thelabelsyğ‘– canbeencodedin{ğ´: â€1,0,0â€;ğµ: â€0,1,0â€;ğ¶ : â€0,0,1â€}.
Assumethatourneuralnetworkisparametrizedbyğœƒ.
Fortruelabelvectorsyğ‘– andpredic- tions ğ‘˜ yË†ğ‘– = ğ‘ ğœƒ â€yğ‘– j xğ‘– â€ = ğ‘¦ ğ‘–ğ‘— ğ‘ ğœƒ â€ğ‘¦ ğ‘–ğ‘— j xğ‘– â€.
(A.28) ğ‘—=1 Hence, thecross-entropylosswouldbe ğ‘› ğ‘› ğ‘˜ CEâ€y, yË†â€ = yğ‘–logyË†ğ‘– = ğ‘¦ ğ‘–ğ‘—logğ‘ ğœƒ â€ğ‘¦ ğ‘–ğ‘— j xğ‘– â€.
(A.29) ğ‘–=1 ğ‘–=1 ğ‘—=1 On the other side, we can also approach the problem through maximum likelihood es- timation.
To begin with, letâ€™s quickly introduce a ğ‘˜-class multinoulli distribution.
It is an extension of the Bernoulli distribution from binary class to multi-class.
If a random variablez = â€ğ‘§ 1 ,...,ğ‘§ ğ‘˜ â€ followsa ğ‘˜-classmultinoullidistributionwithprobabilitiesp = (ğ‘ 1 ğ‘˜ ğ‘–=1 1033 Information Theory thenthejointprobabilitymassfunction(p.
m.
f.) ofzis ğ‘˜ pz = ğ‘ ğ‘§ğ‘—.
(A.31) ğ‘— ğ‘—=1 It can be seen that the label of each data example, yğ‘–, is following a ğ‘˜-class multinoulli distribution with pro Ë› babilities ğ… = (ğœ‹ 1 exampleyğ‘– isÃŸyğ‘– = ğ‘˜ ğ‘—=1 ğœ‹ ğ‘¦ ğ‘— ğ‘–ğ‘—.
Hence, thelog-likelihoodfunctionwouldbe ğ‘› ğ‘› ğ‘˜ ğ‘› ğ‘˜ ğ‘™â€ğœƒâ€ =logğ¿â€ğœƒâ€ =log ğ…yğ‘– =log ğœ‹ ğ‘¦ ğ‘— ğ‘–ğ‘— = ğ‘¦ ğ‘–ğ‘—logğœ‹ ğ‘— .
(A.32) ğ‘–=1 ğ‘–=1 ğ‘—=1 ğ‘–=1 ğ‘—=1 Since in maximum likelihood estimation, we maximizing the objective function ğ‘™â€ğœƒâ€ by having ğœ‹ ğ‘— = ğ‘ ğœƒ â€ğ‘¦ ğ‘–ğ‘— j xğ‘– â€.
Therefore, for any multi-class classification, maximizing the abovelog-likelihoodfunctionğ‘™â€ğœƒâ€isequivalenttominimizingthe CEloss CEâ€ğ‘¦,ğ‘¦Ë†â€.
Totesttheaboveproof, letâ€™sapplythebuilt-inmeasure Negative Log Likelihood.
Using thesamelabelsandpredsasintheearlierexample, wewillgetthesamenumericalloss asthepreviousexampleuptothe5decimalplace.
# Implementation of cross-entropy loss in Py Torch combines `nn.
Log Softmax()` # and `nn.
NLLLoss()` nll_loss = NLLLoss() loss = nll_loss(torch.
log(preds), labels) loss tensor(0.9486) A.11.6 Summary Informationtheoryisafieldofstudyaboutencoding, decoding, transmitting, andma- nipulatinginformation.
Entropyistheunittomeasurehowmuchinformationispresentedindifferentsignals.
KLdivergencecanalsomeasurethedivergencebetweentwodistributions.
Cross-entropycanbeviewedasanobjectivefunctionofmulti-classclassification.
Min- imizingcross-entropylossisequivalenttomaximizingthelog-likelihoodfunction.
A.11.7 Exercises 1.
Verifythatthecardexamplesfromthefirstsectionindeedhavetheclaimedentropy.
2.
Showthatthe KLdivergenceğ·â€ğ‘kğ‘â€isnonnegativeforalldistributionsğ‘andğ‘.
Hint: use Jensenâ€™sinequality, i.
e., usethefactthat logğ‘¥isaconvexfunction.
3.
Letâ€™scomputetheentropyfromafewdatasources: 1034 Mathematicsfor Deep Learning Assumethatyouarewatchingtheoutputgeneratedbyamonkeyatatypewriter.
The monkey presses any of the 44 keys of the typewriter at random (you can assume thatithasnotdiscoveredanyspecialkeysortheshiftkeyyet).
Howmanybitsof randomnesspercharacterdoyouobserve? Being unhappy with the monkey, you replaced it by a drunk typesetter.
It is able to generate words, albeit not coherently.
Instead, it picks a random word out of a vocabulary of 2,000 words.
Letâ€™s assume that the average length of a word is 4.5lettersin English.
Howmanybitsofrandomnesspercharacterdoyouobserve now? Stillbeingunhappywiththeresult, youreplacethetypesetterbyahighqualitylan- guagemodel.
Thelanguagemodelcancurrentlyobtainaperplexityaslowas15 points per word.
The character perplexity of a language model is defined as the inverseofthegeometricmeanofasetofprobabilities, eachprobabilityiscorre- spondingtoacharacterintheword.
Tobespecific, ifthelengthofagivenwordis Ë› Ë ğ‘™, then PPLâ€wordâ€ = Â» ğ‘– ğ‘â€characterğ‘– â€â€¦ 1 ğ‘™ = exp 1 ğ‘™ ğ‘–logğ‘â€characterğ‘– â€ .
As- sumethatthetestwordhas4.5letters, howmanybitsofrandomnesspercharacter doyouobservenow? 4.
Explain intuitively why ğ¼â€ğ‘‹,ğ‘Œâ€ = ğ»â€ğ‘‹â€ ğ»â€ğ‘‹ j ğ‘Œâ€.
Then, show this is true by expressingbothsidesasanexpectationwithrespecttothejointdistribution.
5.
What is the KL Divergence between the two Gaussian distributions Nâ€ğœ‡ ,ğœ2â€ and 1 1 Nâ€ğœ‡ ,ğœ2â€? 2 2 Discussions290.
290 B Tools for Deep Learning Togetthemostoutof Diveinto Deep Learning, wewilltalkyouthroughdifferenttoolsin thisappendix, suchasforrunningandcontributingtothisinteractiveopen-sourcebook.
B.1 Using Jupyter Notebooks This section describes how to edit and run the code in each section of this book using the Jupyter Notebook.
Makesureyouhaveinstalled Jupyteranddownloadedthecodeas described in Installation (page xxxiv).
If you want to know more about Jupyter see the excellenttutorialintheirdocumentation291.
291 B.1.1 Editingand Runningthe Code Locally Supposethatthelocalpathofthebookâ€™scodeisxx/yy/d2l-en/.
Usetheshelltochange thedirectorytothispath(cd xx/yy/d2l-en)andrunthecommandjupyter notebook.
Ifyourbrowserdoesnotdothisautomatically, openhttp://localhost:8888andyouwillsee theinterfaceof Jupyterandallthefolderscontainingthecodeofthebook, asshownin Fig.
B.1.
t Fig.
B.1 Thefolderscontainingthecodeofthisbook.
Youcanaccessthenotebookfilesbyclickingonthefolderdisplayedonthewebpage.
They usuallyhavethesuffixâ€œ.
ipynbâ€.
Forthesakeofbrevity, wecreateatemporaryâ€œtest.
ipynbâ€ file.
Thecontentdisplayedafteryouclickitisshownin Fig.
B.2.
Thisnotebookincludesa 1035 1036 Toolsfor Deep Learning markdowncellandacodecell.
Thecontentinthemarkdowncellincludesâ€œThis Isa Titleâ€ andâ€œThisistext.â€.
Thecodecellcontainstwolinesof Pythoncode.
t Fig.
B.2 Markdownandcodecellsintheâ€œtext.
ipynbâ€file.
Doubleclickonthemarkdowncelltoentereditmode.
Addanewtextstringâ€œHelloworld.â€ attheendofthecell, asshownin Fig.
B.3.
t Fig.
B.3 Editthemarkdowncell.
Asdemonstratedin Fig.
B.4, clickâ€œCellâ€!â€œRun Cellsâ€inthemenubartoruntheedited cell.
Afterrunning, themarkdowncellisshownin Fig.
B.5.
Next, clickonthecodecell.
Multiplytheelementsby2afterthelastlineofcode, asshown in Fig.
B.6.
Youcanalsorunthecellwithashortcut(â€œCtrl+Enterâ€bydefault)andobtaintheoutput resultfrom Fig.
B.7.
Whenanotebookcontainsmorecells, wecanclickâ€œKernelâ€!â€œRestart&Run Allâ€inthe menubartorunallthecellsintheentirenotebook.
Byclickingâ€œHelpâ€!â€œEdit Keyboard Shortcutsâ€inthemenubar, youcanedittheshortcutsaccordingtoyourpreferences.
1037 B.1 Using Jupyter Notebooks t Fig.
B.4 Runthecell.
t Fig.
B.5 Themarkdowncellafterrunning.
t Fig.
B.6 Editthecodecell.
1038 Toolsfor Deep Learning t Fig.
B.7 Runthecodecelltoobtaintheoutput.
B.1.2 Advanced Options Beyondlocaleditingtwothingsarequiteimportant: editingthenotebooksinthemarkdown formatandrunning Jupyterremotely.
Thelattermatterswhenwewanttorunthecodeona fasterserver.
Theformermatterssince Jupyterâ€™snativeipynbformatstoresalotofauxiliary datathatisirrelevanttothecontent, mostlyrelatedtohowandwherethecodeisrun.
This isconfusingfor Git, makingreviewingcontributionsverydifficult.
Fortunatelythereisan alternativeâ€”nativeeditinginthemarkdownformat.
Markdown Filesin Jupyter Ifyouwishtocontributetothecontentofthisbook, youneedtomodifythesourcefile(md file, notipynbfile)on Git Hub.
Usingthenotedownpluginwecanmodifynotebooksinthe mdformatdirectlyin Jupyter.
First, installthenotedownplugin, runthe Jupyter Notebook, andloadtheplugin: pip install d2l-notedown # You may need to uninstall the original notedown.
jupyter notebook --Notebook App.
contents_manager_class='notedown.
â†©! Notedown Contents Manager' Youmayalsoturnonthenotedownpluginbydefaultwheneveryourunthe Jupyter Note- book.
First, generatea Jupyter Notebookconfigurationfile(ifithasalreadybeengenerated, youcanskipthisstep).
jupyter notebook --generate-config Then, addthefollowinglinetotheendofthe Jupyter Notebookconfigurationfile(for Linux ormac OS, usuallyinthepath~/.
jupyter/jupyter_notebook_config.
py): 1039 Using Jupyter Notebooks c.
Notebook App.
contents_manager_class = 'notedown.
Notedown Contents Manager' Afterthat, youonlyneedtorunthejupyter notebookcommandtoturnonthenotedown pluginbydefault.
Running Jupyter Notebooksona Remote Server Sometimes, youmaywanttorun Jupyternotebooksonaremoteserverandaccessitthrough abrowseronyourlocalcomputer.
If Linuxormac OSisinstalledonyourlocalmachine (Windowscanalsosupportthisfunctionthroughthird-partysoftwaresuchas Pu TTY), you canuseportforwarding: ssh myserver -L 8888: localhost:8888 The above string myserver is the address of the remote server.
Then we can use http: //localhost:8888 to access the remote server myserver that runs Jupyter notebooks.
We willdetailonhowtorun Jupyternotebookson AWSinstanceslaterinthisappendix.
Timing We can use the Execute Time plugin to time the execution of each code cell in Jupyter notebooks.
Usethefollowingcommandstoinstalltheplugin: pip install jupyter_contrib_nbextensions jupyter contrib nbextension install --user jupyter nbextension enable execute_time/Execute Time B.1.3 Summary Usingthe Jupyter Notebooktool, wecanedit, run, andcontributetoeachsectionofthe book.
Wecanrun Jupyternotebooksonremoteserversusingportforwarding.
B.1.4 Exercises 1.
Editandrunthecodeinthisbookwiththe Jupyter Notebookonyourlocalmachine.
2.
Editandrunthecodeinthisbookwiththe Jupyter Notebookremotelyviaportforward- ing.
3.
Comparetherunningtimeoftheoperations A>Band ABfortwosquarematricesin 292 R1024 1024.
Whichoneisfaster? Discussions292.
1040 Toolsfor Deep Learning B.2 Using Amazon Sage Maker Deeplearningapplicationsmaydemandsomuchcomputationalresourcethateasilygoes beyond what your local machine can offer.
Cloud computing services allow you to run GPU-intensivecodeofthisbookmoreeasilyusingmorepowerfulcomputers.
Thissection willintroducehowtouse Amazon Sage Makertorunthecodeofthisbook.
B.2.1 Signing Up First, weneedtosignupanaccountathttps://aws.
amazon.
com/.
Foradditionalsecurity, usingtwo-factorauthenticationisencouraged.
Itisalsoagoodideatosetupdetailedbilling andspendingalertstoavoidanysurprise, e.
g., whenforgettingtostoprunninginstances.
After logging into your AWS account, go to your console293 and search for â€œAmazon 293 Sage Makerâ€(see Fig.
B.1), thenclickittoopenthe Sage Makerpanel.
t Fig.
B.1 Searchforandopenthe Sage Makerpanel.
B.2.2 Creatinga Sage Maker Instance Next, letâ€™screateanotebookinstanceasdescribedin Fig.
B.2.
t Fig.
B.2 Createa Sage Makerinstance.
1041 Using Amazon Sage Maker Sage Maker provides multiple instance types294 with varying computational power and 294 prices.
Whencreatinganotebookinstance, wecanspecifyitsnameandtype.
In Fig.
B.3, wechooseml.
p3.2xlarge: withone Tesla V100GPUandan8-core CPU, thisinstanceis powerfulenoughformostofthebook.
t Fig.
B.3 Choosetheinstancetype.
The entire book in the ipynb format for running with Sage Maker is available at https:// github.
com/d2l-ai/d2l-pytorch-sagemaker.
We can specify this Git Hub repository URL (Fig.
B.4)toallow Sage Makertocloneitwhencreatingtheinstance.
t Fig.
B.4 Specifythe Git Hubrepository.
B.2.3 Runningand Stoppingan Instance Creatinganinstancemaytakeafewminutes.
Whenitisready, clickontheâ€œOpen Jupyterâ€ linknexttoit(Fig.
B.5)soyoucaneditandrunallthe Jupyternotebooksofthisbookon thisinstance(similartostepsin Section B.1).
t Fig.
B.5 Open Jupyteronthecreated Sage Makerinstance.
Afterfinishingyourwork, donotforgettostoptheinstancetoavoidbeingchargedfurther (Fig.
B.6).
1042 Toolsfor Deep Learning t Fig.
B.6 Stopa Sage Makerinstance.
B.2.4 Updating Notebooks Notebooks of this open-source book will be regularly updated in the d2l-ai/d2l-pytorch- sagemaker295 repository on Git Hub.
To update to the latest version, you may open a 295 terminalonthe Sage Makerinstance(Fig.
B.7).
t Fig.
B.7 Openaterminalonthe Sage Makerinstance.
Youmaywishtocommityourlocalchangesbeforepullingupdatesfromtheremoterepos- itory.
Otherwise, simply discard all your local changes with the following commands in theterminal: cd Sage Maker/d2l-pytorch-sagemaker/ git reset --hard git pull B.2.5 Summary Wecancreateanotebookinstanceusing Amazon Sage Makertorun GPU-intensivecode ofthisbook.
Wecanupdatenotebooksviatheterminalonthe Amazon Sage Makerinstance.
B.2.6 Exercises 1.
Editandrunanysectionthatrequiresa GPUusing Amazon Sage Maker.
1043 Using AWSEC2Instances 2.
Openaterminaltoaccessthelocaldirectorythathostsallthenotebooksofthisbook.
Discussions296.
296 B.3 Using AWS EC2 Instances Inthissection, wewillshowyouhowtoinstallalllibrariesonaraw Linuxmachine.
Recall thatin Section B.2wediscussedhowtouse Amazon Sage Maker, whilebuildinganinstance byyourselfcostslesson AWS.
Thewalkthroughincludesthreesteps: 1.
Requestfora GPULinuxinstancefrom AWSEC2.
2.
Install CUDA(orusean Amazon Machine Imagewithpreinstalled CUDA).
3.
Installthedeeplearningframeworkandotherlibrariesforrunningthecodeofthebook.
This process applies to other instances (and other clouds), too, albeit with some minor modifications.
Beforegoingforward, youneedtocreatean AWSaccount, see Section B.2 formoredetails.
B.3.1 Creatingand Runningan EC2Instance Afterloggingintoyour AWSaccount, clickâ€œEC2â€(Fig.
B.1)togotothe EC2panel.
t Fig.
B.1 Openthe EC2console.
Fig.
B.2showsthe EC2panel.
Presetting Location Selectanearbydatacentertoreducelatency, e.
g.,â€œOregonâ€(markedbytheredboxinthe top-right of Fig.
B.2).
If you are located in China, you can select a nearby Asia Pacific 1044 Toolsfor Deep Learning t Fig.
B.2 The EC2panel.
region, such as Seoul or Tokyo.
Please note that some data centers may not have GPU instances.
Increasing Limits Beforechoosinganinstance, checkiftherearequantityrestrictionsbyclickingtheâ€œLim- alimitation.
Theaccountcurrentlycannotopenâ€œp2.
xlargeâ€instancesaccordingtothere- gion.
Ifyouneedtoopenoneormoreinstances, clickontheâ€œRequestlimitincreaseâ€link to apply for a higher instance quota.
Generally, it takes one business day to process an application.
t Fig.
B.3 Instancequantityrestrictions.
Launchingan Instance Next, clicktheâ€œLaunch Instanceâ€buttonmarkedbytheredboxin Fig.
B.2tolaunchyour instance.
Webeginbyselectingasuitable Amazon Machine Image(AMI).
Selectan Ubuntuinstance (Fig.
B.4).
EC2providesmanydifferentinstanceconfigurationstochoosefrom.
Thiscansometimes feeloverwhelmingtoabeginner.
tab_ec2listsdifferentsuitablemachines.
: Different EC2instancetypes 1045 Using AWSEC2Instances t Fig.
B.4 Choosean AMI.
Table B.1: label: tab_ec2 Name GPU Notes g2 Grid K520 ancient p2 Kepler K80 oldbutoftencheapasspot g3 Maxwell M60 goodtrade-off p3 Volta V100 highperformancefor FP16 p4 Ampere A100 highperformanceforlarge-scaletraining g4 Turing T4 inferenceoptimized FP16/INT8 Alltheseserverscomeinmultipleflavorsindicatingthenumberof GPUsused.
Forexam- ple, ap2.
xlargehas1GPUandap2.16xlargehas16GPUsandmorememory.
Formore details, seethe AWSEC2documentation297 orasummarypage298.
Forthepurposeof 297 illustration, ap2.
xlargewillsuffice(markedintheredboxof Fig.
B.5).
298 t Fig.
B.5 Chooseaninstance.
1046 Toolsfor Deep Learning Notethatyoushouldusea GPU-enabledinstancewithsuitabledriversanda GPU-enabled deeplearningframework.
Otherwiseyouwillnotseeanybenefitfromusing GPUs.
Wegoontoselectthekeypairusedtoaccesstheinstance.
Ifyoudonothaveakeypair, clickâ€œCreatenewkeypairâ€in Fig.
B.6togenerateakeypair.
Subsequently, youcanselect the previously generated key pair.
Make sure that you download the key pair and store it in a safe location if you generated a new one.
This is your only way to SSH into the server.
t Fig.
B.6 Selectakeypair.
Inthisexample, wewillkeepthedefaultconfigurationsforâ€œNetworksettingsâ€(clickthe â€œEditâ€buttontoconfigureitemssuchasthesubnetandsecuritygroups).
Wejustincrease thedefaultharddisksizeto64GB(Fig.
B.7).
Notethat CUDAbyitselfalreadytakesup 4GB.
t Fig.
B.7 Modifytheharddisksize.
Clickâ€œLaunch Instanceâ€tolaunchthecreatedinstance.
Clicktheinstance IDshownin Fig.
B.8toviewthestatusofthisinstance.
Connectingtothe Instance Asshownin Fig.
B.9, aftertheinstancestateturnsgreen, right-clicktheinstanceandselect Connecttoviewtheinstanceaccessmethod.
Ifthisisanewkey, itmustnotbepubliclyviewablefor SSHtowork.
Gotothefolderwhere 1047 Using AWSEC2Instances t Fig.
B.8 Clicktheinstance ID.
t Fig.
B.9 Viewtheinstanceaccessmethod.
youstore D2L_key.
pemandexecutethefollowingcommandtomakethekeynotpublicly viewable: chmod 400 D2L_key.
pem t Fig.
B.10 Viewinstanceaccessandstartupmethod.
Now, copythe SSHcommandinthelowerredboxof Fig.
B.10andpasteontothecommand line: 1048 Toolsfor Deep Learning Whenthecommandlinepromptsâ€œAreyousureyouwanttocontinueconnecting(yes/no)â€, enterâ€œyesâ€andpress Entertologintotheinstance.
Yourserverisreadynow.
B.3.2 Installing CUDA Beforeinstalling CUDA, besuretoupdatetheinstancewiththelatestdrivers.
sudo apt-get update && sudo apt-get install -y build-essential git libgfortran3 Herewedownload CUDA12.1.
Visit NVIDIAâ€™sofficialrepository299tofindthedownload 299 linkasshownin Fig.
B.11.
t Fig.
B.11 Findthe CUDA12.1downloadaddress.
Copytheinstructionsandpastethemontotheterminaltoinstall CUDA12.1.
# The link and file name are subject to changes wget https://developer.
download.
nvidia.
com/compute/cuda/repos/ubuntu2204/x86_ â†©!64/cuda-ubuntu2204.
pin sudo mv cuda-ubuntu2204.
pin /etc/apt/preferences.
d/cuda-repository-pin-600 (continuesonnextpage) 1049 Using AWSEC2Instances (continuedfrompreviouspage) sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.
gpg /usr/share/ â†©! keyrings/ sudo apt-get update sudo apt-get -y install cuda Afterinstallingtheprogram, runthefollowingcommandtoviewthe GPUs: nvidia-smi Finally, add CUDAtothelibrarypathtohelpotherlibrariesfindit, suchasappendingthe followinglinestotheendof~/.
bashrc.
export PATH="/usr/local/cuda-12.1/bin:$PATH" export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda-12.1/lib64 B.3.3 Installing Librariesfor Runningthe Code Torunthecodeofthisbook, justfollowstepsin Installation(pagexxxiv)for Linuxuserson the EC2instanceandusethefollowingtipsforworkingonaremote Linuxserver: Todownloadthebashscriptonthe Minicondainstallationpage, rightclickthedownload linkandselectâ€œCopy Link Addressâ€, thenexecutewget [copied link address].
Afterrunning~/miniconda3/bin/conda init, youmayexecutesource ~/.
bashrc insteadofclosingandreopeningyourcurrentshell.
B.3.4 Runningthe Jupyter Notebookremotely Torunthe Jupyter Notebookremotelyyouneedtouse SSHportforwarding.
Afterall, the serverintheclouddoesnothaveamonitororkeyboard.
Forthis, logintoyourserverfrom yourdesktop(orlaptop)asfollows: # This command must be run in the local command line â†©!8889: localhost:8888 Next, go to the location of the downloaded code of this book on the EC2 instance, then run: conda activate d2l jupyter notebook Fig.
B.12showsthepossibleoutputafteryourunthe Jupyter Notebook.
Thelastrowisthe URLforport8888.
Sinceyouusedportforwardingtoport8889, copythelastrowintheredboxof Fig.
B.12, replaceâ€œ8888â€withâ€œ8889â€inthe URL, andopenitinyourlocalbrowser.
1050 Toolsfor Deep Learning t Fig.
B.12 Outputafterrunningthe Jupyter Notebook.
Thelastrowisthe URLforport8888.
B.3.5 Closing Unused Instances Ascloudservicesarebilledbythetimeofuse, youshouldcloseinstancesthatarenotbeing used.
Notethattherearealternatives: â€œStoppingâ€ an instance means that you will be able to start it again.
This is akin to switchingoffthepowerforyourregularserver.
However, stoppedinstanceswillstill bebilledasmallamountfortheharddiskspaceretained.
â€œTerminatingâ€aninstancewilldeletealldataassociatedwithit.
Thisincludesthedisk, henceyoucannotstartitagain.
Onlydothisifyouknowthatyouwillnotneeditin thefuture.
If you want to use the instance as a template for many more instances, right-click on the examplein Fig.
B.9andselectâ€œImageâ€!â€œCreateâ€tocreateanimageoftheinstance.
Once thisiscomplete, selectâ€œInstance Stateâ€!â€œTerminateâ€toterminatetheinstance.
Thenext time you want to use this instance, you can follow the steps in this section to create an instancebasedonthesavedimage.
Theonlydifferenceisthat, inâ€œ1.
Choose AMIâ€shown in Fig.
B.4, youmustusetheâ€œMy AMIsâ€optiononthelefttoselectyoursavedimage.
The created instance will retain the information stored on the image hard disk.
For example, youwillnothavetoreinstall CUDAandotherruntimeenvironments.
B.3.6 Summary Wecanlaunchandstopinstancesondemandwithouthavingtobuyandbuildourown computer.
Weneedtoinstall CUDAbeforeusingthe GPU-enableddeeplearningframework.
Wecanuseportforwardingtorunthe Jupyter Notebookonaremoteserver.
B.3.7 Exercises 300 1.
Thecloudoffersconvenience, butitdoesnotcomecheap.
Findouthowtolaunchspot instances300 toseehowtoreducecosts.
1051 Using Google Colab 2.
Experimentwithdifferent GPUservers.
Howfastarethey? 3.
Experimentwithmulti-GPUservers.
Howwellcanyouscalethingsup? Discussions301.
301 B.4 Using Google Colab We introduced how to run this book on AWS in Section B.2 and Section B.3.
Another optionisrunningthisbookon Google Colab302 ifyouhavea Googleaccount.
302 To run the code of a section on Colab, simply click the Colab button as shown in Fig.
B.1.
t Fig.
B.1 Runthecodeofasectionon Colab Ifitisyourfirsttimetorunacodecell, youwillreceiveawarningmessageasshownin Fig.
B.2.
Justclickâ€œRUNANYWAYâ€toignoreit.
t Fig.
B.2 Ignorethewarningmessagebyclickingâ€œRUNANYWAYâ€.
Next, Colab will connect you to an instance to run the code of this section.
Specifically, if a GPU is needed, Colab will be automatically requested for connecting to a GPU in- stance.
B.4.1 Summary Youcanuse Google Colabtoruneachsectionâ€™scodeinthisbook.
Colabwillberequestedtoconnecttoa GPUinstanceifa GPUisneededinanysection ofthisbook.
1052 Toolsfor Deep Learning B.4.2 Exercises 1.
Openanysectionofthisbookusing Google Colab.
2.
Editandrunanysectionthatrequiresa GPUusing Google Colab.
Discussions303.
303 B.5 Selecting Servers and GPUs Deeplearningtraininggenerallyrequireslargeamountsofcomputation.
Atpresent GPUs arethemostcost-effectivehardwareacceleratorsfordeeplearning.
Inparticular, compared with CPUs, GPUs are cheaper and offer higher performance, often by over an order of magnitude.
Furthermore, asingleservercansupportmultiple GPUs, upto8forhighend servers.
More typical numbers are up to 4 GPUs for an engineering workstation, since heat, cooling, andpowerrequirementsescalatequicklybeyondwhatanofficebuildingcan 304 support.
For larger deployments, cloud computing (e.
g., Amazonâ€™s P3304 and G4305 instances)isamuchmorepracticalsolution.
B.5.1 Selecting Servers 305 There is typically no need to purchase high-end CPUs with many threads since much of thecomputationoccursonthe GPUs.
Thatsaid, duetotheglobalinterpreterlock(GIL) in Pythonsingle-threadperformanceofa CPUcanmatterinsituationswherewehave4â€“8 GPUs.
Allthingsequalthissuggeststhat CPUswithasmallernumberofcoresbutahigher clockfrequencymightbeamoreeconomicalchoice.
Forexample, whenchoosingbetween a6-core4GHzandan8-core3.5GHz CPU, theformerismuchpreferable, eventhough itsaggregatespeedisless.
Animportantconsiderationisthat GPUsuselotsofpowerand thusdissipatelotsofheat.
Thisrequiresverygoodcoolingandalargeenoughchassisto usethe GPUs.
Followtheguidelinesbelowifpossible: 1.
Power Supply.
GPUsusesignificantamountsofpower.
Budgetwithupto350Wper device(checkforthepeakdemandofthegraphicscardratherthantypicaldemand, since efficientcodecanuselotsofenergy).
Ifyourpowersupplyisnotuptothedemandyou willfindthatyoursystembecomesunstable.
2.
Chassis Size.
GPUsarelargeandtheauxiliarypowerconnectorsoftenneedextraspace.
Also, largechassisareeasiertocool.
3.
GPUCooling.
Ifyouhavealargenumberof GPUsyoumightwanttoinvestinwater cooling.
Also, aim for reference designs even if they have fewer fans, since they are thinenoughtoallowforairintakebetweenthedevices.
Ifyoubuyamulti-fan GPUit might be too thick to get enough air when installing multiple GPUs and you will run intothermalthrottling.
1053 Selecting Serversand GPUs 4.
PCIe Slots.
Moving data to and from the GPU (and exchanging it between GPUs) requireslotsofbandwidth.
Werecommend PCIe3.0slotswith16lanes.
Ifyoumount multiple GPUs, besuretocarefullyreadthemotherboarddescriptiontoensurethat16 bandwidthisstillavailablewhenmultiple GPUsareusedatthesametimeandthatyou aregetting PCIe3.0asopposedto PCIe2.0fortheadditionalslots.
Somemotherboards downgradeto8 oreven4 bandwidthwithmultiple GPUsinstalled.
Thisispartlydue tothenumberof PCIelanesthatthe CPUoffers.
Inshort, herearesomerecommendationsforbuildingadeeplearningserver: Beginner.
Buyalowend GPUwithlowpowerconsumption(cheapgaming GPUssuit- ablefordeeplearninguse150â€“200W).
Ifyouareluckyyourcurrentcomputersupports it.
1GPU.
Alow-end CPUwith4coreswillbesufficientandmostmotherboardssuffice.
Aimforatleast32GBDRAMandinvestintoan SSDforlocaldataaccess.
Apower supplywith600Wshouldbesufficient.
Buya GPUwithlotsoffans.
2GPUs.
Alow-end CPUwith4-6coreswillsuffice.
Aimfor64GBDRAMandinvest intoan SSD.
Youwillneedintheorderof1000Wfortwohigh-end GPUs.
Interms of mainboards, make sure that they have two PCIe 3.0 x16 slots.
If you can, get a mainboardthathastwofreespaces(60mmspacing)betweenthe PCIe3.0x16slots forextraair.
Inthiscase, buytwo GPUswithlotsoffans.
4GPUs.
Makesurethatyoubuya CPUwithrelativelyfastsingle-threadspeed(i.
e., high clockfrequency).
Youwillprobablyneeda CPUwithalargernumberof PCIelanes, suchasan AMDThreadripper.
Youwilllikelyneedrelativelyexpensivemainboards toget4PCIe3.0x16slotssincetheyprobablyneeda PLXtomultiplexthe PCIelanes.
Buy GPUswithreferencedesignthatarenarrowandletairinbetweenthe GPUs.
You needa1600â€“2000Wpowersupplyandtheoutletinyourofficemightnotsupportthat.
Thisserverwillprobablyrunloudandhot.
Youdonotwantitunderyourdesk.
128 GBof DRAMisrecommended.
Getan SSD(1â€“2TBNVMe)forlocalstorageanda bunchofharddisksin RAIDconfigurationtostoreyourdata.
8GPUs.
Youneedtobuyadedicatedmulti-GPUserverchassiswithmultipleredundant powersupplies(e.
g.,2+1for1600Wperpowersupply).
Thiswillrequiredualsocket server CPUs, 256 GB ECC DRAM, a fast network card (10 GBE recommended), and you will need to check whether the servers support the physical form factor of the GPUs.
Airflowandwiringplacementdiffersignificantlybetweenconsumerand server GPUs(e.
g., RTX2080vs.
Tesla V100).
Thismeansthatyoumightnotbeable toinstalltheconsumer GPUinaserverduetoinsufficientclearanceforthepowercable orlackofasuitablewiringharness(asoneofthecoauthorspainfullydiscovered).
B.5.2 Selecting GPUs Atpresent, AMDand NVIDIAarethetwomainmanufacturersofdedicated GPUs.
NVIDIA wasthefirsttoenterthedeeplearningfieldandprovidesbettersupportfordeeplearning frameworksvia CUDA.
Therefore, mostbuyerschoose NVIDIAGPUs.
1054 Toolsfor Deep Learning NVIDIA provides two types of GPUs, targeting individual users (e.
g., via the GTX and RTX series) and enterprise users (via its Tesla series).
The two types of GPUs provide comparable compute power.
However, the enterprise user GPUs generally use (passive) forcedcooling, morememory, and ECC(errorcorrecting)memory.
These GPUsaremore suitablefordatacentersandusuallycosttentimesmorethanconsumer GPUs.
Ifyouarealargecompanywith100+serversyoushouldconsiderthe NVIDIATeslaseries oralternativelyuse GPUserversinthecloud.
Foralaborasmalltomediumcompanywith 10+serversthe NVIDIARTXseriesislikelymostcosteffective.
Youcanbuypreconfig- uredserverswith Supermicroor Asuschassisthathold4â€“8GPUsefficiently.
GPUvendorstypicallyreleaseanewgenerationeveryonetotwoyears, suchasthe GTX 1000(Pascal)seriesreleasedin2017andthe RTX2000(Turing)seriesreleasedin2019.
Eachseriesoffersseveraldifferentmodelsthatprovidedifferentperformancelevels.
GPU performanceisprimarilyacombinationofthefollowingthreeparameters: 1.
Compute Power.
Generally we look for 32-bit floating-point compute power.
16-bit floatingpointtraining(FP16)isalsoenteringthemainstream.
Ifyouareonlyinterested inprediction, youcanalsouse8-bitinteger.
Thelatestgenerationof Turing GPUsoffers 4-bitacceleration.
Unfortunatelyatthetimeofwritingthealgorithmsfortraininglow- precisionnetworksarenotyetwidespread.
2.
Memory Size.
Asyourmodelsbecomelargerorthebatchesusedduringtraininggrow bigger, youwillneedmore GPUmemory.
Checkfor HBM2(High Bandwidth Memory) vs.
GDDR6(Graphics DDR)memory.
HBM2isfasterbutmuchmoreexpensive.
3.
Memory Bandwidth.
Youcanonlygetthemostoutofyourcomputepowerwhenyou havesufficientmemorybandwidth.
Lookforwidememorybusesifusing GDDR6.
Formostusers, itisenoughtolookatcomputepower.
Notethatmany GPUsofferdifferent typesofacceleration.
Forexample, NVIDIAâ€™s Tensor Coresaccelerateasubsetofopera- tors by 5 .
Ensure that your libraries support this.
The GPU memory should be no less than4GB(8GBismuchbetter).
Trytoavoidusingthe GPUalsofordisplayinga GUI (usethebuilt-ingraphicsinstead).
Ifyoucannotavoidit, addanextra2GBof RAMfor safety.
Fig.
B.1comparesthe32-bitfloating-pointcomputepowerandpriceofthevarious GTX 900, GTX 1000 and RTX 2000 series models.
The prices suggested are those found on Wikipediaatthetimeofwriting.
Wecanseeanumberofthings: 1.
Withineachseries, priceandperformanceareroughlyproportional.
Titanmodelscom- mandasignificantpremiumforthebenefitoflargeramountsof GPUmemory.
How- ever, thenewermodelsofferbettercosteffectiveness, ascanbeseenbycomparingthe 980Tiand1080Ti.
Thepricedoesnotappeartoimprovemuchforthe RTX2000series.
However, thisisduetothefactthattheyofferfarsuperiorlowprecisionperformance (FP16, INT8, and INT4).
1055 Selecting Serversand GPUs t Fig.
B.1 Floating-pointcomputepowerandpricecomparison.
2.
Theperformance-to-costratioofthe GTX1000seriesisabouttwotimesgreaterthan the900series.
3.
Forthe RTX2000seriestheperformance(in GFLOPs)isanaï¬€inefunctionoftheprice.
t Fig.
B.2 Floating-pointcomputepowerandenergyconsumption.
Fig.
B.2 shows how energy consumption scales mostly linearly with the amount of com- 1056 Toolsfor Deep Learning putation.
Second, later generations are more efficient.
This seems to be contradicted by the graph corresponding to the RTX 2000 series.
However, this is a consequence of the Tensor Coresthatdrawdisproportionatelymuchenergy.
B.5.3 Summary Watchoutforpower, PCIebuslanes, CPUsinglethreadspeed, andcoolingwhenbuild- ingaserver.
Youshouldpurchasethelatest GPUgenerationifpossible.
Usethecloudforlargedeployments.
Highdensityserversmaynotbecompatiblewithall GPUs.
Checkthemechanicaland coolingspecificationsbeforeyoubuy.
Use FP16orlowerprecisionforhighefficiency.
306 Discussions306.
B.6 Contributing to This Book 307 Contributionsbyreaders307 helpusimprovethisbook.
Ifyoufindatypo, anoutdatedlink, somethingwhereyouthinkwemissedacitation, wherethecodedoesnotlookelegantor whereanexplanationisunclear, pleasecontributebackandhelpushelpourreaders.
While inregularbooksthedelaybetweenprintruns(andthusbetweentypocorrections)canbe measured in years, it typically takes hours to days to incorporate an improvement in this 308 book.
Thisisallpossibleduetoversioncontrolandcontinuousintegration(CI)testing.
To dosoyouneedtosubmitapullrequest308tothe Git Hubrepository.
Whenyourpullrequest ismergedintothecoderepositorybytheauthors, youwillbecomeacontributor.
B.6.1 Submitting Minor Changes 309 Themostcommoncontributionsareeditingonesentenceorfixingtypos.
Werecommend that you find the source file in the Git Hub repository309 and edit the file directly.
For example, you can search the file through the Find file310 button (Fig.
B.1) to locate the 310 sourcefile(amarkdownfile).
Thenyouclicktheâ€œEditthisfileâ€buttonontheupper-right cornertomakeyourchangesinthemarkdownfile.
Afteryouaredone, fillinyourchangedescriptionsintheâ€œProposefilechangeâ€panelon thepagebottomandthenclicktheâ€œProposefilechangeâ€button.
Itwillredirectyoutoa newpagetoreviewyourchanges(Fig.
B.7).
Ifeverythingisgood, youcansubmitapull requestbyclickingtheâ€œCreatepullrequestâ€button.
1057 Contributingto This Book t Fig.
B.1 Editthefileon Github.
B.6.2 Proposing Major Changes Ifyouplantoupdatealargeportionoftextorcode, thenyouneedtoknowalittlebitmore abouttheformatthisbookisusing.
Thesourcefileisbasedonthemarkdownformat311 311 withasetofextensionsthroughthe D2L-Book312 packagesuchasreferringtoequations, images, chapters, andcitations.
Youcanuseanymarkdowneditorstoopenthesefilesand makeyourchanges.
312 Ifyouwouldliketochangethecode, werecommendthatyouusethe Jupyter Notebookto openthesemarkdownfilesasdescribedin Section B.1, sothatyoucanrunandtestyour changes.
Pleaseremembertoclearalloutputsbeforesubmittingyourchangessinceour CI systemwillexecutethesectionsyouupdatedtogenerateoutputs.
Somesectionsmaysupportmultipleframeworkimplementations.
Ifyouaddanewcode block, please use %%tab to mark this block on the beginning line.
For example, %%tab pytorchfora Py Torchcodeblock, %%tab tensorflowfora Tensor Flowcodeblock, or %%tab all a shared code block for all implementations.
You may refer to the d2lbook packageformoreinformation.
B.6.3 Submitting Major Changes Wesuggestyoutousethestandard Gitprocesstosubmitamajorchange.
Inanutshellthe processworksasdescribedin Fig.
B.2.
t Fig.
B.2 Contributingtothebook.
We will walk you through the steps in detail.
If you are already familiar with Git you canskipthissection.
Forconcretenessweassumethatthecontributorâ€™susernameisâ€œas- tonzhangâ€.
1058 Toolsfor Deep Learning Installing Git The Git open-source book describes how to install Git313.
This typicallyworksvia apt 313 install giton Ubuntu Linux, byinstallingthe Xcodedevelopertoolsonmac OS, orby using Git Hubâ€™sdesktopclient314.
Ifyoudonothavea Git Hubaccount, youneedtosign upforone.
314 Logginginto Git Hub Enter the address315 of the bookâ€™s code repository in your browser.
Click on the Fork buttonintheredboxattheupper-rightof Fig.
B.3, tomakeacopyoftherepositoryofthis 315 book.
Thisisnowyourcopyandyoucanchangeitanywayyouwant.
t Fig.
B.3 Thecoderepositorypage.
Now, thecoderepositoryofthisbookwillbeforked(i.
e., copied)toyourusername, such asastonzhang/d2l-enshownattheupper-leftof Fig.
B.4.
t Fig.
B.4 Theforkedcoderepository.
Cloningthe Repository Toclonetherepository(i.
e., tomakealocalcopy)weneedtogetitsrepositoryaddress.
The green button in Fig.
B.5 displays this.
Make sure that your local copy is up to date withthemainrepositoryifyoudecidetokeepthisforkaroundforlonger.
Fornowsimply follow the instructions in Installation (page xxxiv) to get started.
The main difference is thatyouarenowdownloadingyourownforkoftherepository.
t Fig.
B.5 Cloningtherepository.
1059 Contributingto This Book # Replace your_github_username with your Git Hub username git clone https://github.
com/your_github_username/d2l-en.
git Editingand Pushing Nowitistimetoeditthebook.
Itisbesttoedititinthe Jupyter Notebookfollowinginstruc- tionsin Section B.1.
Makethechangesandcheckthattheyare OK.
Assumethatwehave modified a typo in the file ~/d2l-en/chapter_appendix-tools-for-deep-learning/ contributing.
md.
Youcanthencheckwhichfilesyouhavechanged.
At this point Git will prompt that the chapter_appendix-tools-for-deep-learning/ contributing.
mdfilehasbeenmodified.
mylaptop: d2l-en me$ git status On branch master Your branch is up-to-date with 'origin/master'.
Changes not staged for commit: (use "git add <file>..." to update what will be committed) (use "git checkout -- <file>..." to discard changes in working directory) modified: chapter_appendix-tools-for-deep-learning/contributing.
md Afterconfirmingthatthisiswhatyouwant, executethefollowingcommand: git add chapter_appendix-tools-for-deep-learning/contributing.
md git commit -m 'Fix a typo in git documentation' git push The changed code will then be in your personal fork of the repository.
To request the additionofyourchange, youhavetocreateapullrequestfortheofficialrepositoryofthe book.
Submitting Pull Requests As shown in Fig.
B.6, go to your fork of the repository on Git Hub and select â€œNew pull requestâ€.
This will open up a screen that shows you the changes between your edits and whatiscurrentinthemainrepositoryofthebook.
t Fig.
B.6 Newpullrequest.
1060 Toolsfor Deep Learning Finally, submit a pull request by clicking the button as shown in Fig.
B.7.
Make sure to describe the changes you have made in the pull request.
This will make it easier for the authorstoreviewitandtomergeitwiththebook.
Dependingonthechanges, thismight getacceptedrightaway, rejected, ormorelikely, youwillgetsomefeedbackonthechanges.
Onceyouhaveincorporatedthem, youaregoodtogo.
t Fig.
B.7 Createpullrequest.
B.6.4 Summary Youcanuse Git Hubtocontributetothisbook.
Youcaneditthefileon Git Hubdirectlyforminorchanges.
For a major change, please fork the repository, edit things locally, and only contribute backonceyouareready.
Pullrequestsarehowcontributionsarebeingbundledup.
Trynottosubmithugepull requestssincethismakesthemhardtounderstandandincorporate.
Bettersendseveral smallerones.
B.6.5 Exercises 1.
Starandforkthed2l-ai/d2l-enrepository.
2.
Ifyouspotanythingthatneedsimprovement(e.
g., missingareference), submitapull request.
3.
Itisusuallyabetterpracticetocreateapullrequestusinganewbranch.
Learnhowto doitwith Gitbranching316.
316 Discussions317.
B.7 Utility Functions and Classes 317 This section contains the implementations of utility functions and classes used in this book.
1061 Utility Functionsand Classes import collections import inspect from IPython import display from torch import nn from d2l import torch as d2l Hyperparameters.
@d2l.
add_to_class(d2l.
Hyper Parameters) #@save def save_hyperparameters(self, ignore=[]): """Save function arguments into class attributes.""" frame = inspect.
currentframe().
f_back _, _, _, local_vars = inspect.
getargvalues(frame) self.
hparams = {k: v for k, v in local_vars.
items() if k not in set(ignore+['self']) and not k.
startswith('_')} for k, v in self.
hparams.
items(): setattr(self, k, v) Progressbar.
@d2l.
add_to_class(d2l.
Progress Board) #@save def draw(self, x, y, label, every_n=1): Point = collections.
namedtuple('Point', ['x', 'y']) if not hasattr(self, 'raw_points'): self.
raw_points = collections.
Ordered Dict() self.
data = collections.
Ordered Dict() if label not in self.
raw_points: self.
raw_points[label] = [] self.
data[label] = [] points = self.
raw_points[label] line = self.
data[label] points.
append(Point(x, y)) if len(points) != every_n: return mean = lambda x: sum(x) / len(x) line.
append(Point(mean([p.
x for p in points]), mean([p.
y for p in points]))) points.
clear() if not self.
display: return d2l.
use_svg_display() if self.
fig is None: self.
fig = d2l.
plt.
figure(figsize=self.
figsize) plt_lines, labels = [], [] for (k, v), ls, color in zip(self.
data.
items(), self.
ls, self.
colors): linestyle=ls, color=color)[0]) labels.
append(k) axes = self.
axes if self.
axes else d2l.
plt.
gca() if self.
xlim: axes.
set_xlim(self.
xlim) if self.
ylim: axes.
set_ylim(self.
ylim) if not self.
xlabel: self.
xlabel = self.
x axes.
set_xlabel(self.
xlabel) axes.
set_ylabel(self.
ylabel) (continuesonnextpage) 1062 Toolsfor Deep Learning (continuedfrompreviouspage) axes.
set_xscale(self.
xscale) axes.
set_yscale(self.
yscale) axes.
legend(plt_lines, labels) display.
display(self.
fig) display.
clear_output(wait=True) Add Frozen Lakeenviroment def frozen_lake(seed): #@save # See https://www.
gymlibrary.
dev/environments/toy_text/frozen_lake/ toâ£ â†©! learn more about this env # How to process env.
P.
items is adpated from https://sites.
google.
com/view/ â†©! deep-rl-bootcamp/labs import gym env = gym.
make('Frozen Lake-v1', is_slippery=False) env.
seed(seed) env.
action_space.
np_random.
seed(seed) env.
action_space.
seed(seed) env_info = {} env_info['desc'] = env.
desc # 2D array specifying what each grid itemâ£ â†©! means env_info['num_states'] = env.
n S # Number of observations/states or obs/ â†©! state dim env_info['num_actions'] = env.
n A # Number of actions or action dim # Define indices for (transition probability, nextstate, reward, done)â£ â†©! tuple env_info['trans_prob_idx'] = 0 # Index of transition probability entry env_info['nextstate_idx'] = 1 # Index of next state entry env_info['reward_idx'] = 2 # Index of reward entry env_info['done_idx'] = 3 # Index of done entry env_info['mdp'] = {} env_info['env'] = env for (s, others) in env.
P.
items(): â†©!} for (a, pxrds) in others.
items(): # pxrds is [(p1, next1, r1, d1),(p2, next2, r2, d2),..].
env_info['mdp'][(s, a)] = pxrds return env_info Createenviroment def make_env(name ='', seed=0): #@save # Input parameters: # name: specifies a gym environment.
# For Value iteration, only Frozen Lake-v1 is supported.
if name == 'Frozen Lake-v1': return frozen_lake(seed) (continuesonnextpage) 1063 Utility Functionsand Classes (continuedfrompreviouspage) else: raise Value Error("%s env is not supported in this Notebook") Showvaluefunction def show_value_function_progress(env_desc, V, pi): #@save # This function visualizes how value and policy changes over time.
# V: [num_iters, num_states] # pi: [num_iters, num_states] # How to visualize value function is adapted (but changed) from: https:// â†©! sites.
google.
com/view/deep-rl-bootcamp/labs num_iters = V.
shape[0] fig, ax = plt.
subplots(figsize=(15, 15)) for k in range(V.
shape[0]): plt.
subplot(4, 4, k + 1) plt.
imshow(V[k].
reshape(4,4), cmap="bone") ax = plt.
gca() ax.
set_xticks(np.
arange(0, 5)-.5, minor=True) ax.
set_yticks(np.
arange(0, 5)-.5, minor=True) ax.
grid(which="minor", color="w", linestyle='-', linewidth=3) ax.
tick_params(which="minor", bottom=False, left=False) ax.
set_xticks([]) ax.
set_yticks([]) # LEFT action: 0, DOWN action: 1 # RIGHT action: 2, UP action: 3 action2dxdy = {0:(-.25, 0),1: (0, .25), 2:(0.25, 0),3: (-.25, 0)} for y in range(4): for x in range(4): action = pi[k].
reshape(4,4)[y, x] dx, dy = action2dxdy[action] if env_desc[y, x].
decode() == 'H': ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="y", size=20, fontweight='bold') elif env_desc[y, x].
decode() == 'G': ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="w", size=20, fontweight='bold') else: ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="g", size=15, fontweight='bold') # No arrow for cells with G and H labels if env_desc[y, x].
decode() != 'G' and env_desc[y, x].
decode() != (continuesonnextpage) 1064 Toolsfor Deep Learning (continuedfrompreviouspage) â†©!'H': ax.
arrow(x, y, dx, dy, color='r', head_width=0.2, head_ â†©! length=0.15) ax.
set_title("Step = " + str(k + 1), fontsize=20) fig.
tight_layout() plt.
show() Show Qfunction def show_Q_function_progress(env_desc, V_all, pi_all): #@save # This function visualizes how value and policy changes over time.
# V: [num_iters, num_states] # pi: [num_iters, num_states] # We want to only shows few values num_iters_all = V_all.
shape[0] num_iters = num_iters_all // 10 vis_indx = np.
arange(0, num_iters_all, num_iters).
tolist() vis_indx.
append(num_iters_all - 1) V = np.
zeros((len(vis_indx), V_all.
shape[1])) pi = np.
zeros((len(vis_indx), V_all.
shape[1])) for c, i in enumerate(vis_indx): V[c] = V_all[i] pi[c] = pi_all[i] num_iters = V.
shape[0] fig, ax = plt.
subplots(figsize=(15, 15)) for k in range(V.
shape[0]): plt.
subplot(4, 4, k + 1) plt.
imshow(V[k].
reshape(4,4), cmap="bone") ax = plt.
gca() ax.
set_xticks(np.
arange(0, 5)-.5, minor=True) ax.
set_yticks(np.
arange(0, 5)-.5, minor=True) ax.
grid(which="minor", color="w", linestyle='-', linewidth=3) ax.
tick_params(which="minor", bottom=False, left=False) ax.
set_xticks([]) ax.
set_yticks([]) # LEFT action: 0, DOWN action: 1 # RIGHT action: 2, UP action: 3 action2dxdy = {0:(-.25, 0),1:(0, .25), 2:(0.25, 0),3:(-.25, 0)} for y in range(4): for x in range(4): action = pi[k].
reshape(4,4)[y, x] dx, dy = action2dxdy[action] if env_desc[y, x].
decode() == 'H': (continuesonnextpage) 1065 Utility Functionsand Classes (continuedfrompreviouspage) ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="y", size=20, fontweight='bold') elif env_desc[y, x].
decode() == 'G': ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="w", size=20, fontweight='bold') else: ax.
text(x, y, str(env_desc[y, x].
decode()), ha="center", va="center", color="g", size=15, fontweight='bold') # No arrow for cells with G and H labels if env_desc[y, x].
decode() != 'G' and env_desc[y, x].
decode() != â†©!'H': ax.
arrow(x, y, dx, dy, color='r', head_width=0.2, head_ â†©! length=0.15) ax.
set_title("Step = " + str(vis_indx[k] + 1), fontsize=20) fig.
tight_layout() plt.
show() Trainer Abunchoffunctionsthatwillbedeprecated: def load_array(data_arrays, batch_size, is_train=True): #@save """Construct a Py Torch data iterator.""" dataset = torch.
utils.
data.
Tensor Dataset(*data_arrays) return torch.
utils.
data.
Data Loader(dataset, batch_size, shuffle=is_train) def synthetic_data(w, b, num_examples): #@save """Generate y = Xw + b + noise.""" X = torch.
normal(0, 1, (num_examples, len(w))) y = torch.
matmul(X, w) + b y += torch.
normal(0, 0.01, y.
shape) return X, y.
reshape((-1, 1)) def sgd(params, lr, batch_size): #@save """Minibatch stochastic gradient descent.""" with torch.
no_grad(): for param in params: param -= lr * param.
grad / batch_size param.
grad.
zero_() def get_dataloader_workers(): #@save """Use 4 processes to read the data.""" return 4 def load_data_fashion_mnist(batch_size, resize=None): #@save """Download the Fashion-MNIST dataset and then load it into memory.""" (continuesonnextpage) 1066 Toolsfor Deep Learning (continuedfrompreviouspage) trans = [transforms.
To Tensor()] if resize: trans.
insert(0, transforms.
Resize(resize)) trans = transforms.
Compose(trans) mnist_train = torchvision.
datasets.
Fashion MNIST( root="../data", train=True, transform=trans, download=True) mnist_test = torchvision.
datasets.
Fashion MNIST( root="../data", train=False, transform=trans, download=True) return (torch.
utils.
data.
Data Loader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), torch.
utils.
data.
Data Loader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) def evaluate_accuracy_gpu(net, data_iter, device=None): #@save """Compute the accuracy for a model on a dataset using a GPU.""" if isinstance(net, nn.
Module): net.
eval() # Set the model to evaluation mode if not device: device = next(iter(net.
parameters())).
device # No.
of correct predictions, no.
of predictions metric = d2l.
Accumulator(2) with torch.
no_grad(): for X, y in data_iter: if isinstance(X, list): # Required for BERT Fine-tuning (to be covered later) X = [x.
to(device) for x in X] else: X = X.
to(device) y = y.
to(device) metric.
add(d2l.
accuracy(net(X), y), y.
numel()) return metric[0] / metric[1] #@save def train_ch6(net, train_iter, test_iter, num_epochs, lr, device): """Train a model with a GPU (defined in Chapter 6).""" def init_weights(m): if type(m) == nn.
Linear or type(m) == nn.
Conv2d: nn.
init.
xavier_uniform_(m.
weight) net.
apply(init_weights) print('training on', device) net.
to(device) optimizer = torch.
optim.
SGD(net.
parameters(), lr=lr) loss = nn.
Cross Entropy Loss() animator = d2l.
Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['train loss', 'train acc', 'test acc']) timer, num_batches = d2l.
Timer(), len(train_iter) for epoch in range(num_epochs): # Sum of training loss, sum of training accuracy, no.
of examples metric = d2l.
Accumulator(3) net.
train() for i, (X, y) in enumerate(train_iter): timer.
start() optimizer.
zero_grad() (continuesonnextpage) 1067 Utility Functionsand Classes (continuedfrompreviouspage) X, y = X.
to(device), y.
to(device) y_hat = net(X) l = loss(y_hat, y) l.
backward() optimizer.
step() with torch.
no_grad(): metric.
add(l * X.
shape[0], d2l.
accuracy(y_hat, y), X.
shape[0]) timer.
stop() train_l = metric[0] / metric[2] train_acc = metric[1] / metric[2] if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.
add(epoch + (i + 1) / num_batches, (train_l, train_acc, None)) test_acc = evaluate_accuracy_gpu(net, test_iter) animator.
add(epoch + 1, (None, None, test_acc)) print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, ' f'test acc {test_acc:.3f}') print(f'{metric[2] * num_epochs / timer.
sum():.1f} examples/sec ' f'on {str(device)}') def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save """Plot a list of images.""" figsize = (num_cols * scale, num_rows * scale) _, axes = d2l.
plt.
subplots(num_rows, num_cols, figsize=figsize) axes = axes.
flatten() for i, (ax, img) in enumerate(zip(axes, imgs)): try: img = img.
detach().
numpy() except: pass ax.
imshow(img) ax.
axes.
get_xaxis().
set_visible(False) ax.
axes.
get_yaxis().
set_visible(False) if titles: ax.
set_title(titles[i]) return axes def linreg(X, w, b): #@save """The linear regression model.""" return torch.
matmul(X, w) + b def squared_loss(y_hat, y): #@save """Squared loss.""" return (y_hat - y.
reshape(y_hat.
shape)) ** 2 / 2 def get_fashion_mnist_labels(labels): #@save """Return text labels for the Fashion-MNIST dataset.""" text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'] return [text_labels[int(i)] for i in labels] class Animator: #@save """For plotting data in animation.""" (continuesonnextpage) 1068 Toolsfor Deep Learning (continuedfrompreviouspage) def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale='linear', yscale='linear', fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1, figsize=(3.5, 2.5)): # Incrementally plot multiple lines if legend is None: legend = [] d2l.
use_svg_display() self.
fig, self.
axes = d2l.
plt.
subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.
axes = [self.
axes, ] # Use a lambda function to capture arguments self.
config_axes = lambda: d2l.
set_axes( self.
axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.
X, self.
Y, self.
fmts = None, None, fmts def add(self, x, y): # Add multiple data points into the figure if not hasattr(y, "__len__"): y = [y] n = len(y) if not hasattr(x, "__len__"): x = [x] * n if not self.
X: self.
X = [[] for _ in range(n)] if not self.
Y: self.
Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.
X[i].
append(a) self.
Y[i].
append(b) self.
axes[0].
cla() for x, y, fmt in zip(self.
X, self.
Y, self.
fmts): self.
axes[0].
plot(x, y, fmt) self.
config_axes() display.
display(self.
fig) display.
clear_output(wait=True) class Accumulator: #@save """For accumulating sums over `n` variables.""" def __init__(self, n): self.
data = [0.0] * n def add(self, *args): self.
data = [a + float(b) for a, b in zip(self.
data, args)] def reset(self): self.
data = [0.0] * len(self.
data) def __getitem__(self, idx): return self.
data[idx] def accuracy(y_hat, y): #@save """Compute the number of correct predictions.""" (continuesonnextpage) 1069 Utility Functionsand Classes (continuedfrompreviouspage) if len(y_hat.
shape) > 1 and y_hat.
shape[1] > 1: y_hat = y_hat.
argmax(axis=1) cmp = y_hat.
type(y.
dtype) == y return float(cmp.
type(y.
dtype).
sum()) import hashlib import os import tarfile import zipfile import requests def download(url, folder='../data', sha1_hash=None): #@save """Download a file to folder and return the local filepath.""" if not url.
startswith('http'): # For back compatability url, sha1_hash = DATA_HUB[url] os.
makedirs(folder, exist_ok=True) fname = os.
path.
join(folder, url.
split('/')[-1]) # Check if hit cache if os.
path.
exists(fname) and sha1_hash: sha1 = hashlib.
sha1() with open(fname, 'rb') as f: while True: data = f.
read(1048576) if not data: break sha1.
update(data) if sha1.
hexdigest() == sha1_hash: return fname # Download print(f'Downloading {fname} from {url}...') r = requests.
get(url, stream=True, verify=True) with open(fname, 'wb') as f: f.
write(r.
content) return fname def extract(filename, folder=None): #@save """Extract a zip/tar file into folder.""" base_dir = os.
path.
dirname(filename) _, ext = os.
path.
splitext(filename) assert ext in ('.
zip', '.
tar', '.
gz'), 'Only support zip/tar files.' if ext == '.
zip': fp = zipfile.
Zip File(filename, 'r') else: fp = tarfile.
open(filename, 'r') if folder is None: folder = base_dir fp.
extractall(folder) def download_extract(name, folder=None): #@save """Download and extract a zip/tar file.""" fname = download(name) (continuesonnextpage) 1070 Toolsfor Deep Learning (continuedfrompreviouspage) base_dir = os.
path.
dirname(fname) data_dir, ext = os.
path.
splitext(fname) if ext == '.
zip': fp = zipfile.
Zip File(fname, 'r') elif ext in ('.
tar', '.
gz'): fp = tarfile.
open(fname, 'r') else: assert False, 'Only zip/tar files can be extracted.' fp.
extractall(base_dir) return os.
path.
join(base_dir, folder) if folder else data_dir def tokenize(lines, token='word'): #@save """Split text lines into word or character tokens.""" assert token in ('word', 'char'), 'Unknown token type: ' + token return [line.
split() if token == 'word' else list(line) for line in lines] def evaluate_loss(net, data_iter, loss): #@save """Evaluate the loss of a model on the given dataset.""" metric = d2l.
Accumulator(2) # Sum of losses, no.
of examples for X, y in data_iter: out = net(X) y = y.
reshape(out.
shape) l = loss(out, y) metric.
add(l.
sum(), l.
numel()) return metric[0] / metric[1] def grad_clipping(net, theta): #@save """Clip the gradient.""" if isinstance(net, nn.
Module): params = [p for p in net.
parameters() if p.
requires_grad] else: params = net.
params norm = torch.
sqrt(sum(torch.
sum((p.
grad ** 2)) for p in params)) if norm > theta: for param in params: param.
grad[:] *= theta / norm Morefortheattentionchapter.
#@save d2l.
DATA_HUB['fra-eng'] = (d2l.
DATA_URL + 'fra-eng.
zip', '94646ad1522d915e7b0f9296181140edcf86a4f5') #@save def read_data_nmt(): """Load the English-French dataset.""" data_dir = d2l.
download_extract('fra-eng') with open(os.
path.
join(data_dir, 'fra.
txt'), 'r', encoding='utf-8') as f: return f.
read() #@save (continuesonnextpage) 1071 Utility Functionsand Classes (continuedfrompreviouspage) def preprocess_nmt(text): """Preprocess the English-French dataset.""" def no_space(char, prev_char): return char in set(',.!?') and prev_char != ' ' # Replace non-breaking space with space, and convert uppercase letters to # lowercase ones text = text.
replace('\u202f', ' ').
replace('\xa0', ' ').
lower() # Insert space between words and punctuation marks out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)] return ''.
join(out) #@save def tokenize_nmt(text, num_examples=None): """Tokenize the English-French dataset.""" source, target = [], [] for i, line in enumerate(text.
split('\n')): if num_examples and i > num_examples: break parts = line.
split('\t') if len(parts) == 2: source.
append(parts[0].
split(' ')) target.
append(parts[1].
split(' ')) return source, target #@save def truncate_pad(line, num_steps, padding_token): """Truncate or pad sequences.""" if len(line) > num_steps: return line[: num_steps] # Truncate return line + [padding_token] * (num_steps - len(line)) # Pad #@save def build_array_nmt(lines, vocab, num_steps): """Transform text sequences of machine translation into minibatches.""" lines = [vocab[l] for l in lines] lines = [l + [vocab['<eos>']] for l in lines] array = torch.
tensor([truncate_pad( l, num_steps, vocab['<pad>']) for l in lines]) valid_len = (array != vocab['<pad>']).
type(torch.
int32).
sum(1) return array, valid_len #@save def load_data_nmt(batch_size, num_steps, num_examples=600): """Return the iterator and the vocabularies of the translation dataset.""" text = preprocess_nmt(read_data_nmt()) source, target = tokenize_nmt(text, num_examples) src_vocab = d2l.
Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>']) tgt_vocab = d2l.
Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>']) (continuesonnextpage) 1072 Toolsfor Deep Learning (continuedfrompreviouspage) src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps) tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps) data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len) data_iter = d2l.
load_array(data_arrays, batch_size) return data_iter, src_vocab, tgt_vocab #@save def sequence_mask(X, valid_len, value=0): """Mask irrelevant entries in sequences.""" maxlen = X.
size(1) mask = torch.
arange((maxlen), dtype=torch.
float32, device=X.
device)[None, :] < valid_len[:, None] X[~mask] = value return X #@save class Masked Softmax CELoss(nn.
Cross Entropy Loss): """The softmax cross-entropy loss with masks.""" # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`) # `label` shape: (`batch_size`, `num_steps`) # `valid_len` shape: (`batch_size`,) def forward(self, pred, label, valid_len): weights = torch.
ones_like(label) weights = sequence_mask(weights, valid_len) self.
reduction='none' unweighted_loss = super(Masked Softmax CELoss, self).
forward( pred.
permute(0, 2, 1), label) weighted_loss = (unweighted_loss * weights).
mean(dim=1) return weighted_loss #@save def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device): """Train a model for sequence to sequence.""" def xavier_init_weights(m): if type(m) == nn.
Linear: nn.
init.
xavier_uniform_(m.
weight) if type(m) == nn.
GRU: for param in m._flat_weights_names: if "weight" in param: nn.
init.
xavier_uniform_(m._parameters[param]) net.
apply(xavier_init_weights) net.
to(device) optimizer = torch.
optim.
Adam(net.
parameters(), lr=lr) loss = Masked Softmax CELoss() net.
train() animator = d2l.
Animator(xlabel='epoch', ylabel='loss', xlim=[10, num_epochs]) for epoch in range(num_epochs): timer = d2l.
Timer() metric = d2l.
Accumulator(2) # Sum of training loss, no.
of tokens for batch in data_iter: optimizer.
zero_grad() X, X_valid_len, Y, Y_valid_len = [x.
to(device) for x in batch] (continuesonnextpage) 1073 Utility Functionsand Classes (continuedfrompreviouspage) bos = torch.
tensor([tgt_vocab['<bos>']] * Y.
shape[0], device=device).
reshape(-1, 1) dec_input = torch.
cat([bos, Y[:, :-1]], 1) # Teacher forcing Y_hat, _ = net(X, dec_input, X_valid_len) l = loss(Y_hat, Y, Y_valid_len) l.
sum().
backward() # Make the loss scalar for `backward` d2l.
grad_clipping(net, 1) num_tokens = Y_valid_len.
sum() optimizer.
step() with torch.
no_grad(): metric.
add(l.
sum(), num_tokens) if (epoch + 1) % 10 == 0: animator.
add(epoch + 1, (metric[0] / metric[1],)) print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.
stop():.1f} ' f'tokens/sec on {str(device)}') #@save def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False): """Predict for sequence to sequence.""" # Set `net` to eval mode for inference net.
eval() src_tokens = src_vocab[src_sentence.
lower().
split(' ')] + [ src_vocab['<eos>']] enc_valid_len = torch.
tensor([len(src_tokens)], device=device) src_tokens = d2l.
truncate_pad(src_tokens, num_steps, src_vocab['<pad>']) # Add the batch axis enc_X = torch.
unsqueeze( torch.
tensor(src_tokens, dtype=torch.
long, device=device), dim=0) enc_outputs = net.
encoder(enc_X, enc_valid_len) dec_state = net.
decoder.
init_state(enc_outputs, enc_valid_len) # Add the batch axis dec_X = torch.
unsqueeze(torch.
tensor( [tgt_vocab['<bos>']], dtype=torch.
long, device=device), dim=0) output_seq, attention_weight_seq = [], [] for _ in range(num_steps): Y, dec_state = net.
decoder(dec_X, dec_state) # We use the token with the highest prediction likelihood as input # of the decoder at the next time step dec_X = Y.
argmax(dim=2) pred = dec_X.
squeeze(dim=0).
type(torch.
int32).
item() # Save attention weights (to be covered later) if save_attention_weights: attention_weight_seq.
append(net.
decoder.
attention_weights) # Once the end-of-sequence token is predicted, the generation of the # output sequence is complete if pred == tgt_vocab['<eos>']: break output_seq.
append(pred) return ' '.
join(tgt_vocab.
to_tokens(output_seq)), attention_weight_seq 1074 Toolsfor Deep Learning B.8 The d2l API Document This section displays classes and functions (sorted alphabetically) in the d2l package, showing where they are defined in the book so you can find more detailed implementa- tionsandexplanations.
Seealsothesourcecodeonthe Git Hubrepository318.
318 B.8.1 Classes class d2l.
torch.
Additive Attention(num_hiddens, dropout,**kwargs) Bases: Module Additiveattention.
Definedin Section11.3.2 forward(queries, keys, values, valid_lens) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Add Norm(norm_shape, dropout) Bases: Module Theresidualconnectionfollowedbylayernormalization.
Definedin Section11.7.2 forward(X, Y) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Attention Decoder Bases: Decoder(page1075) Thebaseattention-baseddecoderinterface.
1075 Thed2l APIDocument Definedin Section11.4 property attention_weights class d2l.
torch.
Classifier(plot_train_per_epoch=2, plot_valid_per_epoch=1) Bases: Module(page1078) Thebaseclassofclassificationmodels.
Definedin Section4.3 accuracy(Y_hat, Y, averaged=True) Computethenumberofcorrectpredictions.
Definedin Section4.3 layer_summary(X_shape) Definedin Section7.6 loss(Y_hat, Y, averaged=True) Definedin Section4.5 validation_step(batch) class d2l.
torch.
Data Module(root=â€™../dataâ€™, num_workers=4) Bases: Hyper Parameters(page1077) Thebaseclassofdata.
Definedin Section3.2.2 get_dataloader(train) get_tensorloader(tensors, train, indices=slice(0, None, None)) Definedin Section3.3 train_dataloader() val_dataloader() class d2l.
torch.
Decoder Bases: Module Thebasedecoderinterfacefortheencoderâ€“decoderarchitecture.
Definedin Section10.6 forward(X, state) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
1076 Toolsfor Deep Learning Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
init_state(enc_all_outputs,*args) class d2l.
torch.
Dot Product Attention(dropout) Bases: Module Scaleddotproductattention.
Definedin Section11.3.2 forward(queries, keys, values, valid_lens=None) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Encoder Bases: Module Thebaseencoderinterfacefortheencoderâ€“decoderarchitecture.
Definedin Section10.6 forward(X,*args) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Encoder Decoder(encoder, decoder) Bases: Classifier(page1075) Thebaseclassfortheencoderâ€“decoderarchitecture.
Definedin Section10.6 1077 Thed2l APIDocument forward(enc_X, dec_X,*args) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
predict_step(batch, device, num_steps, save_attention_weights=False) Definedin Section10.7.6 class d2l.
torch.
Fashion MNIST(batch_size=64, resize=(28,28)) Bases: Data Module(page1075) The Fashion-MNISTdataset.
Definedin Section4.2 get_dataloader(train) Definedin Section4.2 text_labels(indices) Returntextlabels.
Definedin Section4.2 visualize(batch, nrows=1, ncols=8, labels=[]) Definedin Section4.2 class d2l.
torch.
GRU(num_inputs, num_hiddens, num_layers, dropout=0) Bases: RNN(page1081) Themultilayer GRUmodel.
Definedin Section10.3 class d2l.
torch.
Hyper Parameters Bases: object Thebaseclassofhyperparameters.
save_hyperparameters(ignore=[]) Savefunctionargumentsintoclassattributes.
Definedin Section B.7 1078 Toolsfor Deep Learning class d2l.
torch.
Le Net(lr=0.1, num_classes=10) Bases: Classifier(page1075) The Le Net-5model.
Definedin Section7.6 class d2l.
torch.
Linear Regression(lr) Bases: Module(page1078) Thelinearregressionmodelimplementedwithhigh-level APIs.
Definedin Section3.5 configure_optimizers() Definedin Section3.5 forward(X) Definedin Section3.5 get_w_b() Definedin Section3.5 loss(y_hat, y) Definedin Section3.5 class d2l.
torch.
Linear Regression Scratch(num_inputs, lr, sigma=0.01) Bases: Module(page1078) Thelinearregressionmodelimplementedfromscratch.
Definedin Section3.4 configure_optimizers() Definedin Section3.4 forward(X) Definedin Section3.4 loss(y_hat, y) Definedin Section3.4 class d2l.
torch.
Module(plot_train_per_epoch=2, plot_valid_per_epoch=1) Bases: Module, Hyper Parameters(page1077) Thebaseclassofmodels.
Definedin Section3.2 apply_init(inputs, init=None) Definedin Section6.4 1079 Thed2l APIDocument configure_optimizers() Definedin Section4.3 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
loss(y_hat, y) plot(key, value, train) Plotapointinanimation.
training_step(batch) validation_step(batch) class d2l.
torch.
MTFra Eng(batch_size, num_steps=9, num_train=512, num_val=128) Bases: Data Module(page1075) The English-Frenchdataset.
Definedin Section10.5 build(src_sentences, tgt_sentences) Definedin Section10.5.3 get_dataloader(train) Definedin Section10.5.3 class d2l.
torch.
Multi Head Attention(num_hiddens, num_heads, dropout, bias=False,**kwargs) Bases: Module(page1078) Multi-headattention.
Definedin Section11.5 forward(queries, keys, values, valid_lens) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
1080 Toolsfor Deep Learning Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
transpose_output(X) Reversetheoperationoftranspose_qkv.
Definedin Section11.5 transpose_qkv(X) Transpositionforparallelcomputationofmultipleattentionheads.
Definedin Section11.5 class d2l.
torch.
Positional Encoding(num_hiddens, dropout, max_len=1000) Bases: Module Positionalencoding.
Definedin Section11.6 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Position Wise FFN(ffn_num_hiddens, ffn_num_outputs) Bases: Module Thepositionwisefeed-forwardnetwork.
Definedin Section11.7 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
1081 Thed2l APIDocument class d2l.
torch.
Progress Board(xlabel=None, ylabel=None, xlim=None, ylim=None, xscale=â€™linearâ€™, yscale=â€™linearâ€™, ls=[â€™-â€™,â€™--â€™,â€™-.â€™,â€™:â€™], colors=[â€™C0â€™,â€™C1â€™,â€™C2â€™, â€™C3â€™], fig=None, axes=None, figsize=(3.5,2.5), display=True) Bases: Hyper Parameters(page1077) Theboardthatplotsdatapointsinanimation.
Definedin Section3.2 draw(x, y, label, every_n=1) Definedin Section B.7 class d2l.
torch.
Residual(num_channels, use_1x1conv=False, strides=1) Bases: Module The Residualblockof Res Netmodels.
Definedin Section8.6 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Res Ne Xt Block(num_channels, groups, bot_mul, use_1x1conv=False, strides=1) Bases: Module The Res Ne Xtblock.
Definedin Section8.6.2 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
1082 Toolsfor Deep Learning class d2l.
torch.
RNN(num_inputs, num_hiddens) Bases: Module(page1078) The RNNmodelimplementedwithhigh-level APIs.
Definedin Section9.6 forward(inputs, H=None) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
RNNLM(rnn, vocab_size, lr=0.01) Bases: RNNLMScratch(page1082) The RNN-basedlanguagemodelimplementedwithhigh-level APIs.
Definedin Section9.6 init_params() output_layer(hiddens) Definedin Section9.5 class d2l.
torch.
RNNLMScratch(rnn, vocab_size, lr=0.01) Bases: Classifier(page1075) The RNN-basedlanguagemodelimplementedfromscratch.
Definedin Section9.5 forward(X, state=None) Definedin Section9.5 init_params() one_hot(X) Definedin Section9.5 output_layer(rnn_outputs) Definedin Section9.5 predict(prefix, num_preds, vocab, device=None) Definedin Section9.5 1083 Thed2l APIDocument training_step(batch) validation_step(batch) class d2l.
torch.
RNNScratch(num_inputs, num_hiddens, sigma=0.01) Bases: Module(page1078) The RNNmodelimplementedfromscratch.
Definedin Section9.5 forward(inputs, state=None) Definedin Section9.5 class d2l.
torch.
Seq2Seq(encoder, decoder, tgt_pad, lr) Bases: Encoder Decoder(page1076) The RNNencoderâ€“decoderforsequencetosequencelearning.
Definedin Section10.7.3 configure_optimizers() Definedin Section4.3 validation_step(batch) class d2l.
torch.
Seq2Seq Encoder(vocab_size, embed_size, num_hiddens, num_layers, dropout=0) Bases: Encoder(page1076) The RNNencoderforsequence-to-sequencelearning.
Definedin Section10.7 forward(X,*args) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
SGD(params, lr) Bases: Hyper Parameters(page1077) Minibatchstochasticgradientdescent.
Definedin Section3.4 1084 Toolsfor Deep Learning step() zero_grad() class d2l.
torch.
Softmax Regression(num_outputs, lr) Bases: Classifier(page1075) Thesoftmaxregressionmodel.
Definedin Section4.5 forward(X) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Synthetic Regression Data(w, b, noise=0.01, num_train=1000, num_val=1000, batch_size=32) Bases: Data Module(page1075) Syntheticdataforlinearregression.
Definedin Section3.3 get_dataloader(train) Definedin Section3.3 class d2l.
torch.
Time Machine(batch_size, num_steps, num_train=10000, num_val=5000) Bases: Data Module(page1075) The Time Machinedataset.
Definedin Section9.2 build(raw_text, vocab=None) Definedin Section9.2 get_dataloader(train) Definedin Section9.3.3 class d2l.
torch.
Trainer(max_epochs, num_gpus=0, gradient_clip_val=0) Bases: Hyper Parameters(page1077) Thebaseclassfortrainingmodelswithdata.
1085 Thed2l APIDocument Definedin Section3.2.2 clip_gradients(grad_clip_val, model) Definedin Section9.5 fit(model, data) fit_epoch() Definedin Section3.4 prepare_batch(batch) Definedin Section6.7 prepare_data(data) prepare_model(model) Definedin Section6.7 class d2l.
torch.
Transformer Encoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, use_bias=False) Bases: Encoder(page1076) The Transformerencoder.
Definedin Section11.7.4 forward(X, valid_lens) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Transformer Encoder Block(num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias=False) Bases: Module The Transformerencoderblock.
Definedin Section11.7.2 forward(X, valid_lens) Definesthecomputationperformedateverycall.
Shouldbeoverriddenbyallsubclasses.
1086 Toolsfor Deep Learning Note: Althoughtherecipeforforwardpassneedstobedefinedwithinthisfunction, oneshouldcallthe Module(page1078)instanceafterwardsinsteadofthissincethe formertakescareofrunningtheregisteredhookswhilethelattersilentlyignoresthem.
class d2l.
torch.
Vocab(tokens=[], min_freq=0, reserved_tokens=[]) Bases: object Vocabularyfortext.
to_tokens(indices) property unk B.8.2 Functions d2l.
torch.
add_to_class(Class) Registerfunctionsasmethodsincreatedclass.
Definedin Section3.2 d2l.
torch.
bleu(pred_seq, label_seq, k) Computethe BLEU.
Definedin Section10.7.6 d2l.
torch.
check_len(a, n) Checkthelengthofalist.
Definedin Section9.5 d2l.
torch.
check_shape(a, shape) Checktheshapeofatensor.
Definedin Section9.5 d2l.
torch.
corr2d(X, K) Compute2Dcross-correlation.
Definedin Section7.2 d2l.
torch.
cpu() Getthe CPUdevice.
Definedin Section6.7 d2l.
torch.
gpu(i=0) Geta GPUdevice.
Definedin Section6.7 1087 Thed2l APIDocument d2l.
torch.
init_cnn(module) Initializeweightsfor CNNs.
Definedin Section7.6 d2l.
torch.
init_seq2seq(module) Initializeweightsforsequence-to-sequencelearning.
Definedin Section10.7 d2l.
torch.
masked_softmax(X, valid_lens) Performsoftmaxoperationbymaskingelementsonthelastaxis.
Definedin Section11.3 d2l.
torch.
num_gpus() Getthenumberofavailable GPUs.
Definedin Section6.7 d2l.
torch.
plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None, ylim=None, xscale=â€™linearâ€™, yscale=â€™linearâ€™, fmts=(â€™-â€™,â€™m--â€™,â€™g-.â€™, â€™r:â€™), figsize=(3.5,2.5), axes=None) Plotdatapoints.
Definedin Section2.4 d2l.
torch.
set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend) Settheaxesformatplotlib.
Definedin Section2.4 d2l.
torch.
set_figsize(figsize=(3.5,2.5)) Setthefiguresizeformatplotlib.
Definedin Section2.4 d2l.
torch.
show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5,2.5), cmap=â€™Redsâ€™) Showheatmapsofmatrices.
Definedin Section11.1 d2l.
torch.
show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist) Plotthehistogramforlistlengthpairs.
Definedin Section10.5 d2l.
torch.
try_all_gpus() Returnallavailable GPUs, or[cpu(),]ifno GPUexists.
Definedin Section6.7 1088 Toolsfor Deep Learning d2l.
torch.
try_gpu(i=0) Returngpu(i)ifexists, otherwisereturncpu().
Definedin Section6.7 d2l.
torch.
use_svg_display() Usethesvgformattodisplayaplotin Jupyter.
Definedin Section2.4 References Flow: asystemforlarge-scalemachinelearning.12th USENIXSymposiumon Operating Systems Designand Implementation(OSDI16)(pp.265â€“283).
volutional neural networks for speech recognition.
IEEE/ACM Transactions on Audio, Speech, and Language Processing,22(10),1533â€“1545.
inferenceinlatentvariablemodels.
Proceedingsofthe Fifth ACMInternational Confer- enceon Web Searchand Data Mining(pp.123â€“132).
hyperparameteroptimizationframework.
Proceedingsofthe25th ACMSIGKDDInter- national Conferenceon Knowledge Discovery&Data Mining.
Flamingo: avisuallanguagemodelforfew-shotlearning.
Ar Xiv:2204.14198.
Mindthe PADâ€“CNNscandevelopblindspots.
Ar Xiv:2010.02178.
Pa LM2Technical Report.
Ar Xiv:2305.10403.
optimizationfordeeplearning.
Ar Xiv:2002.09018.
Aronszajn, N.(1950).
Theoryofreproducingkernels.
Transactionsofthe American Math- ematical Society,68(3),337â€“404.
Baevski, A.,&Auli, M.(2018).
Adaptiveinputrepresentationsforneurallanguagemod- eling.
International Conferenceon Learning Representations.
Bahdanau, D., Cho, K.,&Bengio, Y.(2014).
Neuralmachinetranslationbyjointlylearning toalignandtranslate.
Ar Xiv:1409.0473.
stitutional AI: harmlessnessfrom AIfeedback.
Ar Xiv:2212.08073.
Baptista, R., & Poloczek, M.
(2018).
Bayesian optimization of combinatorial structures.
Proceedingsofthe35th International Conferenceon Machine Learning.
eter tuning.
Proceedings of the 30th International Conference on Machine Learning (ICMLâ€™13).
pean Conferenceon Computer Vision(pp.404â€“417).
1089 1090 REFERENCES Bellman, R.(1966).
Dynamicprogramming.
Science,153,34â€“37.
Bellman, R.(1952).
Onthetheoryofdynamicprogramming.
Proceedingsofthe National Academyof Sciences,38(8),716â€“719.
Bellman, R.(1957).
AMarkoviandecisionprocess.
Journalof Mathematicsand Mechan- ics,6(5),679â€“684.
URL: http://www.
jstor.
org/stable/24900506 Bellman, R.(1957).
Dynamic Programming.
Dover Publications.
former.
Ar Xiv:2004.05150.
model.
Journalof Machine Learning Research,3(Feb),1137â€“1155.
Bengio, Y., Simard, P.,&Frasconi, P.(1994).
Learninglong-termdependencieswithgra- dientdescentisdifficult.
IEEETransactionson Neural Networks,5(2),157â€“166.
optimization.
Advancesin Neural Information Processing Systems,24.
gio, Y.(2010).
Theano: a CPUand GPUmathcompilerin Python.
Proc.9th Pythonin Science Conference(pp.3â€“10).
Bayesianfiltering.
Proceedingsofthe23rd International Conferenceon World Wide Web (pp.97â€“108).
Bishop, C.
M.(1995).
Trainingwithnoiseisequivalentto Tikhonovregularization.
Neural Computation,7(1),108â€“116.
Black, F.,&Scholes, M.(1973).
Thepricingofoptionsandcorporateliabilities.
Journal of Political Economy,81,637â€“654.
detectionwithonelineofcode.
Proceedingsofthe IEEEInternational Conferenceon Computer Vision(pp.5561â€“5569).
subwordinformation.
Transactionsofthe Associationfor Computational Linguistics,5, 135â€“146.
BollobÃ¡s, B.(1999).
Linear Analysis.
Cambridge University Press.
(2021).
Ontheopportunitiesandrisksoffoundationmodels.
Ar Xiv:2108.07258.
Bottou, L.(2010).
Large-scalemachinelearningwithstochasticgradientdescent.
Proceed- ingsof COMPSTATâ€™2010(pp.177â€“186).
Springer.
Bottou, L., &Le Cun, Y.(1988).
SN: asimulatorforconnectionistmodels.
Proceedings bottou-lecun-88 Boucheron, S., Bousquet, O., & Lugosi, G.
(2005).
Theory of classification: a survey of somerecentadvances.
ESAIM: Probabilityand Statistics,9,323â€“375.
forlearningnaturallanguageinference.
Ar Xiv:1508.05326.
Boyd, S., & Vandenberghe, L.
(2004).
Convex Optimization.
Cambridge, England: Cambridge University Press.
1091 REFERENCES methodofpairedcomparisons.
Biometrika,39(3/4),324â€“345.
Brown, N.,&Sandholm, T.(2017).
Libratus: thesuperhuman AIforno-limitpoker.
IJCAI (pp.5226â€“5228).
â€¦Roossin, P.
S.(1990).
Astatisticalapproachtomachinetranslation.
Computational Linguistics,16(2),79â€“85.
&Roossin, P.(1988).
Astatisticalapproachtolanguagetranslation.
COLINGBudapest 1988Volume1: International Conferenceon Computational Linguistics.
Languagemodelsarefew-shotlearners.
Advancesin Neural Information Processing Sys- tems,33,1877â€“1901.
A.
A.
(2020).
Albumentations: Fast and flexible image augmentations.
Information, 11(2),125.
134(1-2),57â€“83.
Canny, J.(1987).
Acomputationalapproachtoedgedetection.
Readingsin Computer Vi- sion(pp.184â€“203).
Elsevier.
1: semantictextualsimilaritymultilingualandcrosslingualfocusedevaluation.
Proceed- ingsofthe11th International Workshopon Semantic Evaluation(Sem Eval-2017)(pp.1â€“ 14).
Ar Xiv:1508.01211.
Decisiontransformer: reinforcementlearningviasequencemodeling.
Advancesin Neu- ral Information Processing Systems,34,15084â€“15097.
aflexibleandefficientmachinelearninglibraryforheterogeneousdistributedsystems.
Ar Xiv:1512.01274.
Cheng, J., Dong, L.,&Lapata, M.(2016).
Longshort-termmemory-networksformachine reading.
Proceedingsofthe2016Conferenceon Empirical Methodsin Natural Language Processing(pp.551â€“561).
neuralmachinetranslation: Encoderâ€“decoderapproaches.
Ar Xiv:1409.1259.
&Bengio, Y.(2014).
Learningphraserepresentationsusing RNNencoderâ€“decoderfor statisticalmachinetranslation.
Ar Xiv:1406.1078.
Pa LM: scalinglanguagemodelingwithpathways.
Ar Xiv:2204.02311.
1092 REFERENCES currentneuralnetworksonsequencemodeling.
Ar Xiv:1412.3555.
encodersasdiscriminatorsratherthangenerators.
International Conferenceon Learning Representations.
Natural language processing (almost) from scratch.
Journal of Machine Learning Re- search,12,2493â€“2537.
attention and convolutional layers.
International Conference on Learning Representa- tions.
CsiszÃ¡r, I.
(2008).
Axiomatic characterizations of information measures.
Entropy, 10(3), 261â€“273.
Cybenko, G.(1989).
Approximationbysuperpositionsofasigmoidalfunction.
Mathemat- icsof Control, Signalsand Systems,2(4),303â€“314.
Dalal, N., & Triggs, B.
(2005).
Histograms of oriented gradients for human detection.
2005IEEEComputer Society Conferenceon Computer Visionand Pattern Recognition (CVPRâ€™05)(pp.886â€“893).
De Cock, D.
(2011).
Ames, Iowa: alternative to the Boston housing data as an end of semesterregressionproject.
Journalof Statistics Education,19(3).
scale distributed deep networks.
Proceedings of the 25th International Conference on Neural Information Processing Systems, Volume1(pp.1223â€“1231).
Vogels, W.(2007).
Dynamo: Amazonâ€™shighlyavailablekey-valuestore.
ACMSIGOPS Operating Systems Review(pp.205â€“220).
scalehierarchicalimagedatabase.2009IEEEConferenceon Computer Visionand Pat- tern Recognition(pp.248â€“255).
Der Kiureghian, A.,&Ditlevsen, O.(2009).
Aleatoryorepistemic? doesitmatter? Struc- tural Safety,31(2),105â€“112.
bidirectionaltransformersforlanguageunderstanding.
Ar Xiv:1810.04805.
Dinh, L., Krueger, D., & Bengio, Y.
(2014).
NICE: non-linear independent components estimation.
Ar Xiv:1410.8516.
ternational Conferenceon Learning Representations.
bycontextprediction.
Proceedingsofthe IEEEInternational Conferenceon Computer Vision(pp.1422â€“1430).
etal.(2021).
Animageisworth16x16words: transformersforimagerecognitionat scale.
International Conferenceon Learning Representations.
1093 REFERENCES Duchi, J., Hazan, E.,&Singer, Y.(2011).
Adaptivesubgradientmethodsforonlinelearning andstochasticoptimization.
Journalof Machine Learning Research,12,2121â€“2159.
Dumoulin, V., & Visin, F.
(2016).
A guide to convolution arithmetic for deep learning.
Ar Xiv:1603.07285.
Ar Xiv:2012.09699.
servingstatisticalvalidityinadaptivedataanalysis.
Proceedingsofthe47th Annual ACM Symposiumon Theoryof Computing(pp.117â€“126).
Ar Xiv:1808.05377[stat.
ML].
Fedus, W., Zoph, B.,&Shazeer, N.(2022).
Switchtransformers: scalingtotrillionparam- etermodelswithsimpleandefficientsparsity.
Journalof Machine Learning Research, 23(120),1â€“39.
Fernando, R.(2004).
GPUGems: Programming Techniques, Tips, and Tricksfor Real-Time Graphics.
Addison-Wesley.
Feurer, M.,&Hutter, F.(2018).
Hyperparameterptimization.
Automatic Machine Learn- ing: Methods, Systems, Challenges.
Springer.
Bayesianoptimization.
Ar Xiv:1802.02219[stat.
ML].
Field, D.
J.
(1987).
Relations between the statistics of natural images and the response propertiesofcorticalcells.
JOSAA,4(12),2379â€“2394.
Flammarion, N.,&Bach, F.(2015).
Fromaveragingtoacceleration, thereisonlyastep- size.
Conferenceon Learning Theory(pp.658â€“695).
gatemodelling.
Proceedingsofthe Royal Society A: Mathematical, Physicaland Engi- neering Sciences,463(2088),3251â€“3269.
based hyperparameter optimization.
Proceedings of the 34th International Conference on Machine Learning(ICMLâ€™17).
Frankle, J., & Carbin, M.
(2018).
The lottery ticket hypothesis: finding sparse, trainable neuralnetworks.
Ar Xiv:1803.03635.
ceedingsofthe International Conferenceon Machine Learning(pp.148â€“156).
Friedman, J.
H.(1987).
Exploratoryprojectionpursuit.
Journalofthe American Statistical Association,82(397),249â€“266.
high-leveltracing.
Proceedingsof Systemsfor Machine Learning.
Fukushima, K.
(1982).
Neocognitron: a self-organizing neural network model for a mechanismofvisualpatternrecognition.
Competitionand Cooperationin Neural Nets (pp.267â€“285).
Springer.
1094 REFERENCES blackbox matrixâ€“matrix Gaussian process inference with GPU acceleration.
Advances in Neural Information Processing Systems.
beleddatatoguaranteegeneralization.
International Conferenceon Machine Learning (pp.3598â€“3609).
neuralnetworks.
Proceedingsofthe IEEEConferenceon Computer Visionand Pattern Recognition(pp.2414â€“2423).
Akademieder Wissenschaften.
Ginibre, J.(1965).
Statisticalensemblesofcomplex, quaternion, andrealmatrices.
Journal of Mathematical Physics,6(3),440â€“449.
Girshick, R.
(2015).
Fast R-CNN.
Proceedings of the IEEE International Conference on Computer Vision(pp.1440â€“1448).
curateobjectdetectionandsemanticsegmentation.
Proceedingsofthe IEEEConference on Computer Visionand Pattern Recognition(pp.580â€“587).
Glorot, X.,&Bengio, Y.(2010).
Understandingthedifficultyoftrainingdeepfeedforward neuralnetworks.
Proceedingsofthe13th International Conferenceon Artificial Intelli- genceand Statistics(pp.249â€“256).
momentum weaveaninformationtapestry.
Communicationsofthe ACM,35(12),61â€“71.
Press.
deeplearningbook.
org.
gio, Y.(2014).
Generativeadversarialnets.
Advancesin Neural Information Processing Systems(pp.2672â€“2680).
heuristics: learningraterestarts, warmupanddistillation.
Ar Xiv:1810.13243.
Ar Xiv:2110.07641.
(2008).
Anovelconnectionistsystemforunconstrainedhandwritingrecognition.
IEEE Transactionson Pattern Analysisand Machine Intelligence,31(5),855â€“868.
Graves, A.,&Schmidhuber, J.(2005).
Framewisephonemeclassificationwithbidirectional LSTMandotherneuralnetworkarchitectures.
Neural Networks,18(5-6),602â€“610.
1095 REFERENCES Griewank, A.
(1989).
On automatic differentiation.
Mathematical Programming: Recent Developmentsand Applications(pp.83â€“107).
Kluwer.
former: convolution-augmented transformer for speech recognition.
Proc.
Interspeech 2020, pp.5036â€“5040.
tionsand Applications.
Springer.
multi-devicedeeplearningon CPUsand GPUs.
Ar Xiv:1606.04487.
Hartley, R., & Zisserman, A.
(2000).
Multiple View Geometry in Computer Vision.
Cambridge University Press.
national Journalof Computer Vision,82(1),64â€“79.
scalablevisionlearners.
Proceedingsofthe IEEE/CVFConferenceon Computer Vision and Pattern Recognition(pp.16000â€“16009).
IEEEInternational Conferenceon Computer Vision(pp.2961â€“2969).
human-levelperformanceon Image Netclassification.
Proceedingsofthe IEEEInterna- tional Conferenceon Computer Vision(pp.1026â€“1034).
tion.
Proceedingsofthe IEEEConferenceon Computer Visionand Pattern Recognition (pp.770â€“778).
European Conferenceon Computer Vision(pp.630â€“645).
Hendrycks, D., & Gimpel, K.
(2016).
Gaussian error linear units (GELUs).
Ar Xiv:1606.08415.
proach.
Elsevier.
in Neural Information Processing Systems,33,6840â€“6851.
rentnets: thedifficultyoflearninglong-termdependencies.
AField Guideto Dynamical Recurrent Neural Networks.
IEEEPress.
Hochreiter, S.,&Schmidhuber, J.(1997).
Longshort-termmemory.
Neural Computation, 9(8),1735â€“1780.
(2022).
Trainingcompute-optimallargelanguagemodels.
Ar Xiv:2203.15556.
Searchingfor Mobile Net V3.
Proceedingsofthe IEEE/CVFInternational Conferenceon Computer Vision(pp.1314â€“1324).
1096 REFERENCES discoverywithadditivenoisemodels.
Advancesin Neural Information Processing Sys- tems(pp.689â€“696).
IEEEConferenceon Computer Visionand Pattern Recognition(pp.7132â€“7141).
Hu, Y., Koren, Y., & Volinsky, C.
(2008).
Collaborative filtering for implicit feedback datasets.20088th IEEEInternational Conferenceon Data Mining(pp.263â€“272).
1145/3544903.3544906 D.(2018).
Musictransformer: generatingmusicwithlong-termstructure.
International Conferenceon Learning Representations.
convolutionalnetworks.
Proceedingsofthe IEEEConferenceon Computer Visionand Pattern Recognition(pp.4700â€“4708).
Huang, Z., Xu, W.,&Yu, K.(2015).
Bidirectional LSTMâ€“CRFmodelsforsequencetag- ging.
Ar Xiv:1508.01991.
cortex.
Journalof Physiology,148(3),574â€“591.
architectureinthecatâ€™svisualcortex.
Journalof Physiology,160(1),106â€“154.
keystriatecortex.
Journalof Physiology,195(1),215â€“243.
Hutter, F., Hoos, H.,&Leyton-Brown, K.(2011).
Sequentialmodel-basedoptimizationfor general algorithm configuration.
Proceedings of the Fifth International Conference on Learningand Intelligent Optimization(LIONâ€™11).
Methods, Systems, Challenges.
Springer.
Ioffe, S.(2017).
Batchrenormalization: towardsreducingminibatchdependenceinbatch- normalized models.
Advances in Neural Information Processing Systems (pp.
1945â€“ 1953).
Ioffe, S.,&Szegedy, C.(2015).
Batchnormalization: acceleratingdeepnetworktraining byreducinginternalcovariateshift.
Ar Xiv:1502.03167.
weightsleadstowideroptimaandbettergeneralization.
Ar Xiv:1803.05407.
Jacot, A., Gabriel, F.,&Hongler, C.(2018).
Neuraltangentkernel: convergenceandgen- eralizationinneuralnetworks.
Advancesin Neural Information Processing Systems.
Jaeger, H.(2002).
Tutorialontrainingrecurrentneuralnetworks, covering BPPT, RTRL, EKF and the â€œecho state networkâ€ approach.
GMD-Forschungszentrum Information- stechnik Bonn.
Jamieson, K., & Talwalkar, A.
(2016).
Non-stochastic best arm identification and hyper- parameteroptimization.
Proceedingsofthe17th International Conferenceon Artificial Intelligenceand Statistics.
1097 REFERENCES withtree-structureddependencies.
Proceedingsofthe34th International Conferenceon Machine Learning(ICMLâ€™17).
deeplearningtrainingsystemwithmixed-precision: training Image Netinfourminutes.
Ar Xiv:1807.11205.
(2014).
Caffe: convolutionalarchitectureforfastfeatureembedding.
Proceedingsofthe 22nd ACMInternational Conferenceon Multimedia(pp.675â€“678).
improvingpre-trainingbyrepresentingandpredictingspans.
Transactionsofthe Asso- ciationfor Computational Linguistics,8,64â€“77.
In-datacenter performance analysis of a tensor processing unit.
2017 ACM/IEEE 44th Annual International Symposiumon Computer Architecture(ISCA)(pp.1â€“12).
Kalchbrenner, N., Grefenstette, E.,&Blunsom, P.(2014).
Aconvolutionalneuralnetwork formodellingsentences.
Ar Xiv:1404.2188.
ceedingsofthe International Joint Conferenceon Neural Networks(IJCNN)(pp.578â€“ 581).
Karnin, Z., Koren, T., & Somekh, O.
(2013).
Almost optimal exploration in multi- armedbandits.
Proceedingsofthe30th International Conferenceon Machine Learning (ICMLâ€™13).
improvedquality, stability, andvariation.
Ar Xiv:1710.10196.
Kim, J., El-Khamy, M., & Lee, J.
(2017).
Residual LSTM: design of a deep recurrent architecturefordistantspeechrecognition.
Ar Xiv:1701.03360.
Kim, Y.
(2014).
Convolutional neural networks for sentence classification.
Ar Xiv:1408.5882.
Ar Xiv:1412.6980.
ferenceon Learning Representations(ICLR).
Kipf, T.
N.,&Welling, M.(2016).
Semi-supervisedclassificationwithgraphconvolutional networks.
Ar Xiv:1609.02907.
arezero-shotreasoners.
arxiv.
org/abs/2205.11916.
Koller, D.,&Friedman, N.(2009).
Probabilistic Graphical Models: Principlesand Tech- niques.
MITPress.
Kolmogorov, A.(1933).
Sulladeterminazioneempiricadiunaleggedidistribuzione.
Inst.
Ital.
Attuari, Giorn.,4,83â€“91.
1098 REFERENCES Kolter, Z.
(2008).
Linear algebra review and reference.
Available online: http://cs229.
stanford.
edu/section/cs229-linalg.
pdf.
convolutional neural networks.
Advances in Neural Information Processing Systems (pp.1097â€“1105).
(2018).
Activationsofdeepconvolutionalneuralnetworksarealignedwithgammaband activityofhumanvisualcortex.
Communications Biology,1(1),1â€“12.
alite BERTforself-supervisedlearningoflanguagerepresentations.
Ar Xiv:1909.11942.
Lavin, A.,&Gray, S.(2016).
Fastalgorithmsforconvolutionalneuralnetworks.
Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition (pp.
4013â€“ 4021).
Le, Q.
V.(2013).
Buildinghigh-levelfeaturesusinglargescaleunsupervisedlearning.
Pro- ceedingsofthe IEEEInternational Conferenceon Acoustics, Speechand Signal Process- ing(pp.8595â€“8598).
Le Cun, Y., Bengio, Y., & et al.
(1995).
Convolutional networks for images, speech, and timeseries.
The Handbookof Brain Theoryand Neural Networks(p.3361).
MITPress.
L.
D.(1989).
Backpropagationappliedtohandwrittenzipcoderecognition.
Neural Com- putation,1(4),541â€“551.
works: Tricksofthe Trade.
Springer.
todocumentrecognition.
Proceedingsofthe IEEE,86(11),2278â€“2324.
parisonoflearningalgorithmsforhandwrittendigitrecognition.
International Confer- enceon Artificial Neural Networks(pp.53â€“60).
Legendre, A.
M.(1805).
MÃ©moiresurles OpÃ©rations TrigonomÃ©triques: dontles RÃ©sultats DÃ©pendentdela Figuredela Terre.
F.
Didot.
L.(2019).
BART: denoisingsequence-to-sequencepre-trainingfornaturallanguagegen- eration, translation, andcomprehension.
Ar Xiv:1910.13461.
V., â€¦ et al.
(2022).
Solving quantitative reasoning problems with language models.
Ar Xiv:2206.14858.
(2018).
Massivelyparallelhyperparametertuning.
Ar Xiv:1810.05934.
Li, M.(2017).
Scaling Distributed Machine Learningwith Systemand Algorithm Co-design (Doctoraldissertation).
Ph DThesis, CMU.
(2014).
Scalingdistributedmachinelearningwiththeparameterserver.11th Symposium on Operating Systems Designand Implementation(OSDI14)(pp.583â€“598).
1099 REFERENCES stochastic optimization.
Proceedings of the 20th ACM SIGKDD International Confer- enceon Knowledge Discoveryand Data Mining(pp.661â€“670).
researchplatformfordistributedmodelselectionandtraining.
Ar Xiv:1807.05118.
ject detection.
Proceedings of the IEEE International Conference on Computer Vision (pp.2980â€“2988).
cation: fastdescriptorcodingandlarge-scale SVMtraining.
Large Scale Visual Recog- nition Challenge.
structuredself-attentivesentenceembedding.
Ar Xiv:1703.03130.
networksforsequencelearning.
Ar Xiv:1506.00019.
LSTM recurrent neural networks.
International Conference on Learning Representa- tions(ICLR).
Communicationsofthe ACM,17,45â€“77.
Liu, D.
C., & Nocedal, J.
(1989).
On the limited memory BFGS method for large scale optimization.
Mathematical Programming,45(1),503â€“528.
Ar Xiv:1806.09055.
SSD: singleshotmultiboxdetector.
European Conferenceon Computer Vision(pp.21â€“ 37).
arobustlyoptimized BERTpretrainingapproach.
Ar Xiv:1907.11692.
hierarchical vision transformer using shifted windows.
Proceedings of the IEEE/CVF International Conferenceon Computer Vision(pp.10012â€“10022).
forthe2020s.
Ar Xiv:2201.03545.
Long, J., Shelhamer, E., &Darrell, T.(2015).
Fullyconvolutionalnetworksforsemantic segmentation.
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(pp.3431â€“3440).
Loshchilov, I.,&Hutter, F.(2016).
SGDR: stochasticgradientdescentwithwarmrestarts.
Ar Xiv:1608.03983.
Lowe, D.
G.
(2004).
Distinctive image features from scale-invariant keypoints.
Interna- tional Journalof Computer Vision,60(2),91â€“110.
batchnormalization.
Ar Xiv:1809.00846.
1100 REFERENCES ingwordvectorsforsentimentanalysis.
Proceedingsofthe49th Annual Meetingofthe Associationfor Computational Linguistics: Human Language Technologies, Volume1 (pp.142â€“150).
regressionestimates.
ZeitschriftfÃ¼r Wahrscheinlichkeitstheorieundverwandte Gebiete, 61(3),405â€“415.
Mac Kay, D.
J.(2003).
Information Theory, Inferenceand Learning Algorithms.
Cambridge University Press.
Maclaurin, D., Duvenaud, D.,&Adams, R.(2015).
Gradient-basedhyperparameteropti- mizationthroughreversiblelearning.
Proceedingsofthe32nd International Conference on Machine Learning(ICMLâ€™15).
Mangasarian, O.
L.(1965).
Linearandnonlinearseparationofpatternsbylinearprogram- ming.
Oper.
Res.,13,444-452.
Mangram, M.
E.(2013).
Asimplifiedperspectiveofthe Markowitzportfoliotheory.
Global Journalof Business Research,7(1),59â€“70.
Gaussianprocessbehaviourinwidedeepneuralnetworks.
Ar Xiv:1804.11271.
tualizedwordvectors.
Advancesin Neural Information Processing Systems(pp.6294â€“ 6305).
Mc Culloch, W.
S.,&Pitts, W.(1943).
Alogicalcalculusoftheideasimmanentinnervous activity.
Bulletinof Mathematical Biophysics,5(4),115â€“133.
Mead, C.(1980).
Introductionto VLSIsystems.
IEEProceedings I-Solid-Stateand Elec- tron Devices,128(1),18.
Ar Xiv:1609.07843.
Micchelli, C.
A.(1984).
Interpolationofscattereddata: distancematricesandconditionally positivedefinitefunctions.
Approximation Theoryand Spline Functions(pp.143â€“145).
Springer.
sentationsinvectorspace.
Ar Xiv:1301.3781.
resentationsofwordsandphrasesandtheircompositionality.
Advancesin Neural Infor- mation Processing Systems(pp.3111â€“3119).
Miller, G.
A.(1995).
Word Net: alexicaldatabasefor English.
Communicationsofthe ACM, 38(11),39â€“41.
Device placement optimization with reinforcement learning.
Proceedings of the 34th International Conferenceon Machine Learning(pp.2430â€“2439).
Advancesin Neural Information Processing Systems(pp.2204â€“2212).
1101 REFERENCES (2015).
Human-level control through deep reinforcement learning.
Nature, 518(7540), 529â€“533.
listwiseandpairwiseconstraints.
Proceedingsofthe3rd ACMInternational Conference on Web Searchand Data Mining(pp.151â€“160).
fallacyofplacingconfidenceinconfidenceintervals.
Psychonomic Bulletin&Review, 23(1),103â€“123.
Nadaraya, E.
A.(1964).
Onestimatingregression.
Theoryof Probability&its Applications, 9(1),141â€“142.
Nair, V.,&Hinton, G.
E.(2010).
Rectifiedlinearunitsimproverestricted Boltzmannma- chines.
ICML.
bledescent: wherebiggermodelsandmoredatahurt.
Journalof Statistical Mechanics: Theoryand Experiment,2021(12),124003.
Naor, M., & Reingold, O.
(1999).
On the construction of pseudorandom permutations: Lubyâ€“Rackoffrevisited.
Journalof Cryptology,12(1),29â€“66.
Nesterov, Y.(2018).
Lectureson Convex Optimization.
Springer.
Automatica,44(6),1559â€“1568.
Neyman, J.(1937).
Outlineofatheoryofstatisticalestimationbasedontheclassicalthe- oryofprobability.
Philosophical Transactionsofthe Royal Societyof London.
Series A, Mathematicaland Physical Sciences,236(767),333â€“380.
(2022).
ASIF: coupled data turns unimodal models to multimodal without training.
Ar Xiv:2210.01738.
Bayesian deep convolutional networks with many channels are Gaussian processes.
Ar Xiv:1810.05148.
posiumonthe Mathematical Theoryof Automata(pp.615â€“622).
bylearningasparsecodefornaturalimages.
Nature,381(6583),607â€“609.
Journalof Machine Learning Research,6,1043â€“1071.
et al.
(2022).
Training language models to follow instructions with human feedback.
Ar Xiv:2203.02155.
evaluationofmachinetranslation.
Proceedingsofthe40th Annual Meetingofthe Asso- ciationfor Computational Linguistics(pp.311â€“318).
1102 REFERENCES modelfornaturallanguageinference.
Ar Xiv:1606.01933.
spatially-adaptivenormalization.
Proceedingsofthe IEEEConferenceon Computer Vi- sionand Pattern Recognition(pp.2337â€“2346).
Parzen, E.(1957).
Onconsistentestimatesofthespectrumofastationarytimeseries.
An- nalsof Mathematical Statistics,28,329â€“348.
Torch: animperativestyle, high-performancedeeplearninglibrary.
Advancesin Neural Information Processing Systems,32,8026â€“8037.
Paulus, R., Xiong, C.,&Socher, R.(2017).
Adeepreinforcedmodelforabstractivesum- marization.
Ar Xiv:1705.04304.
J.(2023).
The Refined Webdatasetfor Falcon LLM: outperformingcuratedcorporawith webdata, andwebdataonly.
Ar Xiv:2306.01116.
Pennington, J., Schoenholz, S., & Ganguli, S.
(2017).
Resurrecting the sigmoid in deep learningthroughdynamicalisometry: theoryandpractice.
Advancesin Neural Informa- tion Processing Systems(pp.4785â€“4795).
Pennington, J., Socher, R.,&Manning, C.(2014).
Glo Ve: globalvectorsforwordrepresen- tation.
Proceedingsofthe2014Conferenceon Empirical Methodsin Natural Language Processing(EMNLP)(pp.1532â€“1543).
Peters, J., Janzing, D.,&SchÃ¶lkopf, B.(2017).
Elementsof Causal Inference: Foundations and Learning Algorithms.
MITPress.
taggingwithbidirectionallanguagemodels.
Proceedingsofthe55th Annual Meetingof the Associationfor Computational Linguistics, Volume1(pp.1756â€“1765).
(2018).
Deepcontextualizedwordrepresentations.
Proceedingsofthe2018Conference ofthe North American Chapterofthe Associationfor Computational Linguistics: Human Language Technologies, Volume1(pp.2227â€“2237).
Denmark.
Memory-efficientimplementationofdensenets.
Ar Xiv:1707.06990.
Polyak, B.
T.(1964).
Somemethodsofspeedinguptheconvergenceofiterationmethods.
USSRComputational Mathematicsand Mathematical Physics,4(5),1â€“17.
paraphrasegenerationwithstackedresidual LSTMnetworks.
Ar Xiv:1610.03098.
general-purposenaturallanguageprocessingtasksolver? Ar Xiv:2302.06476.
Quadrana, M., Cremonesi, P., & Jannach, D.
(2018).
Sequence-aware recommender sys- tems.
ACMComputing Surveys,51(4),66.
1103 REFERENCES Learning transferable visual models from natural language supervision.
International Conferenceon Machine Learning(pp.8748â€“8763).
Radford, A., Metz, L., & Chintala, S.
(2015).
Unsupervised representation learning with deepconvolutionalgenerativeadversarialnetworks.
Ar Xiv:1511.06434.
understandingbygenerativepre-training.
Open AI.
modelsareunsupervisedmultitasklearners.
Open AIBlog,1(8),9.
spaces for visual recognition.
Proceedings of the IEEE/CVF International Conference on Computer Vision(pp.1882â€“1890).
workdesignspaces.
Proceedingsofthe IEEE/CVFConferenceon Computer Visionand Pattern Recognition(pp.10428â€“10436).
(2021).
Scaling language models: methods, analysis & insights from training gopher.
Ar Xiv:2112.11446.
Exploringthelimitsoftransferlearningwithaunifiedtext-to-texttransformer.
Journal of Machine Learning Research,21,1â€“67.
machinecomprehensionoftext.
Ar Xiv:1606.05250.
Stand-aloneself-attentioninvisionmodels.
Advancesin Neural Information Processing Systems,32.
Ar Xiv:1710.05941.
conditionalimagegenerationwithcliplatents.
Ar Xiv:2204.06125.
RamÃ³ny Cajal, Santiago, &Azoulay, L.(1894).
Les Nouvelles IdÃ©essurla Structuredu SystÃ¨me Nerveuxchezlâ€™Hommeetchezles VertÃ©brÃ©s.
Paris, C.
Reinwald&Cie.
frameworkforunsupervisedlearning.
Artificial Intelligenceand Statistics(pp.371â€“379).
MITPress.
Ar Xiv:1904.09237.
real-timeobjectdetection.
Proceedingsofthe IEEEConferenceon Computer Visionand Pattern Recognition(pp.779â€“788).
Redmon, J., & Farhadi, A.
(2018).
YOLOv3: an incremental improvement.
Ar Xiv:1804.02767.
1104 REFERENCES detection with region proposal networks.
Advances in Neural Information Processing Systems(pp.91â€“99).
Revels, J., Lubin, M.,&Papamarkou, T.(2016).
Forward-modeautomaticdifferentiation in Julia.
Ar Xiv:1607.07892.
proximate inference in deep generative models.
International Conference on Machine Learning(pp.1278â€“1286).
Riesenhuber, M.,&Poggio, T.(1999).
Hierarchicalmodelsofobjectrecognitionincortex.
Nature Neuroscience,2(11),1019â€“1025.
labelnoise.
Ar Xiv:1705.10694.
Rudin, W.(1973).
Functional Analysis.
Mc Graw-Hill.
back-propagatingerrors.
Cognitive Modeling,5(3),1.
dostozucchinis: whathavewedone, andwherearewegoing? International Conference on Computer Vision(ICCV).
ge Netlargescalevisualrecognitionchallenge.
International Journalof Computer Vision, 115(3),211â€“252.
Education Limited.
Photorealistic text-to-image diffusion models with deep language understanding.
Ar Xiv:2205.11487.
Syne Tune: a library for large scale hyperparameter tuning and reproducible research.
First Conferenceon Automated Machine Learning.
BERT: smaller, faster, cheaperandlighter.
Ar Xiv:1910.01108.
Multitaskpromptedtrainingenableszero-shottaskgeneralization.
Ar Xiv:2110.08207.
tionhelpoptimization? Advancesin Neural Information Processing Systems(pp.2483â€“ 2493).
filteringrecommendationalgorithms.
Proceedingsof10th International Conferenceon World Wide Web(pp.285â€“295).
a176B-parameteropen-accessmultilinguallanguagemodel.
Ar Xiv:2211.05100.
1105 REFERENCES cold-startrecommendations.
Proceedingsofthe25th Annual International ACMSIGIR Conferenceon Researchand Developmentin Information Retrieval(pp.253â€“260).
(2022).
LAION-5B: anopenlarge-scaledatasetfortrainingnextgenerationimage-text models.
Ar Xiv:2210.08402.
actionson Signal Processing,45(11),2673â€“2681.
(Eds.).
A generalized representer theorem.
Proceedings of the Annual Conference on Computational Learning Theory(pp.416â€“426).
Springer-Verlag.
SchÃ¶lkopf, B., Burges, C.,&Vapnik, V.(1996).
Incorporatinginvariancesinsupportvector learningmachines.
International Conferenceon Artificial Neural Networks(pp.47â€“52).
SchÃ¶lkopf, B.,&Smola, A.
J.(2002).
Learningwith Kernels: Support Vector Machines, Regularization, Optimization, and Beyond.
MITPress.
Sennrich, R., Haddow, B., & Birch, A.
(2015).
Neural machinetranslation of rare words withsubwordunits.
Ar Xiv:1508.07909.
Sergeev, A.,&Del Balso, M.(2018).
Horovod: fastandeasydistributeddeeplearningin Tensor Flow.
Ar Xiv:1802.05799.
Shannon, C.
E.(1948).
Amathematicaltheoryofcommunication.
The Bell System Techni- cal Journal,27(3),379â€“423.
trol VAE: controllable variational autoencoder.
Proceedings of the 37th International Conferenceon Machine Learning.
Shaw, P., Uszkoreit, J.,&Vaswani, A.(2018).
Self-attentionwithrelativepositionrepre- sentations.
Ar Xiv:1803.02155.
Megatron-LM: training multi-billion parameter language models using model paral- lelism.
Ar Xiv:1909.08053.
(2016).
Mastering the game of Go with deep neural networks and tree search.
Nature, 529(7587),484.
Silverman, B.
W.(1986).
Density Estimationfor Statisticaland Data Analysis.
Chapman and Hall.
anceinpatternrecognitionâ€“tangentdistanceandtangentpropagation.
Neural Networks: Tricksofthe Trade(pp.239â€“274).
Springer.
Simonyan, K.,&Zisserman, A.(2014).
Verydeepconvolutionalnetworksforlarge-scale imagerecognition.
Ar Xiv:1409.1556.
footprintdeeplearning.
Ar Xiv:1510.01722.
Sivic, J.,&Zisserman, A.(2003).
Video Google: atextretrievalapproachtoobjectmatch- ing in videos.
Proceedings of the IEEE International Conference on Computer Vision (pp.1470â€“1470).
1106 REFERENCES (2022).
Using Deep Speedand Megatrontotrain Megatron-Turing NLG530B, alarge- scalegenerativelanguagemodel.
Ar Xiv:2201.11990.
Smola, A., &Narayanamurthy, S.(2010).
Anarchitectureforparalleltopicmodels.
Pro- ceedingsofthe VLDBEndowment,3(1-2),703â€“710.
Snoek, J., Larochelle, H.,&Adams, R.(2012).
Practical Bayesianoptimizationofmachine learningalgorithms.
Advancesin Neural Information Processing Systems25(pp.2951â€“ 2959).
pervisedlearningusingnonequilibriumthermodynamics.
International Conferenceon Machine Learning(pp.2256â€“2265).
Song, Y., & Ermon, S.
(2019).
Generative modeling by estimating gradients of the data distribution.
Advancesin Neural Information Processing Systems,32.
Score-basedgenerativemodelingthroughstochasticdifferentialequations.
International Conferenceon Learning Representations.
Speelpenning, B.
(1980).
Compiling fast partial derivatives of functions given by algo- rithms(Doctoraldissertation).
Universityof Illinoisat Urbana-Champaign.
Beyondtheimitationgame: quantifyingandextrapolatingthecapabilitiesoflanguage models.
Ar Xiv:2206.04615.
Dropout: asimplewaytopreventneuralnetworksfromoverfitting.
Journalof Machine Learning Research,15(1),1929â€“1958.
Ar Xiv:1505.00387.
Strang, G.(1993).
Introductionto Linear Algebra.
Wellesleyâ€“Cambridge Press.
vancesin Artificial Intelligence,2009.
in Neural Information Processing Systems(pp.2440â€“2448).
tion and momentum in deep learning.
International Conference on Machine Learning (pp.1139â€“1147).
networks.
Advancesin Neural Information Processing Systems(pp.3104â€“3112).
Res Net and the impact of residual connections on learning.
31st AAAI Conference on Artificial Intelligence.
(2015).
Goingdeeperwithconvolutions.
Proceedingsofthe IEEEConferenceon Com- puter Visionand Pattern Recognition(pp.1â€“9).
tionarchitectureforcomputervision.
Proceedingsofthe IEEEConferenceon Computer Visionand Pattern Recognition(pp.2818â€“2826).
1107 REFERENCES Tallec, C., & Ollivier, Y.
(2017).
Unbiasing truncated backpropagation through time.
Ar Xiv:1705.08209.
Tan, M.,&Le, Q.(2019).
Efficient Net: rethinkingmodelscalingforconvolutionalneural networks.
International Conferenceon Machine Learning(pp.6105â€“6114).
Neural Information Processing Systems,16,25.
Ar Xiv:2009.06732.
(2022).
Galactica: alargelanguagemodelforscience.
Ar Xiv:2211.09085.
Teye, M., Azizpour, H., & Smith, K.
(2018).
Bayesian uncertainty estimation for batch normalizeddeepnetworks.
Ar Xiv:1802.06455.
(2016).
Yfcc100m: thenewdatainmultimediaresearch.
Communicationsofthe ACM, 59(2),64â€“73.
Tieleman, T.,&Hinton, G.(2012).
Dividethegradientbyarunningaverageofitsrecent magnitude.
COURSERA: Neural Networksfor Machine Learning, Lecture6.5-rmsprop.
(2021).
MLP-mixer: anall-MLParchitectureforvision.
Advancesin Neural Information Processing Systems,34.
fornonparametricobjectandscenerecognition.
IEEETransactionson Pattern Analysis and Machine Intelligence,30(11),1958â€“1970.
ingdata-efficientimagetransformers&distillationthroughattention.
International Con- ferenceon Machine Learning(pp.10347â€“10357).
(2023a).
LLa MA: openandefficientfoundationlanguagemodels.
Ar Xiv:2302.13971.
LLa MA2: openfoundationandfine-tunedchatmodels.
Ar Xiv:2307.09288.
Tsoumakas, G.,&Katakis, I.(2007).
Multi-labelclassification: anoverview.
International Journalof Data Warehousingand Mining,3(3),1â€“13.
Turing, A.(1950).
Computingmachineryandintelligence.
Mind,59(236),433.
search for object recognition.
International Journal of Computer Vision, 104(2), 154â€“ 171.
Vapnik, V.(1995).
The Natureof Statistical Learning Theory.
New York: Springer.
Vapnik, V.(1998).
Statistical Learning Theory.
New York: John Wileyand Sons.
Vapnik, V., & Chervonenkis, A.
(1964).
A note on one class of perceptrons.
Automation and Remote Control,25.
Vapnik, V.,&Chervonenkis, A.(1968).
Uniformconvergenceoffrequenciesofoccurence ofeventstotheirprobabilities.
Dokl.
Akad.
Nauk SSSR,181,915-918.
Vapnik, V.,&Chervonenkis, A.(1971).
Ontheuniformconvergenceofrelativefrequencies ofeventstotheirprobabilities.
Theory Probab.
Appl.,16(2),264-281.
1108 REFERENCES Vapnik, V., & Chervonenkis, A.
(1981).
The necessary and sufficient conditions for the uniform convergence of averages to their expected values.
Teoriya Veroyatnostei i Ee Primeneniya,26(3),543-564.
Vapnik, V.,&Chervonenkis, A.(1991).
Thenecessaryandsufficientconditionsforconsis- tencyintheempiricalriskminimizationmethod.
Pattern Recognitionand Image Anal- ysis,1(3),283-305.
Remote Control,35,1226â€“1235,1403â€“1412.
Vapnik, V.(1992).
Principlesofriskminimizationforlearningtheory.
Advancesin Neural Information Processing Systems(pp.831â€“838).
Vapnik, V., Levin, E., & Le Cun, Y.
(1994).
Measuring the VC-dimension of a learning machine.
Neural Computation,6(5),851â€“876.
I.(2017).
Attentionisallyouneed.
Advancesin Neural Information Processing Systems (pp.5998â€“6008).
Wahba, G.(1990).
Spline Modelsfor Observational Data.
SIAM.
nitionusingtime-delayneuralnetworks.
IEEETransactionson Acoustics, Speech, and Signal Processing,37(3),328â€“339.
malization boosts adversarial training.
International Conference on Machine Learning (pp.23433â€“23445).
aggregation.
Networks,2(3),2â€“3.
transformermodelsformachinetranslation.
Proceedingsofthe57th Annual Meetingof the Associationfor Computational Linguistics(pp.1810â€“1822).
improveschainofthoughtreasoninginlanguagemodels.
International Conferenceon Learning Representations.
high-performancegraphprocessinglibraryonthe GPU.
ACMSIGPLANNotices(p.11).
Transactionsofthe Associationfor Computational Linguistics,7,625â€“641.
Wasserman, L.(2013).
Allof Statistics: AConcise Coursein Statistical Inference.
Springer.
Watson, G.
S.(1964).
Smoothregressionanalysis.
SankhyÄ: The Indian Journalof Statis- tics, Series A, pp.359â€“372.
Finetunedlanguagemodelsarezero-shotlearners.
Ar Xiv:2109.01652.
gentabilitiesoflargelanguagemodels.
Ar Xiv:2206.07682.
ofthoughtpromptingelicitsreasoninginlargelanguagemodels.
Ar Xiv:2201.11903.
1109 REFERENCES Welling, M.,&Teh, Y.
W.(2011).
Bayesianlearningviastochasticgradient Langevindy- namics.
Proceedingsofthe28th International Conferenceon Machine Learning(ICML- 11)(pp.681â€“688).
Wengert, R.
E.(1964).
Asimpleautomaticderivativeevaluationprogram.
Communications ofthe ACM,7(8),463â€“464.
Werbos, P.
J.(1990).
Backpropagationthroughtime: whatitdoesandhowtodoit.
Pro- ceedingsofthe IEEE,78(10),1550â€“1560.
Math.(pp.325â€“327).
Wilson, A.
G.,&Izmailov, P.(2020).
Bayesiandeeplearningandaprobabilisticperspective ofgeneralization.
Advancesin Neural Information Processing Systems,33,4697â€“4708.
Ar Xiv:1905.01392[cs.
LG].
Wistuba, M., Schilling, N., & Schmidt-Thieme, L.
(2018).
Scalable Gaussian process- basedtransfersurrogatesforhyperparameteroptimization.
Machine Learning,108,43â€“ 78.
Report SFI-TR-95-02-010, Santa Fe Institute.
memoizer.
Communicationsofthe ACM,54(2),91â€“98.
zero flop, zero parameter alternative to spatial convolutions.
Proceedings of the IEEE Conferenceon Computer Visionand Pattern Recognition(pp.9127â€“9135).
Googleâ€™sneuralmachinetranslationsystem: bridgingthegapbetweenhumanandma- chinetranslation.
Ar Xiv:1609.08144.
Xiao, H., Rasul, K., & Vollgraf, R.
(2017).
Fashion-MNIST: a novel image dataset for benchmarkingmachinelearningalgorithms.
Ar Xiv:1708.07747.
isometryandameanfieldtheoryof CNNs: howtotrain10,000-layervanillaconvolu- tionalneuralnetworks.
International Conferenceon Machine Learning(pp.5393â€“5402).
tionsfordeepneuralnetworks.
Proceedingsofthe IEEEConferenceon Computer Vision and Pattern Recognition(pp.1492â€“1500).
malizationinthetransformerarchitecture.
International Conferenceon Machine Learn- ing(pp.10524â€“10533).
2017conversationalspeechrecognitionsystem.2018IEEEInternational Conferenceon Acoustics, Speechand Signal Processing(ICASSP)(pp.5934â€“5938).
for speaker-independent isolated word recognition.
First International Conference on Spoken Language Processing.
recurrentattentionmodeling.
Ar Xiv:1607.05108.
1110 REFERENCES (2015).
Deepfriedconvnets.
Proceedingsofthe IEEEInternational Conferenceon Com- puter Vision(pp.1476â€“1483).
laborativepoint-of-interestrecommendation.
Proceedingsofthe34th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp.
325â€“ 334).
Ar Xiv:1708.03888.
toregressivemodelsforcontent-richtext-to-imagegeneration.
Ar Xiv:2206.10789.
nonconvexoptimization.
Advancesin Neural Information Processing Systems(pp.9793â€“ 9803).
Zeiler, M.
D.,&Fergus, R.(2013).
Stochasticpoolingforregularizationofdeepconvolu- tionalneuralnetworks.
Ar Xiv:1301.3557.
fully-connectedlayerswithquaternions: parameterizationofhypercomplexmultiplica- tionswith1/nparameters.
International Conferenceon Learning Representations.
learning (still) requires rethinking generalization.
Communications of the ACM, 64(3), 107â€“115.
asurveyandnewperspectives.
ACMComputing Surveys,52(1),5.
openpre-trainedtransformerlanguagemodels.
Ar Xiv:2205.01068.
neural network and its optical architecture.
Proceedings of Annual Conference of the Japan Societyof Applied Physics.
multi-objecttrackingbyassociatingeverydetectionbox.
Ar Xiv:2110.06864.
inlargelanguagemodels.
International Conferenceon Learning Representations.
chain-of-thoughtreasoninginlanguagemodels.
Ar Xiv:2302.00923.
areview.
IEEETransactionson Neural Networksand Learning Systems,30(11),3212â€“ 3232.
to-mostpromptingenablescomplexreasoninginlargelanguagemodels.
International Conferenceon Learning Representations.
tionusingcycle-consistentadversarialnetworks.
Proceedingsofthe IEEEInternational Conferenceon Computer Vision(pp.2223â€“2232).
1111 REFERENCES (2015).
Aligning books and movies: towards story-like visual explanations by watch- ing movies and reading books.
Proceedings of the IEEE International Conference on Computer Vision(pp.19â€“27).
Ar Xiv:1611.01578.